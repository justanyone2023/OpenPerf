{"project": "kubernetes_kubernetes", "title": "kubectl create role for podsecuritypolicies fails", "description": "What happened: I followed documentation for PodSecurityPolicies from the official docs (link). It indicates that you can create a Role granting access to a PodSecurityPolicy by using the kubectl create role command. However, the example command fails: <CODE> What you expected to happen: The example command should successfully create a Role. How to reproduce it (as minimally and precisely as possible): Enable PodSecurityPolicy admission plugin.\nTry to create a Role that grants the 'use' verb to podsecuritypolicies by using the kubectl create role command. Anything else we need to know?: It works fine if I apply the Role as yaml instead: <CODE> Environment: <CODE> ", "code": ["$ kubectl create role psp:unprivileged \\\n  --verb=use \\\n  --resource=podsecuritypolicy \\\n  --resource-name=example\nerror: can not perform 'use' on 'podsecuritypolicies' in group 'policy'\n", "$ cat test.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: psp:unprivileged\nrules:\n- apiGroups: ['policy']\n  resources: ['podsecuritypolicies']\n  verbs: ['use']\n  resourceNames: ['example']\n$ kubectl apply -f test.yaml\nrole.rbac.authorization.k8s.io/psp:unprivileged created\n", "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-17T17:16:09Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-17T17:14:32Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"], "labels": ["kind/bug", "sig/cli"]}
{"project": "electron-userland_electron-builder", "title": "setFeedUrl issue", "description": "Hi everyone, I'm experiencing an issue with setFeedUrl function when I use it in the app, I get the error message saying that \"setFeedUrl is not defined\". Heres my code: <CODE> I specifically want to use setFeedUrl on the programmatic way. Even though I know there's an option of adding it in package.json. ", "code": ["app.on(\"ready\", () => {\n  const log = require(\"electron-log\")\n  log.transports.file.level = \"debug\"\n  autoUpdater.logger = log\n  autoUpdater.setFeedUrl({\n     provider: 'generic',\n     url: 'http://localhost:3002/'\n  });\n  autoUpdater.checkForUpdatesAndNotify()\n  .then(r => {\n    log.debug('r', r);\n  })\n  .catch(e => {\n    log.debug('e', e);\n  })\n});\n"], "labels": ["backlog"]}
{"project": "wenzhixin_bootstrap-table", "title": "OnclickRow \u4e8b\u4ef6\u548c editable \u884c\u4e8b\u4ef6\u51b2\u7a81\u600e\u4e48\u89e3\u51b3", "description": "Short and descriptive example bug report title A summary of the issue and the browser/OS environment in which it occurs. If suitable, include the steps required to reproduce the bug. This is the first step\nThis is the second step\nFurther steps, etc. jsfiddle - a link to the reduced test case(fiddle template). Any other information you want to share that is relevant to the issue being reported. This might include the lines of code that you have identified as causing the bug, and potential solutions (and your opinions on their merits). ", "code": [], "labels": ["help wanted"]}
{"project": "withspectrum_spectrum", "title": "Add visual indicator to v3 design that you're in local dev mode", "description": "\nNo description provided.\n ", "code": [], "labels": ["Feature"]}
{"project": "cockpit-project_cockpit", "title": "Update machine learning from test logs", "description": "Perform machine learning tasks such as retrieving new test logs and updating ", "code": [], "labels": ["bot"]}
{"project": "microsoft_vscode-cpptools", "title": "Linux launch.json errors/hangs", "description": "Type: Debugger\nInput information below Please review existing issues and our documentation at <URL> prior to filing an issue. Describe the bug To Reproduce\nPlease include a code sample and launch.json configuration.\nSteps to reproduce the behavior: Additional context\nIf applicable, please include logging by adding \"logging\": { \"engineLogging\": true, \"trace\": true, \"traceResponse\": true } in your launch.json\nAdd any other context about the problem here including log or error messages in your Debug Console or Output windows. ", "code": [], "labels": ["investigate", "debugger"]}
{"project": "cefsharp_CefSharp", "title": "FrameLoadEnd sometimes throws \"The underlying frame is no longer valid - please check the IsValid property before calling\"", "description": "The underlying frame is no longer valid - please check the IsValid property before calling!\nat CefSharp.Internals.CefFrameWrapper.ThrowIfFrameInvalid()\nat CefSharp.Internals.CefFrameWrapper.get_Url()\nat CefSharp.Internals.ClientAdapter.OnLoadEnd(ClientAdapter* , scoped_refptr* browser, scoped_refptr* frame, Int32 httpStatusCode) ", "code": [], "labels": ["bug"]}
{"project": "OpenTTD_OpenTTD", "title": "typo in about window", "description": "Yexo opened the ticket and wrote: Reported version: 0.6.0\nOperating system: All ", "code": [], "labels": ["Core", "flyspray"]}
{"project": "twbs_bootstrap", "title": "grid layout:", "description": "Before opening an issue: When asking general \"how to\" questions: When reporting a bug, include: When suggesting a feature, include: ", "code": [], "labels": ["awaiting reply"]}
{"project": "twbs_bootstrap", "title": "Support for half-column offsets", "description": "For Bootstrap 4 it would be nice to have half column offset/push support so that we can center a col-md-5 :) ", "code": [], "labels": ["css", "v4", "feature"]}
{"project": "TykTechnologies_tyk", "title": "Make `x-tyk-*` headers configurable", "description": "Do you want to request a feature or report a bug?\nFeature What is the current behavior?\nN/A What is the expected behavior?\nAs a user I should be able to configure the x-tyk-* headers or they could be optional. Which versions of Tyk affected by this issue? Did this work in previous versions of Tyk?\nAll ", "code": [], "labels": ["enhancement"]}
{"project": "glpi-project_glpi", "title": "[9.4] Private reminder also shows on the panel as a public reminder", "description": "Describe the bug Private reminder also shows on the panel as a public reminder. To reproduce Expected behavior\nThe private reminder shows only private reminders panel. Actual result\nThe private reminder shows in both panels: private and public. Screenshots    Your GLPI setup (you can find it in Setup > General menu, System tab)\nGLPI 9.4 beta ", "code": [], "labels": ["beta"]}
{"project": "prisma_prisma", "title": "Document \"Bind for 0.0.0.0:4466 failed: port is already allocated\" error + solution", "description": "When your port 4466 is occupied, and you run <CODE> You receive this error: <CODE> This is because docker-compose.yml sets up port 4466. Possible solutions: ", "code": ["prisma init test # create new database\ncd test\ndocker-compose up -d\n", "Creating postgres18_postgres_1 ...\nCreating postgres18_prisma_1   ... error\n\nCreating postgres18_postgres_1 ... done\n0bca673c801ea252c4f3c0b9fb24301cbb3a8257b75b94af1): Bind for 0.0.0.0:4466 failed: port is already allocated\n\nERROR: for prisma  Cannot start service prisma: driver failed programming external connectivity on endpoint postgres18_prisma_1 (5b37a6309c74c4a0bca673c801ea\n252c4f3c0b9fb24301cbb3a8257b75b94af1): Bind for 0.0.0.0:4466 failed: port is already allocated\nERROR: Encountered errors while bringing up the project.\n"], "labels": ["status/stale", "area/docs"]}
{"project": "ytdl-org_youtube-dl", "title": "v live download error", "description": "I tried again with an updated version with a 9 day date, but v live video is not downloaded either.\nHow do I get v live video? ", "code": [], "labels": ["duplicate"]}
{"project": "ankidroid_Anki-Android", "title": "IllegalStateException: Already attached at android.support.v4.app.FragmentManagerImpl.attachActivity", "description": "Originally reported on Google Code with ID 2083 <CODE> Reported by nicolas.raoul on 2014-04-16 12:00:18 ", "code": ["What steps will reproduce the problem?\n1. Use AnkiDroid\n2. While on review screen, lock screen\n3. Wait a few hours\n4. Unlock phone\n5. Crash\n\nHappens around 30% of the time on my phone GLS07.\nFeel free to ask me to try anything.\n\nFrom 2.2alpha25 to 2.2alpha37\nhttp://ankidroid-triage.appspot.com/view_bug?bug_id=5722183384956928\n\njava.lang.IllegalStateException: Already attached\nat android.support.v4.app.FragmentManagerImpl.attachActivity(FragmentManager.java:1878)\nat android.support.v4.app.FragmentActivity.onCreate(FragmentActivity.java:198)\nat android.support.v7.app.ActionBarActivity.onCreate(ActionBarActivity.java:97)\nat com.ichi2.anki.AnkiActivity.onCreate(AnkiActivity.java:34)\nat com.ichi2.anki.Reviewer.onCreate(Reviewer.java:924)\nat com.ichi2.anki.Reviewer$15.onPostExecute(Reviewer.java:1293)\nat com.ichi2.async.DeckTask$TaskListener.onPostExecute(DeckTask.java:1458)\nat com.ichi2.async.DeckTask.onPostExecute(DeckTask.java:364)\nat com.ichi2.async.DeckTask.onPostExecute(DeckTask.java:78)\nat android.os.AsyncTask.finish(AsyncTask.java:631)\nat android.os.AsyncTask.access$600(AsyncTask.java:177)\nat android.os.AsyncTask$InternalHandler.handleMessage(AsyncTask.java:644)\nat android.os.Handler.dispatchMessage(Handler.java:99)\nat android.os.Looper.loop(Looper.java:137)\nat android.app.ActivityThread.main(ActivityThread.java:4784)\nat java.lang.reflect.Method.invokeNative(Native Method)\nat java.lang.reflect.Method.invoke(Method.java:511)\nat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:776)\n"], "labels": ["fixed", "Bug", "Priority-High"]}
{"project": "wordpress-mobile_WordPress-iOS", "title": "Post error message wrapping on collapsed view", "description": "Mirroring wordpress-mobile/WordPress-Android#10555 Status messages should not truncate on the post list screen. Text should wrap onto the next line when necessary, regardless of the layout (compact or regular). Status messages appear truncated on the post list screen when using the compact layout. An example is the status message to be implemented in #12141, \"You've made unsaved changes to this post\". This text does not fit the available space and is truncated.  ", "code": [], "labels": ["good first issue", "[Type] Bug"]}
{"project": "mapbox_mapbox-gl-js", "title": "query-test failures: symbol/{panned,rotated}-after-insert", "description": "The following related query tests are failing: These failures need investigation and fixing. Refs mapbox/mapbox-gl-native#6627 cc @brunoabinader ", "code": [], "labels": ["bug "]}
{"project": "ant-design_ant-design", "title": "\u4e0b\u62c9\u6846\u9009\u62e9\u65f6\u82e5\u5e26\u6709span\u6807\u7b7e\uff0c\u9f20\u6807\u6ed1\u81f3\u9009\u4e2d\u9879\uff0c\u663e\u793a\u7684title\u662fobject\uff0c\u6709\u5176\u4ed6\u65b9\u5f0f\u5bf9option\u8fdb\u884c\u989c\u8272\u56de\u586b\u5417\uff1f", "description": "Fork <URL> ", "code": [], "labels": ["Feature"]}
{"project": "yarnpkg_yarn", "title": "Updating node_modules breaks transitive deps of packages installed with `link:`", "description": "Do you want to request a feature or report a bug?\nbug What is the current behavior?\nDoing a fresh install (no node_modules directory) in a package that has a dependency installed with a link: version works fine, but when the install is updating an existing node_modules directory any conflicting package versions between the two are installed into to the node_modules of the link:ed package without considering all of its dependencies. If the current behavior is a bug, please provide the steps to reproduce.\nI have created a focused reproduction of this issue here: <URL> I also have a slightly simpler reproduction but it doesn't show how this actually breaks the node_modules directory of the link:ed package, though the issue may just be that the node_modules in link:ed dependencies are touched at all. To reproduce: This seems to indicate that Yarn is attempting to install elasticsearch@^14.1.0 in the root of bar because it conflicts with it's local dependency on elasticsearch@13.0.1, but doesn't take into account the dependencies from bar that don't conflict, like chalk@^2.4.1, so it installs ansi-styles@2.2.1 from chalk@^1.0.0 at the root of bar, wiping out the existing version. What is the expected behavior? Please mention your node.js, yarn and operating system version.\nyarn 1.6.0\nnode v8.11.3\nmacOS 10.13.6 ", "code": [], "labels": ["triaged"]}
{"project": "angular_material", "title": "md-datepicker not opening on selected date when using date range attributes", "description": "Actual Behavior: CodePen (or steps to reproduce the issue): * AngularJS Versions: * Additional Information: Shortcut to create a new CodePen Demo.\nNote: * indicates required information. Without this information, your issue may be auto-closed. ", "code": [], "labels": ["resolution: duplicate"]}
{"project": "ytdl-org_youtube-dl", "title": "[Bug] Shahid.mbc.net", "description": "Add the -v flag to your command line you run youtube-dl with (youtube-dl -v <your command line>), copy the whole output and insert it here. It should look similar to one below (replace it with your log inserted between triple ```): <CODE> I test the new version and it's the same can't download any thing. But there is something i noticed when i use the normal link it gave me the error \"<URL>\" but when i use the link that i got from internet download manger which is \"<URL>\"\nit's start to download the episode. ", "code": ["[debug] System config: []\n[debug] User config: []\n[debug] Custom config: []\n[debug] Command-line args: ['-v', 'https://shahid.mbc.net/ar/series/%D9%8A%D8%BA\n%D9%85%D8%B1%D9%86%D9%8A-%D8%A7%D9%84%D8%B4%D9%88%D9%82-%D8%A7%D9%84%D9%85%D9%88\n%D8%B3%D9%85-1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-39/episode-280210']\n[debug] Encodings: locale cp1256, fs mbcs, out cp720, pref cp1256\n[debug] youtube-dl version 2017.10.12\n[debug] Python version 3.4.4 - Windows-7-6.1.7601-SP1\n[debug] exe versions: ffmpeg N-74158-gf977e69\n[debug] Proxy map: {}\n[generic] episode-280210: Requesting header\nWARNING: Falling back on generic information extractor.\n[generic] episode-280210: Downloading webpage\n[generic] episode-280210: Extracting information\nERROR: Unsupported URL: https://shahid.mbc.net/ar/series/%D9%8A%D8%BA%D9%85%D8%B\n1%D9%86%D9%8A-%D8%A7%D9%84%D8%B4%D9%88%D9%82-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%8\n5-1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-39/episode-280210\nTraceback (most recent call last):\n  File \"C:\\Users\\dst\\AppData\\Roaming\\Build archive\\youtube-dl\\rg3\\tmphdp9utoa\\bu\nild\\youtube_dl\\YoutubeDL.py\", line 784, in extract_info\n  File \"C:\\Users\\dst\\AppData\\Roaming\\Build archive\\youtube-dl\\rg3\\tmphdp9utoa\\bu\nild\\youtube_dl\\extractor\\common.py\", line 434, in extract\n  File \"C:\\Users\\dst\\AppData\\Roaming\\Build archive\\youtube-dl\\rg3\\tmphdp9utoa\\bu\nild\\youtube_dl\\extractor\\generic.py\", line 3041, in _real_extract\nyoutube_dl.utils.UnsupportedError: Unsupported URL: https://shahid.mbc.net/ar/se\nries/%D9%8A%D8%BA%D9%85%D8%B1%D9%86%D9%8A-%D8%A7%D9%84%D8%B4%D9%88%D9%82-%D8%A7%\nD9%84%D9%85%D9%88%D8%B3%D9%85-1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-39/episode-\n280210\n"], "labels": ["invalid"]}
{"project": "nestjs_nest", "title": "Cannot run Nest.js app with Node v10.15.3", "description": "<CODE> I cannot run the app anymore when having Node version set to v10.15.3. The app crashes. To run properly as it used before. git@github.com:bhaidar/nestjs-todo-app.git <CODE> ", "code": ["\n[x] Regression \n[x] Bug report\n[ ] Feature request\n[ ] Documentation issue or request\n[ ] Support request => Please do not submit support request here, instead post your question on Stack Overflow.\n", " 1: 0x10003c597 node::Abort() [/Users/bilalhaidar/.nvm/versions/node/v10.15.3/bin/node]\n 2: 0x1000bc617 node::Chdir(v8::FunctionCallbackInfo<v8::Value> const&) [/Users/bilalhaid\nar/.nvm/versions/node/v10.15.3/bin/node]\n 3: 0x10023663f v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerIn\nfo*) [/Users/bilalhaidar/.nvm/versions/node/v10.15.3/bin/node]\n 4: 0x100235b81 v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous \nnamespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::i\nnternal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handl\ne<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::in\nternal::BuiltinArguments) [/Users/bilalhaidar/.nvm/versions/node/v10.15.3/bin/node]\n 5: 0x100235220 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, \nv8::internal::Isolate*) [/Users/bilalhaidar/.nvm/versions/node/v10.15.3/bin/node]\n 6: 0x2c4e61f5be3d \n 7: 0x2c4e61f118d5 \n 8: 0x2c4e623fd038 \n[nodemon] app crashed - waiting for file changes before starting...\n```\n\n## Environment\n\n<pre><code>\nNest version: 6.2.3\n \nFor Tooling issues:\n- Node version: 10.15.3\n- Platform:  Mac and Windows\n\n</code></pre>\n"], "labels": ["needs triage"]}
{"project": "saltstack_salt", "title": "Add ability to spin up minion swarm to the test execution module", "description": "It would be nice to be able to use Salt to load-test Salt.  ^_^ ", "code": [], "labels": ["Tests", "Feature"]}
{"project": "ClickHouse_ClickHouse", "title": "Threads control", "description": "When I use different index, The Clickhouse use different number of parallel threads(streams). I can refer to the max_threads settings in clickhouse documents. but, It is only for max_threads. Is there any other ways to control thread number by different index? ", "code": [], "labels": ["question"]}
{"project": "SpaceVim_SpaceVim", "title": "runtimepath is wrong", "description": " runtimepath is wrong ", "code": [], "labels": ["help wanted"]}
{"project": "ant-design_ant-design", "title": "\u7a7f\u68ad\u6846API\u7684\"operations\"\u63cf\u8ff0\u9519\u8bef", "description": "3.11.0 <URL> operations\u7684\u8bf4\u660e\u662f\u201c\u64cd\u4f5c\u6587\u6848\u96c6\u5408\uff0c\u987a\u5e8f\u4ece\u4e0a\u81f3\u4e0b\u201d operations\u7684\u8bf4\u660e\u662f\u201c\u64cd\u4f5c\u6587\u6848\u96c6\u5408\uff0c\u987a\u5e8f\u4ece\u4e0b\u81f3\u4e0a\u201d ", "code": [], "labels": ["help wanted"]}
{"project": "rancher_rancher", "title": "Transition from Convoy-NFS to Rancher-NFS", "description": "What do we need to do to move? I have started the Rancher-NFS service but all volumes are still using Convoy-NFS. How do I make sure I don't lose any data? ", "code": [], "labels": ["area/storage", "status/autoclosed", "kind/question", "area/documentation"]}
{"project": "oppia_oppia", "title": "Specify dependencies individually for each widget", "description": "<CODE> Original issue reported on code.google.com by jacobdav...@gmail.com on 27 Mar 2014 at 3:24 ", "code": ["Currently the dependencies of a widget are specified centrally and loaded for \nall explorations, even those that do not use that widget. As the number of \nwidgets rises it would be desirable to specify dependencies individually for \neach, and then when an exploration runs only load what is necessary for the \nwidgets in it.\n\n\n"], "labels": ["auto-migrated"]}
{"project": "z-song_laravel-admin", "title": "\u521a\u767b\u5f55\u6210\u529f\uff0c\u7acb\u5373\u70b9\u7f16\u8f91\uff0c\u53c8\u8df3\u5230\u767b\u5f55\u754c\u9762\uff0c\u518d\u767b\u5f55\u53c8\u53ef\u4ee5\u7f16\u8f91\u4e86", "description": "win10\u672c\u673a\uff0cXAMPP Version: 7.2.4\u96c6\u6210\u73af\u5883\u3002\u4e4b\u524d\u4ee5\u4e3a\u662f\u81ea\u5b9a\u4e49\u4e86\u529f\u80fd\u6309\u94ae\u624d\u4f1a\u51fa\u73b0\u8fd9\u6837\u7684\u60c5\u51b5\uff0c\u60f3\u7740\u662f\u4e0d\u662f_token\u6ca1\u52a0\u9020\u6210\u7684\uff0c\u540e\u6765\u53d1\u73b0\uff0c\u81ea\u5e26\u7684\u57fa\u672c\u589e\u6539\u529f\u80fd\u90fd\u4f1a\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\u3002 1\u3001\u767b\u5f55\n2\u3001\u4efb\u610f\u9009\u62e9\u4e00\u4e2a\u680f\u76ee\uff0c\u70b9\u4efb\u610f\u67d0\u4e2a\u529f\u80fd\uff0c\u76ee\u524d\u53d1\u73b0\u6709\u7f16\u8f91\u529f\u80fd\uff0c\u65b0\u589e\u529f\u80fd\uff0c\u7136\u540e\u63d0\u793a\u672a\u767b\u5f55\n3\u3001\u767b\u5f55\u540e\uff0c\u5c31\u53ef\u4ee5\u64cd\u4f5c\u4e86\n4\u3001\u8fc7\u4e0d\u4e86\u591a\u4e45\uff0c\u8fd9\u6837\u7684\u4e8b\u60c5\u53c8\u4f1a\u53cd\u590d ", "code": [], "labels": ["wontfix"]}
{"project": "cockroachdb_cockroach", "title": "storage/closedts/provider/testutils: package failed under stress", "description": "SHA: <URL> Parameters: <CODE> To repro, try: <CODE> Failed test: <URL> <CODE> ", "code": ["TAGS=\nGOFLAGS=-race\n", "# Don't forget to check out a clean suitable branch and experiment with the\n# stress invocation until the desired results present themselves. For example,\n# using stress instead of stressrace and passing the '-p' stressflag which\n# controls concurrency.\n./scripts/gceworker.sh start && ./scripts/gceworker.sh mosh\ncd ~/go/src/github.com/cockroachdb/cockroach && \\\nstdbuf -oL -eL \\\nmake stressrace TESTS=(unknown) PKG=github.com/cockroachdb/cockroach/pkg/storage/closedts/provider/testutils TESTTIMEOUT=5m STRESSFLAGS='-maxtime 20m -timeout 10m' 2>&1 | tee /tmp/stress.log\n", "github.com/cockroachdb/cockroach/vendor/github.com/kr/pretty\ngithub.com/cockroachdb/cockroach/pkg/util/retry\ngithub.com/cockroachdb/cockroach/pkg/util/stringencoding\ngithub.com/cockroachdb/cockroach/pkg/sql/privilege\ngithub.com/cockroachdb/cockroach/pkg/util/pretty\ngithub.com/cockroachdb/cockroach/pkg/util/timeofday\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/text/internal/tag\ngithub.com/cockroachdb/cockroach/vendor/github.com/prometheus/client_golang/prometheus\ngithub.com/cockroachdb/cockroach/pkg/util/treeprinter\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/text/language\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/text/internal/colltab\ngithub.com/cockroachdb/cockroach/vendor/github.com/prometheus/client_golang/prometheus/graphite\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/text/collate\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/collectorpb\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go\ngithub.com/cockroachdb/cockroach/vendor/github.com/Shopify/sarama\ngithub.com/cockroachdb/cockroach/vendor/github.com/openzipkin-contrib/zipkin-go-opentracing\ngithub.com/cockroachdb/cockroach/pkg/util/tracing\ngithub.com/cockroachdb/cockroach/pkg/util/log\ngithub.com/cockroachdb/cockroach/pkg/util/hlc\ngithub.com/cockroachdb/cockroach/pkg/sql/pgwire/pgerror\ngithub.com/cockroachdb/cockroach/pkg/util/protoutil\ngithub.com/cockroachdb/cockroach/pkg/util/interval\ngithub.com/cockroachdb/cockroach/pkg/util/metric\ngithub.com/cockroachdb/cockroach/pkg/util/ipaddr\ngithub.com/cockroachdb/cockroach/pkg/sql/sessiondata\ngithub.com/cockroachdb/cockroach/pkg/sql/sem/types\ngithub.com/cockroachdb/cockroach/pkg/util/timeutil/pgdate\ngithub.com/cockroachdb/cockroach/pkg/storage/engine/enginepb\ngithub.com/cockroachdb/cockroach/pkg/server/telemetry\ngithub.com/cockroachdb/cockroach/pkg/sql/lex\ngithub.com/cockroachdb/cockroach/pkg/util/encoding\ngithub.com/cockroachdb/cockroach/pkg/util/cache\ngithub.com/cockroachdb/cockroach/pkg/sql/coltypes\ngithub.com/cockroachdb/cockroach/pkg/util/json\ngithub.com/cockroachdb/cockroach/pkg/roachpb\ngithub.com/cockroachdb/cockroach/pkg/util/stop\ngithub.com/cockroachdb/cockroach/pkg/settings/cluster\ngithub.com/cockroachdb/cockroach/pkg/keys\ngithub.com/cockroachdb/cockroach/pkg/security\ngithub.com/cockroachdb/cockroach/pkg/util/mon\ngithub.com/cockroachdb/cockroach/pkg/base\ngithub.com/cockroachdb/cockroach/pkg/internal/client\ngithub.com/cockroachdb/cockroach/pkg/sql/sem/tree\ngithub.com/cockroachdb/cockroach/pkg/sql/sem/transform\ngithub.com/cockroachdb/cockroach/pkg/sql/opt/cat\ngithub.com/cockroachdb/cockroach/pkg/sql/parser\ngithub.com/cockroachdb/cockroach/pkg/config\ngithub.com/cockroachdb/cockroach/pkg/sql/sqlbase\ngithub.com/cockroachdb/cockroach/pkg/sql/exec/types\ngithub.com/cockroachdb/cockroach/pkg/sql/exec/execgen/cmd/execgen\nexecgen pkg/sql/exec/any_not_null_agg.eg.go\nexecgen pkg/sql/exec/distinct.eg.go\nexecgen pkg/sql/exec/colvec.eg.go\nexecgen pkg/sql/exec/projection_ops.eg.go\nexecgen pkg/sql/exec/hashjoiner.eg.go\nexecgen pkg/sql/exec/quicksort.eg.go\nexecgen pkg/sql/exec/avg_agg.eg.go\nexecgen pkg/sql/exec/rowstovec.eg.go\nexecgen pkg/sql/exec/selection_ops.eg.go\nexecgen pkg/sql/exec/sort.eg.go\nexecgen pkg/sql/exec/sum_agg.eg.go\ngo test -race -exec 'stress -maxruns 100 -maxfails 1 -stderr -p 4' -tags ' make x86_64_pc_linux_gnu' -ldflags '-X github.com/cockroachdb/cockroach/pkg/build.typ=development -extldflags \"\" -X \"github.com/cockroachdb/cockroach/pkg/build.tag=v2.2.0-alpha.20181217-600-g0c7e491\" -X \"github.com/cockroachdb/cockroach/pkg/build.rev=0c7e491a76142a67750649facbce798442f74d25\" -X \"github.com/cockroachdb/cockroach/pkg/build.cgoTargetTriple=x86_64-pc-linux-gnu\"  ' -run \".\" -timeout 0 github.com/cockroachdb/cockroach/pkg/storage/closedts/provider/testutils  -v -args -test.timeout 40m\ngo test: race flag may be set only once\nrun \"go help test\" or \"go help testflag\" for more information\nMakefile:860: recipe for target 'stress' failed\nmake: *** [stress] Error 2\n\n"], "labels": ["O-robot", "C-test-failure"]}
{"project": "rubocop-hq_rubocop", "title": "Style/FormatStringToken false positive", "description": "I came across the following false positive while doing rspec-puppet testing on an sshd module.\nSometimes contents of a file can include valid string tokens that look like unannotated Ruby tokens.\nThese are usually wrapped inside a RegEx for testing. For example, sshd_config can include %u which is a valid username reference. The following code shouldn't be flagged as offensive: <CODE> RuboCop triggers Style/FormatStringToken error: <CODE> The snippet above triggers the described offense. <CODE> ", "code": ["it {\n  is_expected.to contain_file('/etc/ssh/sshd_config')\n    .with_content(%r{^    ChrootDirectory /var/chroot/%u$})\n}\n", "spec/classes/sshd_spec.rb:3:55: C: Style/FormatStringToken: Prefer annotated tokens (like %<foo>s) over unannotated tokens (like %s).\n    .with_content(%r{^    ChrootDirectory /var/chroot/%u$})\n                                                      ^^\n", "$ rubocop -V\n0.52.0\n"], "labels": ["bug"]}
{"project": "apache_incubator-echarts", "title": "Android\u4e0b\u997c\u56fe\u4f1a\u51fa\u73b0\u753b\u4e0d\u5168\u7684\u73b0\u8c61", "description": "3.8.5 \u4f7f\u7528\u6846\u67b6\u662fng7 \u997c\u56fe\u6b63\u5e38\u5c55\u793a \u997c\u56fe\u7ecf\u5e38\u6027\u51fa\u73b0\u7ed8\u5236\u4e0d\u5168\u7684\u95ee\u9898 \n\u5176\u4e2dcanvas\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u662f\u591f\u7684 ", "code": [], "labels": ["pending", "mobile", "bug"]}
{"project": "golang_go", "title": "cmd/6l: No .debug_gdb_script section in ELF", "description": "by erik.westrup: <CODE> ", "code": ["The resulting ELF produced does not contain a \".debug_gdb_script\" section.\nThus no Go runtime support for Go is loaded when running the ELF in GDB.\n\n\n> What does 'go version' print?\n\ngo version devel +e3ff5d42017d Mon Mar 10 07:57:58 2014 +0100 linux/amd64\n\n> What steps reproduce the problem?\n1. $ hg clone -u release https://code.google.com/p/go\n   $ cd go\n   $ hg update default\n   $ src/all.bash\n2. $ go build hello.go\n3. $ readelf -S hello | grep -c debug_gdb_script\n   0\n\n> What happened?\nNo debug gdb script path included.\n\n> What should have happened instead?\n$ readelf -S hello | grep -c debug_gdb_script\n1\nwhich happens on the release-branch.go1.2 branch.\n\n\n> Please provide any additional information below.\nHas the way of loading the debug_gdb_script changed intentionally?"], "labels": ["FrozenDueToAge", "fixed"]}
{"project": "Kunena_Kunena-Forum", "title": "SEO: Wrong Rel Canonical href", "description": "To Reproduce Expected behavior\nRel canonical should be: /forum/HTTP-500-Internal-Server-Error Actual result\nRel canonical is: /forum/HTTP-500-Internal-Server-Error?us=search System information (please complete the following information)\nJoomla version: 3.9.6\nKunena version: 5.1.12.1\nPhp version: 7.3.5\nDatabase version: MySQL 5.7.26 ", "code": [], "labels": ["no-issue-activity"]}
{"project": "kubernetes_kubernetes", "title": "NFS Example: Challenged executing scripts|binaries stored on shared volumes", "description": "/kind bug\n@kubernetes/sig-storage-bug What happened: I'm using the NFS volume backed by PD SSD to share read-write volumes across multiple nodes. This appeared to  have been working (and still does for executale) files but, on shared volumes, I'm able to reliably kill a shell by attempting to execute a script and receive \"file not found errors\". What you expected to happen: I expect to be able to create executable files on volumes shared read-write by the NFS volume, execute these and not crash. I've tried both PD Standard and SSD. I've tried different container OSs (Debian, Ubuntu, Alpine) but the behavior is consistent and repro's. How to reproduce it (as minimally and precisely as possible): PV: <CODE> PVC: <CODE> Shell into a debug container: <CODE> and: <CODE> The shell will hang attempting to run the script from the /shared directory. This also fails attempting to run binaries that are copied to (and even from!) the volume or downloaded to it. Anything else we need to know?: Attempting to run binaries is curious. I receive \"file not found\" errors for files that demonstrably exist: <CODE> The binaries are the correct size.\nI tried chown'ing the binaries to root:root for want of another idea and that made no difference. Environment: Debian, Ubuntu, Alpine container images all appear to fail consistently <CODE> ", "code": ["kind: PersistentVolume\napiVersion: v1\nmetadata:\n  name: shared-pv\n  labels:\n    component: volume\nspec:\n  capacity:\n    storage: 1Gi\n  accessModes:\n    - ReadWriteMany\n  nfs:\n    server: nfs.imkm.svc.cluster.local\n    path: \"/\"\n", "kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: shared-pvc\n  labels:\n    component: claim\nspec:\n  accessModes:\n    - ReadWriteMany\n  storageClassName: \"\"\n  resources:\n    requests:\n      storage: 1Gi\n  volumeName: shared-pv\n", "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    component: debug\n  name: debug-cfd5489df-rjvmp\n  namespace: imkm\nspec:\n  containers:\n  - command:\n    - sh\n    - -c\n    - |\n      while true; do\n        sleep 15s\n      done\n    image: alpine\n    imagePullPolicy: IfNotPresent\n    name: debug\n    volumeMounts:\n    - mountPath: /shared\n      name: shared-pvc\n  volumes:\n  - name: shared-pvc\n    persistentVolumeClaim:\n      claimName: shared-pvc\n", "/ # echo \"echo Hello Henry!\" > /tmp/test.sh\n/ # echo \"echo Hello Henry!\" > /shared/test.sh\n\n/ # more /tmp/test.sh\necho Hello Henry!\n/ # more /shared/test.sh\necho Hello Henry!\n\n/ # chmod +x /tmp/test.sh\n/ # chmod +x /shared/test.sh\n\n/ # /tmp/test.sh\nHello Henry!\n/ # /shared/test.sh\n", "/shared/bin # ls -l\n-rwxrwxr-x    1 1001     1001      23653336 Mar 15 22:13 configtxgen\n-rwxrwxr-x    1 1001     1001      12473976 Mar 15 22:13 cryptogen\n-rwxrwxr-x    1 1001     1001      31536304 Mar 15 22:14 orderer\n-rwxrwxr-x    1 1001     1001      39016824 Mar 15 22:14 peer\n\n/shared/bin # ./configtxgen\nash: ./configtxgen: not found\n\n/shared/bin # ./peer\nash: ./peer: not found\n\n/shared/bin # cp peer /tmp\n/shared/bin # cd /tmp\n/tmp # ./peer\nash: ./peer: not found\n", "kubectl version\nClient Version: version.Info{Major:\"1\", Minor:\"10\", GitVersion:\"v1.10.5\", GitCommit:\"32ac1c9073b132b8ba18aa830f46b77dcceb0723\", GitTreeState:\"clean\", BuildDate:\"2018-06-21T11:46:00Z\", GoVersion:\"go1.9.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"10+\", GitVersion:\"v1.10.5-gke.0\", GitCommit:\"f4c74e18e57148052c59cc0467bb7e99dcc46399\", GitTreeState:\"clean\", BuildDate:\"2018-06-21T14:11:26Z\", GoVersion:\"go1.9.3b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"], "labels": ["kind/bug", "needs-sig"]}
{"project": "firefly-iii_firefly-iii", "title": "Rules: \"After updating, return here\" - empty trigger/actions fields", "description": "is it a bug or works as designed? ", "code": [], "labels": ["bug", "fixed"]}
{"project": "timgrossmann_InstaPy", "title": "Follow user followers stuck on an user & Grabbed 0 usernames from XXXX followers (Updated code)", "description": "Hello, I want the bot to follow the user followers and not get stuck on an user, the code was updated on 18/01/2019 and I tried e07aa4a It is having issues such as and when it get an user that doesn't match the minimum requirements it keeps trying to follow it, such as Get a list of the users that the bot is already following and session.set_ignore_users(Following_list) or something like that ", "code": [], "labels": ["wontfix"]}
{"project": "pytest-dev_pytest", "title": "Fix typo in word 'vulnerability' on homepage", "description": "The Security section of the home page (latest docs) contains a typo in the word vunerability vulnerability, which is also present in the README. Opening a PR to address this momentarily. ", "code": [], "labels": ["type: docs"]}
{"project": "bokeh_bokeh", "title": "There is a gap between rectangles", "description": "There are small gaps between rendered rectangles even when every effort is made to remove the border. It's not the border of the rectangle there is actually a gap between them! Most obvious when done using this script  <URL> on the attached image at the bottom. Also included are images of the gaps. Problem is present in safari/chrome/firefox , IE untested. \n\n ", "code": [], "labels": ["type: discussion"]}
{"project": "nylas_nylas-mail", "title": "Z key undoes last command and snoozes.", "description": "Running latest version of El Capitan on Macbook pro and N1 Version 0.4.45-7637265 (0.4.45-7637265) (the latest I'm . Have reset shortcuts to Gmail defaults. Haven't created or edited any custom shortcuts. Any thoughts? ... ... ... Bug? ... ... ... Feature Request? ... ", "code": [], "labels": ["bug"]}
{"project": "hashicorp_terraform", "title": "upgrade to terraform 0.9.0 - use legacy remote state", "description": "Hi there, Thank you for opening an issue. Please note that we try to keep the Terraform issue tracker reserved for bug reports and feature requests. For general usage questions, please see: <URL> 0.9.0 Please list the resources as a list, for example: Upgrade exist stack from 0.8.8 to 0.9.0 <CODE> <CODE> This part has been updated to 0.9.0 <CODE> But still have the session of remote. If compare with a total new stack created by terraform 0.9.0, there is no remote session any more. terraform apply is successful, no error, only warning How to get the old state file converted to 0.9.0 properly? State file gets version updates, but still with old format. Detail in Debug Output <CODE> ", "code": ["Successfully configured the backend \"s3\"! Terraform will automatically\nuse this backend unless the backend configuration changes.\n\nTerraform has been successfully initialized!\n", "Deprecation warning: This environment is configured to use legacy remote state.\nRemote state changed significantly in Terraform 0.9. Please update your remote\nstate configuration to use the new 'backend' settings. For now, Terraform\nwill continue to use your existing settings. Legacy remote state support\nwill be removed in Terraform 0.11.\n\nYou can find a guide for upgrading here:\n\nhttps://www.terraform.io/docs/backends/legacy-0-8.html\n", "\"terraform_version\": \"0.9.0\",\n", "TERRAFORM_CMD=\"docker run --rm -w /app -v $(pwd):/app hashicorp/terraform:0.9.0\"\n$TERRAFORM_CMD init\n"], "labels": ["waiting-response", "bug", "core"]}
{"project": "ampproject_amphtml", "title": "Investigate running of realWin(amp) tests in shadow and non-shadow modes", "description": "We could try to run describes.realWin({amp: true}) tests in two modes: ", "code": [], "labels": ["P3: When Possible", "WG: infra", "Type: Feature Request"]}
{"project": "borgbackup_borg", "title": "Improve documentation for --keep-exclude-tags", "description": "The current documentation for the --keep-exclude-tags option consists of this one \"sentence\" in the Usage section of the documentation: This leaves a lot to be understood (I had to read through the source to figure out what it actually does).  Perhaps a bit more detail on this option should be included in the documentation (along with --exclude-if-present) in the Description section. ", "code": [], "labels": ["documentation"]}
{"project": "CachetHQ_Cachet", "title": "Error Running Composer Commands", "description": "When trying to run composer install -o command following the recent dependency update 02fe8d1, the following error is thrown in the console: <CODE>  ", "code": ["[ErrorException]\nUndefined index: hash\n"], "labels": ["question"]}
{"project": "aspnetboilerplate_aspnetboilerplate", "title": "could not proxy Abp.WebApi.Controllers.Dynamic.DynamicApiController", "description": "Can't create component 'TEAA.FrontEnd.NewsAppService' as it has dependencies to be satisfied.\\r\\n\\r\\n'TEAA.FrontEnd.NewsAppService' is waiting for the following dependencies:\\r\\n- Service 'Abp.Domain.Repositories.IRepository`1[[TEAA.FrontEnd.NewsMedia, TEAA.Core, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null]]' which was not registered i get this issue when i publish the website to iis, it's working fine when running from Visual Studio.\nFollowing are the service class and the two involved entities ", "code": [], "labels": ["question"]}
{"project": "ValveSoftware_steam-for-linux", "title": "Steam Controller: right bumper button, when click moves cursor up forever", "description": "so is all working great, and even in some games with out any change on my part, but on \"big screen\" and \"some\" games, when I press the right bumper button, I believe is the left click by default, acts like if my mouse were scrolling up, non-stop until I stop steam and turn off the controller..\nI did notice that if I \"disable\" the analog option then seems to work on all games.. on big picture I cant disable this option since there is no way to change defaults from big screen yet.. STILL even if I could this is clearly a bug, I want my controller to work, if not im going to have to return it. I spoke with support and they told me to post the issue here since Im not using Ubuntu, my system is Manjaro GNU/Linux using KDE, nvidia card, etc.  Any ideas? anyone else having this problem? ", "code": [], "labels": ["reviewed"]}
{"project": "sebastianbergmann_phpunit", "title": "Optionally mark a test as risky when an unconfigured method is called on a test double", "description": "This could be implemented by (optionally) throwing an exception when an unconfigured method call is detected in  ", "code": [], "labels": ["enhancement"]}
{"project": "BuildCraft_BuildCraft", "title": "Stripes Transport pipe cannot place blocks.", "description": "Stripes Transport pipe cannot place blocks.\n ", "code": [], "labels": ["type: bug"]}
{"project": "Semantic-Org_Semantic-UI", "title": "input .error  dont work correct inside .ui.form", "description": "<URL> when i try to use input with class error  inside element with class .ui.form\ninput has no red background or border ", "code": [], "labels": ["Question"]}
{"project": "helm_helm", "title": "Incorrect/missing hooks run on rollback", "description": "When doing a helm rollback from version 2 of a chart to version 1, the rollback hooks from version 1 are run, not the ones from version 2. I think this is the wrong behaviour. The problem is if there's an upgrade hook in version 2 that does something that would need to be undone on a rollback, there's no place in the lifecycle to do that. It would make sense to put the undo in the rollback hook for version 2, i.e. do this if you have to rollback from this version to a previous one. It can't be done in the version 1 rollback hooks as when version 1 was installed it wouldn't have been known that this thing would be done in the version 2 upgrade. The upgrade/delete hooks aren't run on a rollback either and wouldn't be the place to put the undo anyway. Tested against minikube on Mac. <CODE> ", "code": ["Client: &version.Version{SemVer:\"v2.8.1\", GitCommit:\"6af75a8fd72e2aa18a2b278cfe5c7a1c5feca7f2\", GitTreeState:\"clean\"}\nServer: &version.Version{SemVer:\"v2.8.1\", GitCommit:\"6af75a8fd72e2aa18a2b278cfe5c7a1c5feca7f2\", GitTreeState:\"clean\"}\n"], "labels": ["question/support"]}
{"project": "NervJS_taro", "title": "\u6709\u652f\u6301react-hook\u7684\u65f6\u95f4\u8868\u561b", "description": "\u5982\u679c\u662f\u63d0\u4ea4 bug\uff0c\u8bf7\u641c\u7d22\u6587\u6863\u548c issue\uff0c\u786e\u8ba4\u4ee5\u4e0b\u4e8b\u9879\uff1a \u5982\u679c\u4e0d\u6ee1\u8db3\u4ee5\u4e0a\u4e24\u70b9\u8981\u6c42\u7684 bug \u62a5\u544a\uff0cissue \u4f1a\u88ab\u76f4\u63a5\u5173\u6389\u3002 \u8bf7\u591a\u591a\u7406\u89e3\uff0c\u60a8\u73b0\u5728\u7684\u4e0d\u4fbf\u5c06\u4f1a\u4f7f Taro \u5f00\u53d1\u8005\u66f4\u9ad8\u6548\u5730\u5b9a\u4f4d\u4f60\u7684\u95ee\u9898\uff0c\u4fee\u590d\u4f60\u7684\u95ee\u9898\u3002\u50cf\u4f60\u4e00\u6837\u7684 Taro \u7684\u4f7f\u7528\u8005\u4e5f\u53ef\u4ee5\u901a\u8fc7\u641c\u7d22\u627e\u5230\u4f60\u63d0\u4f9b\u7684 bug\uff0c\u5bf9\u5404\u65b9\u90fd\u6709\u5f88\u5927\u597d\u5904\u3002 \u95ee\u9898\u63cf\u8ff0\n[\u95ee\u9898\u63cf\u8ff0\uff1a\u7ad9\u5728\u5176\u5b83\u4eba\u7684\u89d2\u5ea6\u5c3d\u53ef\u80fd\u6e05\u6670\u5730\u3001\u7b80\u6d01\u5730\u628a\u95ee\u9898\u63cf\u8ff0\u6e05\u695a] \u590d\u73b0\u6b65\u9aa4\n[\u590d\u73b0\u95ee\u9898\u7684\u6b65\u9aa4] [\u6216\u8005\u53ef\u4ee5\u76f4\u63a5\u8d34\u6e90\u4ee3\u7801\uff0c\u80fd\u8d34\u6587\u5b57\u5c31\u4e0d\u8981\u622a\u56fe] \u671f\u671b\u884c\u4e3a\n[\u8fd9\u91cc\u8bf7\u7528\u7b80\u6d01\u6e05\u6670\u7684\u8bed\u8a00\u63cf\u8ff0\u4f60\u671f\u671b\u7684\u884c\u4e3a] \u62a5\u9519\u4fe1\u606f [\u8fd9\u91cc\u8bf7\u8d34\u4e0a\u4f60\u7684\u5b8c\u6574\u62a5\u9519\u622a\u56fe\u6216\u6587\u5b57] \u7cfb\u7edf\u4fe1\u606f \u8865\u5145\u4fe1\u606f\n[\u53ef\u9009]\n[\u6839\u636e\u4f60\u7684\u8c03\u67e5\u7814\u7a76\uff0c\u51fa\u73b0\u8fd9\u4e2a\u95ee\u9898\u7684\u539f\u56e0\u53ef\u80fd\u5728\u54ea\u91cc\uff1f] ", "code": [], "labels": ["answered", "question"]}
{"project": "microsoft_TypeScript", "title": "Error TS7006 when the compiler can actually imply the expected type?", "description": "TypeScript Version:  2.1.1 / 2.1-rc Summary\nWhile trying version 2.1-rc on an AngularJS v1.4 application, I've stumbled on a compiler error (TS7006) that doesn't happen on previous versions (ie: 2.0.6). The interface in question (IQService) defines types for a callback, and so the compiler used to imply such types when the interface was used. Now, it complains that the parameters for the callback have any as an implicit type. Code Expected behavior (ts 2.0.6):\n Actual behavior (ts 2.1.1):\n ", "code": [], "labels": ["External"]}
{"project": "Jackett_Jackett", "title": "certificate validation failed exception for every indexers", "description": "Hi there, I have an issue regarding the indexers. I can add an indexer and when I add it, the test check mark is green but I can't use it. As soon as I click on the test button, the test fail and I get an exception (see below). I tried running jackett with the --IgnoreSslErrors option but it does nothing different. I also tried follow these instructions to add root authorities certificate to mono #1245 but still doesn't work. <CODE> Any idea how to fix this? Thanks, ", "code": ["12-05 11:46:35 Error Jackett.Common.IndexerException: Exception (kickasstorrent): certificate validation failed: [Subject]\n  CN=*.katcr.co, OU=EssentialSSL Wildcard, OU=Domain Control Validated\n\n[Issuer]\n  CN=Sectigo RSA Domain Validation Secure Server CA, O=Sectigo Limited, L=Salford, S=Greater Manchester, C=GB\n\n[Serial Number]\n  25F24BC2767EE7B610D14D88EB6398AA\n\n[Not Before]\n  11/20/2019 7:00:00 PM\n\n[Not After]\n  11/20/2020 6:59:59 PM\n\n[Thumbprint]\n  52C8AD968ECD9285BF6DA760D1F5906C79C7CC7B\n\n ---> System.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception.\n ---> System.Exception: certificate validation failed: [Subject]\n  CN=*.katcr.co, OU=EssentialSSL Wildcard, OU=Domain Control Validated\n\n[Issuer]\n  CN=Sectigo RSA Domain Validation Secure Server CA, O=Sectigo Limited, L=Salford, S=Greater Manchester, C=GB\n\n[Serial Number]\n  25F24BC2767EE7B610D14D88EB6398AA\n\n[Not Before]\n  11/20/2019 7:00:00 PM\n\n[Not After]\n  11/20/2020 6:59:59 PM\n\n[Thumbprint]\n  52C8AD968ECD9285BF6DA760D1F5906C79C7CC7B\n\n   at Jackett.Common.Utils.Clients.HttpWebClient2NetCore.ValidateCertificate(HttpRequestMessage request, X509Certificate2 certificate, X509Chain chain, SslPolicyErrors sslPolicyErrors) in /home/appveyor/projects/jackett/src/Jackett.Common/Utils/Clients/HttpWebClient2NetCore.cs:line 55\n   at System.Net.Http.ConnectHelper.<>c__DisplayClass3_0.<EstablishSslConnectionAsync>b__0(Object sender, X509Certificate certificate, X509Chain chain, SslPolicyErrors sslPolicyErrors)\n   at System.Net.Security.SslStream.UserCertValidationCallbackWrapper(String hostName, X509Certificate2 certificate, X509Chain chain, SslPolicyErrors sslPolicyErrors)\n   at System.Net.Security.SecureChannel.VerifyRemoteCertificate(RemoteCertValidationCallback remoteCertValidationCallback, ProtocolToken& alertToken)\n   at System.Net.Security.SslStream.CompleteHandshake(ProtocolToken& alertToken)\n   at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReceiveBlob(Byte[] buffer, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReceiveBlob(Byte[] buffer, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.PartialFrameCallback(AsyncProtocolRequest asyncRequest)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Net.Security.SslStream.ThrowIfExceptional()\n   at System.Net.Security.SslStream.InternalEndProcessAuthentication(LazyAsyncResult lazyResult)\n   at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n   at System.Net.Security.SslStream.EndAuthenticateAsClient(IAsyncResult asyncResult)\n   at System.Net.Security.SslStream.<>c.<AuthenticateAsClientAsync>b__65_1(IAsyncResult iar)\n   at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n   --- End of inner exception stack trace ---\n   at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.ConnectAsync(HttpRequestMessage request, Boolean allowHttp2, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.CreateHttp11ConnectionAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.GetHttpConnectionAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.SendWithRetryAsync(HttpRequestMessage request, Boolean doRequestAuth, CancellationToken cancellationToken)\n   at System.Net.Http.DecompressionHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.DiagnosticsHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at CloudflareSolverRe.ClearanceHandler.SendRequestAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at CloudflareSolverRe.ClearanceHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpClient.FinishSendAsyncBuffered(Task`1 sendTask, HttpRequestMessage request, CancellationTokenSource cts, Boolean disposeCts)\n   at Jackett.Common.Utils.Clients.HttpWebClient2NetCore.Run(WebRequest webRequest) in /home/appveyor/projects/jackett/src/Jackett.Common/Utils/Clients/HttpWebClient2NetCore.cs:line 241\n   at Jackett.Common.Utils.Clients.WebClient.GetString(WebRequest request) in /home/appveyor/projects/jackett/src/Jackett.Common/Utils/Clients/WebClient.cs:line 114\n   at Jackett.Common.Indexers.BaseWebIndexer.RequestStringWithCookies(String url, String cookieOverride, String referer, Dictionary`2 headers) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 445\n   at Jackett.Common.Indexers.CardigannIndexer.PerformQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/CardigannIndexer.cs:line 1238\n   at Jackett.Common.Indexers.BaseIndexer.ResultsForQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 331\n   --- End of inner exception stack trace ---\n   at Jackett.Common.Indexers.BaseIndexer.ResultsForQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 351\n   at Jackett.Common.Indexers.BaseWebIndexer.ResultsForQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 815\n   at Jackett.Common.Services.IndexerManagerService.TestIndexer(String name) in /home/appveyor/projects/jackett/src/Jackett.Common/Services/IndexerManagerService.cs:line 222\n   at Jackett.Server.Controllers.IndexerApiController.Test() in /home/appveyor/projects/jackett/src/Jackett.Server/Controllers/IndexerApiController.cs:line 129\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.TaskOfIActionResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Awaited|12_0(ControllerActionInvoker invoker, ValueTask`1 actionResultValueTask)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeInnerFilterAsync>g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Awaited|17_0(ResourceInvoker invoker, Task task, IDisposable scope)\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\n   at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware.Invoke(HttpContext context)\n   at Jackett.Server.Middleware.CustomExceptionHandler.Invoke(HttpContext httpContext) in /home/appveyor/projects/jackett/src/Jackett.Server/Middleware/CustomExceptionHandler.cs:line 29 Jackett.Common.IndexerException: Exception (kickasstorrent): certificate validation failed: [Subject]\n  CN=*.katcr.co, OU=EssentialSSL Wildcard, OU=Domain Control Validated\n\n[Issuer]\n  CN=Sectigo RSA Domain Validation Secure Server CA, O=Sectigo Limited, L=Salford, S=Greater Manchester, C=GB\n\n[Serial Number]\n  25F24BC2767EE7B610D14D88EB6398AA\n\n[Not Before]\n  11/20/2019 7:00:00 PM\n\n[Not After]\n  11/20/2020 6:59:59 PM\n\n[Thumbprint]\n  52C8AD968ECD9285BF6DA760D1F5906C79C7CC7B\n\n ---> System.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception.\n ---> System.Exception: certificate validation failed: [Subject]\n  CN=*.katcr.co, OU=EssentialSSL Wildcard, OU=Domain Control Validated\n\n[Issuer]\n  CN=Sectigo RSA Domain Validation Secure Server CA, O=Sectigo Limited, L=Salford, S=Greater Manchester, C=GB\n\n[Serial Number]\n  25F24BC2767EE7B610D14D88EB6398AA\n\n[Not Before]\n  11/20/2019 7:00:00 PM\n\n[Not After]\n  11/20/2020 6:59:59 PM\n\n[Thumbprint]\n  52C8AD968ECD9285BF6DA760D1F5906C79C7CC7B\n\n   at Jackett.Common.Utils.Clients.HttpWebClient2NetCore.ValidateCertificate(HttpRequestMessage request, X509Certificate2 certificate, X509Chain chain, SslPolicyErrors sslPolicyErrors) in /home/appveyor/projects/jackett/src/Jackett.Common/Utils/Clients/HttpWebClient2NetCore.cs:line 55\n   at System.Net.Http.ConnectHelper.<>c__DisplayClass3_0.<EstablishSslConnectionAsync>b__0(Object sender, X509Certificate certificate, X509Chain chain, SslPolicyErrors sslPolicyErrors)\n   at System.Net.Security.SslStream.UserCertValidationCallbackWrapper(String hostName, X509Certificate2 certificate, X509Chain chain, SslPolicyErrors sslPolicyErrors)\n   at System.Net.Security.SecureChannel.VerifyRemoteCertificate(RemoteCertValidationCallback remoteCertValidationCallback, ProtocolToken& alertToken)\n   at System.Net.Security.SslStream.CompleteHandshake(ProtocolToken& alertToken)\n   at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReceiveBlob(Byte[] buffer, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReceiveBlob(Byte[] buffer, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.CheckCompletionBeforeNextReceive(ProtocolToken message, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartSendBlob(Byte[] incoming, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.ProcessReceivedBlob(Byte[] buffer, Int32 count, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.StartReadFrame(Byte[] buffer, Int32 readBytes, AsyncProtocolRequest asyncRequest)\n   at System.Net.Security.SslStream.PartialFrameCallback(AsyncProtocolRequest asyncRequest)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Net.Security.SslStream.ThrowIfExceptional()\n   at System.Net.Security.SslStream.InternalEndProcessAuthentication(LazyAsyncResult lazyResult)\n   at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n   at System.Net.Security.SslStream.EndAuthenticateAsClient(IAsyncResult asyncResult)\n   at System.Net.Security.SslStream.<>c.<AuthenticateAsClientAsync>b__65_1(IAsyncResult iar)\n   at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n   --- End of inner exception stack trace ---\n   at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.ConnectAsync(HttpRequestMessage request, Boolean allowHttp2, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.CreateHttp11ConnectionAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.GetHttpConnectionAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpConnectionPool.SendWithRetryAsync(HttpRequestMessage request, Boolean doRequestAuth, CancellationToken cancellationToken)\n   at System.Net.Http.DecompressionHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.DiagnosticsHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at CloudflareSolverRe.ClearanceHandler.SendRequestAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at CloudflareSolverRe.ClearanceHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpClient.FinishSendAsyncBuffered(Task`1 sendTask, HttpRequestMessage request, CancellationTokenSource cts, Boolean disposeCts)\n   at Jackett.Common.Utils.Clients.HttpWebClient2NetCore.Run(WebRequest webRequest) in /home/appveyor/projects/jackett/src/Jackett.Common/Utils/Clients/HttpWebClient2NetCore.cs:line 241\n   at Jackett.Common.Utils.Clients.WebClient.GetString(WebRequest request) in /home/appveyor/projects/jackett/src/Jackett.Common/Utils/Clients/WebClient.cs:line 114\n   at Jackett.Common.Indexers.BaseWebIndexer.RequestStringWithCookies(String url, String cookieOverride, String referer, Dictionary`2 headers) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 445\n   at Jackett.Common.Indexers.CardigannIndexer.PerformQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/CardigannIndexer.cs:line 1238\n   at Jackett.Common.Indexers.BaseIndexer.ResultsForQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 331\n   --- End of inner exception stack trace ---\n   at Jackett.Common.Indexers.BaseIndexer.ResultsForQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 351\n   at Jackett.Common.Indexers.BaseWebIndexer.ResultsForQuery(TorznabQuery query) in /home/appveyor/projects/jackett/src/Jackett.Common/Indexers/BaseIndexer.cs:line 815\n   at Jackett.Common.Services.IndexerManagerService.TestIndexer(String name) in /home/appveyor/projects/jackett/src/Jackett.Common/Services/IndexerManagerService.cs:line 222\n   at Jackett.Server.Controllers.IndexerApiController.Test() in /home/appveyor/projects/jackett/src/Jackett.Server/Controllers/IndexerApiController.cs:line 129\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.TaskOfIActionResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Awaited|12_0(ControllerActionInvoker invoker, ValueTask`1 actionResultValueTask)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeInnerFilterAsync>g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Awaited|17_0(ResourceInvoker invoker, Task task, IDisposable scope)\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\n   at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware.Invoke(HttpContext context)\n   at Jackett.Server.Middleware.CustomExceptionHandler.Invoke(HttpContext httpContext) in /home/appveyor/projects/jackett/src/Jackett.Server/Middleware/CustomExceptionHandler.cs:line 29\n"], "labels": ["Help wanted"]}
{"project": "framework7io_framework7", "title": "dropdownContainerEl in Autocomplete (F7 v2.2.5)", "description": "Hi all, i am trying to create an autocomplete with app.autocomplete.create() and realized that the option dropdownContainerEl cant be used because it is empty in framework7.js For some reason when i try to create my autocomplete dropdown, its position is wrong (check image below). It should be aligned to left of my input box.  So, i would appreciate to use the dropdownContainerEl param to put my autocomplete inside a container of my choice because it is always appended to element .page-content ", "code": [], "labels": ["outdated"]}
{"project": "jersey_jersey", "title": "Error determining paths", "description": "I have found a bug in Jersey 1.2 and 1.1.5 regarding the selecting of the\ncorrect path when a static path and dynamic path are used with POST and GET\nannotations. I have added sample java code that highlights the issue. The issue\narises when you have two methods, one annotated with @post the other with @get.\nThe @post method has a static path, @path( \"/test\" ), the @get method has a\ndynamic path,\n@path( \"/ {testpath} \" ). When the @get method has the same path as the static\n@post method's path, the Jersey runtime does not determine the correct path to\nuse. See code below for reproducible scenario. import javax.ws.rs.Consumes;\nimport javax.ws.rs.GET;\nimport javax.ws.rs.POST;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.PathParam;\nimport javax.ws.rs.Produces;\nimport javax.ws.rs.core.MediaType; @path( \"/Test\" )\n@Consumes( \"/\" )\n@Produces( \"/\" )\npublic class ReproTerminatingRuleAcceptError\n{\npublic ReproTerminatingRuleAcceptError()\n{} @get\n@path( \"/\" )\n@Produces( MediaType.TEXT_PLAIN )\npublic String testcase1() { return \"root path segment\"; } /** @post\n@path( \"testreport\" )\n@Produces( MediaType.TEXT_PLAIN)\npublic String testcase3() { return \"testcase3 via POST.\"; } /* Operating System: All\nPlatform: All [1.2] ", "code": [], "labels": ["ERR: Assignee", "Priority: Major", "Type: Bug", "Component: core"]}
{"project": "RasaHQ_rasa", "title": "Unable to install rasa", "description": "Rasa X version (if used & relevant): Python version: python 3.5.2 Operating system (windows, osx, ...): Ubuntu 16.04 Issue: Unable to install rasa in my system Error (including full traceback): <CODE> Command or request that led to error: <CODE> ", "code": ["Collecting aiohttp~=3.5 (from rasa)\n  ERROR: Could not find a version that satisfies the requirement aiohttp~=3.5 (from rasa) (from versions: 0.1, 0.2, 0.3, 0.4, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.5.0, 0.6.0, 0.6.1, 0.6.2, 0.6.3, 0.6.4, 0.6.5, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.8.4, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.10.0, 0.10.1, 0.10.2, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.14.2, 0.14.3, 0.14.4, 0.15.0, 0.15.1, 0.15.2, 0.15.3, 0.16.0, 0.16.1, 0.16.2, 0.16.3, 0.16.4, 0.16.5, 0.16.6, 0.17.0, 0.17.1, 0.17.2, 0.17.3, 0.17.4, 0.18.0, 0.18.1, 0.18.2, 0.18.3, 0.18.4, 0.19.0, 0.20.0, 0.20.1, 0.20.2, 0.21.0, 0.21.1, 0.21.2, 0.21.4, 0.21.5, 0.21.6, 0.22.0a0, 0.22.0b0, 0.22.0b1, 0.22.0b2, 0.22.0b3, 0.22.0b4, 0.22.0b5, 0.22.0b6, 0.22.0, 0.22.1, 0.22.2, 0.22.3, 0.22.4, 0.22.5, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.5, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.1.6, 1.2.0, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 2.0.0rc1, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.6.post1, 2.0.7, 2.1.0, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.3.0a1, 2.3.0a2, 2.3.0a4, 2.3.0, 2.3.1a1, 2.3.1, 2.3.2b2, 2.3.2b3, 2.3.2, 2.3.3, 2.3.4, 2.3.5, 2.3.6, 2.3.7, 2.3.8, 2.3.9, 2.3.10, 3.0.0b0)\nERROR: No matching distribution found for aiohttp~=3.5 (from rasa)\n", "pip3 install rasa-x --extra-index-url https://pypi.rasa.com/simple\n"], "labels": ["bug"]}
{"project": "knative_serving", "title": "Need to upgrade cert-manager to newer version", "description": "/area networking Currently our Auto TLS feature is using cert-manager 0.6.1.\nThis version is a bit old and will be blocked by LetsEncrypt by 11/01/2019 because it could potentially send excessive traffic to LetsEncrypt. We should upgrade our cert-manager version to 0.8.1 or above. Probably we should try v0.9.1. ", "code": [], "labels": ["area/networking", "kind/feature"]}
{"project": "hypothesis_h", "title": "SSLv3 problem", "description": "When trying to launch latest master on my system, I get this: <CODE> I guess it's because of the POODLE thingie ... Can we adapt gunicorn / gevent? (Or has it already been done, and we just need to pick up newer dependencies?) ", "code": ["Error: class uri 'gevent' invalid or not found: \n\n[Traceback (most recent call last):\n  File \"<whatever>/h/local/lib/python2.7/site-packages/gunicorn/util.py\", line 139, in load_class\n    mod = import_module('.'.join(components))\n  File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\n  File \"<whatever>/h/local/lib/python2.7/site-packages/gunicorn/workers/ggevent.py\", line 24, in <module>\n    from gevent.server import StreamServer\n  File \"<whatever>/h/local/lib/python2.7/site-packages/gevent/server.py\", line 6, in <module>\n    from gevent.socket import EWOULDBLOCK, socket\n  File \"<whatever>/h/local/lib/python2.7/site-packages/gevent/socket.py\", line 659, in <module>\n    from gevent.ssl import sslwrap_simple as ssl, SSLError as sslerror, SSLSocket as SSLType\n  File \"<whatever>/h/local/lib/python2.7/site-packages/gevent/ssl.py\", line 386, in <module>\n    def get_server_certificate(addr, ssl_version=PROTOCOL_SSLv3, ca_certs=None):\nNameError: name 'PROTOCOL_SSLv3' is not defined\n]\n"], "labels": ["Upstream", "Bug"]}
{"project": "este_este", "title": "Write a new readme", "description": "I really don't care. But someone can. ", "code": [], "labels": ["good first issue"]}
{"project": "orientechnologies_orientdb", "title": "date data type", "description": "Date data type is not store the value as date format, but datetime format. for this case, we will have the timezone issue as it won't return the exact value you have stored.\nIt will convert the value to timezone that you set into database and return the local timezone. for the datetime data type. it will always return you the exact value without timezone conversion .\nfor example,  i store the value as 2015-04-22T21:24:09+0000 and it will return the same value. ", "code": [], "labels": ["bug"]}
{"project": "jOOQ_jOOQ", "title": "Cache internal BindingGetResultSetContext instance across a single Cursor", "description": "There is no value in creating new DefaultBindingGetResultSetContext afresh for each bind value. We should cache the instance, updating ResultSet indexes, only This contributes to improved performance (#3065) ", "code": [], "labels": ["P: Medium", "R: Fixed", "T: Defect", "C: Functionality"]}
{"project": "dotnet_roslyn", "title": "\"Use explicit type instead of 'var'\" doesn't fire for deconstructed tuples", "description": " Expected: <CODE> Which expands to: Actual: No message Note: It does fire for: ", "code": ["Message\tIDE0008\tUse explicit type instead of 'var' \n"], "labels": ["Resolution-Fixed", "Area-IDE"]}
{"project": "playgameservices_play-games-plugin-for-unity", "title": "Sudden massive increase in crashes on live version", "description": "I know that Google Play Games is having a hard time right now due to a recent update and this may be related to that. On my Play console crash report there has been a major uptick of crashes. Here's an example stack trace. Unfortunately it is obfuscated.   at android.os.Parcel.createException (Parcel.java:1978) at android.os.Parcel.readException (Parcel.java:1935) at android.os.Parcel.readException (Parcel.java:1885) at com.google.android.gms.internal.games.zza.transactAndReadExceptionReturnVoid (Unknown Source:10) at com.google.android.gms.games.internal.zzz.zza (Unknown Source:12) at com.google.android.gms.games.internal.zze.zza (Unknown Source:12) at com.google.android.gms.games.internal.zzac.zzbj (Unknown Source:12) at com.google.android.gms.games.internal.zzaf.zzbj (Unknown Source:6) at com.google.android.gms.games.internal.zze.onConnectedLocked (Unknown Source:11) at com.google.android.gms.common.internal.BaseGmsClient.zza (Unknown Source:113) at com.google.android.gms.common.internal.BaseGmsClient.zza (Unknown Source:129) at com.google.android.gms.common.internal.BaseGmsClient.zza (Unknown Source:354) at com.google.android.gms.common.internal.BaseGmsClient$zzf.zzm (Unknown Source:19) at com.google.android.gms.common.internal.BaseGmsClient$zza.zza (Unknown Source:12) at com.google.android.gms.common.internal.BaseGmsClient$zzc.zzo (Unknown Source:11) at com.google.android.gms.common.internal.BaseGmsClient$zzb.handleMessage (Unknown Source:49) at android.os.Handler.dispatchMessage (Handler.java:106) at com.google.android.gms.internal.common.zze.dispatchMessage (Unknown Source:7) at android.os.Looper.loop (Looper.java:280) at android.app.ActivityThread.main (ActivityThread.java:6706) at java.lang.reflect.Method.invoke (Native Method) at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run (RuntimeInit.java:493) at com.android.internal.os.ZygoteInit.main (ZygoteInit.java:858) ", "code": [], "labels": ["bug"]}
{"project": "sqlalchemy_sqlalchemy", "title": "MS SQL Insert from CTE", "description": "Migrated issue, originally created by Johnathon Hege It appears that insert().from_select(), when passed a CTE, doesn't generate syntactically valid MS SQL code. The code it generates (using the recursive \"parts\" example in the CTE documentation) looks like: <CODE> But SQL Server requires the INSERT below the CTE definition, as below: <CODE> ", "code": ["INSERT INTO destination (part, sub_part, quantity) WITH anon_1(part, sub_part, quantity) AS \n(SELECT parts.sub_part AS sub_part, parts.part AS part, parts.quantity AS quantity \nFROM parts \nWHERE parts.part = ? UNION ALL SELECT parts_1.sub_part AS sub_part, parts_1.part AS part, parts_1.quantity AS quantity \nFROM parts AS parts_1, anon_1 AS anon_2 \nWHERE parts_1.part = anon_2.sub_part)\n SELECT anon_1.part, anon_1.sub_part, anon_1.quantity \nFROM anon_1\n\n", "WITH anon_1(part, sub_part, quantity) AS \n(SELECT parts.sub_part AS sub_part, parts.part AS part, parts.quantity AS quantity \nFROM parts \nWHERE parts.part = ? UNION ALL SELECT parts_1.sub_part AS sub_part, parts_1.part AS part, parts_1.quantity AS quantity \nFROM parts AS parts_1, anon_1 AS anon_2 \nWHERE parts_1.part = anon_2.sub_part)\nINSERT INTO destination (part, sub_part, quantity)\n SELECT anon_1.part, anon_1.sub_part, anon_1.quantity \nFROM anon_1\n\n"], "labels": ["duplicate", "bug"]}
{"project": "riot_riot", "title": "Unsafe expressions", "description": "Unsafe expressions Having this html:\n<div if=\"{!hello.world}\">show me</div> \"hello\" is not defined. Div is not shown. However, i expect it to be shown Would you consider having this expression parser instead? It's super fast and safe. <URL> ", "code": [], "labels": ["wontfix"]}
{"project": "cleanflight_cleanflight", "title": "Why not allowing LED_STRIP together with SOFTSERIAL on NAZE?", "description": "SOFTSERIAL feature can be useful (e.g. for telemetry). But I guess 2 SOFTSERIAL ports are used less often. Why not allowing to enable a single SOFTSERIAL, leaving pins for other cool features like LED_STRIP or current meter? ", "code": [], "labels": ["question"]}
{"project": "hashicorp_vagrant", "title": "Unable to load Vagrantfile (unknown escape character while parsing a quoted scalar)", "description": "I tried to vagrant up my Homestead VM today and got the following error: <CODE> I am on windows 10, vagrant 1.7.4, have tried reinstalling both vagrant and virtual box. Have only started getting this issue today. ", "code": ["C:/HashiCorp/Vagrant/embedded/lib/ruby/2.0.0/psych.rb:205:in `parse': (<unknown>): found unknown escape character while parsing a quoted scalar at line 16 column 12 (Psych::SyntaxError)\n        from C:/HashiCorp/Vagrant/embedded/lib/ruby/2.0.0/psych.rb:205:in `parse_stream'\n        from C:/HashiCorp/Vagrant/embedded/lib/ruby/2.0.0/psych.rb:153:in `parse'\n        from C:/HashiCorp/Vagrant/embedded/lib/ruby/2.0.0/psych.rb:129:in `load'\n        from D:/Development/Homestead/Vagrantfile:20:in `block in <top (required)>'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/config/v2/loader.rb:37:in `call'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/config/v2/loader.rb:37:in `load'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/config/loader.rb:103:in `block (2 levels) in load'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/config/loader.rb:97:in `each'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/config/loader.rb:97:in `block in load'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/config/loader.rb:94:in `each'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/config/loader.rb:94:in `load'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/vagrantfile.rb:28:in `initialize'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/environment.rb:689:in `new'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/environment.rb:689:in `vagrantfile'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/environment.rb:441:in `host'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/environment.rb:207:in `block in action_runner'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/action/runner.rb:33:in `call'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/action/runner.rb:33:in `run'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/environment.rb:428:in `hook'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/lib/vagrant/environment.rb:671:in `unload'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/bin/vagrant:177:in `ensure in <main>'\n        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.4/bin/vagrant:177:in `<main>'\n"], "labels": ["waiting-reply"]}
{"project": "CleverRaven_Cataclysm-DDA", "title": "Snap-To-Target camera doesn't follow target in tiles mode", "description": "Last tested ea94807 in fullscreen on ubuntu 32bit but unknown when it started. How to test: Start up cataclysm and try to fire a gun with snap to target on, with tiles on and with tiles off. Expected result: Camera follows reticule around in both ascii and tiles mode. Current result:\nIn ascii mode, the camera will follow the reticule. In tiles mode, the snapping still functions, but the camera remains static. Want to back this issue? Post a bounty on it! We accept bounties via Bountysource.\n ", "code": [], "labels": ["Info / User Interface", "<Bug>", "(S2 - Confirmed)"]}
{"project": "lodash_lodash", "title": "Q: Link to lodash-element for usage as a webcomponent", "description": "Hello\nI created a webcomponent for importing lodash in other webcomponents for sharing. Nothing fancy.\nMay I make a PR and link to it in your README? It may be useful to others when they want to use lodash in webcomponents. What's the right way for it? <URL> /Kind regard ", "code": [], "labels": ["question"]}
{"project": "Unity-Technologies_ml-agents", "title": "Saving fails every 15k steps", "description": "Having a weird issue during training. I set the max steps to 500k but at around 15k-20k steps (last status was 14k) the training just stops. No exception in either Unity OR the console. It just ends, and there is no bytes file saved.\nThis was after I continued the training for the third time. First time it reached 15k and stopped, second time almost 35k and stopped, and third time 50k and stopped. I get the feeling that it may be failing during the status update. I've seen the Unity Editor freeze and become unresonsive when the console was supposed to write a status update and would only continue if I pressed Ctrl+C. Note that it would CONTINUE not end when I pressed Ctrl+C. ", "code": [], "labels": ["help-wanted", "bug"]}
{"project": "angular_protractor", "title": "Error while waiting for protractor to sync with the page: Firefox and IE", "description": "Hi, I am using protractor version4, Firefox-47, IE-11 to run my test cases.\nFacing intermittent failures on FF and IE both while execution. Given is the stack trace for the same:\nFailures: <CODE> Example of my Config file: ", "code": ["  Message:\n    Failed: Error while waiting for Protractor to sync with the page: \"[ng:test] http://errors.angularjs.org/1.4.7/ng/test\"\n  Stack:\n    Error: Failed: Error while waiting for Protractor to sync with the page: \"[ng:test] http://errors.angularjs.org/1.4.7/ng/test\"\n        at stack (C:\\Projects\\Repository\\node_modules\\gulp-angular-protractor\\node_modules\\gulp-protractor\\node_modules\\protractor\\node_modul\nes\\jasmine\\node_modules\\jasmine-core\\lib\\jasmine-core\\jasmine.js:1482:17)\n        at buildExpectationResult (C:\\Projects\\Repository\\node_modules\\gulp-angular-protractor\\node_modules\\gulp-protractor\\node_modules\\prot\nractor\\node_modules\\jasmine\\node_modules\\jasmine-core\\lib\\jasmine-core\\jasmine.js:1452:14)\n        at Spec.Env.expectationResultFactory (C:\\Projects\\Repository\\node_modules\\gulp-angular-protractor\\node_modules\\gulp-protractor\\node_m\nodules\\protractor\\node_modules\\jasmine\\node_modules\\jasmine-core\\lib\\jasmine-core\\jasmine.js:583:18)\n        at Spec.addExpectationResult (C:\\Projects\\Repository\\node_modules\\gulp-angular-protractor\\node_modules\\gulp-protractor\\node_modules\\p\nrotractor\\node_modules\\jasmine\\node_modules\\jasmine-core\\lib\\jasmine-core\\jasmine.js:324:34)\n        at Env.fail (C:\\Projects\\Repository\\node_modules\\gulp-angular-protractor\\node_modules\\gulp-protractor\\node_modules\\protractor\\node_mo\ndules\\jasmine\\node_modules\\jasmine-core\\lib\\jasmine-core\\jasmine.js:894:25)\n        at Function.next.fail (C:\\Projects\\Repository\\node_modules\\gulp-angular-protractor\\node_modules\\gulp-protractor\\node_modules\\protract\nor\\node_modules\\jasmine\\node_modules\\jasmine-core\\lib\\jasmine-core\\jasmine.js:1806:19)\n        at C:\\Projects\\Repository\\node_modules\\gulp-angular-protractor\\node_modules\\gulp-protractor\\node_modules\\protractor\\node_modules\\jasm\ninewd2\\index.js:101:16\n"], "labels": ["status: needs more info"]}
{"project": "ant-design_ant-design-mobile", "title": "404\u9875\u9762", "description": "<URL> ", "code": [], "labels": ["Invalid"]}
{"project": "SpiderLabs_ModSecurity", "title": "libmodsecurity (3.0.2) memory leak in runtime", "description": "There is a leak in recent 3.0.2 release. On the test environment created by <URL> it can be easily reproduced with the following commands (17847 is the single nginx worker): <CODE> nikto scanning tool [2] generates about 6300 requests per run, according to nginx stub_status counters, triggering various parts of OWASP CRS rules. I've built nginx, ModSecurity-nginx, and libmodsecurity with ASAN [1] and found the following after single run of nikto scanning tool: <CODE> I have also added support for building both nginx and libmodsecurity with ASAN in defanator/modsecurity-performance@9317dd8, so the above observation can be reproduced easily. Note that nginx.conf should include master_process off;. [1] <URL>\n[2] <URL> ", "code": ["root@vagrant:/home/vagrant# cat /proc/17847/status | egrep \"^Name|^VmRSS\"\nName:    nginx\nVmRSS:       60276 kB\nroot@vagrant:/home/vagrant# nikto -host localhost -root /modsec-full/ >/dev/null 2>&1\nroot@vagrant:/home/vagrant# cat /proc/17847/status | egrep \"^Name|^VmRSS\"\nName:    nginx\nVmRSS:      158852 kB\nroot@vagrant:/home/vagrant# nikto -host localhost -root /modsec-full/ >/dev/null 2>&1\nroot@vagrant:/home/vagrant# cat /proc/17847/status | egrep \"^Name|^VmRSS\"\nName:    nginx\nVmRSS:      250880 kB\n", "ERROR: LeakSanitizer: detected memory leaks\n\nDirect leak of 2985277 byte(s) in 6249 object(s) allocated from:\n    #0 0x7fe59d3cc30f in strdup (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x6230f)\n    #1 0x7fe59c793e37 in modsecurity::Transaction::intervention(modsecurity::ModSecurityIntervention_t*) /home/test/ModSecurity/src/transaction.cc:1362\n\nDirect leak of 18720 byte(s) in 36 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59c8d5a5c in modsecurity::utils::expandEnv(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) utils/system.cc:126\n\nDirect leak of 48 byte(s) in 2 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59c7bb2ab in modsecurity::audit_log::AuditLog::init(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) audit_log/audit_log.cc:222\n\nIndirect leak of 51541752 byte(s) in 6249 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59c86ff24 in __gnu_cxx::new_allocator<std::__detail::_Hash_node_base*>::allocate(unsigned long, void const*) /usr/include/c++/5/ext/new_allocator.h:104\n    #2 0x7fe59c86ff24 in std::allocator_traits<std::allocator<std::__detail::_Hash_node_base*> >::allocate(std::allocator<std::__detail::_Hash_node_base*>&, unsigned long) /usr/include/c++/5/bits/alloc_traits.h:491\n    #3 0x7fe59c86ff24 in std::__detail::_Hashtable_alloc<std::allocator<std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true> > >::_M_allocate_buckets(unsigned long) /usr/include/c++/5/bits/hashtable_policy.h:1996\n    #4 0x7fe59c86ff24 in std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_allocate_buckets(unsigned long) /usr/include/c++/5/bits/hashtable.h:347\n    #5 0x7fe59c86ff24 in std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_rehash_aux(unsigned long, std::integral_constant<bool, false>) /usr/include/c++/5/bits/hashtable.h:2015\n\nIndirect leak of 20492480 byte(s) in 256156 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59c86847d in __gnu_cxx::new_allocator<std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true> >::allocate(unsigned long, void const*) /usr/include/c++/5/ext/new_allocator.h:104\n    #2 0x7fe59c86847d in std::allocator_traits<std::allocator<std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true> > >::allocate(std::allocator<std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true> >&, unsigned long) /usr/include/c++/5/bits/alloc_traits.h:491\n    #3 0x7fe59c86847d in std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>* std::__detail::_Hashtable_alloc<std::allocator<std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true> > >::_M_allocate_node<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable_policy.h:1949\n    #4 0x7fe59c86847d in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__detail::_Node_const_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true>, std::integral_constant<bool, false>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:1565\n    #5 0x7fe59c86847d in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::integral_constant<bool, false>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:671\n    #6 0x7fe59c86847d in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:726\n    #7 0x7fe59c86847d in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::unordered_multimap<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, modsecurity::collection::backend::MyHash, modsecurity::collection::backend::MyEqual, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/unordered_map.h:1128\n    #8 0x7fe59c86847d in modsecurity::collection::backend::InMemoryPerProcess::store(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) collection/backend/in_memory-per_process.cc:52\n\nIndirect leak of 5854630 byte(s) in 65858 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59c86875f in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char*>(char*, char*, std::forward_iterator_tag) /usr/include/c++/5/bits/basic_string.tcc:223\n    #2 0x7fe59c86875f in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct_aux<char*>(char*, char*, std::__false_type) /usr/include/c++/5/bits/basic_string.h:195\n    #3 0x7fe59c86875f in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char*>(char*, char*) /usr/include/c++/5/bits/basic_string.h:214\n    #4 0x7fe59c86875f in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) /usr/include/c++/5/bits/basic_string.h:400\n    #5 0x7fe59c86875f in std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, void>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/stl_pair.h:145\n    #6 0x7fe59c86875f in void __gnu_cxx::new_allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::construct<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/ext/new_allocator.h:120\n    #7 0x7fe59c86875f in void std::allocator_traits<std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::construct<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >&, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/alloc_traits.h:530\n    #8 0x7fe59c86875f in std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>* std::__detail::_Hashtable_alloc<std::allocator<std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true> > >::_M_allocate_node<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable_policy.h:1955\n    #9 0x7fe59c86875f in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__detail::_Node_const_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true>, std::integral_constant<bool, false>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:1565\n    #10 0x7fe59c86875f in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::integral_constant<bool, false>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:671\n    #11 0x7fe59c86875f in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:726\n    #12 0x7fe59c86875f in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::unordered_multimap<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, modsecurity::collection::backend::MyHash, modsecurity::collection::backend::MyEqual, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/unordered_map.h:1128\n    #13 0x7fe59c86875f in modsecurity::collection::backend::InMemoryPerProcess::store(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) collection/backend/in_memory-per_process.cc:52\n\nIndirect leak of 4030813 byte(s) in 157059 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59c8687df in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char*>(char*, char*, std::forward_iterator_tag) /usr/include/c++/5/bits/basic_string.tcc:223\n    #2 0x7fe59c8687df in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct_aux<char*>(char*, char*, std::__false_type) /usr/include/c++/5/bits/basic_string.h:195\n    #3 0x7fe59c8687df in void std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_construct<char*>(char*, char*) /usr/include/c++/5/bits/basic_string.h:214\n    #4 0x7fe59c8687df in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) /usr/include/c++/5/bits/basic_string.h:400\n    #5 0x7fe59c8687df in std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, void>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/stl_pair.h:145\n    #6 0x7fe59c8687df in void __gnu_cxx::new_allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::construct<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/ext/new_allocator.h:120\n    #7 0x7fe59c8687df in void std::allocator_traits<std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::construct<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >&, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/alloc_traits.h:530\n    #8 0x7fe59c8687df in std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>* std::__detail::_Hashtable_alloc<std::allocator<std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true> > >::_M_allocate_node<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable_policy.h:1955\n    #9 0x7fe59c8687df in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__detail::_Node_const_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true>, std::integral_constant<bool, false>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:1565\n    #10 0x7fe59c8687df in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::_M_emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::integral_constant<bool, false>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:671\n    #11 0x7fe59c8687df in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, modsecurity::collection::backend::MyEqual, modsecurity::collection::backend::MyHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, false> >::emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/hashtable.h:726\n    #12 0x7fe59c8687df in std::__detail::_Node_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false, true> std::unordered_multimap<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, modsecurity::collection::backend::MyHash, modsecurity::collection::backend::MyEqual, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::emplace<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /usr/include/c++/5/bits/unordered_map.h:1128\n    #13 0x7fe59c8687df in modsecurity::collection::backend::InMemoryPerProcess::store(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) collection/backend/in_memory-per_process.cc:52\n\nIndirect leak of 849864 byte(s) in 6249 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59c860e7c in modsecurity::collection::Collections::Collections(modsecurity::collection::Collection*, modsecurity::collection::Collection*, modsecurity::collection::Collection*, modsecurity::collection::Collection*, modsecurity::collection::Collection*) collection/collections.cc:47\n    #2 0x7fe59c910642  (/usr/lib/libmodsecurity.so.3+0x3cc642)\n\nIndirect leak of 633779 byte(s) in 7350 object(s) allocated from:\n    #0 0x7fe59d403532 in operator new(unsigned long) (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x99532)\n    #1 0x7fe59a2533de in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_assign(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (/usr/lib/x86_64-linux-gnu/libstdc++.so.6+0x11f3de)\n\nSUMMARY: AddressSanitizer: 86407363 byte(s) leaked in 505208 allocation(s).\n"], "labels": ["3.x"]}
{"project": "cockroachdb_cockroach", "title": "storage/engine: (unknown) failed under stress", "description": "SHA: <URL> Parameters: <CODE> Stress build found a failed test: <URL> <CODE> ", "code": ["COCKROACH_PROPOSER_EVALUATED_KV=false\nTAGS=\nGOFLAGS=-race\n", "GOPATH set to /go\ngit submodule update --init\ngithub.com/cockroachdb/cockroach/pkg/cmd/ncpus\ngithub.com/cockroachdb/cockroach/vendor/github.com/cockroachdb/crlfmt\ngithub.com/cockroachdb/cockroach/vendor/github.com/jteeuwen/go-bindata/go-bindata\ngithub.com/cockroachdb/cockroach/vendor/github.com/mibk/dupl\ngithub.com/cockroachdb/cockroach/vendor/github.com/golang/lint/golint\ngithub.com/cockroachdb/cockroach/vendor/github.com/wadey/gocovmerge\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/tools/cmd/goyacc\ngithub.com/cockroachdb/cockroach/pkg/cmd/metacheck\ngithub.com/cockroachdb/cockroach/pkg/cmd/returncheck\ngithub.com/cockroachdb/cockroach/vendor/github.com/Masterminds/glide\ngithub.com/cockroachdb/cockroach/vendor/github.com/client9/misspell/cmd/misspell\ngithub.com/cockroachdb/cockroach/vendor/github.com/cockroachdb/stress\ngithub.com/cockroachdb/cockroach/vendor/github.com/google/pprof\ngithub.com/cockroachdb/cockroach/vendor/github.com/grpc-ecosystem/grpc-gateway/protoc-gen-grpc-gateway\ngithub.com/cockroachdb/cockroach/vendor/github.com/kisielk/errcheck\ngithub.com/cockroachdb/cockroach/vendor/github.com/mattn/goveralls\ngithub.com/cockroachdb/cockroach/vendor/github.com/mdempsky/unconvert\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/tools/cmd/goimports\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/tools/cmd/guru\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/tools/cmd/stringer\ntouch /go/src/github.com/cockroachdb/cockroach/bin/.bootstrap\ngo list -tags ' make x86_64_unknown_linux_gnu' -f '  CC=/x-tools/x86_64-unknown-linux-gnu/bin/x86_64-unknown-linux-gnu-gcc CXX=/x-tools/x86_64-unknown-linux-gnu/bin/x86_64-unknown-linux-gnu-g++ go test -v -race -installsuffix release -tags '\\'' make x86_64_unknown_linux_gnu'\\'' -ldflags '\\'' -s -w -extldflags \"-static-libgcc -static-libstdc++\" -X github.com/cockroachdb/cockroach/pkg/build.typ=release'\\'' -i -c {{.ImportPath}} -o '\\''{{.Dir}}'\\''/stress.test && (cd '\\''{{.Dir}}'\\'' && if [ -f stress.test ]; then COCKROACH_STRESS=true stress -maxtime 15m -maxfails 1 -stderr ./stress.test -test.run '\\''.'\\''  -test.timeout 30m -test.v; fi)' github.com/cockroachdb/cockroach/pkg/storage/engine | /bin/bash\nruntime/internal/sys\nruntime/internal/atomic\nruntime\nerrors\nruntime/cgo\nruntime/race\ninternal/race\nsync/atomic\nunicode\nunicode/utf8\nmath\nencoding\nunicode/utf16\ninternal/nettrace\ncontainer/list\ncrypto/subtle\ncrypto/internal/cipherhw\nvendor/golang_org/x/crypto/curve25519\nvendor/golang_org/x/crypto/poly1305\ngithub.com/cockroachdb/cockroach/vendor/github.com/biogo/store/llrb\nsync\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/internal\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/naming\ngithub.com/cockroachdb/cockroach/pkg/util/bufalloc\nio\nsyscall\ngithub.com/cockroachdb/cockroach/pkg/util/syncutil\ninternal/singleflight\nhash\ncrypto/cipher\nruntime/trace\nbytes\nstrings\nhash/crc32\ncrypto/hmac\nstrconv\nmath/rand\nbufio\nvendor/golang_org/x/text/transform\ntext/tabwriter\ngithub.com/cockroachdb/cockroach/vendor/github.com/kr/text\npath\nhtml\ntime\ninternal/syscall/unix\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/sys/unix\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/crypto/ssh/terminal\nencoding/base64\nreflect\ncrypto/aes\ncrypto\ncrypto/rc4\ncrypto/sha512\ncrypto/md5\ncrypto/sha1\ncrypto/sha256\ngithub.com/cockroachdb/cockroach/vendor/github.com/petermattis/goid\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/crypto/blowfish\nos\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/keepalive\nos/signal\nencoding/binary\nfmt\nsort\nregexp/syntax\nencoding/pem\npath/filepath\nruntime/debug\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/sortkeys\ngithub.com/cockroachdb/cockroach/vendor/github.com/grpc-ecosystem/grpc-gateway/utilities\ncrypto/des\nvendor/golang_org/x/crypto/chacha20poly1305/internal/chacha20\nio/ioutil\nvendor/golang_org/x/crypto/chacha20poly1305\nencoding/json\nencoding/hex\ngithub.com/cockroachdb/cockroach/vendor/github.com/pkg/errors\nmath/big\nflag\nlog\nencoding/csv\ncontext\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/opentracing-go/log\ncompress/flate\nvendor/golang_org/x/net/http2/hpack\nvendor/golang_org/x/net/idna\nnet\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/context\nvendor/golang_org/x/text/unicode/norm\nregexp\nvendor/golang_org/x/text/width\nmime\nmime/quotedprintable\nnet/http/internal\ncompress/gzip\nnet/url\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/internal/timeseries\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/proto\ntext/template/parse\ngithub.com/cockroachdb/cockroach/pkg/util/caller\nos/user\ndatabase/sql/driver\ngithub.com/cockroachdb/cockroach/pkg/util/interval\ngithub.com/cockroachdb/cockroach/vendor/github.com/golang/protobuf/proto\ngithub.com/cockroachdb/cockroach/vendor/github.com/cockroachdb/apd\ngithub.com/cockroachdb/cockroach/vendor/github.com/dustin/go-humanize\ncrypto/rand\ncrypto/elliptic\nencoding/asn1\ncrypto/rsa\ncrypto/dsa\ntext/template\ngithub.com/cockroachdb/cockroach/pkg/util/duration\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/http2/hpack\ncrypto/ecdsa\ncrypto/x509/pkix\ngithub.com/cockroachdb/cockroach/pkg/util/encoding\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/idna\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/codes\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/grpclog\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/metadata\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/tap\nencoding/gob\nencoding/xml\ngithub.com/cockroachdb/cockroach/vendor/gopkg.in/yaml.v2\ngithub.com/cockroachdb/cockroach/vendor/github.com/golang/protobuf/jsonpb\ngithub.com/cockroachdb/cockroach/vendor/github.com/grpc-ecosystem/grpc-gateway/runtime/internal\ngithub.com/cockroachdb/cockroach/vendor/github.com/golang/protobuf/ptypes/timestamp\nhtml/template\ngithub.com/cockroachdb/cockroach/pkg/build\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/types\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/basictracer-go/wire\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/crypto/bcrypt\ngithub.com/cockroachdb/cockroach/pkg/util/retry\ntesting\ngithub.com/cockroachdb/cockroach/pkg/testutils/zerofields\ngithub.com/cockroachdb/cockroach/vendor/github.com/elastic/gosigar\ngithub.com/cockroachdb/cockroach/vendor/github.com/kr/pretty\ngithub.com/cockroachdb/cockroach/vendor/github.com/termie/go-shutil\ninternal/pprof/profile\ngithub.com/cockroachdb/cockroach/vendor/github.com/spf13/pflag\ncrypto/x509\nvendor/golang_org/x/net/lex/httplex\nnet/textproto\ngithub.com/cockroachdb/cockroach/vendor/github.com/satori/go.uuid\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/lex/httplex\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/stats\ngithub.com/cockroachdb/cockroach/pkg/util/uuid\nmime/multipart\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/jsonpb\ncrypto/tls\nruntime/pprof/internal/protopprof\nruntime/pprof\ngithub.com/cockroachdb/cockroach/pkg/util/humanizeutil\ngithub.com/cockroachdb/cockroach/pkg/util/log/logflags\ngithub.com/cockroachdb/cockroach/pkg/util/envutil\ntesting/internal/testdeps\ngithub.com/cockroachdb/cockroach/pkg/util/timeutil\ngithub.com/cockroachdb/cockroach/pkg/util/randutil\ngithub.com/cockroachdb/cockroach/pkg/util\ngithub.com/cockroachdb/cockroach/pkg/util/leaktest\nnet/http/httptrace\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/credentials\nnet/http\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/peer\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/trace\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/opentracing-go\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/http2\ngithub.com/cockroachdb/cockroach/pkg/util/httputil\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/thrift_0_9_2/lib/go/thrift\ngithub.com/cockroachdb/cockroach/vendor/github.com/rlmcpherson/s3gof3r\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/opentracing-go/ext\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/basictracer-go\ngithub.com/cockroachdb/cockroach/pkg/util/log\ngithub.com/cockroachdb/cockroach/pkg/util/hlc\ngithub.com/cockroachdb/cockroach/pkg/storage/engine/enginepb\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/transport\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/lightstep_thrift\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/thrift_rpc\ngithub.com/cockroachdb/cockroach/vendor/github.com/grpc-ecosystem/grpc-gateway/runtime\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/collectorpb\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go\ngithub.com/cockroachdb/cockroach/pkg/util/protoutil\ngithub.com/cockroachdb/cockroach/pkg/util/tracing\ngithub.com/cockroachdb/cockroach/pkg/roachpb\ngithub.com/cockroachdb/cockroach/pkg/keys\ngithub.com/cockroachdb/cockroach/pkg/util/stop\ngithub.com/cockroachdb/cockroach/pkg/security\ngithub.com/cockroachdb/cockroach/pkg/config\ngithub.com/cockroachdb/cockroach/pkg/base\ngithub.com/cockroachdb/cockroach/pkg/testutils\nruntime/internal/sys\ngithub.com/cockroachdb/cockroach/pkg/storage/engine_test\nruntime/internal/atomic\nruntime\nerrors\nruntime/cgo\nruntime/race\ninternal/race\nsync/atomic\nunicode\nunicode/utf8\nmath\nencoding\nunicode/utf16\ninternal/nettrace\ncontainer/list\ncrypto/subtle\nsync\ncrypto/internal/cipherhw\nvendor/golang_org/x/crypto/poly1305\nvendor/golang_org/x/crypto/curve25519\ngithub.com/cockroachdb/cockroach/vendor/github.com/biogo/store/llrb\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/internal\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/naming\ngithub.com/cockroachdb/cockroach/pkg/util/bufalloc\nio\nsyscall\ngithub.com/cockroachdb/cockroach/pkg/util/syncutil\ninternal/singleflight\nbytes\nruntime/trace\nstrings\nhash\ncrypto/cipher\nhash/crc32\ncrypto/hmac\nstrconv\nmath/rand\npath\nhtml\nbufio\ntext/tabwriter\nvendor/golang_org/x/text/transform\ngithub.com/cockroachdb/cockroach/vendor/github.com/kr/text\nreflect\nencoding/base64\ncrypto/aes\ncrypto\ncrypto/rc4\ngithub.com/cockroachdb/cockroach/vendor/github.com/petermattis/goid\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/crypto/blowfish\ncrypto/sha512\ncrypto/md5\ntime\ninternal/syscall/unix\ncrypto/sha1\ncrypto/sha256\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/sys/unix\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/crypto/ssh/terminal\nos\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/keepalive\nos/signal\nsort\nfmt\nencoding/binary\nruntime/debug\nregexp/syntax\npath/filepath\nencoding/pem\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/sortkeys\ngithub.com/cockroachdb/cockroach/vendor/github.com/grpc-ecosystem/grpc-gateway/utilities\ncrypto/des\nvendor/golang_org/x/crypto/chacha20poly1305/internal/chacha20\nvendor/golang_org/x/crypto/chacha20poly1305\nio/ioutil\nflag\ncompress/flate\nencoding/json\nencoding/hex\nmath/big\ngithub.com/cockroachdb/cockroach/vendor/github.com/pkg/errors\nlog\nencoding/csv\ncontext\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/opentracing-go/log\nvendor/golang_org/x/net/http2/hpack\nvendor/golang_org/x/net/idna\ntesting\nvendor/golang_org/x/text/unicode/norm\nregexp\nnet\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/context\nvendor/golang_org/x/text/width\ncompress/gzip\nmime\nmime/quotedprintable\nnet/http/internal\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/proto\nnet/url\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/internal/timeseries\ninternal/pprof/profile\ngithub.com/cockroachdb/cockroach/pkg/util/caller\ntext/template/parse\nos/user\ndatabase/sql/driver\ngithub.com/cockroachdb/cockroach/pkg/util/interval\ngithub.com/cockroachdb/cockroach/vendor/github.com/cockroachdb/apd\ngithub.com/cockroachdb/cockroach/vendor/github.com/dustin/go-humanize\ncrypto/rand\ncrypto/elliptic\nencoding/asn1\nruntime/pprof/internal/protopprof\ncrypto/rsa\nruntime/pprof\ncrypto/dsa\ntext/template\ngithub.com/cockroachdb/cockroach/pkg/util/duration\ngithub.com/cockroachdb/cockroach/vendor/github.com/golang/protobuf/proto\ncrypto/ecdsa\ntesting/internal/testdeps\ncrypto/x509/pkix\ngithub.com/cockroachdb/cockroach/pkg/util/encoding\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/http2/hpack\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/idna\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/codes\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/grpclog\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/metadata\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/tap\nencoding/gob\nencoding/xml\ngithub.com/cockroachdb/cockroach/vendor/gopkg.in/yaml.v2\ngithub.com/cockroachdb/cockroach/vendor/github.com/elastic/gosigar\nhtml/template\ngithub.com/cockroachdb/cockroach/pkg/build\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/types\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/basictracer-go/wire\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/crypto/bcrypt\ngithub.com/cockroachdb/cockroach/pkg/util/retry\ngithub.com/cockroachdb/cockroach/pkg/testutils/zerofields\ngithub.com/cockroachdb/cockroach/vendor/github.com/kr/pretty\ngithub.com/cockroachdb/cockroach/vendor/github.com/termie/go-shutil\ngithub.com/cockroachdb/cockroach/vendor/github.com/golang/protobuf/jsonpb\ngithub.com/cockroachdb/cockroach/vendor/github.com/grpc-ecosystem/grpc-gateway/runtime/internal\ngithub.com/cockroachdb/cockroach/vendor/github.com/golang/protobuf/ptypes/timestamp\ngithub.com/cockroachdb/cockroach/vendor/github.com/spf13/pflag\ncrypto/x509\nvendor/golang_org/x/net/lex/httplex\nnet/textproto\ngithub.com/cockroachdb/cockroach/vendor/github.com/satori/go.uuid\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/lex/httplex\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/stats\ngithub.com/cockroachdb/cockroach/vendor/github.com/gogo/protobuf/jsonpb\ngithub.com/cockroachdb/cockroach/pkg/util/uuid\nmime/multipart\ncrypto/tls\ngithub.com/cockroachdb/cockroach/pkg/util/humanizeutil\ngithub.com/cockroachdb/cockroach/pkg/util/log/logflags\ngithub.com/cockroachdb/cockroach/pkg/util/envutil\ngithub.com/cockroachdb/cockroach/pkg/util/timeutil\ngithub.com/cockroachdb/cockroach/pkg/util/randutil\ngithub.com/cockroachdb/cockroach/pkg/util\ngithub.com/cockroachdb/cockroach/pkg/util/leaktest\nnet/http/httptrace\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/credentials\nnet/http\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/peer\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/opentracing-go\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/trace\ngithub.com/cockroachdb/cockroach/pkg/util/httputil\ngithub.com/cockroachdb/cockroach/vendor/golang.org/x/net/http2\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/thrift_0_9_2/lib/go/thrift\ngithub.com/cockroachdb/cockroach/vendor/github.com/rlmcpherson/s3gof3r\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/opentracing-go/ext\ngithub.com/cockroachdb/cockroach/vendor/github.com/opentracing/basictracer-go\ngithub.com/cockroachdb/cockroach/pkg/util/log\ngithub.com/cockroachdb/cockroach/pkg/util/hlc\ngithub.com/cockroachdb/cockroach/pkg/storage/engine/enginepb\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc/transport\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/lightstep_thrift\ngithub.com/cockroachdb/cockroach/vendor/google.golang.org/grpc\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/thrift_rpc\ngithub.com/cockroachdb/cockroach/vendor/github.com/grpc-ecosystem/grpc-gateway/runtime\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go/collectorpb\ngithub.com/cockroachdb/cockroach/vendor/github.com/lightstep/lightstep-tracer-go\ngithub.com/cockroachdb/cockroach/pkg/util/protoutil\ngithub.com/cockroachdb/cockroach/pkg/util/tracing\ngithub.com/cockroachdb/cockroach/pkg/roachpb\ngithub.com/cockroachdb/cockroach/pkg/util/stop\ngithub.com/cockroachdb/cockroach/pkg/keys\ngithub.com/cockroachdb/cockroach/pkg/security\ngithub.com/cockroachdb/cockroach/pkg/config\ngithub.com/cockroachdb/cockroach/pkg/base\ngithub.com/cockroachdb/cockroach/pkg/testutils\ngithub.com/cockroachdb/cockroach/pkg/storage/engine\n# github.com/cockroachdb/cockroach/pkg/storage/engine\nIn file included from pkg/storage/engine/cockroach/pkg/util/hlc/timestamp.pb.cc:5:0,\n                 from pkg/storage/engine/cockroach_pkg_util_hlc_timestamp.pb.cc:1:\npkg/storage/engine/cockroach/pkg/util/hlc/timestamp.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n #include <google/protobuf/stubs/common.h>\n                                          ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\nIn file included from pkg/storage/engine/cockroach/pkg/roachpb/data.pb.cc:5:0,\n                 from pkg/storage/engine/cockroach_pkg_roachpb_data.pb.cc:1:\npkg/storage/engine/cockroach/pkg/roachpb/data.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n #include <google/protobuf/stubs/common.h>\n                                          ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\npkg/storage/engine/encoding.cc:18:27: fatal error: rocksdb/slice.h: No such file or directory\n #include \"rocksdb/slice.h\"\n                           ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\nIn file included from pkg/storage/engine/cockroach/pkg/roachpb/internal.pb.cc:5:0,\n                 from pkg/storage/engine/cockroach_pkg_roachpb_internal.pb.cc:1:\npkg/storage/engine/cockroach/pkg/roachpb/internal.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n #include <google/protobuf/stubs/common.h>\n                                          ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\npkg/storage/engine/eventlistener.cc:17:38: fatal error: rocksdb/table_properties.h: No such file or directory\n #include <rocksdb/table_properties.h>\n                                      ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\nIn file included from pkg/storage/engine/cockroach/pkg/storage/engine/enginepb/rocksdb.pb.cc:5:0,\n                 from pkg/storage/engine/cockroach_pkg_storage_engine_enginepb_rocksdb.pb.cc:1:\npkg/storage/engine/cockroach/pkg/storage/engine/enginepb/rocksdb.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n #include <google/protobuf/stubs/common.h>\n                                          ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\nIn file included from pkg/storage/engine/cockroach/pkg/roachpb/metadata.pb.cc:5:0,\n                 from pkg/storage/engine/cockroach_pkg_roachpb_metadata.pb.cc:1:\npkg/storage/engine/cockroach/pkg/roachpb/metadata.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n #include <google/protobuf/stubs/common.h>\n                                          ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\nIn file included from pkg/storage/engine/cockroach/pkg/storage/engine/enginepb/mvcc.pb.cc:5:0,\n                 from pkg/storage/engine/cockroach_pkg_storage_engine_enginepb_mvcc.pb.cc:1:\npkg/storage/engine/cockroach/pkg/storage/engine/enginepb/mvcc.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n #include <google/protobuf/stubs/common.h>\n                                          ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\nIn file included from pkg/storage/engine/cockroach/pkg/util/unresolved_addr.pb.cc:5:0,\n                 from pkg/storage/engine/cockroach_pkg_util_unresolved_addr.pb.cc:1:\npkg/storage/engine/cockroach/pkg/util/unresolved_addr.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n #include <google/protobuf/stubs/common.h>\n                                          ^\ncompilation terminated.\n# github.com/cockroachdb/cockroach/pkg/storage/engine\npkg/storage/engine/db.cc:19:48: fatal error: google/protobuf/stubs/stringprintf.h: No such file or directory\n #include <google/protobuf/stubs/stringprintf.h>\n                                                ^\ncompilation terminated.\nmake: *** [stress] Error 2\nMakefile:192: recipe for target 'stress' failed\n\n"], "labels": ["O-robot", "C-test-failure"]}
{"project": "PrestaShop_PrestaShop", "title": "Multistore | Product quantity for all shops", "description": "PrestaShop version: 1.7.5.0 To simulate the probem: Prestashop returns an error, changes only one combination at a time.\nTo change the quantities of all combinations, I have to click on save multiple times. ", "code": [], "labels": ["Duplicate"]}
{"project": "bridgedotnet_Bridge", "title": "bridge.json no attribute for adding stylesheet reference to the auto-generated index.html", "description": "bridge.json no attribute for adding stylesheet reference to the auto-generated index.html ", "code": [], "labels": ["feature"]}
{"project": "cockroachdb_cockroach", "title": "teamcity: failed tests on master: testrace/TestMonotonicInserts, testrace/TestParallel, testrace/TestBackupRestoreNegativePrimaryKey", "description": "The following tests appear to have failed: #687826: <CODE> Please assign, take a look and update the issue accordingly. ", "code": ["--- FAIL: testrace/TestBackupRestoreNegativePrimaryKey (0.000s)\nRace detected!\n\n------- Stdout: -------\nI180530 15:19:05.722782 15949 server/server.go:784  [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled\nI180530 15:19:05.766429 15949 server/config.go:539  [n?] 1 storage engine initialized\nI180530 15:19:05.767387 15949 server/config.go:542  [n?] RocksDB cache size: 128 MiB\nI180530 15:19:05.767476 15949 server/config.go:542  [n?] store 0: in-memory, size 0 B\nI180530 15:19:05.936937 15949 server/node.go:376  [n?] **** cluster 8410f8b5-6176-43eb-a107-9719eb4222ff has been created\nI180530 15:19:05.937193 15949 server/server.go:1358  [n?] **** add additional nodes by specifying --join=127.0.0.1:36071\nI180530 15:19:05.992385 15949 storage/store.go:1454  [n1,s1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available\nI180530 15:19:05.994095 15949 server/node.go:506  [n1] initialized store [n1,s1]: disk (capacity=512 MiB, available=512 MiB, used=0 B, logicalBytes=6.9 KiB), ranges=1, leases=0, writes=0.00, bytesPerReplica={p10=7043.00 p25=7043.00 p50=7043.00 p75=7043.00 p90=7043.00 pMax=7043.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}\nI180530 15:19:05.994497 15949 server/node.go:354  [n1] node ID 1 initialized\nI180530 15:19:05.996085 15949 gossip/gossip.go:333  [n1] NodeDescriptor set to node_id:1 address:<network_field:\"tcp\" address_field:\"127.0.0.1:36071\" > attrs:<> locality:<> ServerVersion:<major_val:2 minor_val:0 patch:0 unstable:5 > \nI180530 15:19:05.998349 15949 storage/stores.go:222  [n1] read 0 node addresses from persistent storage\nI180530 15:19:06.000424 15949 server/node.go:647  [n1] connecting to gossip network to verify cluster ID...\nI180530 15:19:06.000786 15949 server/node.go:672  [n1] node connected via gossip and verified as part of cluster \"8410f8b5-6176-43eb-a107-9719eb4222ff\"\nI180530 15:19:06.003487 15949 server/node.go:440  [n1] node=1: started with [<no-attributes>=<in-mem>] engine(s) and attributes []\nI180530 15:19:06.021818 15949 server/server.go:1485  [n1] starting https server at 127.0.0.1:39893\nI180530 15:19:06.022009 15949 server/server.go:1486  [n1] starting grpc/postgres server at 127.0.0.1:36071\nI180530 15:19:06.022062 15949 server/server.go:1487  [n1] advertising CockroachDB node at 127.0.0.1:36071\nW180530 15:19:06.022455 15949 sql/jobs/registry.go:287  [n1] unable to get node liveness: node not in the liveness table\nI180530 15:19:06.088247 16291 storage/replica_command.go:863  [split,n1,s1,r1/1:/M{in-ax}] initiating a split of this range at key /System/\"\" [r2]\nI180530 15:19:06.686942 16323 storage/replica_command.go:863  [split,n1,s1,r2/1:/{System/-Max}] initiating a split of this range at key /System/NodeLiveness [r3]\nW180530 15:19:06.719504 16182 storage/intent_resolver.go:320  [n1,s1] failed to push during intent resolution: failed to push \"sql txn\" id=6f61dc06 key=/Table/SystemConfigSpan/Start rw=true pri=0.03405465 iso=SERIALIZABLE stat=PENDING epo=0 ts=1527693546.183363820,0 orig=1527693546.183363820,0 max=1527693546.183363820,0 wto=false rop=false seq=6\nI180530 15:19:06.880011 16049 sql/event_log.go:126  [n1,intExec=optInToDiagnosticsStatReporting] Event: \"set_cluster_setting\", target: 0, info: {SettingName:diagnostics.reporting.enabled Value:true User:root}\nI180530 15:19:06.979492 16338 storage/replica_command.go:863  [split,n1,s1,r3/1:/{System/NodeL\u2026-Max}] initiating a split of this range at key /System/NodeLivenessMax [r4]\nI180530 15:19:07.214617 16340 storage/replica_command.go:863  [split,n1,s1,r4/1:/{System/NodeL\u2026-Max}] initiating a split of this range at key /System/tsd [r5]\nI180530 15:19:07.505509 16344 storage/replica_command.go:863  [split,n1,s1,r5/1:/{System/tsd-Max}] initiating a split of this range at key /System/\"tse\" [r6]\nI180530 15:19:07.801448 16267 sql/event_log.go:126  [n1,intExec=set-setting] Event: \"set_cluster_setting\", target: 0, info: {SettingName:version Value:$1 User:root}\nI180530 15:19:07.836443 16320 storage/replica_command.go:863  [split,n1,s1,r6/1:/{System/tse-Max}] initiating a split of this range at key /Table/SystemConfigSpan/Start [r7]\nI180530 15:19:08.055299 16346 storage/replica_command.go:863  [split,n1,s1,r7/1:/{Table/System\u2026-Max}] initiating a split of this range at key /Table/11 [r8]\nW180530 15:19:08.062247 15982 storage/intent_resolver.go:320  [n1,s1] failed to push during intent resolution: failed to push \"sql txn\" id=20b5b232 key=/Table/SystemConfigSpan/Start rw=true pri=0.00281571 iso=SERIALIZABLE stat=PENDING epo=0 ts=1527693547.823909204,0 orig=1527693547.823909204,0 max=1527693547.823909204,0 wto=false rop=false seq=6\nI180530 15:19:08.214576 16318 sql/event_log.go:126  [n1,intExec=disableNetTrace] Event: \"set_cluster_setting\", target: 0, info: {SettingName:trace.debug.enable Value:false User:root}\nI180530 15:19:08.449073 16348 storage/replica_command.go:863  [split,n1,s1,r8/1:/{Table/11-Max}] initiating a split of this range at key /Table/12 [r9]\nI180530 15:19:08.746862 16382 storage/replica_command.go:863  [split,n1,s1,r9/1:/{Table/12-Max}] initiating a split of this range at key /Table/13 [r10]\nI180530 15:19:08.943257 16364 sql/event_log.go:126  [n1,intExec=initializeClusterSecret] Event: \"set_cluster_setting\", target: 0, info: {SettingName:cluster.secret Value:gen_random_uuid()::STRING User:root}\nI180530 15:19:09.050207 16385 storage/replica_command.go:863  [split,n1,s1,r10/1:/{Table/13-Max}] initiating a split of this range at key /Table/14 [r11]\nI180530 15:19:09.135085 16439 sql/event_log.go:126  [n1,intExec=create-default-db] Event: \"create_database\", target: 50, info: {DatabaseName:defaultdb Statement:CREATE DATABASE IF NOT EXISTS defaultdb User:root}\nI180530 15:19:09.270847 16468 sql/event_log.go:126  [n1,intExec=create-default-db] Event: \"create_database\", target: 51, info: {DatabaseName:postgres Statement:CREATE DATABASE IF NOT EXISTS postgres User:root}\nI180530 15:19:09.284061 15949 server/server.go:1564  [n1] done ensuring all necessary migrations have run\nI180530 15:19:09.284329 15949 server/server.go:1567  [n1] serving sql connections\nI180530 15:19:09.339648 16457 storage/replica_command.go:863  [split,n1,s1,r11/1:/{Table/14-Max}] initiating a split of this range at key /Table/15 [r12]\nI180530 15:19:09.407052 16474 sql/event_log.go:126  [n1] Event: \"node_join\", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:127.0.0.1:36071} Attrs: Locality: ServerVersion:2.0-5} ClusterID:8410f8b5-6176-43eb-a107-9719eb4222ff StartedAt:1527693546000926527 LastUp:1527693546000926527}\nI180530 15:19:09.438041 16472 server/server_update.go:66  [n1] no need to upgrade, cluster already at the newest version\nI180530 15:19:09.510707 16487 storage/replica_command.go:863  [split,n1,s1,r12/1:/{Table/15-Max}] initiating a split of this range at key /Table/16 [r13]\nI180530 15:19:09.748046 16445 storage/replica_command.go:863  [split,n1,s1,r13/1:/{Table/16-Max}] initiating a split of this range at key /Table/17 [r14]\nI180530 15:19:09.894179 16415 storage/replica_command.go:863  [split,n1,s1,r14/1:/{Table/17-Max}] initiating a split of this range at key /Table/18 [r15]\nI180530 15:19:09.991352 16425 storage/replica_command.go:863  [split,n1,s1,r15/1:/{Table/18-Max}] initiating a split of this range at key /Table/19 [r16]\nI180530 15:19:10.105970 16522 storage/replica_command.go:863  [split,n1,s1,r16/1:/{Table/19-Max}] initiating a split of this range at key /Table/20 [r17]\nI180530 15:19:10.203294 16526 storage/replica_command.go:863  [split,n1,s1,r17/1:/{Table/20-Max}] initiating a split of this range at key /Table/21 [r18]\nI180530 15:19:10.365964 16578 storage/replica_command.go:863  [split,n1,s1,r18/1:/{Table/21-Max}] initiating a split of this range at key /Table/22 [r19]\nI180530 15:19:10.605169 16615 storage/replica_command.go:863  [split,n1,s1,r19/1:/{Table/22-Max}] initiating a split of this range at key /Table/23 [r20]\nI180530 15:19:10.813353 16647 storage/replica_command.go:863  [split,n1,s1,r20/1:/{Table/23-Max}] initiating a split of this range at key /Table/50 [r21]\nI180530 15:19:10.940390 16619 storage/replica_command.go:863  [split,n1,s1,r21/1:/{Table/50-Max}] initiating a split of this range at key /Table/51 [r22]\nI180530 15:19:12.079253 15949 server/server.go:784  [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled\nI180530 15:19:12.143078 15949 server/config.go:539  [n?] 1 storage engine initialized\nI180530 15:19:12.143294 15949 server/config.go:542  [n?] RocksDB cache size: 128 MiB\nI180530 15:19:12.143372 15949 server/config.go:542  [n?] store 0: in-memory, size 0 B\nW180530 15:19:12.143893 15949 gossip/gossip.go:1293  [n?] no incoming or outgoing connections\nI180530 15:19:12.170825 15949 server/server.go:1360  [n?] no stores bootstrapped and --join flag specified, awaiting init command.\nI180530 15:19:12.356417 16555 gossip/client.go:129  [n?] started gossip client to 127.0.0.1:36071\nI180530 15:19:12.360376 16662 gossip/server.go:219  [n1] received initial cluster-verification connection from {tcp 127.0.0.1:44349}\nI180530 15:19:12.375973 15949 storage/stores.go:222  [n?] read 0 node addresses from persistent storage\nI180530 15:19:12.376600 15949 storage/stores.go:241  [n?] wrote 1 node addresses to persistent storage\nI180530 15:19:12.376817 15949 server/node.go:647  [n?] connecting to gossip network to verify cluster ID...\nI180530 15:19:12.377041 15949 server/node.go:672  [n?] node connected via gossip and verified as part of cluster \"8410f8b5-6176-43eb-a107-9719eb4222ff\"\nI180530 15:19:12.420550 15949 kv/dist_sender.go:368  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping\nI180530 15:19:12.436864 15949 server/node.go:347  [n?] new node allocated ID 2\nI180530 15:19:12.437629 15949 gossip/gossip.go:333  [n2] NodeDescriptor set to node_id:2 address:<network_field:\"tcp\" address_field:\"127.0.0.1:44349\" > attrs:<> locality:<> ServerVersion:<major_val:2 minor_val:0 patch:0 unstable:5 > \nI180530 15:19:12.438630 15949 server/node.go:421  [n2] node=2: asynchronously bootstrapping engine(s) [<no-attributes>=<in-mem>]\nI180530 15:19:12.439426 15949 server/node.go:440  [n2] node=2: started with [] engine(s) and attributes []\nI180530 15:19:12.442406 15949 server/server.go:1485  [n2] starting https server at 127.0.0.1:33001\nI180530 15:19:12.442655 15949 server/server.go:1486  [n2] starting grpc/postgres server at 127.0.0.1:44349\nI180530 15:19:12.442741 15949 server/server.go:1487  [n2] advertising CockroachDB node at 127.0.0.1:44349\nW180530 15:19:12.443091 15949 sql/jobs/registry.go:287  [n2] unable to get node liveness: node not in the liveness table\nI180530 15:19:12.471687 16747 storage/stores.go:241  [n1] wrote 1 node addresses to persistent storage\nI180530 15:19:12.483442 15949 server/server.go:1564  [n2] done ensuring all necessary migrations have run\nI180530 15:19:12.483775 15949 server/server.go:1567  [n2] serving sql connections\nI180530 15:19:12.622780 16786 server/node.go:628  [n2] bootstrapped store [n2,s2]\nI180530 15:19:12.769051 16758 sql/event_log.go:126  [n2] Event: \"node_join\", target: 2, info: {Descriptor:{NodeID:2 Address:{NetworkField:tcp AddressField:127.0.0.1:44349} Attrs: Locality: ServerVersion:2.0-5} ClusterID:8410f8b5-6176-43eb-a107-9719eb4222ff StartedAt:1527693552438995454 LastUp:1527693552438995454}\nI180530 15:19:12.782242 16756 server/server_update.go:66  [n2] no need to upgrade, cluster already at the newest version\nI180530 15:19:12.861851 15949 server/server.go:784  [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled\nI180530 15:19:12.893615 15949 server/config.go:539  [n?] 1 storage engine initialized\nI180530 15:19:12.893824 15949 server/config.go:542  [n?] RocksDB cache size: 128 MiB\nI180530 15:19:12.893873 15949 server/config.go:542  [n?] store 0: in-memory, size 0 B\nW180530 15:19:12.894278 15949 gossip/gossip.go:1293  [n?] no incoming or outgoing connections\nI180530 15:19:12.914725 15949 server/server.go:1360  [n?] no stores bootstrapped and --join flag specified, awaiting init command.\nI180530 15:19:13.052892 16732 gossip/client.go:129  [n?] started gossip client to 127.0.0.1:36071\nI180530 15:19:13.056720 16809 gossip/server.go:219  [n1] received initial cluster-verification connection from {tcp 127.0.0.1:38845}\nI180530 15:19:13.072184 15949 storage/stores.go:222  [n?] read 0 node addresses from persistent storage\nI180530 15:19:13.072756 15949 storage/stores.go:241  [n?] wrote 2 node addresses to persistent storage\nI180530 15:19:13.072931 15949 server/node.go:647  [n?] connecting to gossip network to verify cluster ID...\nI180530 15:19:13.073157 15949 server/node.go:672  [n?] node connected via gossip and verified as part of cluster \"8410f8b5-6176-43eb-a107-9719eb4222ff\"\nI180530 15:19:13.089893 15949 kv/dist_sender.go:368  [n?] unable to determine this node's attributes for replica selection; node is most likely bootstrapping\nI180530 15:19:13.100040 15949 server/node.go:347  [n?] new node allocated ID 3\nI180530 15:19:13.100738 15949 gossip/gossip.go:333  [n3] NodeDescriptor set to node_id:3 address:<network_field:\"tcp\" address_field:\"127.0.0.1:38845\" > attrs:<> locality:<> ServerVersion:<major_val:2 minor_val:0 patch:0 unstable:5 > \nI180530 15:19:13.101696 15949 server/node.go:421  [n3] node=3: asynchronously bootstrapping engine(s) [<no-attributes>=<in-mem>]\nI180530 15:19:13.102521 15949 server/node.go:440  [n3] node=3: started with [] engine(s) and attributes []\nI180530 15:19:13.110696 15949 server/server.go:1485  [n3] starting https server at 127.0.0.1:41947\nI180530 15:19:13.113633 15949 server/server.go:1486  [n3] starting grpc/postgres server at 127.0.0.1:38845\nI180530 15:19:13.113760 15949 server/server.go:1487  [n3] advertising CockroachDB node at 127.0.0.1:38845\nI180530 15:19:13.166860 16781 storage/stores.go:241  [n1] wrote 2 node addresses to persistent storage\nI180530 15:19:13.178143 16784 storage/stores.go:241  [n2] wrote 2 node addresses to persistent storage\nI180530 15:19:13.193692 15949 server/server.go:1564  [n3] done ensuring all necessary migrations have run\nI180530 15:19:13.193906 15949 server/server.go:1567  [n3] serving sql connections\nI180530 15:19:13.229978 17021 server/node.go:628  [n3] bootstrapped store [n3,s3]\nI180530 15:19:13.316588 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r10/1:/Table/1{3-4}] generated preemptive snapshot 240d3214 at index 38\nI180530 15:19:13.385158 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:13.411829 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:13.475760 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:13.520296 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:13.588175 17057 sql/event_log.go:126  [n3] Event: \"node_join\", target: 3, info: {Descriptor:{NodeID:3 Address:{NetworkField:tcp AddressField:127.0.0.1:38845} Attrs: Locality: ServerVersion:2.0-5} ClusterID:8410f8b5-6176-43eb-a107-9719eb4222ff StartedAt:1527693553102055106 LastUp:1527693553102055106}\nI180530 15:19:13.591372 17055 server/server_update.go:66  [n3] no need to upgrade, cluster already at the newest version\nI180530 15:19:13.597194 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r10/1:/Table/1{3-4}] streamed snapshot to (n2,s2):?: kv pairs: 133, log entries: 28, rate-limit: 8.0 MiB/sec, 16ms\nI180530 15:19:13.601423 17033 storage/replica_raftstorage.go:730  [n2,s2,r10/?:{-}] applying preemptive snapshot at index 38 (id=240d3214, encoded size=33103, 1 rocksdb batches, 28 log entries)\nI180530 15:19:13.609086 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:13.612872 17033 storage/replica_raftstorage.go:736  [n2,s2,r10/?:/Table/1{3-4}] applied preemptive snapshot in 11ms [clear=0ms batch=0ms entries=8ms commit=2ms]\nI180530 15:19:13.617792 16262 storage/replica_command.go:1777  [replicate,n1,s1,r10/1:/Table/1{3-4}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r10:/Table/1{3-4} [(n1,s1):1, next=2]\nI180530 15:19:13.681763 16262 storage/replica.go:3320  [n1,s1,r10/1:/Table/1{3-4}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:13.689133 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r6/1:/{System/tse-Table/System\u2026}] generated preemptive snapshot a4ef4294 at index 20\nI180530 15:19:13.706135 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:13.746871 17191 storage/raft_transport.go:459  [n2] raft transport stream to node 1 established\nI180530 15:19:13.829198 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:13.909261 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r6/1:/{System/tse-Table/System\u2026}] streamed snapshot to (n3,s3):?: kv pairs: 9, log entries: 10, rate-limit: 8.0 MiB/sec, 5ms\nI180530 15:19:13.921704 17250 storage/replica_raftstorage.go:730  [n3,s3,r6/?:{-}] applying preemptive snapshot at index 20 (id=a4ef4294, encoded size=4161, 1 rocksdb batches, 10 log entries)\nI180530 15:19:13.932641 17250 storage/replica_raftstorage.go:736  [n3,s3,r6/?:/{System/tse-Table/System\u2026}] applied preemptive snapshot in 8ms [clear=0ms batch=0ms entries=4ms commit=3ms]\nI180530 15:19:13.937264 16262 storage/replica_command.go:1777  [replicate,n1,s1,r6/1:/{System/tse-Table/System\u2026}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r6:/{System/tse-Table/SystemConfigSpan/Start} [(n1,s1):1, next=2]\nI180530 15:19:13.947593 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.001582 16262 storage/replica.go:3320  [n1,s1,r6/1:/{System/tse-Table/System\u2026}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:14.009607 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r1/1:/{Min-System/}] generated preemptive snapshot 06d120a3 at index 75\nI180530 15:19:14.037197 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r1/1:/{Min-System/}] streamed snapshot to (n3,s3):?: kv pairs: 58, log entries: 49, rate-limit: 8.0 MiB/sec, 10ms\nI180530 15:19:14.063135 17252 storage/replica_raftstorage.go:730  [n3,s3,r1/?:{-}] applying preemptive snapshot at index 75 (id=06d120a3, encoded size=65946, 1 rocksdb batches, 49 log entries)\nI180530 15:19:14.068428 17215 storage/raft_transport.go:459  [n3] raft transport stream to node 1 established\nI180530 15:19:14.108369 17252 storage/replica_raftstorage.go:736  [n3,s3,r1/?:/{Min-System/}] applied preemptive snapshot in 45ms [clear=0ms batch=0ms entries=41ms commit=3ms]\nI180530 15:19:14.116277 16262 storage/replica_command.go:1777  [replicate,n1,s1,r1/1:/{Min-System/}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r1:/{Min-System/} [(n1,s1):1, next=2]\nI180530 15:19:14.130083 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.234353 16262 storage/replica.go:3320  [n1,s1,r1/1:/{Min-System/}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:14.260560 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r16/1:/Table/{19-20}] generated preemptive snapshot 94fd34a3 at index 17\nI180530 15:19:14.266952 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.300289 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r16/1:/Table/{19-20}] streamed snapshot to (n2,s2):?: kv pairs: 8, log entries: 7, rate-limit: 8.0 MiB/sec, 39ms\nI180530 15:19:14.320590 17198 storage/replica_raftstorage.go:730  [n2,s2,r16/?:{-}] applying preemptive snapshot at index 17 (id=94fd34a3, encoded size=2244, 1 rocksdb batches, 7 log entries)\nI180530 15:19:14.324137 17198 storage/replica_raftstorage.go:736  [n2,s2,r16/?:/Table/{19-20}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=1ms]\nI180530 15:19:14.343284 16262 storage/replica_command.go:1777  [replicate,n1,s1,r16/1:/Table/{19-20}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r16:/Table/{19-20} [(n1,s1):1, next=2]\nI180530 15:19:14.357851 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.441305 16262 storage/replica.go:3320  [n1,s1,r16/1:/Table/{19-20}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:14.459483 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.462834 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r17/1:/Table/2{0-1}] generated preemptive snapshot 29c086a3 at index 17\nI180530 15:19:14.472282 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r17/1:/Table/2{0-1}] streamed snapshot to (n2,s2):?: kv pairs: 8, log entries: 7, rate-limit: 8.0 MiB/sec, 8ms\nI180530 15:19:14.475783 17200 storage/replica_raftstorage.go:730  [n2,s2,r17/?:{-}] applying preemptive snapshot at index 17 (id=29c086a3, encoded size=2244, 1 rocksdb batches, 7 log entries)\nI180530 15:19:14.478734 17200 storage/replica_raftstorage.go:736  [n2,s2,r17/?:/Table/2{0-1}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:14.483261 16262 storage/replica_command.go:1777  [replicate,n1,s1,r17/1:/Table/2{0-1}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r17:/Table/2{0-1} [(n1,s1):1, next=2]\nI180530 15:19:14.525548 16205 storage/replica_proposal.go:202  [n1,s1,r7/1:/Table/{SystemCon\u2026-11}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693554.518551213,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:14.569715 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.616927 16225 storage/replica_proposal.go:202  [n1,s1,r10/1:/Table/1{3-4}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693554.575694432,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:14.675791 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.682337 16232 storage/replica_proposal.go:202  [n1,s1,r17/1:/Table/2{0-1}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693554.667372542,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:14.690995 16262 storage/replica.go:3320  [n1,s1,r17/1:/Table/2{0-1}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:14.750453 16240 storage/replica_proposal.go:202  [n1,s1,r21/1:/Table/5{0-1}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693554.706153302,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:14.787368 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r21/1:/Table/5{0-1}] generated preemptive snapshot a745b0c4 at index 16\nI180530 15:19:14.790156 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.794607 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r21/1:/Table/5{0-1}] streamed snapshot to (n3,s3):?: kv pairs: 7, log entries: 6, rate-limit: 8.0 MiB/sec, 5ms\nI180530 15:19:14.798167 17246 storage/replica_raftstorage.go:730  [n3,s3,r21/?:{-}] applying preemptive snapshot at index 16 (id=a745b0c4, encoded size=2084, 1 rocksdb batches, 6 log entries)\nI180530 15:19:14.804077 17246 storage/replica_raftstorage.go:736  [n3,s3,r21/?:/Table/5{0-1}] applied preemptive snapshot in 6ms [clear=0ms batch=0ms entries=1ms commit=2ms]\nI180530 15:19:14.812372 16262 storage/replica_command.go:1777  [replicate,n1,s1,r21/1:/Table/5{0-1}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r21:/Table/5{0-1} [(n1,s1):1, next=2]\nI180530 15:19:14.883623 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:14.906423 16262 storage/replica.go:3320  [n1,s1,r21/1:/Table/5{0-1}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:14.961454 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r3/1:/System/NodeLiveness{-Max}] generated preemptive snapshot 34ddc90c at index 26\nI180530 15:19:14.968361 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r3/1:/System/NodeLiveness{-Max}] streamed snapshot to (n2,s2):?: kv pairs: 13, log entries: 16, rate-limit: 8.0 MiB/sec, 6ms\nI180530 15:19:14.988731 17248 storage/replica_raftstorage.go:730  [n2,s2,r3/?:{-}] applying preemptive snapshot at index 26 (id=34ddc90c, encoded size=5362, 1 rocksdb batches, 16 log entries)\nI180530 15:19:14.995406 17248 storage/replica_raftstorage.go:736  [n2,s2,r3/?:/System/NodeLiveness{-Max}] applied preemptive snapshot in 6ms [clear=0ms batch=0ms entries=3ms commit=2ms]\nI180530 15:19:15.009512 16262 storage/replica_command.go:1777  [replicate,n1,s1,r3/1:/System/NodeLiveness{-Max}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r3:/System/NodeLiveness{-Max} [(n1,s1):1, next=2]\nI180530 15:19:15.012288 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.026210 17068 storage/replica_proposal.go:202  [n3,s3,r6/2:/{System/tse-Table/System\u2026}] new range lease repl=(n3,s3):2 seq=3 start=1527693554.995637914,1 epo=1 pro=1527693555.011665767,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:15.075596 17249 storage/replica_raftstorage.go:520  [replicate,n3,s3,r6/2:/{System/tse-Table/System\u2026}] generated preemptive snapshot ce6400f7 at index 24\nI180530 15:19:15.145493 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.182855 16881 storage/replica_proposal.go:202  [n2,s2,r16/2:/Table/{19-20}] new range lease repl=(n2,s2):2 seq=3 start=1527693554.995637914,1 epo=1 pro=1527693555.043261149,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:15.189594 17280 storage/replica_raftstorage.go:520  [replicate,n2,s2,r16/2:/Table/{19-20}] generated preemptive snapshot 1972878b at index 21\nI180530 15:19:15.240730 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.255974 16262 storage/replica.go:3320  [n1,s1,r3/1:/System/NodeLiveness{-Max}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:15.275573 16108 storage/replica_proposal.go:202  [n1,s1,r19/1:/Table/2{2-3}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693555.261751420,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:15.289746 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r19/1:/Table/2{2-3}] generated preemptive snapshot ecd352ea at index 18\nI180530 15:19:15.312372 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r19/1:/Table/2{2-3}] streamed snapshot to (n3,s3):?: kv pairs: 8, log entries: 8, rate-limit: 8.0 MiB/sec, 22ms\nI180530 15:19:15.336913 17350 storage/replica_raftstorage.go:730  [n3,s3,r19/?:{-}] applying preemptive snapshot at index 18 (id=ecd352ea, encoded size=2411, 1 rocksdb batches, 8 log entries)\nI180530 15:19:15.338353 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.340029 17350 storage/replica_raftstorage.go:736  [n3,s3,r19/?:/Table/2{2-3}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:15.347852 16262 storage/replica_command.go:1777  [replicate,n1,s1,r19/1:/Table/2{2-3}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r19:/Table/2{2-3} [(n1,s1):1, next=2]\nI180530 15:19:15.416660 17249 storage/store_snapshot.go:605  [replicate,n3,s3,r6/2:/{System/tse-Table/System\u2026}] streamed snapshot to (n2,s2):?: kv pairs: 10, log entries: 14, rate-limit: 8.0 MiB/sec, 12ms\nI180530 15:19:15.419924 17291 storage/replica_raftstorage.go:730  [n2,s2,r6/?:{-}] applying preemptive snapshot at index 24 (id=ce6400f7, encoded size=5403, 1 rocksdb batches, 14 log entries)\nI180530 15:19:15.424514 17291 storage/replica_raftstorage.go:736  [n2,s2,r6/?:/{System/tse-Table/System\u2026}] applied preemptive snapshot in 4ms [clear=0ms batch=0ms entries=2ms commit=1ms]\nI180530 15:19:15.441703 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.481619 16262 storage/replica.go:3320  [n1,s1,r19/1:/Table/2{2-3}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:15.493332 17280 storage/store_snapshot.go:605  [replicate,n2,s2,r16/2:/Table/{19-20}] streamed snapshot to (n3,s3):?: kv pairs: 9, log entries: 11, rate-limit: 8.0 MiB/sec, 5ms\nI180530 15:19:15.496735 17430 storage/replica_raftstorage.go:730  [n3,s3,r16/?:{-}] applying preemptive snapshot at index 21 (id=1972878b, encoded size=3447, 1 rocksdb batches, 11 log entries)\nI180530 15:19:15.500514 17430 storage/replica_raftstorage.go:736  [n3,s3,r16/?:/Table/{19-20}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=2ms commit=0ms]\nI180530 15:19:15.520171 16203 storage/replica_proposal.go:202  [n1,s1,r8/1:/Table/1{1-2}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693555.506546988,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:15.568844 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r8/1:/Table/1{1-2}] generated preemptive snapshot 8df5b6a3 at index 19\nI180530 15:19:15.581845 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r8/1:/Table/1{1-2}] streamed snapshot to (n3,s3):?: kv pairs: 8, log entries: 9, rate-limit: 8.0 MiB/sec, 6ms\nI180530 15:19:15.590030 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.592528 17390 storage/replica_raftstorage.go:730  [n3,s3,r8/?:{-}] applying preemptive snapshot at index 19 (id=8df5b6a3, encoded size=3633, 1 rocksdb batches, 9 log entries)\nI180530 15:19:15.598644 17390 storage/replica_raftstorage.go:736  [n3,s3,r8/?:/Table/1{1-2}] applied preemptive snapshot in 6ms [clear=0ms batch=0ms entries=4ms commit=1ms]\nI180530 15:19:15.605802 16262 storage/replica_command.go:1777  [replicate,n1,s1,r8/1:/Table/1{1-2}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r8:/Table/1{1-2} [(n1,s1):1, next=2]\nI180530 15:19:15.607197 17280 storage/replica_command.go:1777  [replicate,n2,s2,r16/2:/Table/{19-20}] change replicas (ADD_REPLICA (n3,s3):3): read existing descriptor r16:/Table/{19-20} [(n1,s1):1, (n2,s2):2, next=3]\nI180530 15:19:15.624410 17249 storage/replica_command.go:1777  [replicate,n3,s3,r6/2:/{System/tse-Table/System\u2026}] change replicas (ADD_REPLICA (n2,s2):3): read existing descriptor r6:/{System/tse-Table/SystemConfigSpan/Start} [(n1,s1):1, (n3,s3):2, next=3]\nI180530 15:19:15.663746 17343 storage/store.go:2496  [replicaGC,n2,s2,r6/?:/{System/tse-Table/System\u2026}] removing replica\nI180530 15:19:15.666004 17343 storage/replica.go:829  [replicaGC,n2,s2,r6/?:/{System/tse-Table/System\u2026}] removed 7 (0+7) keys in 1ms [clear=0ms commit=1ms]\nI180530 15:19:15.745223 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.850882 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:15.862416 16262 storage/replica.go:3320  [n1,s1,r8/1:/Table/1{1-2}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:15.966611 16104 storage/replica_proposal.go:202  [n1,s1,r11/1:/Table/1{4-5}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693555.880917474,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:16.065504 15968 server/status/runtime.go:219  [n1] runtime stats: 1.2 GiB RSS, 586 goroutines, 52 MiB/53 MiB/134 MiB GO alloc/idle/total, 84 MiB/114 MiB CGO alloc/total, 0.00cgo/sec, 0.00/0.00 %(u/s)time, 0.00 %gc (100x)\nI180530 15:19:16.086779 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r11/1:/Table/1{4-5}] generated preemptive snapshot e14d2565 at index 18\nI180530 15:19:16.092083 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:16.105582 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r11/1:/Table/1{4-5}] streamed snapshot to (n2,s2):?: kv pairs: 8, log entries: 8, rate-limit: 8.0 MiB/sec, 18ms\nI180530 15:19:16.109909 17376 storage/replica_raftstorage.go:730  [n2,s2,r11/?:{-}] applying preemptive snapshot at index 18 (id=e14d2565, encoded size=2576, 1 rocksdb batches, 8 log entries)\nI180530 15:19:16.113311 17376 storage/replica_raftstorage.go:736  [n2,s2,r11/?:/Table/1{4-5}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:16.129274 16262 storage/replica_command.go:1777  [replicate,n1,s1,r11/1:/Table/1{4-5}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r11:/Table/1{4-5} [(n1,s1):1, next=2]\nI180530 15:19:16.216024 17523 storage/replica.go:3320  [n3,s3,r6/2:/{System/tse-Table/System\u2026}] proposing ADD_REPLICA((n2,s2):3): updated=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4\nI180530 15:19:16.216707 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 22 underreplicated ranges\nI180530 15:19:16.329308 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 21 underreplicated ranges\nI180530 15:19:16.332950 17473 storage/replica.go:3320  [n2,s2,r16/2:/Table/{19-20}] proposing ADD_REPLICA((n3,s3):3): updated=[(n1,s1):1 (n2,s2):2 (n3,s3):3] next=4\nI180530 15:19:16.342594 16262 storage/replica.go:3320  [n1,s1,r11/1:/Table/1{4-5}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:16.422621 16222 storage/replica_proposal.go:202  [n1,s1,r5/1:/System/ts{d-e}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693556.373734779,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:16.437627 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:16.454992 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r5/1:/System/ts{d-e}] generated preemptive snapshot 7d04c8b3 at index 26\nI180530 15:19:16.567580 17509 storage/replica_raftstorage.go:520  [raftsnapshot,n3,s3,r6/2:/{System/tse-Table/System\u2026}] generated Raft snapshot bf8cad7c at index 28\nI180530 15:19:16.571636 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nW180530 15:19:16.593706 16258 server/node.go:802  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:20} {StoreID:1 Category:METRICS Description:queue.replicate.process.failure Value:311}]}\nI180530 15:19:16.594381 17509 storage/store_snapshot.go:605  [raftsnapshot,n3,s3,r6/2:/{System/tse-Table/System\u2026}] streamed snapshot to (n2,s2):3: kv pairs: 11, log entries: 18, rate-limit: 8.0 MiB/sec, 25ms\nI180530 15:19:16.597017 17512 storage/replica_raftstorage.go:730  [n2,s2,r6/3:{-}] applying Raft snapshot at index 28 (id=bf8cad7c, encoded size=6641, 1 rocksdb batches, 18 log entries)\nI180530 15:19:16.605567 17512 storage/replica_raftstorage.go:736  [n2,s2,r6/3:/{System/tse-Table/System\u2026}] applied Raft snapshot in 8ms [clear=0ms batch=0ms entries=3ms commit=1ms]\nI180530 15:19:16.612276 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r5/1:/System/ts{d-e}] streamed snapshot to (n2,s2):?: kv pairs: 966, log entries: 3, rate-limit: 8.0 MiB/sec, 156ms\nI180530 15:19:16.606731 16244 storage/replica_proposal.go:202  [n1,s1,r4/1:/System/{NodeLive\u2026-tsd}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693556.599121470,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:16.618038 17559 storage/replica_raftstorage.go:730  [n2,s2,r5/?:{-}] applying preemptive snapshot at index 26 (id=7d04c8b3, encoded size=130039, 1 rocksdb batches, 3 log entries)\nI180530 15:19:16.669952 17559 storage/replica_raftstorage.go:736  [n2,s2,r5/?:/System/ts{d-e}] applied preemptive snapshot in 52ms [clear=0ms batch=1ms entries=21ms commit=28ms]\nI180530 15:19:16.687736 16262 storage/replica_command.go:1777  [replicate,n1,s1,r5/1:/System/ts{d-e}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r5:/System/ts{d-e} [(n1,s1):1, next=2]\nI180530 15:19:16.690942 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:16.780346 16262 storage/replica.go:3320  [n1,s1,r5/1:/System/ts{d-e}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:16.829604 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:16.834246 16221 storage/replica_proposal.go:202  [n1,s1,r20/1:/Table/{23-50}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693556.814197632,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:16.846611 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r20/1:/Table/{23-50}] generated preemptive snapshot 93fc0c54 at index 16\nI180530 15:19:16.867249 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r20/1:/Table/{23-50}] streamed snapshot to (n3,s3):?: kv pairs: 11, log entries: 6, rate-limit: 8.0 MiB/sec, 20ms\nI180530 15:19:16.871180 17546 storage/replica_raftstorage.go:730  [n3,s3,r20/?:{-}] applying preemptive snapshot at index 16 (id=93fc0c54, encoded size=2243, 1 rocksdb batches, 6 log entries)\nI180530 15:19:16.880902 17546 storage/replica_raftstorage.go:736  [n3,s3,r20/?:/Table/{23-50}] applied preemptive snapshot in 9ms [clear=0ms batch=0ms entries=2ms commit=6ms]\nI180530 15:19:16.889684 16262 storage/replica_command.go:1777  [replicate,n1,s1,r20/1:/Table/{23-50}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r20:/Table/{23-50} [(n1,s1):1, next=2]\nI180530 15:19:16.952816 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.012597 16262 storage/replica.go:3320  [n1,s1,r20/1:/Table/{23-50}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:17.034919 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r4/1:/System/{NodeLive\u2026-tsd}] generated preemptive snapshot b81d8bad at index 43\nI180530 15:19:17.051458 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.061836 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r4/1:/System/{NodeLive\u2026-tsd}] streamed snapshot to (n3,s3):?: kv pairs: 37, log entries: 2, rate-limit: 8.0 MiB/sec, 26ms\nI180530 15:19:17.079415 17618 storage/replica_raftstorage.go:730  [n3,s3,r4/?:{-}] applying preemptive snapshot at index 43 (id=b81d8bad, encoded size=69324, 1 rocksdb batches, 2 log entries)\nI180530 15:19:17.098084 17618 storage/replica_raftstorage.go:736  [n3,s3,r4/?:/System/{NodeLive\u2026-tsd}] applied preemptive snapshot in 17ms [clear=0ms batch=0ms entries=5ms commit=11ms]\nI180530 15:19:17.105847 16262 storage/replica_command.go:1777  [replicate,n1,s1,r4/1:/System/{NodeLive\u2026-tsd}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r4:/System/{NodeLivenessMax-tsd} [(n1,s1):1, next=2]\nI180530 15:19:17.199707 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.227290 16262 storage/replica.go:3320  [n1,s1,r4/1:/System/{NodeLive\u2026-tsd}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:17.238544 16113 storage/replica_proposal.go:202  [n1,s1,r9/1:/Table/1{2-3}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693557.233251510,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:17.247805 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r9/1:/Table/1{2-3}] generated preemptive snapshot e2530010 at index 32\nI180530 15:19:17.262662 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r9/1:/Table/1{2-3}] streamed snapshot to (n2,s2):?: kv pairs: 53, log entries: 22, rate-limit: 8.0 MiB/sec, 13ms\nI180530 15:19:17.274347 17503 storage/replica_raftstorage.go:730  [n2,s2,r9/?:{-}] applying preemptive snapshot at index 32 (id=e2530010, encoded size=17182, 1 rocksdb batches, 22 log entries)\nI180530 15:19:17.317046 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.340531 17503 storage/replica_raftstorage.go:736  [n2,s2,r9/?:/Table/1{2-3}] applied preemptive snapshot in 66ms [clear=0ms batch=0ms entries=7ms commit=57ms]\nI180530 15:19:17.346762 16262 storage/replica_command.go:1777  [replicate,n1,s1,r9/1:/Table/1{2-3}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r9:/Table/1{2-3} [(n1,s1):1, next=2]\nI180530 15:19:17.430874 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.483045 16262 storage/replica.go:3320  [n1,s1,r9/1:/Table/1{2-3}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:17.525974 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.527868 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r7/1:/Table/{SystemCon\u2026-11}] generated preemptive snapshot d3f33ab2 at index 32\nI180530 15:19:17.554881 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r7/1:/Table/{SystemCon\u2026-11}] streamed snapshot to (n3,s3):?: kv pairs: 57, log entries: 22, rate-limit: 8.0 MiB/sec, 25ms\nI180530 15:19:17.558194 17666 storage/replica_raftstorage.go:730  [n3,s3,r7/?:{-}] applying preemptive snapshot at index 32 (id=d3f33ab2, encoded size=15980, 1 rocksdb batches, 22 log entries)\nI180530 15:19:17.573081 17666 storage/replica_raftstorage.go:736  [n3,s3,r7/?:/Table/{SystemCon\u2026-11}] applied preemptive snapshot in 14ms [clear=9ms batch=0ms entries=4ms commit=1ms]\nI180530 15:19:17.598275 16262 storage/replica_command.go:1777  [replicate,n1,s1,r7/1:/Table/{SystemCon\u2026-11}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r7:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2]\nI180530 15:19:17.662957 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.764811 16262 storage/replica.go:3320  [n1,s1,r7/1:/Table/{SystemCon\u2026-11}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:17.787723 16240 storage/replica_proposal.go:202  [n1,s1,r12/1:/Table/1{5-6}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693557.783063381,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:17.791433 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.801459 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r12/1:/Table/1{5-6}] generated preemptive snapshot f4a1168a at index 18\nI180530 15:19:17.827920 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r12/1:/Table/1{5-6}] streamed snapshot to (n2,s2):?: kv pairs: 8, log entries: 8, rate-limit: 8.0 MiB/sec, 13ms\nI180530 15:19:17.831563 17640 storage/replica_raftstorage.go:730  [n2,s2,r12/?:{-}] applying preemptive snapshot at index 18 (id=f4a1168a, encoded size=2580, 1 rocksdb batches, 8 log entries)\nI180530 15:19:17.834979 17640 storage/replica_raftstorage.go:736  [n2,s2,r12/?:/Table/1{5-6}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:17.841716 16262 storage/replica_command.go:1777  [replicate,n1,s1,r12/1:/Table/1{5-6}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r12:/Table/1{5-6} [(n1,s1):1, next=2]\nI180530 15:19:17.887324 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:17.942895 16262 storage/replica.go:3320  [n1,s1,r12/1:/Table/1{5-6}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:17.983471 16201 storage/replica_proposal.go:202  [n1,s1,r13/1:/Table/1{6-7}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693557.974610668,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:18.011559 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r13/1:/Table/1{6-7}] generated preemptive snapshot 0ab25bb2 at index 18\nI180530 15:19:18.016889 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.017686 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r13/1:/Table/1{6-7}] streamed snapshot to (n3,s3):?: kv pairs: 8, log entries: 8, rate-limit: 8.0 MiB/sec, 5ms\nI180530 15:19:18.022850 17685 storage/replica_raftstorage.go:730  [n3,s3,r13/?:{-}] applying preemptive snapshot at index 18 (id=0ab25bb2, encoded size=2415, 1 rocksdb batches, 8 log entries)\nI180530 15:19:18.026082 17685 storage/replica_raftstorage.go:736  [n3,s3,r13/?:/Table/1{6-7}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:18.035532 16262 storage/replica_command.go:1777  [replicate,n1,s1,r13/1:/Table/1{6-7}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r13:/Table/1{6-7} [(n1,s1):1, next=2]\nI180530 15:19:18.104057 16262 storage/replica.go:3320  [n1,s1,r13/1:/Table/1{6-7}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:18.129472 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.140219 16236 storage/replica_proposal.go:202  [n1,s1,r14/1:/Table/1{7-8}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693558.111350949,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:18.146775 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r14/1:/Table/1{7-8}] generated preemptive snapshot 70db692e at index 18\nI180530 15:19:18.201436 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r14/1:/Table/1{7-8}] streamed snapshot to (n2,s2):?: kv pairs: 8, log entries: 8, rate-limit: 8.0 MiB/sec, 23ms\nI180530 15:19:18.204968 17687 storage/replica_raftstorage.go:730  [n2,s2,r14/?:{-}] applying preemptive snapshot at index 18 (id=70db692e, encoded size=2576, 1 rocksdb batches, 8 log entries)\nI180530 15:19:18.213433 17687 storage/replica_raftstorage.go:736  [n2,s2,r14/?:/Table/1{7-8}] applied preemptive snapshot in 8ms [clear=0ms batch=0ms entries=6ms commit=1ms]\nI180530 15:19:18.227457 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.229554 16262 storage/replica_command.go:1777  [replicate,n1,s1,r14/1:/Table/1{7-8}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r14:/Table/1{7-8} [(n1,s1):1, next=2]\nI180530 15:19:18.321560 16262 storage/replica.go:3320  [n1,s1,r14/1:/Table/1{7-8}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:18.326188 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.344965 16195 storage/replica_proposal.go:202  [n1,s1,r15/1:/Table/1{8-9}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693558.334871707,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:18.350113 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r15/1:/Table/1{8-9}] generated preemptive snapshot 1d40f163 at index 18\nI180530 15:19:18.386864 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r15/1:/Table/1{8-9}] streamed snapshot to (n3,s3):?: kv pairs: 8, log entries: 8, rate-limit: 8.0 MiB/sec, 35ms\nI180530 15:19:18.391171 17705 storage/replica_raftstorage.go:730  [n3,s3,r15/?:{-}] applying preemptive snapshot at index 18 (id=1d40f163, encoded size=2415, 1 rocksdb batches, 8 log entries)\nI180530 15:19:18.394664 17705 storage/replica_raftstorage.go:736  [n3,s3,r15/?:/Table/1{8-9}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:18.401800 16262 storage/replica_command.go:1777  [replicate,n1,s1,r15/1:/Table/1{8-9}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r15:/Table/1{8-9} [(n1,s1):1, next=2]\nI180530 15:19:18.452171 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.466656 16262 storage/replica.go:3320  [n1,s1,r15/1:/Table/1{8-9}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:18.492135 16229 storage/replica_proposal.go:202  [n1,s1,r18/1:/Table/2{1-2}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693558.472565979,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:18.523171 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r18/1:/Table/2{1-2}] generated preemptive snapshot 3b11d67e at index 18\nI180530 15:19:18.534083 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r18/1:/Table/2{1-2}] streamed snapshot to (n2,s2):?: kv pairs: 8, log entries: 8, rate-limit: 8.0 MiB/sec, 7ms\nI180530 15:19:18.538383 17613 storage/replica_raftstorage.go:730  [n2,s2,r18/?:{-}] applying preemptive snapshot at index 18 (id=3b11d67e, encoded size=2411, 1 rocksdb batches, 8 log entries)\nI180530 15:19:18.552621 17613 storage/replica_raftstorage.go:736  [n2,s2,r18/?:/Table/2{1-2}] applied preemptive snapshot in 14ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:18.565547 16262 storage/replica_command.go:1777  [replicate,n1,s1,r18/1:/Table/2{1-2}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r18:/Table/2{1-2} [(n1,s1):1, next=2]\nI180530 15:19:18.572260 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.661190 16262 storage/replica.go:3320  [n1,s1,r18/1:/Table/2{1-2}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:18.675140 16103 storage/replica_proposal.go:202  [n1,s1,r22/1:/{Table/51-Max}] new range lease repl=(n1,s1):1 seq=3 start=1527693545.941879893,0 epo=1 pro=1527693558.667192860,0 following repl=(n1,s1):1 seq=2 start=1527693545.941879893,0 exp=1527693554.995637914,0 pro=1527693545.995723382,0\nI180530 15:19:18.687671 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.711577 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r22/1:/{Table/51-Max}] generated preemptive snapshot cfaff468 at index 12\nI180530 15:19:18.735663 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r22/1:/{Table/51-Max}] streamed snapshot to (n2,s2):?: kv pairs: 6, log entries: 2, rate-limit: 8.0 MiB/sec, 17ms\nI180530 15:19:18.748158 17696 storage/replica_raftstorage.go:730  [n2,s2,r22/?:{-}] applying preemptive snapshot at index 12 (id=cfaff468, encoded size=465, 1 rocksdb batches, 2 log entries)\nI180530 15:19:18.751237 17696 storage/replica_raftstorage.go:736  [n2,s2,r22/?:/{Table/51-Max}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=0ms commit=1ms]\nI180530 15:19:18.775812 16262 storage/replica_command.go:1777  [replicate,n1,s1,r22/1:/{Table/51-Max}] change replicas (ADD_REPLICA (n2,s2):2): read existing descriptor r22:/{Table/51-Max} [(n1,s1):1, next=2]\nI180530 15:19:18.797567 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.927611 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:18.971694 16262 storage/replica.go:3320  [n1,s1,r22/1:/{Table/51-Max}] proposing ADD_REPLICA((n2,s2):2): updated=[(n1,s1):1 (n2,s2):2] next=3\nI180530 15:19:19.013901 16262 storage/replica_raftstorage.go:520  [replicate,n1,s1,r2/1:/System/{-NodeLive\u2026}] generated preemptive snapshot d0271aca at index 24\nI180530 15:19:19.036887 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:19.046783 16262 storage/store_snapshot.go:605  [replicate,n1,s1,r2/1:/System/{-NodeLive\u2026}] streamed snapshot to (n3,s3):?: kv pairs: 9, log entries: 14, rate-limit: 8.0 MiB/sec, 28ms\nI180530 15:19:19.053516 17757 storage/replica_raftstorage.go:730  [n3,s3,r2/?:{-}] applying preemptive snapshot at index 24 (id=d0271aca, encoded size=5594, 1 rocksdb batches, 14 log entries)\nI180530 15:19:19.076198 17757 storage/replica_raftstorage.go:736  [n3,s3,r2/?:/System/{-NodeLive\u2026}] applied preemptive snapshot in 5ms [clear=0ms batch=0ms entries=3ms commit=1ms]\nI180530 15:19:19.087010 16262 storage/replica_command.go:1777  [replicate,n1,s1,r2/1:/System/{-NodeLive\u2026}] change replicas (ADD_REPLICA (n3,s3):2): read existing descriptor r2:/System/{-NodeLiveness} [(n1,s1):1, next=2]\nI180530 15:19:19.145991 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:19.245232 16262 storage/replica.go:3320  [n1,s1,r2/1:/System/{-NodeLive\u2026}] proposing ADD_REPLICA((n3,s3):2): updated=[(n1,s1):1 (n3,s3):2] next=3\nI180530 15:19:19.265487 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:19.269552 16262 storage/queue.go:864  [n1,replicate] purgatory is now empty\nI180530 15:19:19.280148 17785 storage/replica_raftstorage.go:520  [replicate,n1,s1,r10/1:/Table/1{3-4}] generated preemptive snapshot 4c1fe52c at index 90\nI180530 15:19:19.298004 17785 storage/store_snapshot.go:605  [replicate,n1,s1,r10/1:/Table/1{3-4}] streamed snapshot to (n3,s3):?: kv pairs: 260, log entries: 80, rate-limit: 8.0 MiB/sec, 17ms\nI180530 15:19:19.302734 17760 storage/replica_raftstorage.go:730  [n3,s3,r10/?:{-}] applying preemptive snapshot at index 90 (id=4c1fe52c, encoded size=81955, 1 rocksdb batches, 80 log entries)\nI180530 15:19:19.358626 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:19.405872 17760 storage/replica_raftstorage.go:736  [n3,s3,r10/?:/Table/1{3-4}] applied preemptive snapshot in 103ms [clear=0ms batch=1ms entries=84ms commit=12ms]\nI180530 15:19:19.424187 17785 storage/replica_command.go:1777  [replicate,n1,s1,r10/1:/Table/1{3-4}] change replicas (ADD_REPLICA (n3,s3):3): read existing descriptor r10:/Table/1{3-4} [(n1,s1):1, (n2,s2):2, next=3]\nI180530 15:19:19.461645 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 20 underreplicated ranges\nI180530 15:19:19.512185 17832 storage/replica.go:3320  [n1,s1,r10/1:/Table/1{3-4}] proposing ADD_REPLICA((n3,s3):3): updated=[(n1,s1):1 (n2,s2):2 (n3,s3):3] next=4\nI180530 15:19:19.556691 17842 storage/replica_raftstorage.go:520  [replicate,n1,s1,r2/1:/System/{-NodeLive\u2026}] generated preemptive snapshot 027deaf5 at index 28\nI180530 15:19:19.561460 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 19 underreplicated ranges\nI180530 15:19:19.602736 17842 storage/store_snapshot.go:605  [replicate,n1,s1,r2/1:/System/{-NodeLive\u2026}] streamed snapshot to (n2,s2):?: kv pairs: 10, log entries: 18, rate-limit: 8.0 MiB/sec, 25ms\nI180530 15:19:19.607893 17834 storage/replica_raftstorage.go:730  [n2,s2,r2/?:{-}] applying preemptive snapshot at index 28 (id=027deaf5, encoded size=6893, 1 rocksdb batches, 18 log entries)\nI180530 15:19:19.613117 17834 storage/replica_raftstorage.go:736  [n2,s2,r2/?:/System/{-NodeLive\u2026}] applied preemptive snapshot in 5ms [clear=0ms batch=0ms entries=3ms commit=1ms]\nI180530 15:19:19.618558 17842 storage/replica_command.go:1777  [replicate,n1,s1,r2/1:/System/{-NodeLive\u2026}] change replicas (ADD_REPLICA (n2,s2):3): read existing descriptor r2:/System/{-NodeLiveness} [(n1,s1):1, (n3,s3):2, next=3]\nI180530 15:19:19.659103 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 19 underreplicated ranges\nI180530 15:19:19.703708 17842 storage/replica.go:3320  [n1,s1,r2/1:/System/{-NodeLive\u2026}] proposing ADD_REPLICA((n2,s2):3): updated=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4\nI180530 15:19:19.786769 17862 storage/replica_raftstorage.go:520  [replicate,n1,s1,r22/1:/{Table/51-Max}] generated preemptive snapshot faaf123f at index 17\nI180530 15:19:19.787129 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 18 underreplicated ranges\nI180530 15:19:19.797857 17862 storage/store_snapshot.go:605  [replicate,n1,s1,r22/1:/{Table/51-Max}] streamed snapshot to (n3,s3):?: kv pairs: 8, log entries: 7, rate-limit: 8.0 MiB/sec, 10ms\nI180530 15:19:19.851670 17892 storage/replica_raftstorage.go:730  [n3,s3,r22/?:{-}] applying preemptive snapshot at index 17 (id=faaf123f, encoded size=1800, 1 rocksdb batches, 7 log entries)\nI180530 15:19:19.854825 17892 storage/replica_raftstorage.go:736  [n3,s3,r22/?:/{Table/51-Max}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI180530 15:19:19.860676 17862 storage/replica_command.go:1777  [replicate,n1,s1,r22/1:/{Table/51-Max}] change replicas (ADD_REPLICA (n3,s3):3): read existing descriptor r22:/{Table/51-Max} [(n1,s1):1, (n2,s2):2, next=3]\nI180530 15:19:19.909080 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 18 underreplicated ranges\nI180530 15:19:19.993763 17862 storage/replica.go:3320  [n1,s1,r22/1:/{Table/51-Max}] proposing ADD_REPLICA((n3,s3):3): updated=[(n1,s1):1 (n2,s2):2 (n3,s3):3] next=4\nI180530 15:19:20.020235 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 18 underreplicated ranges\nI180530 15:19:20.033788 17871 storage/replica_raftstorage.go:520  [replicate,n1,s1,r18/1:/Table/2{1-2}] generated preemptive snapshot d420924d at index 21\nI180530 15:19:20.049302 17871 storage/store_snapshot.go:605  [replicate,n1,s1,r18/1:/Table/2{1-2}] streamed snapshot to (n3,s3):?: kv pairs: 9, log entries: 11, rate-limit: 8.0 MiB/sec, 14ms\nI180530 15:19:20.053249 17906 storage/replica_raftstorage.go:730  [n3,s3,r18/?:{-}] applying preemptive snapshot at index 21 (id=d420924d, encoded size=3439, 1 rocksdb batches, 11 log entries)\nI180530 15:19:20.088771 17906 storage/replica_raftstorage.go:736  [n3,s3,r18/?:/Table/2{1-2}] applied preemptive snapshot in 35ms [clear=0ms batch=0ms entries=33ms commit=1ms]\nI180530 15:19:20.097149 17871 storage/replica_command.go:1777  [replicate,n1,s1,r18/1:/Table/2{1-2}] change replicas (ADD_REPLICA (n3,s3):3): read existing descriptor r18:/Table/2{1-2} [(n1,s1):1, (n2,s2):2, next=3]\nI180530 15:19:20.149086 15949 testutils/testcluster/testcluster.go:536  [n1,s1] has 17 underreplicated ranges\nI180530 15:19:20.199451 17871 storage/replica.go:3320  [n1,s1,r18/1:/Table/2{1-2}] proposing ADD_REPLICA((n3,s3):3): updated=[(n1,s1):1 (n2,s2):2 (n3,s3):3] next=4\nI1\n"], "labels": ["O-robot", "C-test-failure"]}
{"project": "dotnet_coreclr", "title": "Test failed: JIT\\Methodical\\tailcall\\_il_dbgdeep_gc\\_il_dbgdeep_gc.cmd", "description": "Job:\ncoreclr-jitstress #20191015.2 Run Test Pri1 Windows_NT arm checked Detail:\n<URL> OS & Arch:\nwindows arm Mode:\nCOMPlus_TieredCompilation=0\nCOMPlus_JitStress=1 Note:\nwe can't run this program on our windows rt 8.1. Log: <CODE> category:correctness\ntheme:gc-stress\nskill-level:intermediate\ncost:medium ", "code": ["JIT\\Methodical\\tailcall\\_il_dbgdeep_gc\\_il_dbgdeep_gc.cmd [FAIL]\n      \n      Assert failure(PID 3684 [0x00000e64], Thread: 14000 [0x36b0]): Consistency check failed: AV in clr at this callstack:\n      ------\n      <no module>! <no symbol> + 0x0 (0x00000000)\n      -----\n      .AV on tid=0x36b0 (14000), cxr=0057DE08, exr=0057DFA8\n      FAILED: false\n      \n      <no module>! <no symbol> + 0x0 (0x00000000)\n          File: f:\\workspace.4\\_work\\1\\s\\src\\vm\\excep.cpp Line: 7590\n          Image: C:\\dotnetbuild\\work\\160a80d4-8632-4dfe-9f89-99e3815072a5\\Payload\\CoreRun.exe\n      \n      \n      Return code:      1\n      Raw output file:      C:\\dotnetbuild\\work\\160a80d4-8632-4dfe-9f89-99e3815072a5\\Work\\3f016667-3c4f-4918-aef6-b4ede053a75c\\Exec\\JIT\\Methodical\\Reports\\JIT.Methodical\\tailcall\\_il_dbgdeep_gc\\_il_dbgdeep_gc.output.txt\n      Raw output:\n      BEGIN EXECUTION\n       \"C:\\dotnetbuild\\work\\160a80d4-8632-4dfe-9f89-99e3815072a5\\Payload\\corerun.exe\" _il_dbgdeep_gc.dll \n      Expected: 100\n      Actual: -1073740286\n      END EXECUTION - FAILED\n      FAILED\n      Test Harness Exitcode is : 1\n"], "labels": ["arch-arm32", "area-CodeGen", "os-windows"]}
{"project": "magento_magento2", "title": "installation sample data", "description": "I have an error when trying to install the sample data : root@magento2-cloud:/var/www/magento2# /var/www/magento2/bin/magento sampledata:install admin [Magento\\Framework\\Exception\\LocalizedException]\nSource class \"\\Magento\\Setup\\Model\\Console\" for \"Magento\\Setup\\Model\\ConsoleLogger\" generation does not exist. maybe i missed something ? Pierre. ", "code": [], "labels": ["Progress: needs update", "PS"]}
{"project": "ClickHouse_ClickHouse", "title": "Insert into from MySQL tables doesn't work when column is nullable", "description": "Describe the bug or unexpected behaviour\nInsert into from MySQL tables doesn't work when column is nullable type and mysql value is NULL\ni get error msg\nHow to reproduce\nmysql table is: <CODE> clickhouse table use ReplacingMergeTree engine,when i insert data use sql:\nINSERT INTO test_clickhouse SELECT * FROM mysql('127.0.0.1:3306', 'test', 'test_mysql', 'admin', '123456') is error:\nDB::Exception: Attempt to read after eof: while converting source column a to destination column b. is ok:\nINSERT INTO(id,name,a) test_clickhouse SELECT id,name,a FROM mysql('127.0.0.1:3306', 'test', 'test_mysql', 'admin', '123456') ", "code": ["CREATE TABLE test_mysql (\nid int(11) unsigned NOT NULL AUTO_INCREMENT,\nname varchar(20) NOT NULL,\na decimal(10,2) DEFAULT NULL,\nb decimal(10,2) DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB ;\n"], "labels": ["bug", "duplicate"]}
{"project": "godotengine_godot", "title": "range type/method does not accept negative values or count down.", "description": "Operating system or device - Godot version:\nWindows 10x 64 Godot Alpha 1 Issue description:\nthe \"range\" type/method does not accept a negative value. It also cannot count down only upwards Steps to reproduce:\ncreate a for loop using the rage method. input negative value or a higher start value and a lower final value. Link to minimal example project:\nexample. for num in range ( 0, -10 ) or for num in range ( 10, 5 ). ", "code": [], "labels": ["archived"]}
{"project": "dotnet_csharplang", "title": "Parallel Inline Tasks", "description": "I suggest this structure to make writing async tasks easier: <CODE> Note: the await block in optional to execute any code after the task completes. WhenAny, WhenEach and WhenAll are optional also.\nThe sync and a wsit can be removed if desling with direct pieces of code that excute imediately without waiting a response from long or slow process. Like internet resopnse. <CODE> this is useful in dividing any function into small parallel tasks to get use of the processor cores, without writing so many functions, each of then will be called one time only. This will encourage us to enhance any code by parallelism.\nOperations on numeric arrays can be SIMD in many cases, but other types of arrays and operations in larg loops can be parallelized. LinQ has AsParallel , but what about other normal loops?.. Can we have loops \"AsParallel\" somehow? This is why I suggested a new structure to make async more readable. Putting a loop un lambda and passing it to the Task.Run( ) may be a solution, but I prefer a more compact syntax.\nAs I said, most of us now has a capable hardware, but most software doesn't make the most of it. If you have 4 loops, 3 ot them are independent but the forth depends on the results ot them, I don't expect you will think of using threads or async to optimize this code, because one minute delay for the user doesn't worth the effort. although the user can be frustrated! I see that easing writing parallel code to make it a habit for programmers worth the effort. I don't mind to change the suggested structure to any better syntax. I only care about finding an easy fast way to tell the compiler how to divide the code into parallel parts, and what are the dependencies between them.\nTo prevent concurrency, c# should give warnings if more than one task tries to change the value of the same variable (or you can suggest a better action). ", "code": ["parallel \n{   \n   task Task1: \n       async {\n         // do something\n        }\n\n        await {\n         // do something\n        } \n\n   task Task2: \n       async {\n         // do something\n        }\n\n        await {\n         // do something\n        } \n    // .................\n\n   task TaskN: \n       async {\n         // do something\n        }\n\n        await {\n         // do something\n        } \n\n   WhenAny\n   {\n         // do something\n   }\n\n   WhenEach\n   {\n         // do something\n   }\n\n   WhenAll\n   {\n         // do something\n   }\n\n}\n\n", "parallel {\n    Task task1{\n         //Do sometjing\n    }\n    Task task2{\n        //Do sometjing\n    }\n}\n"], "labels": ["Feature Request", "Discussion"]}
{"project": "angular_angular", "title": "Form Validator Directives not working", "description": "<CODE> Form Validators directives don't seem to work for implicit FormGroup instances. I've observed this recently with the min and pattern validators. For a field with directive min=\"0\" the value -1 should result in an error and set valid to false. Example Stackblitz Observe how there are no errors and valid is still true. Also observe how e is an accepted value (this looks like default but counter-intuitive behavior) <CODE> ", "code": ["[ ] Regression (a behavior that used to work and stopped working in a new release)\n[x] Bug report  \n[ ] Feature request\n[ ] Documentation issue or request\n[ ] Support request => Please do not submit support request here, instead see https://github.com/angular/angular/blob/master/CONTRIBUTING.md#question\n", "Angular version: 5.2.4\n"], "labels": ["comp: forms"]}
{"project": "twosigma_beakerx", "title": "Table content omitted in TabbedOutputContainerLayout", "description": "\n The table behaves well individually. However the content is ommited, showing \"Table xxx..\" when it is integrated into the TabbedOutputContainter. Output like arrays have the same issue, but the graphs work properly. The file could reproduce the issue is <URL> ", "code": [], "labels": ["Widgets JS", "Bug"]}
{"project": "GoogleChrome_lighthouse", "title": "DevTools Error: You probably have multiple tabs open to the same origin.", "description": "Initial URL: <URL>\nChrome Version: 62.0.3202.94\nError Message: You probably have multiple tabs open to the same origin.\nStack Trace: <CODE> ", "code": ["Error: You probably have multiple tabs open to the same origin.\n    at versions.forEach.ver (chrome-devtools://devtools/remote/serve_file/@4fd852a98d66564c88736c017b0a0b0478e885ad/audits2_worker/audits2_worker_module.js:605:65)\n    at Array.forEach (<anonymous>)\n    at registrations.filter.forEach.reg (chrome-devtools://devtools/remote/serve_file/@4fd852a98d66564c88736c017b0a0b0478e885ad/audits2_worker/audits2_worker_module.js:604:419)\n    at Array.forEach (<anonymous>)\n    at getServiceWorkerRegistrations.then.then.then.then._ (chrome-devtools://devtools/remote/serve_file/@4fd852a98d66564c88736c017b0a0b0478e885ad/audits2_worker/audits2_worker_module.js:604:396)\n    at <anonymous>\n"], "labels": ["duplicate"]}
{"project": "MicrosoftDocs_azure-docs", "title": "Request for WPF/UWP Native Custom Sign-in Screen in XAML", "description": "It would be great if we could develop sign-in forms/screen in XAML for our WPF/UWP apps. Not a fan of having to build a HTML/CSS UI; it is not a great experience. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["active-directory/svc", "triaged", "in-progress", "product-feedback", "cxp"]}
{"project": "ytti_oxidized", "title": "SSH authentication failures on select Cisco ASR 9901 gear", "description": "So I have these Cisco ASR 9901 routers that aren't playing nice with Oxidized and I'm trying to figure out why. In the web interface, Oxidized shows a blue \"never\" connected status.\nThe log (debug enabled) shows: <CODE> I can connect via SSH and run all the same commands successfully using the credentials Oxidized is configured to use. On the router side, I'm seeing: <CODE> Any ideas worth trying? ", "code": ["Starting fetching process for router.domain.com at 2019-07-30 20:38:55 UTC\nConnecting to router.domain.com\nAUTH METHODS::[\"password\", \"keyboard-interactive\"]\nestablishing connection to x.x.x.x:22\nAdded /router.domain.com to the job queue\n2 jobs running in parallel\nconnection established\nnegotiating protocol version\nlocal is `SSH-2.0-Ruby/Net::SSH_5.2.0 x86_64-linux'\nremote is `SSH-2.0-Cisco-2.0'\nsending KEXINIT\nqueueing packet nr 0 type 20 len 1276\nsent 1280 bytes\nread 400 bytes\nreceived packet nr 0 type 20 len 396\ngot KEXINIT from server\nnegotiating algorithms\nnegotiated:\n* kex: ecdh-sha2-nistp521\n* host_key: ssh-dss\n* encryption_server: aes256-ctr\n* encryption_client: aes256-ctr\n* hmac_client: hmac-sha2-512\n* hmac_server: hmac-sha2-512\n* compression_client: none\n* compression_server: none\n* language_client: \n* language_server:\nexchanging keys\nqueueing packet nr 1 type 30 len 148\nsent 152 bytes\nread 656 bytes\nreceived packet nr 1 type 31 len 652\nqueueing packet nr 2 type 21 len 20\nsent 24 bytes\nread 16 bytes\nreceived packet nr 2 type 21 len 12\nbeginning authentication of `oxidized'\nqueueing packet nr 3 type 5 len 28\nsent 96 bytes\nread 96 bytes\nreceived packet nr 3 type 6 len 28\ntrying password\nqueueing packet nr 4 type 50 len 76\nsent 144 bytes\nreceived packet nr 4 type 51 len 28\npassword\npassword failed\nall authorization methods failed (tried password)\nx.x.x.x raised Net::SSH::AuthenticationFailed with msg \"Authentication failed for user oxidized@x.x.x.x\"\nOxidized::SSH failed for router.domain.com\nConfig fetched for router.domain.com at 2019-07-30 20:46:59 UTC\n/router.domain.com status no_connection, retry attempt 3\n0 of 160\n", "%SECURITY-SSHD-3-ERR_GENERAL : Failed to receive User authentication request\n%SECURITY-SSHD-6-INFO_GENERAL : Client closes socket connection\n%SECURITY-SSHD-4-INFO_FAILURE : Failed autentication attempt by user 'oxidized' from 'x.x.x.x' on 'vty0'\n"], "labels": ["triage"]}
{"project": "rancher_rancher", "title": "Stateless go-machine-service", "description": "To support a multi-node Rancher setup and to recover in case the local docker-machine directories are lost or becomes corrupted, we need to support the ability to be able to re-build local docker-machine directories from stored machine configs. ", "code": [], "labels": ["kind/enhancement", "status/to-test"]}
{"project": "Homebrew_legacy-homebrew", "title": "mongodb does not run", "description": "kleisli:~ me$ brew install mongodb\n==> Downloading <URL>\nAlready downloaded: /Library/Caches/Homebrew/mongodb-3.0.6.yosemite.bottle.tar.gz\n==> Pouring mongodb-3.0.6.yosemite.bottle.tar.gz\n==> Caveats\nTo have launchd start mongodb at login:\nln -sfv /usr/local/opt/mongodb/*.plist /Library/LaunchAgents\nThen to load mongodb now:\nlaunchctl load /Library/LaunchAgents/homebrew.mxcl.mongodb.plist\nOr, if you don't want/need launchctl, you can just run:\nmongod --config /usr/local/etc/mongod.conf\n==> Summary\n\ud83c\udf7a  /usr/local/Cellar/mongodb/3.0.6: 17 files, 159M\nkleisli: me$ mongod --config /usr/local/etc/mongod.conf\n-bash: /usr/local/mongodb/bin/mongod: No such file or directory\nkleisli: me$ ", "code": [], "labels": ["user configuration"]}
{"project": "iodide-project_iodide", "title": "cell up / cell down not implemented in menu", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug"]}
{"project": "electron-userland_electron-builder", "title": "Option to use system-installed electrion instead of per-package electron", "description": "I'm trying to package stanfieldr/ghetto-skype for Arch Linux. With v1.5.0, the project is now using electron-builder. I cannot seem to find a way to use the system installed copy of electron. The build system currently pulls an entire copy of electron, bloating the package to ~240mb. Arch has an electron package in the official community repos, which lets us share the large runtime amongst packages that we install, decreasing the overall size of each application significantly in most cases. Is there existing functionality that I've missed, or does this not exist yet? ", "code": [], "labels": ["linux", "question"]}
{"project": "dart-lang_sdk", "title": "co19 test String_a02_t01 writes unicode improperly", "description": "This issue was originally filed by dcarlson@google.com What steps will reproduce the problem? What is the expected output? What do you see instead? Please use labels and text to provide additional information.\nThe test represents unicode values as:\n\u00a0\u00a0String str = \"a\"; //UTF-8;\n\u00a0\u00a0str = str + \"\\x1d02\"; //UTF-16;\n\u00a0\u00a0str = str + \"\\x10000\"; //UTF-32; According to the spec, the \\x notation is only for bytes (2-hex chars), so the test is not producing the content it seems to think it producing. ", "code": [], "labels": ["Type-Defect", "P3"]}
{"project": "golang_go", "title": "io: should TeeReader return an io.ReadCloser?", "description": "io.TeeReader can't be used to wrap an io.ReadCloser as that strips the io.Closer part. io.TeeReader could return an io.ReadCloser though as it could implement the Close method by calling the Close method of the given reader if it is an io.ReadCloser. The question is just what should happen if the given reader is just an io.Reader. In that case I would propose to just do nothing on Close method call as the wrapped io.Reader doesn't need to be closed. IMHO this shouldn't violate the Go 1 compatibility as io.ReadCloser includes io.Reader and so all existing code should continue to work. Thoughts? I'm happy to send a pull request. ", "code": [], "labels": ["NeedsDecision", "Go2"]}
{"project": "osmdroid_osmdroid", "title": "can you provide a algorithm of baidu tile\uff1f", "description": "i need to use baidu tile in android platform\nthanks ", "code": [], "labels": ["waiting for feedback", "question"]}
{"project": "microsoft_vscode", "title": "Test confirmation", "description": "\nNo description provided.\n ", "code": [], "labels": ["confirmed"]}
{"project": "dart-lang_sdk", "title": "The case List.skip(negative) is not described.", "description": "This issue was originally filed by alexe.kaigorodov@gmail.com The description of Iterable<E> skip(int n) does not describe what happens if n<0.\nCurrently it returns an Iterable which is unusable: iterator.moveNext throws RangeError. For early error detection, an error should be thrown when calling to the method skip(negative), and the documentation should reflect that. ", "code": [], "labels": ["area-library", "Type-Enhancement"]}
{"project": "saltstack_salt", "title": "file.managed state should not download a file if the checksum did not change", "description": "When using the file.managed state with a source HTTPS source url and a provided source_hash I would expect Salt to check the hash of an existing local file before downloading the file from the server.  This appears to be a regression of #33831.  Today, it's been eating my limited mobile data. Salt Version: 2017.7.2 (Nitrogen) - in masterless local mode\nUbuntu 16.04 xenial <CODE> ", "code": ["Salt Version:\n           Salt: 2017.7.2\n \nDependency Versions:\n           cffi: Not Installed\n       cherrypy: Not Installed\n       dateutil: 2.4.2\n      docker-py: Not Installed\n          gitdb: Not Installed\n      gitpython: Not Installed\n          ioflo: Not Installed\n         Jinja2: 2.8\n        libgit2: Not Installed\n        libnacl: Not Installed\n       M2Crypto: Not Installed\n           Mako: 1.0.3\n   msgpack-pure: Not Installed\n msgpack-python: 0.4.6\n   mysql-python: Not Installed\n      pycparser: Not Installed\n       pycrypto: 2.6.1\n   pycryptodome: Not Installed\n         pygit2: Not Installed\n         Python: 2.7.12 (default, Nov 20 2017, 18:23:56)\n   python-gnupg: Not Installed\n         PyYAML: 3.11\n          PyZMQ: 15.2.0\n           RAET: Not Installed\n          smmap: Not Installed\n        timelib: Not Installed\n        Tornado: 4.2.1\n            ZMQ: 4.1.4\n \nSystem Versions:\n           dist: Ubuntu 16.04 xenial\n         locale: UTF-8\n        machine: x86_64\n        release: 4.4.0-103-generic\n         system: Linux\n        version: Ubuntu 16.04 xenial\n"], "labels": ["Duplicate"]}
{"project": "twbs_bootstrap", "title": "Proposal: Drop jQuery dependency.", "description": "For upcoming version 4, with no support for even IE8, there is little inconsistencies in Javascript APIs used by Bootstrap Javascript components, so why not drop a dependency at the cost of little to no overhead? I am happy to contribute. ", "code": [], "labels": ["meta", "v4", "js"]}
{"project": "eslint_eslint", "title": "replacement for valid-typeof rule", "description": "\nNo description provided.\n ", "code": [], "labels": ["triage", "archived due to age"]}
{"project": "hashicorp_terraform", "title": "Support AWS Lambda Aliases and Versions", "description": "I would like to be able to use terraform to configure the aliases and versions for Lambda functions. I'll try to squeeze in some time to start working on it, but as the terraform acc. test quality is quite high - kudos ;-) - I'll first have to read and understand parts of the testing code. ", "code": [], "labels": ["provider/aws", "enhancement"]}
{"project": "shadowsocks_shadowsocks-android", "title": "\u6bd4\u8f83\u597d\u5947\u662f\u8c01\u6216\u8005\u662f\u4ec0\u4e48\u7ec4\u7ec7\u5728\u7ef4\u62a4\u5462\uff1f", "description": "Please read FAQ then answer these questions before submitting your issue. Thanks! Put an x inside the [ ] that applies. ", "code": [], "labels": ["help wanted"]}
{"project": "odoo_odoo", "title": "Stock Picking - Return form's \"To Refund\" toggle button doesn't responsive", "description": "Impacted versions:\nOdoo 11: reproducible since this commit in odoo-11 branch Revision (SHA-1): 2f5e44d\nDate: 4/18/2018 3:44:01 PM\n[FIX] web: checkbox in editable list are clickable Steps to reproduce: Current behavior: Expected behavior: Note: ", "code": [], "labels": ["Logistics", "11.0"]}
{"project": "emberjs_ember.js", "title": "{{input}} should generate a void element (not <input></input>)", "description": "Using the following: Generates the following HTML output: Demo: <URL>,js,output ", "code": [], "labels": ["Bug"]}
{"project": "joomla_joomla-cms", "title": "Possibility to have an expiry date on Menu Items", "description": "Would it be possible to have an expiry date on menu items as we already have on articles ? ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "microsoft_vscode-python", "title": "Fallback to Jedi if user opts not to proceed downloading analysis engine", "description": "@qubitron @brettcannon ", "code": [], "labels": ["closed-question"]}
{"project": "scrapy_scrapy", "title": "Scrapy chokes on HTTP response status lines without a Reason phrase", "description": "Try fetch page: <CODE> output: <CODE> ", "code": ["$ scrapy fetch 'http://www.gidroprofmontag.ru/bassein/sbornue_basseynu'\n", "2013-07-11 09:15:37+0400 [scrapy] INFO: Scrapy 0.17.0-304-g3fe2a32 started (bot: amon)\n/home/tonal/amon/amon/amon/downloadermiddleware/blocked.py:6: ScrapyDeprecationWarning: Module `scrapy.stats` is deprecated, use `crawler.stats` attribute instead\n  from scrapy.stats import stats\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Spider opened\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2013-07-11 09:15:37+0400 [amon_ra] ERROR: Error downloading <GET http://www.gidroprofmontag.ru/bassein/sbornue_basseynu>: [<twisted.python.failure.Failure <class 'scrapy.xlib.tx._newclient.ParseError'>>]\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Closing spider (finished)\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Dumping Scrapy stats:\n        {'downloader/exception_count': 1,\n         'downloader/exception_type_count/scrapy.xlib.tx._newclient.ResponseFailed': 1,\n         'downloader/request_bytes': 256,\n         'downloader/request_count': 1,\n         'downloader/request_method_count/GET': 1,\n         'finish_reason': 'finished',\n         'finish_time': datetime.datetime(2013, 7, 11, 5, 15, 37, 512010),\n         'log_count/ERROR': 1,\n         'log_count/INFO': 4,\n         'scheduler/dequeued': 1,\n         'scheduler/dequeued/memory': 1,\n         'scheduler/enqueued': 1,\n         'scheduler/enqueued/memory': 1,\n         'start_time': datetime.datetime(2013, 7, 11, 5, 15, 37, 257898)}\n2013-07-11 09:15:37+0400 [amon_ra] INFO: Spider closed (finished)\n"], "labels": ["bug"]}
{"project": "kubernetes_kubeadm", "title": "Fix the kubeadm upgrade test jobs", "description": "The upgrade tests are facing a multitude of problems.\n<URL> 1 ginkgo is not skipping 3 tests that we want skipped:\n<URL> can't tell if this is a kube-test vs ginkgo vs e2e framework bug. 2 kubernetes-anywhere 's paths in the e2e framework for old branches is bogus after we switched to pulling branches instead of specific commits in prow jobs:\nkubernetes/kubernetes#70894\nkubernetes/kubernetes#70895 3 we have actual failures in the [master-upgrade] tests:\n<URL> this PR:\n#1224 and the two cherry picks above might fix these. cc @timothysc @fabriziopandini\ncc @kubernetes/sig-cluster-lifecycle /assign\n/kind failing-test\n/priority important-longterm\n/area testing ", "code": [], "labels": ["kind/failing-test", "priority/important-longterm", "area/testing"]}
{"project": "google_ExoPlayer", "title": "IMA extension and Open Measurement", "description": "Is there a way we can see VAST response when using IMA extension? More specifically, I'd like to get contents of Extensions node (or Verification node, VAST 4.0) in order to implement Open Measurement. We're in the the process of certifying our Android SDK with the Google team and implementing Open Measurement is one of the requirements. ", "code": [], "labels": ["question"]}
{"project": "angular-ui_ui-select", "title": "Empty dropdown not hidden when using mobile-angular-ui and Bootstrap theme", "description": "When using mobile-angular-ui and bootstrap theme, the dropdown of the select component is not hiden after outfocus. The issue can be seen after writing some characters in the first select component at <URL> where a ui-select plunker sample has been modified adding the file mobile-angular-ui-base.css as stylesheet. Please, let me know if the issue belongs here or I should open a new issue at mobile-angular-ui instead.\nThanks! ", "code": [], "labels": ["needs: investigation"]}
{"project": "nextcloud_server", "title": "Enhance Redis cache funcionality to allow us to specify multiple redis servers", "description": "Please enhance Redis cache feature in config.php so Nextcloud could talk to a new elected Redis Master by Redis Sentinel upon failover. Currently we can only specify one IP or Hostname in config.php.\nAfter a failover event a new redis master will be elected, which has a different IP/Domain name, so Nextcloud will be unavailable until we point config.php to the new master.\nA similar feature exists for Memcached, where we can list an array of arrays with multiple memcached servers. Operating system: CentOS 7 x86_64 Web server: Nginx 1.10.2 LibresSSL static linked Database: PerconaDB 5.7 Cluster 3 nodes PHP version: php70u from IUS repo Nextcloud version: Latest 10.0.1 Updated from an older Nextcloud/ownCloud or fresh install: Fresh install Where did you install Nextcloud from: packaged tar.bz2 installer from main website ", "code": [], "labels": ["enhancement"]}
{"project": "deis_deis", "title": "Ceph Object Storage", "description": "We need object storage as a service in Deis v2. The likely candidate is Ceph OS Gateway. ", "code": [], "labels": ["v2"]}
{"project": "NVIDIA_nvidia-docker", "title": "nnvidia-container-cli: driver error: timed out when persistence mode is disabled | Azure N-nvidiaSeries VMs", "description": "Hey NVIDIA! When running the sample docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi throws error: [root@RH74NV yum.repos.d]# docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi\ndocker: Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused \"process_linux.go:402: container init caused \"process_linux.go:385: running prestart hook 1 caused \\\"error running hook: exit status 1, stdout: , stderr: exec command: [/usr/bin/nvidia-container-cli --load-kmods configure --ldconfig=@/sbin/ldconfig --device=all --compute --utility --require=cuda>=9.0 --pid=4107 /var/lib/docker/overlay2/3d396bcc61c0fb4464b82f7b5d38acaf438bbdd4cf7bce2bba00a8869a582f58/merged]\\\\nnvidia-container-cli: initialization error: driver error: timed out\\\\n\\\"\"\": unknown. Run command docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi with persistence mode disabled. -Kernel version from uname -a\n[root@RH74NV yum.repos.d]# uname -a\nLinux RH74NV 3.10.0-693.21.1.el7.x86_64 #1 SMP Fri Feb 23 18:54:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux -Driver information from nvidia-smi -a\n[root@RH74NV yum.repos.d]# nvidia-smi\nThu May  3 18:03:18 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |\n|-------------------------------+----------------------+----------------------+ -Docker version from docker version\n[root@RH74NV yum.repos.d]# docker version\nClient:\nVersion:      18.03.1-ce\nAPI version:  1.37\nGo version:   go1.9.5\nGit commit:   9ee9f40\nBuilt:        Thu Apr 26 07:20:16 2018\nOS/Arch:      linux/amd64\nExperimental: false\nOrchestrator: swarm Server:\nEngine:\nVersion:      18.03.1-ce\nAPI version:  1.37 (minimum version 1.12)\nGo version:   go1.9.5\nGit commit:   9ee9f40\nBuilt:        Thu Apr 26 07:23:58 2018\nOS/Arch:      linux/amd64\nExperimental: false -Docker command, image and tag used\ndocker run --runtime=nvidia --rm nvidia/cuda nvidia-smi Extra Info It takes roughly a minute and a half on a NC24 VM (4 K80 GPUs) for nvidia-smi to return anything when either persistence mode or the persistenced daemon are disabled. When persistence mode is enabled it takes about 4 seconds for nvidia-smi to query the GPUs. The expected behavior would be for docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi to take longer to respond when persistence mode is disabled rather than error out. Posibly related to #628 Thanks! ", "code": [], "labels": ["wontfix"]}
{"project": "dart-lang_sdk", "title": "Interface Map uses type \"Object\" in remove()", "description": "This issue was originally filed by robert.w.hartun...@gmail.com What steps will reproduce the problem? What is the expected output? What do you see instead?\nI expect the remove() method to have the signature of remove(K key) not remove(Object key). The same applies in my opinion at least for .containsKey() and the [] Operator. Using .containsValue(Object) is fine I guess. If you don't want to change it, at least make the type system correct, so I cannot call .remove() with a wrong type of key. What version of the product are you using?\nLatest Dev-Version ", "code": [], "labels": ["library-core", "Type-Defect", "area-library", "closed-as-intended"]}
{"project": "mochajs_mocha", "title": "Broken links in docs", "description": "Broken links in the documentation: In the \"Base Reporter\" \"Events\" table, the links to Test, Suite, and Hook are broken.\n<URL> Expected behavior: [What you expect to happen] Actual behavior: [What actually happens] Reproduces how often: [What percentage of the time does it reproduce?] ", "code": [], "labels": ["confirmed-bug"]}
{"project": "urbit_urbit", "title": "Some bogus turf", "description": "I was having trouble using ship.arvo.network, so I rebooted the pier (after seeing some similar issues here). After reboot I see: <CODE> Not sure what's going on here. But I wonder whether a few of these recent issues aren't connected. ", "code": ["~ravmel-ropdyl:dojo> fund: turf is bogus\n[ %no-build-for-duct\n  [ i=/e/ay/~taglux-nidsep/0v7.jmkgs.kcfcj.a1vum.3cqdk.bic2m\n    t=~[/a/~ravmel-ropdyl/~taglux-nidsep/e/get-inner //ames]\n  ]\n]\n[ %no-build-for-duct\n  [ i=/e/ay/~ravmel-ropdyl/0v7.rrnrt.8jq66.rl12u.e7bi5.adoun\n    t=~[/a/~ravmel-ropdyl/~ravmel-ropdyl/e/get-inner //ames]\n  ]\n]\n"], "labels": ["bug"]}
{"project": "Homebrew_homebrew-core", "title": "I run brew install python3 installed python3, but not installed pip3", "description": " ", "code": [], "labels": ["python"]}
{"project": "qgis_QGIS", "title": "Split tool fails to split line if start and end are the same", "description": "Author Name: Nathan Woodrow (@NathanW2)\nOriginal Redmine Issue: 4618\nAffected QGIS version: master\nRedmine category:digitising If the start and end node of a line are snapped together e.g. a closed loop, the split tool fails to split the line and create two new lines. To reproduce: ", "code": [], "labels": ["Digitizing", "Bug"]}
{"project": "qgis_QGIS", "title": "SAGA \"slope, aspect, curvature\" return wrong  output", "description": "Author Name: Giovanni Manghi (@gioman)\nOriginal Redmine Issue: 16486\nAffected QGIS version: 2.18.7\nRedmine category:processing/saga\nAssignee: Victor Olaya Tagging this as a regression because I don't remember being an issue in the past, but not sure 100% now. Tested on macOS, Windows and Linux, on 2.14.8, 2.14.14/2.18.7 and 2.18.7 with different SAGA versions. Take the attached dataset and use as input for the \"slope, aspect, curvature\" alg. Leave output fields empty. Run the the tool, point layers are returned instead of raster layers. If an output is manually defined then after running the right results is returned (but with the attached dataset it seems that the output is not given the right CRS, the one of the input). This does not happen with other sample inputs of the same type (but other CRSs). ", "code": [], "labels": ["High Priority", "Processing", "Regression", "Bug"]}
{"project": "CachetHQ_Cachet", "title": "durations both incidents and maintenance", "description": "It would be nice to set durations on both normal incidents and maintenance scheduled. At the moment we can set the time of an event, but not how long an incident lasted or how long a particular maintenance window might last. ", "code": [], "labels": ["Enhancement"]}
{"project": "pypa_pip", "title": "pip wheel should not build if the wheel already exists", "description": "Currently <CODE> downloads and builds mock twice. It would be good if it checked whether the wheel was already present, and if so did not rebuild it. This would be extremely useful for automatically maintaining local wheel caches. (A flag to force a build would also be useful, to allow building from a development source that has changed, but the version has not changed). ", "code": ["    pip wheel mock\n    pip wheel mock\n"], "labels": ["S: auto-locked"]}
{"project": "CleverRaven_Cataclysm-DDA", "title": "Lighting is broken (Brightness at night time)", "description": "See the picture but pretty much it's night time and very dark but it does not look like it and I can see farther. If it helps I just had an encounter with a Wraith and recently put on sunglasses. The tile I am on is very dark tho so I cannot read or anything. I had something similar happen before but it would not follow me around and it would only keep the insides of places bright. To not be able to see in the dark? Maybe the Wrath did something to me (does not appear in character screen if it did). If applicable, add screenshots to help explain your problem.\n   ", "code": [], "labels": ["<Bug>"]}
{"project": "grpc_grpc-java", "title": "AndroidChannels: failing requests right after network recovery", "description": "1.20.0 In our project we use android JobService, which starts right after device establish network connection. Inside that service we run Grpc request over AndroidChannel. We expect to see successful network calls at that point Most of the time, this request fails few times in a row (as JobService reschedules itself on failure). At first it seems that though JobService is started, no connection is available for some reason, but then we tried to add simple http request via OkHttpClient - and they work well.  Additional digging in logs and debugging reveals, that this might be related to DnsNameResolver, as it might resolve address when request is already in progress. This issue seems highly related to #4028, but occurs in AndroidChannel. Given mentioned setup (JobService + AndroidChannel), it requires android device with API 24+. Issue can be reproduced by toggling off device internet connection (both WiFi and mobile, seems no difference), wait around 10-15 seconds, and toggling on connection.\nExample project, which can demonstrate this issue can be found at <URL> ", "code": [], "labels": ["bug"]}
{"project": "dotnet_efcore", "title": "RevEng: Round-tripability of non clustered PK", "description": "<CODE> <CODE> The PK becomes clustered (the default).\nFor some reason it works for simplest scenario correctly. Perhaps some column in above script is throwing it off.\nTested using CI builds Build no. 26744 This causes issue if the table has clustered index. Migration or database creation fails due to multiple clustered PK/index ", "code": ["CREATE TABLE [BLLICENSEWFSTEP](\n\t[BLLICENSEWFSTEPID] [char](36) NOT NULL,\n\t[BLLICENSEID] [char](36) NOT NULL,\n\t[WFTEMPLATESTEPID] [char](36) NULL,\n\t[WFSTEPTYPEID] [int] NOT NULL,\n\t[PRIORITYORDER] [int] NOT NULL,\n\t[STARTDATE] [datetime] NULL,\n\t[ENDDATE] [datetime] NULL,\n\t[DESCRIPTION] [nvarchar](max) NULL,\n\t[WORKFLOWSTATUSID] [int] NOT NULL,\n\t[ROWVERSION] [int] NOT NULL,\n\t[LASTCHANGEDON] [datetime] NOT NULL,\n\t[LASTCHANGEDBY] [char](36) NOT NULL,\n\t[REQUIREDSUBPLPLANID] [char](36) NULL,\n\t[NAME] [nvarchar](50) NOT NULL,\n\t[WORKFLOWCOMPLETETYPEID] [int] NULL,\n\t[ICON] [varbinary](max) NULL,\n\t[DAYSTOCOMPLETE] [int] NULL,\n\t[BLLICENSEWFPARENTSTEPID] [char](36) NULL,\n\t[VERSIONNUMBER] [int] NULL,\n\t[SORTORDER] [int] NOT NULL,\n\t[GENERALREASON] [nvarchar](max) NULL,\n\t[AUTOCOMPLETED] [bit] NOT NULL,\n\t[NOPRIORITY] [bit] NOT NULL DEFAULT ((0)),\n\t[DUEDATE] [datetime] NULL,\n\t[IDENTITYCOLUMN] [bigint] IDENTITY(1,1) NOT NULL,\n CONSTRAINT [PK_BLLicenseWFStep] PRIMARY KEY NONCLUSTERED \n(\n\t[BLLICENSEWFSTEPID] ASC\n)\n)\n", "CREATE TABLE [BLLICENSEWFSTEP] (                                      \n    [BLLICENSEWFSTEPID] char(36) NOT NULL,                            \n    [AUTOCOMPLETED] bit NOT NULL,                                     \n    [BLLICENSEID] char(36) NOT NULL,                                  \n    [BLLICENSEWFPARENTSTEPID] char(36) NULL,                          \n    [DAYSTOCOMPLETE] int NULL,                                        \n    [DESCRIPTION] nvarchar(max) NULL,                                 \n    [DUEDATE] datetime NULL,                                          \n    [ENDDATE] datetime NULL,                                          \n    [GENERALREASON] nvarchar(max) NULL,                               \n    [ICON] varbinary(max) NULL,                                       \n    [IDENTITYCOLUMN] bigint NOT NULL IDENTITY,                        \n    [LASTCHANGEDBY] char(36) NOT NULL,                                \n    [LASTCHANGEDON] datetime NOT NULL,                                \n    [NAME] nvarchar(50) NOT NULL,                                     \n    [NOPRIORITY] bit NULL DEFAULT (((0))),                            \n    [PRIORITYORDER] int NOT NULL,                                     \n    [REQUIREDSUBPLPLANID] char(36) NULL,                              \n    [ROWVERSION] int NOT NULL,                                        \n    [SORTORDER] int NOT NULL,                                         \n    [STARTDATE] datetime NULL,                                        \n    [VERSIONNUMBER] int NULL,                                         \n    [WFSTEPTYPEID] int NOT NULL,                                      \n    [WFTEMPLATESTEPID] char(36) NULL,                                 \n    [WORKFLOWCOMPLETETYPEID] int NULL,                                \n    [WORKFLOWSTATUSID] int NOT NULL,                                  \n    CONSTRAINT [PK_BLLICENSEWFSTEP] PRIMARY KEY ([BLLICENSEWFSTEPID]) \n);                                                                    \n"], "labels": ["closed-fixed", "type-bug"]}
{"project": "rook_rook", "title": "Add automated e2e test for rook helm charts", "description": "add an automated test to deploy rook via helm chats so we don't regress. ", "code": [], "labels": ["test"]}
{"project": "sqlalchemy_sqlalchemy", "title": "make_transient_to_detached expires deferred attrs making them load on refresh", "description": "Migrated issue, originally created by Michael Bayer (@zzzeek) <CODE> this is due to state._expire(state, state.unloaded) in make_transient_to_pending(). When a deferred attribute is explicitly expired, it becomes part of the next full load. ", "code": ["from sqlalchemy import Column, Integer, String, create_engine\nfrom sqlalchemy.orm import Session, deferred\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm.session import make_transient_to_detached\n\n\nBase = declarative_base()\n\n\nclass MyTable(Base):\n    __tablename__ = 'my_table'\n\n    id = Column(Integer, primary_key=True)\n    undeferred = Column(String)\n    deferred_column = deferred(Column(String))\n\ne = create_engine(\"sqlite://\", echo=True)\nBase.metadata.create_all(e)\ne.execute(\n    \"insert into my_table (id, undeferred, \"\n    \"deferred_column) values (1, 'foo', 'bar')\")\n\ns = Session(e)\n\n\ndef expire_via_detached():\n    item = MyTable(id=1)\n\n    make_transient_to_detached(item)\n    s.add(item)\n    item.undeferred\n    assert 'deferred_column' not in item.__dict__\n    s.close()\n\n\ndef expire_normally():\n    item = s.query(MyTable).first()\n    s.expire(item)\n    item.undeferred\n    assert 'deferred_column' not in item.__dict__\n    s.close()\n\n\ndef expire_explicit_attrs():\n    item = s.query(MyTable).first()\n    s.expire(item, ['undeferred', 'deferred_column'])\n    item.undeferred\n    assert 'deferred_column' in item.__dict__\n    s.close()\n\nexpire_normally()\nexpire_explicit_attrs()\nexpire_via_detached()\n\n"], "labels": ["bug", "orm"]}
{"project": "PokemonGoF_PokemonGo-Bot", "title": "BOT can't start", "description": "I use Master branch, when i start the bot i have this :\nTraceback (most recent call last):\nFile \"pokecli.py\", line 43, in \nfrom pgoapi.exceptions import NotLoggedInException, ServerSideRequestThrottlingException, ServerBusyOrOfflineException\nImportError: No module named pgoapi.exceptions\nlundi 22 ao\u00fbt 2016, 15:49:02 (UTC+0200) Pokebot  Stopped.\nPress any button or wait 20 seconds to continue. My config.json :\n{\n\"auth_service\": \"ptc\",\n\"username\": \"xx,\n\"password\": \"xxx\",\n\"location\": \"xxx\",\n\"gmapkey\": \"xxx\",\n\"libencrypt_location\": \"\",\n\"tasks\": [\n{\n\"type\": \"HandleSoftBan\"\n},\n{\n\"type\": \"CollectLevelUpReward\"\n},\n{\n\"type\": \"IncubateEggs\",\n\"config\": {\n\"longer_eggs_first\": true\n}\n},\n{\n\"type\": \"SleepSchedule\",\n\"config\": {\n\"time\": \"21:00\",\n\"duration\":\"8:00\",\n\"time_random_offset\": \"00:30\",\n\"duration_random_offset\": \"00:30\"\n}\n},\n{\n\"type\": \"TransferPokemon\"\n},\n{\n\"type\": \"EvolvePokemon\",\n\"config\": {\n\"evolve_all\" : \"Pidgey,Weedle,Rattata,Zubat,Pidgey,Caterpie,Spearow\",\n\"//evolve_all\": \"all\",\n\"//first_evolve_by\": \"cp\",\n\"//evolve_above_cp\": 200,\n\"evolve_cp_min\": 10,\n\"evolve_above_iv\": 0,\n\"logic\": \"or\",\n\"evolve_speed\": 20,\n\"use_lucky_egg\": false\n}\n},\n{\n\"type\": \"RecycleItems\",\n\"config\": {\n\"item_filter\": {\n\"Pokeball\":       { \"keep\" : 30 },\n\"Greatball\":       { \"keep\" : 70 },\n\"Ultraball\": { \"keep\" : 50 },\n\"Potion\":         { \"keep\" : 0 },\n\"Super Potion\":   { \"keep\" : 0 },\n\"Hyper Potion\":   { \"keep\" : 30 },\n\"Max Potion\":   { \"keep\" : 50 },\n\"Revive\":         { \"keep\" : 0 },\n\"Razz Berry\":     { \"keep\" : 50 }\n}\n}\n},\n{\n\"type\": \"CatchVisiblePokemon\"\n},\n{\n\"type\": \"CatchLuredPokemon\"\n},\n{\n\"type\": \"SpinFort\"\n},\n{\n\"type\": \"MoveToMapPokemon\",\n\"config\": {\n\"address\": \"xxxxxxxxxxx\",\n\"max_distance\": 500,\n\"min_ball\": 50,\n\"prioritize_vips\": true,\n\"snipe\": false,\n\"snipe_high_prio_only\": true,\n\"snipe_high_prio_threshold\": 400,\n\"update_map\": true,\n\"mode\": \"priority\",\n\"map_path\": \"raw_data\",\n\"catch\": {\n\"==========Legendaries==========\": 0,\n\"Aerodactyl\": 1000,\n\"Snorlax\": 1000,\n\"Articuno\": 1000,\n\"Zapdos\": 1000,\n\"Moltres\": 1000,\n\"Dratini\": 1000,\n\"Dragonair\": 1000,\n\"Dragonite\": 1000,\n\"Mewtwo\": 1000,\n\"Mew\": 1000, <CODE> } Thanks for ur help ", "code": ["        \"==========Region Locked==========\": 0,\n        \"Farfetch'd\": 1000,\n        \"Kangaskhan\": 1000,\n        \"Mr. Mime\": 1000,\n        \"Tauros\": 1000,\n\n        \"==========Very Rare==========\": 0,\n        \"Lapras\": 900,\n        \"Electabuzz\": 900,\n        \"Magmar\": 900,\n        \"Ditto\": 900,\n\n        \"==========Starters==========\": 0,\n        \"Bulbasaur\": 400,\n        \"Ivysaur\": 600,\n        \"Venusaur\": 1000,\n\n        \"Charmander\": 400,\n        \"Charmeleon\": 600,\n        \"Charizard\": 1000,\n\n        \"Squirtle\": 400,\n        \"Wartortle\": 600,\n        \"Blastoise\": 1000,\n\n        \"Pikachu\": 600,\n        \"Raichu\": 1000,\n\n        \"==========Semi Rare==========\": 0,\n        \"Porygon\": 200,\n        \"Scyther\": 200,\n        \"Jynx\": 200,\n\n        \"==========Uncommon==========\": 0,\n\n        \"Omanyte\": 150,\n        \"Omastar\": 500,\n\n        \"Seel\": 300,\n        \"Dewgong\": 500,\n\n        \"Grimer\": 200,\n        \"Muk\": 500,\n\n        \"Shellder\": 200,\n        \"Cloyster\": 500,\n\n        \"Gastly\": 200,\n        \"Haunter\": 500,\n        \"Gengar\": 1000,\n\n        \"Onix\": 600,\n\n        \"Drowzee\": 600,\n\n        \"Hypno\": 600,\n\n        \"Vulpix\": 200,\n        \"Ninetales\": 600,\n\n        \"Paras\": 100,\n        \"Parasect\": 500,\n\n        \"Growlithe\": 200,\n        \"Arcanine\": 700,\n\n        \"Tentacool\": 200,\n        \"Tentacruel\": 500,\n\n        \"Mankey\": 150,\n        \"Primeape\": 500,\n\n        \"Clefairy\": 150,\n        \"Clefable\": 500,\n\n        \"Jigglypuff\": 150,\n        \"Wigglytuff\": 500,\n\n        \"Venonat\": 100,\n        \"Venomoth\": 500,\n\n        \"Diglett\": 200,\n        \"Dugtrio\": 500,\n\n        \"Meowth\": 250,\n        \"Persian\": 500,\n\n        \"Psyduck\": 150,\n        \"Golduck\": 500,\n\n        \"Geodude\": 100,\n        \"Graveler\": 500,\n        \"Golem\": 800,\n\n        \"Eevee\": 200,\n        \"Vaporeon\": 800,\n        \"Jolteon\": 800,\n        \"Flareon\": 800,\n\n        \"Kabuto\": 150,\n        \"Kabutops\": 500,\n\n        \"Magikarp\": 150,\n        \"Gyarados\": 800,\n\n        \"Pinsir\": 150,\n\n        \"Ponyta\": 200,\n        \"Rapidash\": 500,\n\n        \"Slowpoke\": 200,\n        \"Slowbro\": 500,\n\n        \"Magnemite\": 250,\n        \"Magneton\": 500,\n\n        \"Krabby\": 100,\n        \"Kingler\": 500,\n\n        \"Voltorb\": 200,\n        \"Electrode\": 500,\n\n        \"Exeggcute\": 250,\n        \"Exeggcutor\": 500,\n\n        \"Cubone\": 300,\n        \"Marowak\": 800,\n\n        \"Hitmonlee\": 400,\n\n        \"Hitmonchan\": 400,\n\n        \"Lickitung\": 500,\n\n        \"Koffing\": 200,\n        \"Weezing\": 500,\n\n        \"Rhyhorn\": 200,\n        \"Rhydon\": 500,\n\n        \"Chansey\": 800,\n\n        \"Tangela\": 300,\n\n        \"Horsea\": 200,\n        \"Seadra\": 600,\n\n        \"Goldeen\": 150,\n        \"Seaking\": 500,\n\n        \"Staryu\": 200,\n        \"Starmie\": 800,\n\n\n        \"==========T1 Evolvers==========\": 0,\n        \"Caterpie\": 10,\n        \"Metapod\": 10,\n        \"Butterfree\": 500,\n\n        \"Weedle\": 10,\n        \"Kakuna\": 10,\n        \"Beedrill\": 500,\n\n        \"Pidgey\": 10,\n        \"Pidgeotto\": 10,\n        \"Pidgeot\": 300,\n\n        \"==========T2 Evolvers==========\": 0,\n        \"Nidoran F\": 10,\n        \"Nidorina\": 10,\n        \"Nidoqueen\": 10,\n\n        \"Nidoran M\": 10,\n        \"Nidorino\": 10,\n        \"Nidoking\": 10,\n\n        \"Oddish\": 100,\n        \"Gloom\": 200,\n        \"Vileplume\": 600,\n\n        \"Poliwag\": 200,\n        \"Poliwhirl\": 400,\n        \"Poliwrath\": 800,\n\n        \"Abra\": 300,\n        \"Kadabra\": 600,\n        \"Alakazam\": 800,\n\n        \"Machop\": 150,\n        \"Machoke\": 400,\n        \"Machamp\": 800,\n\n        \"Bellsprout\": 100,\n        \"Weepinbell\": 400,\n        \"Victreebel\": 800,\n\n        \"==========Trash==========\": 0,\n\n        \"Rattata\": 10,\n        \"Raticate\": 10,\n\n        \"Spearow\": 10,\n        \"Fearow\": 10,\n\n        \"Ekans\": 10,\n        \"Arbok\": 10,\n\n        \"Sandshrew\": 10,\n        \"Sandslash\": 10,\n\n        \"Zubat\": 10,\n        \"Golbat\": 10,\n\n        \"Doduo\": 10,\n        \"Dodrio\": 10\n      }\n    }\n  },\n  {\n    \"type\": \"MoveToFort\",\n    \"config\": {\n        \"lure_attraction\": true,\n        \"lure_max_distance\": 2000\n    }\n  },\n  {\n\"type\": \"FollowSpiral\",\n\"config\": {\n    \"diameter\": 4,\n    \"step_size\": 70\n}\n  }\n],\n\"map_object_cache_time\": 5,\n\"forts\": {\n  \"avoid_circles\": true,\n  \"max_circle_size\": 50\n},\n\"websocket_server\": false,\n\"walk_max\": 6.16,\n\"walk_min\": 5.16,\n\"//walk\": 8.16,\n\"action_wait_min\": 1,\n\"action_wait_max\": 4,\n\"debug\": false,\n\"test\": false,\n\"health_record\": true,\n\"location_cache\": true,\n\"distance_unit\": \"km\",\n\"reconnecting_timeout\": 15,\n\"//evolve_captured\" : \"Pidgey,Weedle,Rattata,Zubat,Pidgey,Caterpie,Spearow\",\n\"//catch_randomize_reticle_factor\": 1.0,\n\"//catch_randomize_spin_factor\": 1.0,\n\"catch_throw_parameters\": {\n   \"excellent_rate\": 0.4,\n   \"great_rate\": 0.2,\n   \"nice_rate\": 0.1,\n   \"normal_rate\": 0.3,\n   \"spin_success_rate\" : 0.5\n },\n\"catch\": {\n  \"any\": {\"catch_above_cp\": 0, \"catch_above_iv\": 0, \"logic\": \"or\"},\n  \"// Example of always catching Rattata:\": {},\n  \"//Rattata\": { \"always_catch\" : true },\n  \"//Zubat\": {\"always_catch\": true},\n  \"//Pidgey\": {\"always_catch\": true},\n  \"//Weedle\": { \"always_catch\": true }\n},\n\"release\": {\n  \"any\": {\"release_below_cp\": 120, \"release_below_iv\": 0.85, \"keep_best_cp\": 3, \"logic\": \"or\"},\n  \"// Example of always releasing Rattata:\": {},\n  \"Rattata\": {\"always_release\": true},\n  \"Raticate\": { \"always_release\": true },\n  \"Zubat\": {\"always_release\": true},\n  \"Golbat\": { \"always_release\": true },\n  \"Pidgey\": {\"always_release\": true},\n  \"Pidgeot\": { \"always_release\": true },\n  \"Pidgeotto\": { \"always_release\": true },\n  \"Caterpie\": {\"always_release\": true},\n  \"Spearow\": {\"always_release\": true},\n  \"Nidoran F\": { \"always_release\": true },\n  \"Nidoran M\": { \"always_release\": true },\n  \"Fearow\": { \"always_release\": true },\n  \"Weedle\": { \"always_release\": true },\n  \"Kakuna\": { \"always_release\": true },\n  \"Beedrill\": { \"always_release\": true },\n  \"//Example of keeping 3 stronger (based on CP) Pidgey:\": {},\n  \" Pidgey\": {\"keep_best_cp\": 3},\n  \"//Example of keeping 2 stronger (based on IV) Zubat:\": {},\n  \"// Zubat\": {\"keep_best_iv\": 2},\n  \"// Also, it is working with any\": {},\n  \"// any\": {\"keep_best_iv\": 2},\n  \"// Example of keeping the 2 strongest (based on CP) and 3 best (based on IV) Zubat:\": {},\n  \"//any\": {\"keep_best_cp\": 1, \"keep_best_iv\": 2}\n},\n\"vips\" : {\n     \"Any pokemon put here directly force to use Berry & Best Ball to capture, to secure the capture rate!\": {},\n    \"//any\": {\"catch_above_cp\": 1200, \"catch_above_iv\": 0.9, \"logic\": \"or\" },\n\"Lapras\": {},\n    \"//any\": {},\n    \"Moltres\": {},\n    \"Zapdos\": {},\n    \"Snorlax\": {},\n    \"Articuno\": {},\n\n    \"// S-Tier pokemons (if pokemon can be evolved into tier, list the representative)\": {},\n    \"Mewtwo\": {},\n    \"Dragonite\": {},\n    \"// Mew evolves to Mewtwo\": {},\n    \"Mew\": {},\n    \"Arcanine\": {},\n    \"Vaporeon\": {},\n    \"Gyarados\": {},\n    \"Exeggutor\": {},\n    \"Muk\": {},\n    \"Weezing\": {},\n    \"Flareon\": {}\n\n}\n"], "labels": ["Help Wanted"]}
{"project": "github_VisualStudio", "title": "gitignore templates in \"Create Repository\" not sorted correctly", "description": "The .gitignore templates in the repository creation dialog are not sorted correctly, and in addition are sometimes duplicated:  The \"Recommended\" templates should appear at the top, and the remaining templates should be sorted. However this does not happen and they appear in essentially random order. In addition the templates are read from Akavache, which when refreshing the list can produce the list of templates twice, causing duplicates to appear. ", "code": [], "labels": ["bug"]}
{"project": "mrdoob_three.js", "title": "[idea] Switch to a module system instead of a global namespace, then use the module system to optionally construct a global namespace.", "description": "For example, use CommonJS or ES6 modules for all things. This will help to convert to a properly modular library for NPM. The advantage of this is that people will be able to require/import certain classes into their projects, and their build tools will compile only those classes, not the entire library, making application more lean. The user can optionally use THREE as a contain-all by importing three. That would load the project's index.js file, and that file would use CommonJS or ES6 import syntax to load all the other files it needs, and it would export a single object equivalent of what THREE currently is. Users would also be able to import, say, three/core/Object3D as in or <CODE> to import classes directly, and when their program is compiled, only the things they use will be built into their applications. ES6 modules are an official part of JavaScript now, so it would be super beneficial to convert to those, use semver, and to publish on NPM. ", "code": ["let Object3D = require('three/core/Object3D')\n"], "labels": ["Suggestion"]}
{"project": "facebook_react-native", "title": "Text Shadow (elevation) for Android Support", "description": "Text Component to apply Shadow (elevation) styles for Android is not working but is working in ios. Is this even supported for the Text component for Android? ", "code": [], "labels": ["Resolution: Locked", "Android"]}
{"project": "kubernetes_kops", "title": "dockerConfig: ipTables and IpMasq are ignored", "description": "1. What kops version are you running? The command kops version, will display\nthis information. 1.12.1 2. What Kubernetes version are you running? kubectl version will print the\nversion if a cluster is running or provide the Kubernetes version specified as\na kops flag. 1.11.10 3. What cloud provider are you using? aws 4. What commands did you run?  What is the simplest way to reproduce this issue? 5. What happened after the commands executed? Rolling-update happens smoothly, but the Docker options are not set in /etc/sysconfig/docker: 6. What did you expect to happen? --ip-masq and --iptables are set to true. 7. Please provide your cluster manifest. Execute\nkops get --name my.example.com -o yaml to display your cluster manifest.\nYou may want to remove your cluster name and other sensitive information. 8. Please run the commands with most verbose logging by adding the -v 10 flag.\nPaste the logs into this report, or in a gist and provide the gist link here. Unfortunately this is way too much details that I cannot share, we will see after discussion if any particular part is relevant to add to the issue. 9. Anything else do we need to know? I'm trying to re-add the following docker iptables rule: It is present in our other Kubernetes cluster deployed with kops 1.11.1 without these setting (default are false).\nI have tried to set them to true manually in /etc/sysconfig/docker and restart the Docker daemon, and it works. ", "code": [], "labels": ["lifecycle/rotten"]}
{"project": "OpenTTD_OpenTTD", "title": "[OSX] On Mac, add keyboard shortcut for save (cmd-S)", "description": "leecbaker opened the ticket and wrote: Reported version: 1.5.0\nOperating system: Mac OS X ", "code": [], "labels": ["enhancement", "flyspray", "Interface"]}
{"project": "microsoft_vscode", "title": "clear command - Windows Terminal in VSCode", "description": " I deployed the windows terminal dev build and then started working on a separate project on VScode. I opened the VScode terminal and then after typing a couple of commands, I hit clear\n\nAfter hitting clear, the cursor just moves to the top, but the contents of the terminal aren't cleared. In fact, everytime I write a command after clearing, it just writes over the previous command as if it were an empty line.\n I am not sure if this is a bug in VSCode or the windows terminal, so I have posted this issue in the terminal github page too. ", "code": [], "labels": ["*duplicate", "integrated-terminal"]}
{"project": "flutter_flutter", "title": "flutter run builds the FLX twice", "description": "I'm starting to enhance our analytics, and I noticed that we're generating two 'flx' screens. My debug output: <CODE> (The XXXX is my debug output) Conclusion: we're building the FLX twice, when a user types flutter run, at least for Android. ", "code": ["Running \"flutter packages get\" in myapp...\nXXXX flx\nXXXX flx\n"], "labels": ["t: gradle"]}
{"project": "fritzing_fritzing-app", "title": "gerber export: tiny fonts not converting very well", "description": "From irasc...@gmail.com on November 12, 2010 14:41:33 try opening attached fzz and exporting to gerber.  The tiny fonts inside the resistor silkscreens don't convert very well. Attachment: domotica.fzz Original issue: <URL> ", "code": [], "labels": ["bug"]}
{"project": "spring-projects_spring-boot", "title": "How to Flatten dynamic field with parent document in Spring data Mongo DB", "description": "In my Spring boot project have a Document like so: <CODE> where properties is a dynamic field i.e. it can take in as many different key-value pairs. I use MongoRepository to store this value: <CODE> Now when I store it in the Collection it looks like this:  whereas I want it to look like this: basically I want to flatten the properties to make the values it stores a part of the Root Document itself. Any idea about how I should do this? Thanks. ", "code": ["@Document(collection=\"AuditTable\")\npublic class AuditTable {\n\n    @Id\n    private String id;\n\n    private Map<String, String> properties;\n", "@Repository\npublic interface AuditTableRepo extends MongoRepository<AuditTable, String> {\n}\n"], "labels": ["for: stackoverflow"]}
{"project": "saltstack_salt", "title": "git.latest uses SSH_AUTH_SOCK instead of the defined identity", "description": "While using git.latest in a state combined with a specified identity git latest.uses my local SSH_AUTH_SOCK instead of the identity to clone the repo. This fails as my personal identity does not have read permissions to the repository. git clone repo ABC:\ngit.latest:\n- name: git@git.url.de:ABC\n- rev: master\n- branch: master\n- target: /opt/ABC/\n- submodules: True\n- identity: /root/.ssh/salt_git_deploy_key\n- require:\n- sls: setup.salt_git_deploy_key Salt Version:\nSalt: 2016.11.6 Dependency Versions:\ncffi: Not Installed\ncherrypy: Not Installed\ndateutil: 2.2\ndocker-py: Not Installed\ngitdb: Not Installed\ngitpython: Not Installed\nioflo: Not Installed\nJinja2: 2.9.4\nlibgit2: Not Installed\nlibnacl: Not Installed\nM2Crypto: Not Installed\nMako: Not Installed\nmsgpack-pure: Not Installed\nmsgpack-python: 0.4.2\nmysql-python: Not Installed\npycparser: Not Installed\npycrypto: 2.6.1\npycryptodome: Not Installed\npygit2: Not Installed\nPython: 2.7.9 (default, Jun 29 2016, 13:08:31)\npython-gnupg: Not Installed\nPyYAML: 3.11\nPyZMQ: 14.4.0\nRAET: Not Installed\nsmmap: Not Installed\ntimelib: Not Installed\nTornado: 4.2.1\nZMQ: 4.0.5 System Versions:\ndist: debian 8.7\nmachine: x86_64\nrelease: 4.4.79+523-ph\nsystem: Linux\nversion: debian 8.7 ", "code": [], "labels": ["Pending Discussion"]}
{"project": "opencv_opencv", "title": "cv2.error: OpenCV(3.4.1) /feedstock_root/build_artefacts/opencv_1520722599420/work/opencv-3.4.1/modules/dnn/src/caffe/caffe_io.cpp:1145: error: (-2) FAILED: ReadProtoFromTextFile(param_file, param). Failed to parse NetParameter file: openpose_pose_coco.prototxt in function ReadNetParamsFromTextFileOrDie", "description": "Can you please suggest how to fix this? <CODE> I already followed #11077 to download the necessary files. <CODE> ", "code": ["[jalal@goku opencv]$ ls\nCOCO_val2014_000000000589.jpg  openpose_pose_coco.prototxt  openpose.py  pose_iter_440000.caffemodel\n[jalal@goku opencv]$ python openpose.py --input=COCO_val2014_000000000589.jpg --proto=openpose_pose_coco.prototxt --model=pose_iter_440000.caffemodel --dataset=COCO\n[libprotobuf ERROR /feedstock_root/build_artefacts/opencv_1520722599420/work/opencv-3.4.1/3rdparty/protobuf/src/google/protobuf/text_format.cc:288] Error parsing text-format opencv_caffe.NetParameter: 7:1: Expected identifier, got: <\nOpenCV(3.4.1) Error: Unspecified error (FAILED: ReadProtoFromTextFile(param_file, param). Failed to parse NetParameter file: openpose_pose_coco.prototxt) in ReadNetParamsFromTextFileOrDie, file /feedstock_root/build_artefacts/opencv_1520722599420/work/opencv-3.4.1/modules/dnn/src/caffe/caffe_io.cpp, line 1145\nTraceback (most recent call last):\n  File \"openpose.py\", line 51, in <module>\n    net = cv.dnn.readNetFromCaffe(args.proto, args.model)\ncv2.error: OpenCV(3.4.1) /feedstock_root/build_artefacts/opencv_1520722599420/work/opencv-3.4.1/modules/dnn/src/caffe/caffe_io.cpp:1145: error: (-2) FAILED: ReadProtoFromTextFile(param_file, param). Failed to parse NetParameter file: openpose_pose_coco.prototxt in function ReadNetParamsFromTextFileOrDie\n", "[jalal@goku opencv]$ which python\n/scratch/sjn/anaconda/bin/python\n[jalal@goku opencv]$ python -V\nPython 3.6.3 :: Anaconda custom (64-bit)\n[jalal@goku opencv]$ lsb_release -a\nLSB Version:\t:core-4.1-amd64:core-4.1-noarch\nDistributor ID:\tCentOS\nDescription:\tCentOS Linux release 7.4.1708 (Core) \nRelease:\t7.4.1708\nCodename:\tCore\n[jalal@goku opencv]$ gcc -v\nUsing built-in specs.\nCOLLECT_GCC=gcc\nCOLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.5/lto-wrapper\nTarget: x86_64-redhat-linux\nConfigured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux\nThread model: posix\ngcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)\n"], "labels": ["category: dnn"]}
{"project": "AutoMapper_AutoMapper", "title": "Threading Issue when CreateMissingTypeMaps option is true", "description": "Hi,\nJust spotted an issue in automapper. When you are mapping and also specified CreateMissionTypeMaps = true then sometimes it causes an issue and throws AutoMapperMappingException. I am posting the source code as well so that you can replicate the issue on your machine. since this is a threading issue so it happens sometimes so you need to execute the code few times in order to see the error message. FYI  I installed AutoMapper v3.2.1 from package manager console. <CODE> ", "code": ["\nusing System;\nusing System.Threading;\n\nnamespace AutoMapperDynamicMappingIssue\n{\n    public class UserViewModel\n    {\n        public string EmailAddress { get; set; }\n\n        public string LastName { get; set; }\n\n        public string FirstName { get; set; }\n\n        public int Id { get; set; }\n\n        public UserViewModel()\n        {\n            Id = 1;\n            FirstName = \"Dummy\";\n            LastName = \"User\";\n            EmailAddress = \"dummy.user@testing.co.uk\";\n        }\n    }\n\n    public class UserDto\n    {\n        public string EmailAddress { get; set; }\n\n        public string LastName { get; set; }\n\n        public string FirstName { get; set; }\n\n        public int Id { get; set; }\n    }\n\n\n    internal class Program\n    {\n        private static void Main( string[] args )\n        {\n            var startTime = DateTime.Now;\n            var endTime = startTime.AddSeconds( 2 );\n\n            while ( endTime.Ticks > DateTime.Now.Ticks )\n            {\n                for ( var i = 0; i < 200; i++ )\n                {\n                    //Works fine\n                    //AutoMapper.Mapper.Map<UserViewModel, UserDto>( new UserViewModel(), opt => opt.CreateMissingTypeMaps = true );\n\n\n                    // Threading issue.\n                    new Thread( () => AutoMapper.Mapper.Map<UserViewModel, UserDto>( new UserViewModel(), opt => opt.CreateMissingTypeMaps = true ) ).Start();\n                }\n            }\n\n            Console.WriteLine( \"Enter anything to quit\" );\n            Console.Read();\n        }\n    }\n}\n\n"], "labels": ["Bug"]}
{"project": "arendst_Tasmota", "title": "Blind controller remote emulation", "description": "Hi All,\nHave been playing with a motorised blind / curtain controls from China. They appear to be branded under various names world wide but google \"Dooya\" you'll get the idea. Anyway I've hack the protocol which is a 40bit RF 433mhz data stream and have it working on a Uno and compiling on the ESP8266. Next step is integration to Tasmota I now use Tasmota exclusively and don't want to build an orphan.\nQ1, How many people are interested blind control?\nQ2, Where would I put it? Is it a remote or in the RF Bridge or new device? It could also be a user pin device as it just requires a RF Transmitter and could be mounted on a Sonoff device really easy. Jason ", "code": [], "labels": ["stale"]}
{"project": "gatsbyjs_gatsby", "title": "How to get Gatsby-Remark-Prismjs to work With WordPress Posts", "description": "Hello,\nI'm having a hard time trying to figure out why the syntax on my site won't update after installing Gatsby-Remark-Prism. I've installed the dependencies and added the plugin to the gatsby-config.js file.\nAlso required the the theme in my layout.js file. I suspect that it's not working because this plugin transforms markdown files and the data that gets queried inthe gatsby-source-wordpress plugin are not .md files. Any help in the right direction would be appreciated. Thank you.  <URL> <URL> <CODE> <CODE> <CODE> ", "code": ["{\n  \"name\": \"gatsby-starter-default\",\n  \"description\": \"Gatsby default starter\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Kyle Mathews \",\n  \"dependencies\": {\n    \"babel-plugin-styled-components\": \"0.0.3-0\",\n    \"gatsby\": \"next\",\n    \"gatsby-image\": \"^1.0.54\",\n    \"gatsby-paginate\": \"^1.0.16\",\n    \"gatsby-plugin-react-helmet\": \"next\",\n    \"gatsby-plugin-sharp\": \"^1.6.48\",\n    \"gatsby-plugin-styled-components\": \"^3.0.0-beta.2\",\n    \"gatsby-remark-prismjs\": \"^2.0.5\",\n    \"gatsby-source-filesystem\": \"^1.5.39\",\n    \"gatsby-source-wordpress\": \"^2.0.93\",\n    \"gatsby-transformer-remark\": \"^1.7.44\",\n    \"gatsby-transformer-sharp\": \"^1.6.27\",\n    \"prismjs\": \"^1.15.0\",\n    \"react\": \"^16.4.1\",\n    \"react-dom\": \"^16.4.1\",\n    \"react-fontawesome\": \"^1.6.1\",\n    \"react-helmet\": \"^5.2.0\",\n    \"react-instagram-embed\": \"^1.4.0\",\n    \"styled-components\": \"^3.3.3\"\n  },\n  \"keywords\": [\n    \"gatsby\"\n  ],\n  \"license\": \"MIT\",\n  \"scripts\": {\n    \"build\": \"gatsby build\",\n    \"develop\": \"gatsby develop\",\n    \"format\": \"prettier --write 'src/**/*.js'\",\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\",\n    \"deploy\": \"gatsby build --prefix-paths && gh-pages -d public\"\n  },\n  \"devDependencies\": {\n    \"gh-pages\": \"^1.2.0\",\n    \"prettier\": \"^1.12.0\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/gatsbyjs/gatsby-starter-default\"\n  }\n}\n", "gatsby-config.js:", "module.exports = {\n  siteMetadata: {\n    title: 'Swizec Blog',\n    subtitle: `Fetch Data From Local WP Install`,\n    \n  },\n  pathPrefix: `/swizecblog`,\n  plugins: [\n    'gatsby-plugin-react-helmet',\n    'gatsby-transformer-sharp',\n    'gatsby-plugin-sharp',\n    `gatsby-transformer-remark`,\n    `gatsby-plugin-styled-components`,\n    \n    {\n      resolve: \"gatsby-source-wordpress\",\n      options: {\n        /*\n         * The base URL of the Wordpress site without the trailingslash and the protocol. This is required.\n         * Example : 'gatsbyjsexamplewordpress.wordpress.com' or 'www.example-site.com'\n         */\n        baseUrl: \"swizec.com/blog\",\n        // The protocol. This can be http or https.\n        protocol: \"https\",\n        // Indicates whether the site is hosted on wordpress.com.\n        // If false, then the assumption is made that the site is self hosted.\n        // If true, then the plugin will source its content on wordpress.com using the JSON REST API V2.\n        // If your site is hosted on wordpress.org, then set this to false.\n        hostingWPCOM: false,\n        // If useACF is true, then the source plugin will try to import the Wordpress ACF Plugin contents.\n        // This feature is untested for sites hosted on Wordpress.com.\n        // Defaults to true.\n        useACF: true,\n        auth: {\n          // If auth.user and auth.pass are filled, then the source plugin will be allowed\n          // to access endpoints that are protected with .htaccess.\n          htaccess_user: \"your-htaccess-username\",\n          htaccess_pass: \"your-htaccess-password\",\n          htaccess_sendImmediately: false,\n  \n          // If hostingWPCOM is true then you will need to communicate with wordpress.com API\n          // in order to do that you need to create an app (of type Web) at https://developer.wordpress.com/apps/\n          // then add your clientId, clientSecret, username, and password here\n          wpcom_app_clientSecret:\n            \"NMPnXYFtj2gKas7V1kZyMxr7oLry9V5ZxIyBQGu2txjVHg0GhFz6RYcKopkHICYg\",\n          wpcom_app_clientId: \"54793\",\n          wpcom_user: \"gatsbyjswpexample@gmail.com\",\n          wpcom_pass: \"very-secured-password\",\n        },\n        // Set verboseOutput to true to display a verbose output on `npm run develop` or `npm run build`\n        // It can help you debug specific API Endpoints problems.\n        verboseOutput: false,\n        // Set how many pages are retrieved per API request.\n        perPage: 100,\n        // Search and Replace Urls across WordPress content.\n        searchAndReplaceContentUrls: {\n          sourceUrl: \"https://source-url.com\",\n          replacementUrl: \"https://replacement-url.com\",\n        },\n        // Set how many simultaneous requests are sent at once.\n        concurrentRequests: 10,\n        // Exclude specific routes using glob parameters\n        // See: https://github.com/isaacs/minimatch\n        // Example:  `[\"/*/*/comments\", \"/yoast/**\"]` will exclude routes ending in `comments` and\n        // all routes that begin with `yoast` from fetch.\n        excludedRoutes: [\"/*/*/comments\", \"/yoast/**\"],\n        // use a custom normalizer which is applied after the built-in ones.\n        normalizer: function({ entities }) {\n          return entities;\n        },\n      },\n    },\n    {\n      resolve: `gatsby-source-filesystem`,\n      options: {\n        name: `pages`,\n        path: `${__dirname}/src/pages/`,\n      },\n    },\n    {\n      resolve: `gatsby-source-filesystem`,\n      options: {\n        name: `data`,\n        path: `${__dirname}/src/data/`,\n      },\n    },\n    {\n      resolve: `gatsby-transformer-remark`,\n      options: {\n        plugins: [\n          {\n            resolve: `gatsby-remark-prismjs`,\n            options: {\n              // Class prefix for  tags containing syntax highlighting;\n              // defaults to 'language-' (eg ).\n              // If your site loads Prism into the browser at runtime,\n              // (eg for use with libraries like react-live),\n              // you may use this to prevent Prism from re-processing syntax.\n              // This is an uncommon use-case though;\n              // If you're unsure, it's best to use the default value.\n              classPrefix: \"language-\",\n              // This is used to allow setting a language for inline code\n              // (i.e. single backticks) by creating a separator.\n              // This separator is a string and will do no white-space\n              // stripping.\n              // A suggested value for English speakers is the non-ascii\n              // character '\u203a'.\n              inlineCodeMarker: null,\n              // This lets you set up language aliases.  For example,\n              // setting this to '{ sh: \"bash\" }' will let you use\n              // the language \"sh\" which will highlight using the\n              // bash highlighter.\n              aliases: {},\n            },\n          },\n        ],\n      },\n    },\n    \n  \n  ],\n}\n"], "labels": ["type: feature or enhancement"]}
{"project": "scikit-image_scikit-image", "title": "Tracing the boundary curve of an image region", "description": "I need to trace the boundary curve of an image region enumerated by measure.regionprops, similar to bwboundaries in Matlab. By boundary curve, I mean a list of border pixels of the region in, say, clockwise direction around the region's perimeter, such that I can, for example, represent the region with a polygon. I need the exact coordinates of all border pixels, not a convex hull approximation. I am currently using measure.find_contours, but this is an algorithmic overkill for simple binary boundary tracing (and slow). Issue created as suggested by Stefan van der Walt on StackOverflow. ", "code": [], "labels": ["type: enhancement"]}
{"project": "OfficeDev_office-ui-fabric-react", "title": "DatePicker/Calendar: rationalize tab order and/or where initial focus is set", "description": "See @vibhava's comments on #1476. He suggests setting initial focus on the header of the Calendar so that the user can reach all parts of the Calendar popup without having to tab backwards. However, I think setting focus on the DayPicker is the optimized method for user interaction. Should we maybe change the tab ordering within the Calendar control? ", "code": [], "labels": ["Status: No Recent Activity", "Area: Accessibility"]}
{"project": "golang_go", "title": "testing: provide access to initial thread from tests", "description": "<CODE> ", "code": ["I spent some time on GopherCon trying to figure how to make the qml package work\nsmoothly on Mac OS. Apparently it was working fine out of luck, because the OS requires\nsome calls to be made from the initial thread. Now something unrelated was touched, and\nthe graphic goroutine is landing on a different thread and generating errors.\n\nThe solution is simple: an init function that locks the main thread, and a qml.Run\nfunction that runs the main loop. Problem solved.\n\nExcept, that doesn't work with the testing package anymore, because the test logic\nitself is run at the end of main, and tests are moved on their own goroutine.\n\nThis problem might be easily solved by changing the test template from:\n\n  testing.Main(matchString, tests, benchmarks, examples)\n\nto something like:\n\n  go func() {\n          testing.Main(matchString, tests, benchmarks, examples)\n          close(done)\n  }()\n  if testing.RunFromMain != nil {\n          testing.RunFromMain(done)\n  }\n  <-done\n\nThen, for the qml package, I'd implement RunFromMain along the lines of:\n\n  testing.RunFromMain = func(done chan struct{}) {\n          stopWhenClosed(done)\n          qml.Run(nil)\n  }\n\nCan we add such a testing.RunFromMain hook?\n\nAnother alternative, suggested by Dmitry Vyukov, is to run tests on the initial thread\ninstead of spawning them in goroutines. That would solve the problem too."], "labels": ["duplicate", "FrozenDueToAge"]}
{"project": "envoyproxy_envoy", "title": "Build: Fails grpc_mux_impl.cc:236:18: error: no viable overloaded '='", "description": "I am trying to build below envoy release with bazel.\n<URL> Build failed as no viable overloaded '=' . grpc_mux_impl.cc:236:18: error: no viable overloaded '='\nrequest_queue_ = {}; void GrpcMuxImpl::clearRequestQueue() {\ngrpc_stream_.maybeUpdateQueueSizeStat(0);\nrequest_queue_ = {};\n} Build steps:\ncd envoy-%{version}\nsed -i 's#github.com/eile#github.com/mirror#' ./bazel/repository_locations.bzl\necho -n \"%{git_commit}\" > SOURCE_VERSION\nexport CC=clang\nexport CXX=clang++\necho $GOPATH\ngo get -u github.com/bazelbuild/buildtools/buildifier\nexport BUILDIFIER_BIN=$GOPATH/bin/buildifier\ngo get -u github.com/bazelbuild/buildtools/buildozer\nexport BUILDOZER_BIN=$GOPATH/bin/buildozer\nbazel build //source/exe:envoy-static Build error logs: bazel-out/k8-fastbuild/bin/external/opencensus_proto/opencensus/proto/agent/trace/v1/trace_service.grpc.pb.h:368:221: warning: unused parameter 'stream' [-Wunused-parameter]\n::grpc::Status Export(::grpc::ServerContext* context, ::grpc::ServerReaderWriter< ::opencensus::proto::agent::trace::v1::ExportTraceServiceResponse, ::opencensus::proto::agent::trace::v1::ExportTraceServiceRequest>* stream)  override {\n^\n30 warnings generated.\nINFO: From CcCmakeMakeRule external/envoy/bazel/foreign_cc/event/include:\n[2,801 / 3,138] CcCmakeMakeRule bazel/foreign_cc/curl/include; 29s processwrapper-sandbox ... (12 actions running)\nrules_foreign_cc: Cleaning temp directories\nINFO: From CcCmakeMakeRule bazel/foreign_cc/curl/include:\nrules_foreign_cc: Cleaning temp directories\nINFO: From CcCmakeMakeRule external/envoy/bazel/foreign_cc/curl/include:\n[2,856 / 3,138] Compiling source/common/grpc/common.cc; 7s processwrapper-sandbox ... (12 actions running)\n[2,913 / 3,138] Compiling source/extensions/filters/http/buffer/config.cc; 10s processwrapper-sandbox ... (12 actions running)\n[2,979 / 3,138] Compiling source/extensions/filters/common/ext_authz/check_request_utils.cc; 13s processwrapper-sandbox ... (12 actions, 11 running)\nrules_foreign_cc: Cleaning temp directories\nERROR: /usr/src/photon/BUILD/envoy-v1.12.1/envoy-1.12.1/source/common/config/BUILD:176:1: C++ compilation of rule '//source/common/config:grpc_mux_lib' failed (Exit 1) clang failed: error executing command /bin/clang -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer '-std=c++0x' -MD -MF ... (remaining 352 argument(s) skipped) Use --sandbox_debug to see verbose messages from the sandbox\nsource/common/config/grpc_mux_impl.cc:236:18: error: no viable overloaded '='\nrequest_queue_ = {}; <CODE> ", "code": ["/bin/../lib64/gcc/x86_64-pc-linux-gnu/6.3.0/../../../../include/c++/6.3.0/bits/stl_queue.h:96:11: note: candidate function (the implicit move assignment operator) not viable: cannot convert initializer list argument to 'std::queue<std::__cxx11::basic_string<char>, std::deque<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > > >'\n  class queue\n        ^\n/bin/../lib64/gcc/x86_64-pc-linux-gnu/6.3.0/../../../../include/c++/6.3.0/bits/stl_queue.h:96:11: note: candidate function (the implicit copy assignment operator) not viable: cannot convert initializer list argument to 'const std::queue<std::__cxx11::basic_string<char>, std::deque<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > > >'\n1 error generated.\nTarget //source/exe:envoy-static failed to build\n"], "labels": ["question"]}
{"project": "telegramdesktop_tdesktop", "title": "[shared media] sort file by descending date from top to bottom", "description": "Currently the files are displayed in this way, but from the bottom up and differ with the order of links. Cheers ", "code": [], "labels": ["enhancement"]}
{"project": "signalapp_Signal-Android", "title": "Gifs not loading/unable to view or search gifs", "description": "I have: unable to view or search for any gifs using the built in Giphy feature. No matter the input, the message \"nothing found\" is displayed for both the gif and sticker search. Actual result: No images available\nExpected result: See images   Device: Galaxy Note II\nAndroid version: 4.4.2 Rooted\nSignal version: 3.27.1 <URL> 'I/ProxyService( 7191): Request 24 CONNECT api.giphy.com:443 HTTP/1.1\nI/adblock.( 7191): false: <URL>\nI/Error   ( 7191): 500 Server Error: java.lang.IllegalArgumentException: <URL>\nI/ProxyService( 7191): unexpected error\nW/GiphyProxySelector( 5018): java.io.IOException: Unexpected response code for CONNECT: 500` EDIT:\nlog with third party app \"AdBlock-free\" disabled:\n<URL> ", "code": [], "labels": ["bug"]}
{"project": "doxygen_doxygen", "title": "Unable to quote file filter command (Origin: bugzilla #792846)", "description": "status NEW severity normal in component general for ---\nReported in version 1.8.13 on platform Other\nAssigned to: Dimitri van Heesch On 2018-01-23 21:56:26 +0000, corey.taylor.fl@gmail.com wrote: <CODE> On 2018-05-04 12:07:02 +0000, albert wrote: <CODE> On 2018-05-04 12:29:33 +0000, albert wrote: <CODE> On 2018-05-08 05:19:13 +0000, corey.taylor.fl@gmail.com wrote: <CODE> ", "code": ["While trying to configure Doxygen to run a file filter that works on both\nWindows and Linux, there doesn't seem to be a way to quote the path to the\ncommand.\n\nFILTER_PATTERNS        = *.glsl=\"\"scripts/runpython\" scripts/doxygen-\nglslfilter.py\"\n\nThe scripts/runpython needs to be quoted on Windows to allowing the forward\nslash.\n\nHowever, the quotes seem to be stripped away.  The command ends up with a \n\nExecuting popen(` scripts/runpython scripts/doxygen-glslfilter.py\n\"C:/dev/g3d/G3D10/data-files/shader/AlphaFilter.glsl\"`)\n\nThe function getFileFilter() in util.cpp seems to only remove the\nsurrounding quotes, so we were hoping the quotes around the path would stay.\n\n    /* remove surrounding double quotes */\n    if ((filterName.right(1) == \"\\\"\") && (filterName.left(1) == \"\\\"\"))\n    {\n       filterName.remove(filterName.length() - 1, 1);\n       filterName.remove(0, 1);\n    }\n\n\nThe call to popen in readCodeFragement() in definition.cpp does not seem to\nadd this space or remove other quotes.\n\n    QCString cmd=filter+\" \\\"\"+fileName+\"\\\"\";\n    Debug::print(Debug::ExtCmd,0,\"Executing popen(`%s`)\\n\",qPrint(cmd));\n    f = portable_popen(cmd,\"r\");\n\nWould it be possible to allow specifying a quoted path/command?\n\nWithout this, there doesn't seem to be a way to run a script on both Windows\nand Linux from the file filter.\n", "Relevant discussion on StackExchange:\nhttps://stackoverflow.com/questions/48394181/is-it-possible-to-wrap-a\n-doxygen-filter-command-in-quotes.\n\nWouldn't it be better that doxygen replaces the '/' by '\\' on windows?\n", "Similar StachOverflow issue: https://stackoverflow.com/questions/49750869\n/what-is-the-qhg-location-path-relative-to-for-doxygen.\n\nFor this pull request 703 has been submitted(\nhttps://github.com/doxygen/doxygen/pull/703).\n", "I think that would work, thanks!\n"], "labels": ["bug"]}
{"project": "odoo_odoo", "title": "[11.0]Sale order group order by month, group by date_order  not date_confirmation", "description": "Impacted versions:\n11.0 Steps to reproduce:\n1.- Create a database with demo activated\n2.- install sale manager\n3.- go to sales\n4.- click on orders Current behavior: Orders is grouping by date_order ( same quotations) and confuse  when is grouping in orders Expected behavior: in menu orders, group by date_confirmation Video/Screenshot link (optional):  ", "code": [], "labels": ["Services", "11.0"]}
{"project": "kubernetes_test-infra", "title": "Support run_after_failure jobs", "description": "Brought up during kubecon @krzyzacy @cjwagner /area prow\n/kind feature ", "code": [], "labels": ["help wanted", "lifecycle/rotten", "area/prow", "kind/feature"]}
{"project": "lingochamp_FileDownloader", "title": "If there an exception thrown on `FileDownloadListener#blockComplete`, callback error instead completed.", "description": "In the current version, if you occur an exception on FileDownloadListener#blockCompleted, you must handle it by yourself, It does not so make sense consider FileDownloadListener has error method, but we don't call back it. In the next version, FileDownloader will handle any Throwable which thrown on FileDownloadListener#blockComplete method and callback FileDownloadListener#error method instead of still call back FileDownloadListener#completed. ", "code": [], "labels": ["enhancement"]}
{"project": "rancher_rancher", "title": "Repeatedly using dig to resolve the domain name, there may be cases where parsing fails", "description": "Rancher versions:\nrancher/rancher:cee0b2b Docker version: (docker version,docker info preferred)\n17.03.2-ce\nOperating system and kernel: (cat /etc/os-release, uname -r preferred)\nubuntu 16.04\nType/provider of hosts: (VirtualBox/Bare-metal/AWS/GCE/DO)\nAWS\nSteps to Reproduce: <CODE> ", "code": ["ksd@wanghailongdeMacBook-Pro \ue0b0 ~/rancher/rke \ue0b0 dig lb-7.default.vrgfmi.lb.rancher.cloud\n\n; <<>> DiG 9.9.7-P3 <<>> lb-7.default.vrgfmi.lb.rancher.cloud\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 20450\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;lb-7.default.vrgfmi.lb.rancher.cloud. IN A\n\n;; ANSWER SECTION:\nlb-7.default.vrgfmi.lb.rancher.cloud. 160 IN A\t34.240.116.102\nlb-7.default.vrgfmi.lb.rancher.cloud. 160 IN A\t34.245.222.219\n\n;; Query time: 8 msec\n;; SERVER: 192.168.1.1#53(192.168.1.1)\n;; WHEN: Tue Jun 05 15:45:02 CST 2018\n;; MSG SIZE  rcvd: 97\n\n ksd@wanghailongdeMacBook-Pro \ue0b0 ~/rancher/rke \ue0b0 dig lb-7.default.vrgfmi.lb.rancher.cloud\n\n; <<>> DiG 9.9.7-P3 <<>> lb-7.default.vrgfmi.lb.rancher.cloud\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 12511\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;lb-7.default.vrgfmi.lb.rancher.cloud. IN A\n\n;; AUTHORITY SECTION:\nlb.rancher.cloud.\t50\tIN\tSOA\tns.dns.lb.rancher.cloud. hostmaster.lb.rancher.cloud. 1528184476 7200 1800 86400 30\n\n;; Query time: 6 msec\n;; SERVER: 192.168.1.1#53(192.168.1.1)\n;; WHEN: Tue Jun 05 15:45:03 CST 2018\n;; MSG SIZE  rcvd: 119\n\n ksd@wanghailongdeMacBook-Pro \ue0b0 ~/rancher/rke \ue0b0 dig lb-7.default.vrgfmi.lb.rancher.cloud\n\n; <<>> DiG 9.9.7-P3 <<>> lb-7.default.vrgfmi.lb.rancher.cloud\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 35374\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;lb-7.default.vrgfmi.lb.rancher.cloud. IN A\n\n;; ANSWER SECTION:\nlb-7.default.vrgfmi.lb.rancher.cloud. 159 IN A\t34.240.116.102\nlb-7.default.vrgfmi.lb.rancher.cloud. 159 IN A\t34.245.222.219\n\n;; Query time: 16 msec\n;; SERVER: 192.168.1.1#53(192.168.1.1)\n;; WHEN: Tue Jun 05 15:45:03 CST 2018\n;; MSG SIZE  rcvd: 97\n"], "labels": ["status/autoclosed", "kind/bug"]}
{"project": "odoo_odoo", "title": "Document Management taks rename and remove task v12", "description": "Impacted versions: v12 2 problems Steps to reproduce:\nproblem 1\nCreate a task with the action button\nthe task is created\nRename the task\nGo to My task\nYou can see the renamed task and the attached documents. When you go back to the document management and the document, you can see the task has the initial task name and not the renamed task. Problem 2\nWhen you remove the task, the document is als removed in the document management app. See video: <URL> Kind regards,\nElise van Maarschalkerweerd\ndutchworld.nl ", "code": [], "labels": ["12.0"]}
{"project": "antonpup_Aurora", "title": "The Division for Corsair Straife", "description": "I install the Logitech patch, when I get into the Division the option to enable LED support is still grayed out. ", "code": [], "labels": ["Type: Bug"]}
{"project": "electron-userland_electron-builder", "title": "Tries to download electron from invalid URL", "description": "Trying to build a Windows release, I get the following: <CODE> There's a 0 missing in the filename, it should be: <CODE> ", "code": ["Error: GET https://github.com/atom/electron/releases/download/v.36.10/electron-v.36.10-win32-ia32.zip returned 404\n", "https://github.com/atom/electron/releases/download/v0.36.10/electron-v0.36.10-win32-ia32.zip\n"], "labels": ["duplicate"]}
{"project": "mRemoteNG_mRemoteNG", "title": "[Feature Request] Zoom / Presentation mode", "description": "Sometimes I use the mRemoteNG to demonstrate things and the problem I'm facing is that the font is too small and nearly impossible to read on TV screens or projectors. I tried the Windows Magnifying glass, but it's not very convenient and the screen sharing app we use (coincidentally called \"Zoom\") doesn't support that. It would be very useful to have a zoom feature like in IDEs and browsers: Zoom In/Out by Ctrl+ / Ctrl- (or Ctrl + Scroll). It's implemented simply by changing font size. Or something like a \"presentation mode\" in IntelliJ where the selected terminal fills the whole screen and massively increases the font size. Or maybe there is a workaround I don't know? ", "code": [], "labels": ["Enhancement"]}
{"project": "knowm_XChange", "title": "Complete the generic API with exceptions", "description": "One of the main features of XChange is the unified API to access many exchanges. This is provided through interfaces and their methods, eg: <CODE> So there is a single method signature that works for any exchange: the method parameters and the return type are well defined. This is great for the obvious reasons. One thing that is lacking in the definition of the method is a well-defined model for exceptions. We've neglected the exception declarations in the API a bit, even though the exceptions declared by an API method are just as much a part of the API as the method parameters and return type. In an environment where errors happen often (like the HTTP I/O), the exception API is of even greater importance than in the general case. The proposal consists of several parts. Note that \"well-defined\" means, among other things, clear and well-defined JavaDocs. Something like (part of this already exists but needs a clean-up): Note that this may be implemented in an own XChange exception hierarchy, or by reusing some of the general Java exceptions like java.lang.UnsupportedOperationException. Since most of these can occur on any API call, they should probably be unchecked exceptions. Eg.: <CODE> ", "code": ["public interface PollingTradeService { \n     ...\n     public String placeLimitOrder(LimitOrder limitOrder) /*...*/;\n}\n", "public String placeLimitOrder(LimitOrder limitOrder)\n    throws FundsLackException, IllegalCurrencyException;\n"], "labels": ["Feature Request"]}
{"project": "kubernetes_kubernetes", "title": "kubelet's enable-debugging-handlers command line flag should default to false(?)", "description": "\"/run/\", \"/exec/\", \"/attach/\", \"/portForward/\", \"/containerLogs/\", \"/runningpods/\" etc are installed at:\n<URL> These are supposed to be used ONLY for debugging, however they are always on by default. Can we please default enable-debugging-handler to false, so these are not installed by mistake? ", "code": [], "labels": ["sig/node"]}
{"project": "timgrossmann_InstaPy", "title": "schedule automation", "description": "I'm trying to make an automation with windows schedule in python. But the problem is that 1 scheduler can run forever for example, because the function that I use with it is running like 3 days, but I want the next Scheduler will determinate The last Schedule, i will give you an example with my code <CODE> the .do(follow) for example is calling my function named \"follow\". I want the function will run at 8am in the morning and will stop at 15:57 and do the next job, and in 15:58 will stop the job of the 15:57 and keep a new job of \"unfollow\" at 15:58 and at 01:00 will quit the last job and make the new job \"unfollow_all\" Thanks! ", "code": ["import schedule\n\n\nschedule.every().day.at(\"8:00\").do(follow)  \nschedule.every().day.at(\"15:57\").do(follow)\nschedule.every().day.at(\"15:58\").do(unfollow)\nschedule.every().day.at(\"01:00\").do(unfollow_all)\n\n"], "labels": ["wontfix"]}
{"project": "dotnet_efcore", "title": "NullReferenceException bug with nested LINQ query", "description": "Left join with inner query: causes this excepion: Exception message:\nStack trace: System.NullReferenceException: Object reference not set to an instance of an object.\nat lambda_method(Closure , QueryContext , TransparentIdentifier2 ) at Microsoft.EntityFrameworkCore.Query.ExpressionVisitors.Internal.ProjectionShaper.TypedProjectionShaper3.Shape(QueryContext queryContext, ValueBuffer& valueBuffer)\nat Microsoft.EntityFrameworkCore.Query.ExpressionVisitors.Internal.CompositeShaper.TypedCompositeShaper5.Shape(QueryContext queryContext, ValueBuffer& valueBuffer) at Microsoft.EntityFrameworkCore.Query.ExpressionVisitors.Internal.ProjectionShaper.TypedProjectionShaper3.Shape(QueryContext queryContext, ValueBuffer& valueBuffer)\nat Microsoft.EntityFrameworkCore.Query.Internal.QueryingEnumerable1.Enumerator.BufferlessMoveNext(DbContext _, Boolean buffer) at Microsoft.EntityFrameworkCore.SqlServer.Storage.Internal.SqlServerExecutionStrategy.Execute[TState,TResult](TState state, Func3 operation, Func3 verifySucceeded) at Microsoft.EntityFrameworkCore.Query.Internal.QueryingEnumerable1.Enumerator.MoveNext()\nat Microsoft.EntityFrameworkCore.Query.Internal.LinqOperatorProvider.ExceptionInterceptor1.EnumeratorExceptionInterceptor.MoveNext() at System.Collections.Generic.LargeArrayBuilder1.AddRange(IEnumerable1 items) at System.Collections.Generic.EnumerableHelpers.ToArray[T](IEnumerable1 source)\nat System.Linq.Enumerable.ToArray[TSource](IEnumerable`1 source)\nat EfLinqBug.Program.Main(String[] args) in C:\\Users\\LEAL1\\source\\repos\\EfLinqBug\\Program.cs:line 80 I've created a test console EF project with two tables Customer & Order which shows the problem. It seems to be just selecting  the OrderId in the nested linq causes the exception. If I change it to OrderId.ToString(), it works....It doesn't seem to like the integer for some reason. Also switching to the in-memory provider the exception doesn't happen. EF Core version: netcoreapp2.2\nDatabase Provider: Microsoft.EntityFrameworkCore.SqlServer 2.2.6\nOperating system:\nIDE: (e.g. Visual Studio 2017 15.4) ", "code": [], "labels": ["closed-fixed", "customer-reported"]}
{"project": "microsoft_azure-pipelines-tasks", "title": "##[error]Failed to download or parse release-index.json with error: {}", "description": "Issues in this repo are for tracking bugs, feature requests and questions for the tasks in this repo For a list:\n<URL> If you have an issue or request for the Azure Pipelines service, use developer community instead: <URL> ) Entering this information will route you directly to the right team and expedite traction. Question, Bug, or Feature?\nType: Bug Enter Task Name:  UseDotNet@2 list here (V# not needed):\n<URL> Azure Pipelines Receive the following error downloading the .NETCore SDK: ##[error]Failed to download or parse release-index.json with error: {} [Enable debug logging and please provide the zip file containing all the logs for a speedy resolution] Checkout how to troubleshoot failures and collect debug logs: <URL> ##[error]Failed to download or parse release-index.json with error: {} Before: After: ", "code": [], "labels": ["Area: Release", "bug"]}
{"project": "OrchardCMS_Orchard", "title": "custom error pages do not display, IIS page displays instead", "description": "@bleroy created:\n<URL> This is in IIS classic mode, with cache disabled. With cache enabled, the right page appears on refresh. ", "code": [], "labels": ["resolved"]}
{"project": "zammad_zammad", "title": "Style Tasks", "description": "Commit: martini@f11a12f  add class modified to priority icon     To set the colors defined by the user the following CSS has to be and added to the DOM behind the main stylesheet and modified accordingly. ", "code": [], "labels": ["UX/UI"]}
{"project": "dotnet_efcore", "title": "Use DotnetToolDispatcher for dispatching project dependency command in dotnet-ef", "description": "<URL> ", "code": [], "labels": ["2 - Done"]}
{"project": "mesosphere_marathon", "title": "Marathon crashes after getting restarted", "description": "Hi, We are currently running Marathon 0.8.0 on Mesos 0.21 (with zookeeper).  At the beginning everything works well,  but sometimes Marathon crashes, and once it crashes and get restarted (we use systemd service to automatically restart Marathon),  it looks problematic and we could not access the UI anymore.  I paste the log below ( after restarting Marathon ). Any clue about this issue ?  thanks very much ! 18:13:17,393 INFO  [MarathonSchedulerService] Defeated (Leader Interface)\n18:13:17,393 INFO  [MarathonSchedulerService] Defeat leadership\n18:13:17,393 INFO  [MarathonSchedulerService] Stopping driver\n18:13:17,396 INFO  [MarathonSchedulerService] Setting framework ID to 20141216-070346-1912885258-5050-32095-0000\n18:13:17,400 ERROR [CandidateImpl] Current member ID member_0000116201 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,401 ERROR [CandidateImpl] Current member ID member_0000116959 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,402 ERROR [CandidateImpl] Current member ID member_0000115792 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,403 ERROR [CandidateImpl] Current member ID member_0000113574 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,404 ERROR [CandidateImpl] Current member ID member_0000116170 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,404 ERROR [CandidateImpl] Current member ID member_0000112561 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,405 ERROR [CandidateImpl] Current member ID member_0000114454 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,406 ERROR [CandidateImpl] Current member ID member_0000114284 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,407 ERROR [CandidateImpl] Current member ID member_0000114498 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,407 ERROR [CandidateImpl] Current member ID member_0000117153 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,408 ERROR [CandidateImpl] Current member ID member_0000114963 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,409 ERROR [CandidateImpl] Current member ID member_0000117400 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,410 ERROR [CandidateImpl] Current member ID member_0000115583 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,411 ERROR [CandidateImpl] Current member ID member_0000115197 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,411 ERROR [CandidateImpl] Current member ID member_0000116787 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,412 ERROR [CandidateImpl] Current member ID member_0000113660 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,413 ERROR [CandidateImpl] Current member ID member_0000113321 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,413 ERROR [CandidateImpl] Current member ID member_0000115560 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,414 ERROR [CandidateImpl] Current member ID member_0000117729 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,415 ERROR [CandidateImpl] Current member ID member_0000112526 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,416 ERROR [CandidateImpl] Current member ID member_0000117530 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,416 ERROR [CandidateImpl] Current member ID member_0000117129 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,417 ERROR [CandidateImpl] Current member ID member_0000113744 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,418 ERROR [CandidateImpl] Current member ID member_0000115832 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,419 ERROR [CandidateImpl] Current member ID member_0000114725 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,420 ERROR [CandidateImpl] Current member ID member_0000117750 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,420 ERROR [CandidateImpl] Current member ID member_0000112941 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,421 ERROR [CandidateImpl] Current member ID member_0000116102 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,422 ERROR [CandidateImpl] Current member ID member_0000116888 is not a candidate for leader, current voting: [member_0000117751]\n18:13:17,423 INFO  [LeaderProxyFilter] Proxying request to leader at dev1-cm1.corp.att.com:8080\n18:13:17,464 INFO  [LeaderProxyFilter] Proxying request to leader at dev1-cm1.corp.att.com:8080 ", "code": [], "labels": ["bug"]}
{"project": "golang_go", "title": "runtime/cgo: cgo is broken on freebsd/arm", "description": "<CODE> ", "code": ["What steps will reproduce the problem?\n\nThe freebsd/arm build breaks at the point go_bootstrap calls to $GOROOT/bin/go.\n\nThis appears to be a cgo issue as a build with CGO_ENABLED=0 passes well into the test\nphase of run.bash.\n\nWhat is the expected output? What do you see instead?\n\n# Testing packages.\nrun.bash: line 48: 21684 Segmentation fault      go test std -short -timeout=$(expr 120\n\\* $timeout_scale)s\nBuild complete, duration 19m32.740155s. Result: error: exit status 139\n\nPlease use labels and text to provide additional information.\n\nhttp://build.golang.org/log/c90283ecc73417f5ec41a095193e9af59c2cc587"], "labels": ["FrozenDueToAge", "fixed"]}
{"project": "ccxt_ccxt", "title": "Unable to place stop limit order on hitbtc exchange", "description": "Hi,\nI am unable to place stop limit order for buy or sell on hitbtc through ccxt. my call is this like -\nreq.exchange.createOrder(req.query.symbol, 'stopLimit', req.query.side, parseFloat(req.query.amount), limitPrice, { 'stopPrice': parseFloat(req.query.stopPrice) }); I am getting this error can you please help me,\n ", "code": [], "labels": ["duplicate", "question"]}
{"project": "openshift_origin", "title": "/docker-entrypoint.sh: line 37: /etc/hosts: Permission denied", "description": "[provide a description of the issue] [provide output of the openshift version or oc version command]\noc v1.2.0\nkubernetes v1.2.0-36-g4a3f9c5 dockerimage  from ubuntu and install nginx [root@master1 ec2-user]# docker exec -ti k8s_test.2ea41a60_test-1-e6gld_backend_32eb220a-8039-11e6-abfa-023688d9a871_9b479fca bash\ngroups: cannot find name for group ID 1000040000\nI have no name!@test-1-e6gld:/$ whoami\nwhoami: cannot find name for user ID 1000040000\nI have no name!@test-1-e6gld:/$ echo \"127.0.0.1 test \" >> /etc/hosts\nbash: /etc/hosts: Permission denied Permission denied in CMD or ENTRYPOIND sections in docker file, but if run this image on docker I have all permitions [try to run $ oadm diagnostics command if possible]\n[if you are reporting issue related to builds, provide build logs with BUILD_LOGLEVEL=5]\n[consider attaching output of the $ oc get all -o json -n <namespace> command to the issue]\n[visit <URL>] run command: oc new-app --docker-image=private_docker_hub/test --name test ", "code": [], "labels": ["kind/question", "priority/P2"]}
{"project": "facebook_react-native", "title": "Geolocation timed out, code 3", "description": "my code is\nnavigator.geolocation.getCurrentPosition(\nposition => {\nconsole.log(position)\n},\nerror => {\nconsole.log(error)\n},\n{\nenableHighAccuracy: Platform.OS !== 'android',\ntimeout: 20000\n}\n)\nBefore when I open the device's position\nthe result is   code:1  message: \"No location provider available.\"\nAfter when I open the device's position\nthe result is   code:3   message: \"Location request timed out\" my device is Nexus 5 android version 4.4.4 ", "code": [], "labels": ["Resolution: Locked"]}
{"project": "spring-projects_spring-framework", "title": "spring-beans-4.3.xsd and spring-utils-4.3.xsd schemaLocation change from http to https: is inconsistent with META-INF/spring.schemas", "description": "The XSD files spring-util-4.3.xsd and spring-context-4.3.xsd in the 4.3.23 release changed the schemaLocation for the xsd:import lines so now they refer to https URLs. in schemaLocation. <CODE> However the spring.schemas files in the spring-beans and spring-context jars do not contain entries for https urls, and MyEclipse Spring Editor (which is an extended version of Spring Tool Suite) now chokes on the XML context configuration files which were working fine with Spring 4.3.22 with various errors (cvc-elt.1, cvc-complex-type.2.4.c, Referenced file contains errors (http://..../spring-context-4.3.xsd...) and Referenced file contains errors (http://..../spring-utils-4.3.xsd...). There are possible other XSD files pulling in other XSDs with a changed https location, I only encountered these two in my code, yet. ", "code": ["<xsd:import namespace=\"http://www.springframework.org/schema/beans\" schemaLocation=\"https://www.springframework.org/schema/beans/spring-beans-4.3.xsd\"/>\n<xsd:import namespace=\"http://www.springframework.org/schema/tool\" schemaLocation=\"https://www.springframework.org/schema/tool/spring-tool-4.3.xsd\"/>\n"], "labels": ["status: waiting-for-triage"]}
{"project": "stan-dev_stan", "title": "stan_csv_reader is sensitive (crashes) to super small floats in sampling data", "description": "stansummary crashes when run on a csv file that contains 1.5316e-322 in the accept_stat__ column of the csv file. [Copied from comment below]  The problem seems to be that the Boost lexical_cast function can only deal with normal double values;  1.6e-322 is too small to be represented as normal number---here are the double-precision numerical limits. The Boost doc only suggests using std::stringstream for more control. My cmdstan code runs without warnings or errors, but when I run stansummary on the resulting csv file I get the error: <CODE> In order to trace the source of the error, I proceeded to delete sample-output lines from the csv file until I found the following offending line: <CODE> Run stansummary of the following csv file. I edited it down to the offending sample-output line: <CODE> I added a second sampling-output line below the offending line so stansummary will work when 1.5316e-322 is changed to 1.5316e-3 <CODE> When the offending number in the sampling output is changed from 1.5316e-322 to 1.5316e-3, the output is <CODE> v2.17.1 ", "code": ["prange% /usr/local/cmdstan-2.17.1/bin/stansummary hyper_samples_1.csv \nlibc++abi.dylib: terminating with uncaught exception of type boost::exception_detail::clone_impl<boost::exception_detail::error_info_injector<boost::bad_lexical_cast> >: bad lexical cast: source type value could not be interpreted as target\nAbort\n", "-27.7811,1.5316e-322,0.0547959,1,1,0,37.0581,0.718519,-1.14652,0.133214,2.21245,0.938323,-1.35562,-0.222546,0.970578,-0.274166,-1.11156,0.119766,-0.132146,-0.022578,0.229995,-0.0303289,-0.23872,0.0410686,0.0588429,-4.76369e-05,-0.18922,-18.4997\nWhen I change the number 1.5316e-322 to 1.5316e-3, stansummary works again.\n", "# stan_version_major = 2\n# stan_version_minor = 17\n# stan_version_patch = 1\n# model = hyper_model\n# method = sample (Default)\n#   sample\n#     num_samples = 1000 (Default)\n#     num_warmup = 1000 (Default)\n#     save_warmup = 0 (Default)\n#     thin = 1 (Default)\n#     adapt\n#       engaged = 1 (Default)\n#       gamma = 0.050000000000000003 (Default)\n#       delta = 0.80000000000000004 (Default)\n#       kappa = 0.75 (Default)\n#       t0 = 10 (Default)\n#       init_buffer = 75 (Default)\n#       term_buffer = 50 (Default)\n#       window = 25 (Default)\n#     algorithm = hmc (Default)\n#       hmc\n#         engine = nuts (Default)\n#           nuts\n#             max_depth = 10 (Default)\n#         metric = diag_e (Default)\n#         metric_file =  (Default)\n#         stepsize = 1 (Default)\n#         stepsize_jitter = 1\n# id = 1\n# data\n#   file = hyper_1.data.R\n# init = hyper_1.init.R\n# random\n#   seed = 3959268712\n# output\n#   file = hyper_samples_1.csv\n#   diagnostic_file =  (Default)\n#   refresh = 100 (Default)\nlp__,accept_stat__,stepsize__,treedepth__,n_leapfrog__,divergent__,energy__,z.1\n# Adaptation terminated\n# Step size = 0.0547959\n# Diagonal elements of inverse mass matrix:\n# 0.713329, 1.08275, 0.596216, 0.607337, 0.289338, 0.159566, 0.477, 0.425896, 0.603512, 2.59539\n-27.7811,1.5316e-322,0.0547959,1,1,0,37.0581,0.718519\n-25.3671,0.86028,0.0547959,4,22,1,30.5591,0.690161\n# \n#  Elapsed Time: 6.95684 seconds (Warm-up)\n#                2.52359 seconds (Sampling)\n#                9.48043 seconds (Total)\n# \n", "prange% /usr/local/cmdstan-2.17.1/bin/stansummary hyper_samples_1.csv \nlibc++abi.dylib: terminating with uncaught exception of type boost::exception_detail::clone_impl<boost::exception_detail::error_info_injector<boost::bad_lexical_cast> >: bad lexical cast: source type value could not be interpreted as target\nAbort\n", "prange% /usr/local/cmdstan-2.17.1/bin/stansummary tmp\nInference for Stan model: hyper_model\n1 chains: each with iter=(2); warmup=(0); thin=(1); 2 iterations saved.\n\nWarmup took (7.0) seconds, 7.0 seconds total\nSampling took (2.5) seconds, 2.5 seconds total\n\n                 Mean   MCSE  StdDev        5%    50%    95%  N_Eff  N_Eff/s    R_hat\nlp__              -27    1.2     1.7  -2.8e+01    -25    -25    2.0     0.79      nan\naccept_stat__    0.43   0.43    0.61   1.5e-03   0.86   0.86    2.0     0.79      nan\nstepsize__      0.055   0.00    0.00   5.5e-02  0.055  0.055    2.0     0.79      nan\ntreedepth__       2.5    1.5     2.1   1.0e+00    4.0    4.0    2.0     0.79      nan\nn_leapfrog__       12     10      15   1.0e+00     22     22    2.0     0.79      nan\ndivergent__      0.50   0.50    0.71   0.0e+00    1.0    1.0    2.0     0.79      nan\nenergy__           34    3.2     4.6   3.1e+01     37     37    2.0     0.79      nan\nz[1]             0.70  0.014   0.020   6.9e-01   0.72   0.72    2.0     0.79      nan\n\nSamples were drawn using hmc with nuts.\nFor each parameter, N_Eff is a crude measure of effective sample size,\nand R_hat is the potential scale reduction factor on split chains (at \nconvergence, R_hat=1).\n"], "labels": ["bug"]}
{"project": "dart-lang_sdk", "title": "dart2js: cannot closurize call method of a closure", "description": "call_closurization_test: RuntimeError ", "code": [], "labels": ["Type-Defect", "web-dart2js"]}
{"project": "qgis_QGIS", "title": "Couldn't load plugin postgis_manager due an error when calling its initGui() method", "description": "Author Name: vvj - (vvj -)\nOriginal Redmine Issue: 3491 Redmine category:python_plugins\nAssignee: Martin Dobias After updating Qgis to 1.6.0-3 from 1.6.0-2 using OSGeo4W advanced installer (and some new libs were offered), Postgis Manager plugin stopped working: <CODE> I also get this error when trying to install this plugin after removing it.\nJust checked with 1.6.0-4 version - problem remains. ", "code": ["*Couldn't load plugin postgis_manager due an error when calling its initGui() method*\n\nTraceback (most recent call last):\n  File \"C:/OSGeo4W/apps/qgis/./python\\\\qgis\\\\utils.py\", line 147, in startPlugin\n    plugins[packageName].initGui()\n  File \"D:/Users/user1/.qgis/python/plugins\\\\postgis_manager\\\\ManagerPlugin.py\", line 24, in initGui\n    self.iface.addPluginToDatabaseMenu(\"&PostGIS Manager\", self.action)\n[[TypeError]]: 'sip.methoddescriptor' object is not callable\n\nPython version:\n2.5.2 (r252:60911, Feb 21 2008, 13:11:45) [MSC v.1310 32 bit (Intel)]\n\n\nQGIS version:\n1.6.0-Capiapo Capiapo, exported\n\nPython path: ['C:/OSGeo4W/apps/qgis/./python', 'D:/Users/arctic/.qgis/python', 'D:/Users/user1/.qgis/python/plugins', 'C:/OSGeo4W/apps/qgis/./python/plugins', 'C:\\\\\\\\OSGeo4W\\\\\\\\bin\\\\\\\\python25.zip', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\DLLs', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib\\\\\\\\plat-win', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib\\\\\\\\lib-tk', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\qgis\\\\\\\\bin', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib\\\\\\\\site-packages', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32\\\\\\\\lib', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\Pythonwin', 'C:\\\\\\\\OSGeo4W\\\\\\\\apps\\\\\\\\Python25\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\wx-2.8-msw-unicode', 'D:\\\\\\\\Users\\\\\\\\arctic\\\\\\\\.qgis\\\\\\\\python\\\\\\\\plugins\\\\\\\\cadtools\\\\\\\\tools']\n\n"], "labels": ["Bug", "Plugins"]}
{"project": "scikit-image_scikit-image", "title": "Computing structural similarity between images", "description": "I am trying to compare 3D images using SSIM, and finding expected results (nearly identical images are more similar than those with greater differences). What I was unable to glean from the SSIM documentation, however, (as the documentation is in 2d) is how is the 3rd dimension handled? Additionally how would this scale to a 4th dimension, such as time? Thanks so much for your time and help! ", "code": [], "labels": ["type: support"]}
{"project": "facebook_flow", "title": "$FlowFixMe ignored when used inside [declarations] file", "description": "If I add this configuration to my .flowconfig file: <CODE> I get an error in one of the .js.flow definitions living in a dist folder that should be ignored by a // $FlowFixMe. In practice, if I remove [declarations] I don't get any error ($FlowFixMe respected), if I add [declarations] I get an error ($FlowFixMe ignored) ", "code": ["[declarations]\n.*/dist/.*\n"], "labels": ["bug"]}
{"project": "facebook_react-native", "title": "Android: scrollReponderScrollWithoutAnimationTo on ListView doesn't do anything.", "description": "The documentation has me believing that calling scrollResponderScrollWithoutAnimationTo on a ListView ref should allow me to set the scroll position on Android. It looks like it's not doing anything. Is this known behavior? ", "code": [], "labels": ["Resolution: Locked"]}
{"project": "netbox-community_netbox", "title": "Error activating user secret key", "description": "Hello! I created a key for my netbox user to be able to use secrets. The key is inactive. When I try to activate the key from the admin panel with my own user I receive an error (debug below) . If I try to activate using the admin user the message You do not have an active User Key. appears on the top of the page without any debug error. Netbox v1.3.0. <CODE> ", "code": ["TypeError at /admin/secrets/userkey/\n\nobject of type 'NoneType' has no len()\n\nRequest Method:     POST\nRequest URL:    https://netbox.mpsc.mp.br/admin/secrets/userkey/\nDjango Version:     1.9.7\nException Type:     TypeError\nException Value:    \n\nobject of type 'NoneType' has no len()\n\nException Location:     /usr/local/lib/python2.7/dist-packages/Crypto/Cipher/PKCS1_OAEP.py in encrypt, line 139\nPython Executable:  /usr/bin/python\nPython Version:     2.7.6\nPython Path:    \n\n['/opt/netbox/netbox/netbox',\n '/opt/netbox/netbox',\n '/usr/bin',\n '/usr/lib/python2.7',\n '/usr/lib/python2.7/plat-x86_64-linux-gnu',\n '/usr/lib/python2.7/lib-tk',\n '/usr/lib/python2.7/lib-old',\n '/usr/lib/python2.7/lib-dynload',\n '/usr/local/lib/python2.7/dist-packages',\n '/usr/lib/python2.7/dist-packages']\n\nServer time:    Wed, 20 Jul 2016 16:47:32 -0300\n"], "labels": ["need more info"]}
{"project": "bigbluebutton_bigbluebutton", "title": "Incorrectly marking failed exact locale match as an error", "description": " ", "code": [], "labels": ["Bug", "HTML5 Client"]}
{"project": "hashicorp_packer", "title": "New ISO on same URL requires two executions to download", "description": "I am publishing a base ISO on a certain URL, with a checksum file on another URL. Both URLs are static, with only the contents changing between versions. When the ISO and checksum file change, Packer detects that the ISO it downloaded in the past is out out date but instead of downloading a new ISO, it just errors out: <CODE> However, if I then re-run the build it correctly starts downloading the ISO (presumably because the previous checksum mismatch resulted in it getting deleted). I would expect Packer to perform the download on the first run if it detects out of date already-downloaded files. Packer version: master branch from early February\nHost platform: Windows 10 v1709\nBuilder type: Hyper-V ISO ", "code": ["==> Windows1709-HyperV: Downloading or copying ISO\n    Windows1709-HyperV: Downloading or copying: https://xxxx/windows1709-setupiso.iso?xxxxxxxx\n    Windows1709-HyperV: Download progress: 100%\n    Windows1709-HyperV: Download progress: 100%\n    Windows1709-HyperV: Error downloading: checksums didn't match expected: bf0a4096947e8cd1491bde93754bcf43007515761b7b4f1d741119c4c5c3ae48\n==> Windows1709-HyperV: ISO download failed.\n==> Windows1709-HyperV: Step \"StepDownload\" failed, aborting...\nBuild 'Windows1709-HyperV' errored: unexpected EOF\n\n==> Some builds didn't complete successfully and had errors:\n--> Windows1709-HyperV: unexpected EOF\n"], "labels": ["enhancement", "core", "wontfix"]}
{"project": "agda_agda", "title": "Problem with ~ + with + ()", "description": "<CODE> Original issue reported on code.google.com by nils.anders.danielsson on 18 Jun 2008 at 4:49 ", "code": ["module Bug where\n\ndata _\u2261_ {a : Set} (x : a) : a -> Set where\n  refl : x \u2261 x\n\ndata D : Set where\n  d\u2081 : D\n  d\u2082 : D\n\nfoo : D -> d\u2081 \u2261 d\u2082 -> Set\nfoo d\u2081 eq ~ D\nfoo d\u2082 eq with eq\nfoo d\u2082 eq | ()\n\n-- Not implemented: mutual recursion and corecursion\n\n"], "labels": ["Priority-Low", "type: bug"]}
{"project": "highcharts_highcharts", "title": "Chart not showing in Angular 2/4 Modal after upgrade to 5.0.14 (Caused by #5783)", "description": "Chart should display in modal dialog. The chart element is missing when using highcharts > 5.0.12\nIt appears to have been broken by the fix for #5783 By changing the version of highcharts in package.json, you can reproduce the issue. <URL> 5.0.12 is fine\n5.0.13, 5.0.14 are broken. chrome 60 ", "code": [], "labels": ["Type: Duplicate"]}
{"project": "sqlmapproject_sqlmap", "title": "Unhandled exception (#0ee2c1b5)", "description": "<CODE> <CODE> ", "code": ["sqlmap version: 1.0-dev-nongit-20150125\nPython version: 2.7.2\nOperating system: posix\nCommand line: sdl --disable-col -m /sdcard/md5_5211698b2803cd308590f70cc4a98166.apk -v 1 --timeout=30 --retries=3 --threads=1 --risk=1 --level=1 --technique=BEUSTQ\nTechnique: None\nBack-end DBMS: None (identified)\n", "Traceback (most recent call last):\n  File \"Volumes/BADA/repos/my/sqlmapchik/.buildozer/android/app/sqlmap/sqlmap.py\", line 100, in main\n  File \"Volumes/BADA/repos/my/sqlmapchik/.buildozer/android/app/sqlmap/lib/controller/controller.py\", line 279, in start\n  File \"Volumes/BADA/repos/my/sqlmapchik/.buildozer/android/app/sqlmap/lib/core/common.py\", line 1246, in parseTargetUrl\n  File \"Volumes/BADA/repos/my/sqlmapchik/.buildozer/android/platform/python-for-android/dist/sqlmapchik/private/lib/python2.7/encodings/idna.py\", line 164, in encode\n  File \"Volumes/BADA/repos/my/sqlmapchik/.buildozer/android/platform/python-for-android/dist/sqlmapchik/private/lib/python2.7/encodings/idna.py\", line 95, in ToASCII\nLookupError: unknown encoding: punycode\n"], "labels": ["duplicate"]}
{"project": "emscripten-core_emscripten", "title": "File globbing on windows", "description": "On Windows, when I try to use file globs, they don't work.  FWIW, file globs work on linux. Example <CODE> yields <CODE> so it is clearly not handling the glob properly. ", "code": ["dir *.cpp\nC:\\Users\\Belli\\Documents\\Code\\emscripten\\em++ *.cpp\n", " Volume in drive C is Windows7_OS\n Volume Serial Number is 8E2A-26D8\n\n Directory of C:\\Users\\Belli\\Documents\\Code\\CoolProp\\CoolProp\n\n09/22/2013  04:07 PM             1,927 AllFluids.cpp\n08/11/2013  01:50 PM            23,349 Brine.cpp\n09/27/2013  12:13 PM            32,092 CoolProp.cpp\n09/21/2013  10:42 PM            12,556 CoolPropDLL.cpp\n09/15/2013  11:09 PM             5,817 CoolPropTools.cpp\n09/26/2013  05:03 PM            75,761 CPState.cpp\n08/11/2013  01:50 PM             1,314 CriticalSplineConstants.cpp\n09/25/2013  02:22 PM           123,579 FluidClass.cpp\n09/27/2013  01:30 PM            63,760 Helmholtz.cpp\n09/27/2013  12:13 PM            52,806 HumidAirProp.cpp\n08/11/2013  01:50 PM             3,926 Ice.cpp\n09/27/2013  12:13 PM            11,313 IncompBase.cpp\n09/27/2013  12:13 PM             3,796 IncompLiquid.cpp\n09/27/2013  12:13 PM             6,861 IncompSolution.cpp\n09/27/2013  12:13 PM             4,171 MatrixMath.cpp\n09/15/2013  11:09 PM            27,533 Mixtures.cpp\n09/15/2013  11:09 PM             2,844 PengRobinson.cpp\n09/21/2013  09:49 PM            43,289 REFPROP.cpp\n09/19/2013  04:54 PM             8,506 Solvers.cpp\n09/11/2013  03:20 PM             1,081 Spline.cpp\n09/26/2013  05:29 PM            85,778 TTSE.cpp\n09/27/2013  12:13 PM             3,150 Units.cpp\n              22 File(s)        595,209 bytes\n               0 Dir(s)  16,914,239,488 bytes free\n\nC:\\Users\\Belli\\Documents\\Code\\CoolProp\\CoolProp>C:\\Users\\Belli\\Documents\\Code\\emscripten\\em++ *.cpp \nERROR    root: *.cpp: No such file or directory\n"], "labels": ["wontfix"]}
{"project": "CartoDB_cartodb", "title": "Histogram tooltips don't refresh after changing column", "description": "Histogram tooltips use the same value after changing the column. The values are the same The values are updated ", "code": [], "labels": ["Frontend", "bug"]}
{"project": "microsoft_vscode", "title": "Breakpoint mark stays visible after mouse leave", "description": "It's an issue that hard to reproduce on the first try \ud83d\ude08 but I get it occasionally and it confuses me\n ", "code": [], "labels": ["bug", "*out-of-scope", "debug"]}
{"project": "npm_npm", "title": "Having issues installing Braintree", "description": "I've updated my latest version of node.js and trying to install braintree and getting the following errors. 0 info it worked if it ends with ok\n1 verbose cli [ 'C:\\Program Files (x86)\\nodejs\\node.exe',\n1 verbose cli   'C:\\Program Files (x86)\\nodejs\\node_modules\\npm\\bin\\npm-cli.js',\n1 verbose cli   'install',\n1 verbose cli   '--save',\n1 verbose cli   'braintree-web' ]\n2 info using npm@2.14.7\n3 info using node@v4.2.1\n4 verbose install initial load of D:\\Visual Studio\\Visual Studio 2013\\Projects\\ZR\\Braintree\\package.json\n5 verbose readDependencies loading dependencies from D:\\Visual Studio\\Visual Studio 2013\\Projects\\ZR\\Braintree\\package.json\n6 silly cache add args [ 'braintree-web', null ]\n7 verbose cache add spec braintree-web\n8 silly cache add parsed spec Result {\n8 silly cache add   raw: 'braintree-web',\n8 silly cache add   scope: null,\n8 silly cache add   name: 'braintree-web',\n8 silly cache add   rawSpec: '',\n8 silly cache add   spec: '',\n8 silly cache add   type: 'range' }\n9 silly addNamed braintree-web@\n10 verbose addNamed \"\" is a valid semver range for braintree-web\n11 silly addNameRange { name: 'braintree-web', range: '', hasData: false }\n12 silly mapToRegistry name braintree-web\n13 silly mapToRegistry using default registry\n14 silly mapToRegistry registry <URL>\n15 silly mapToRegistry uri <URL>\n16 verbose addNameRange registry:<URL> not in flight; fetching\n17 verbose request uri <URL>\n18 verbose request no auth needed\n19 info attempt registry request try #1 at 3:26:26 PM\n20 verbose request id f9226657f8dc20bb\n21 http request GET <URL>\n22 info retry will retry, error on last attempt: Error: write EPROTO\n23 info attempt registry request try #2 at 3:26:37 PM\n24 http request GET <URL>\n25 info retry will retry, error on last attempt: Error: write EPROTO\n26 info attempt registry request try #3 at 3:27:37 PM\n27 http request GET <URL>\n28 verbose stack Error: write EPROTO\n28 verbose stack     at Object.exports._errnoException (util.js:874:11)\n28 verbose stack     at exports._exceptionWithHostPort (util.js:897:20)\n28 verbose stack     at WriteWrap.afterWrite (net.js:763:14)\n29 verbose cwd D:\\Visual Studio\\Visual Studio 2013\\Projects\\ZR\\Braintree\n30 error Windows_NT 6.1.7601\n31 error argv \"C:\\Program Files (x86)\\nodejs\\node.exe\" \"C:\\Program Files (x86)\\nodejs\\node_modules\\npm\\bin\\npm-cli.js\" \"install\" \"--save\" \"braintree-web\"\n32 error node v4.2.1\n33 error npm  v2.14.7\n34 error code EPROTO\n35 error errno EPROTO\n36 error syscall write\n37 error write EPROTO\n38 error If you need help, you may report this error at:\n38 error     <URL>\n39 verbose exit [ 1, true ] ", "code": [], "labels": ["support"]}
{"project": "AutoMapper_AutoMapper", "title": "Conditional inheritance with AutoMapper", "description": "Hello, I have a small problem regarding the use conditional inheritance with AutoMapper in the DTO to Entity direction. I have inheritance (TPH) between my entities, namely an abstract mother class \"ConnectorBaseEntity\". And two children classes:\n\"ConnectorOracleEntity\" and \"ConnectorMySQLEntity\" To add a new connector, I go through a end point POST type that takes as parameter a \"ConnectorCreateDTO\" which contains all the properties of children. I defined my mapping between my DTO and my classes like this: I use the \"As\" because my mother entity is abstract, I can not use it, so I use the derived type as a base. Then in my controller I map: The problem is that I do not know how to tell AutoMapper to use the right child based on the \"type\" property in my \"ConnectorCreateDTO\". I have to make a big \"if\" or a \"switch\" to handle all the mapping cases in my controller? Is there not a cleaner way to handle inheritance conditions directly in the map? What do you recommend ? Thank you. AutoMapper 8.1.0\nPomelo.EntityFrameworkCore.MySql 2.2.0 ", "code": [], "labels": ["Question"]}
{"project": "JosefNemec_Playnite", "title": "Playtime tracking broken for some Microsoft Store games (Possibly due to Title Update ?)", "description": "So I've had Sea of Thieves added to Playnite for some time, now. However, I've only reinstalled it recently and noticed on both a first and second launch that Playnite, while able to launch the game, is unable to keep track of the process. I've re-imported the .exe of the game and the issue was caused by the installation folder now having a different ID. Former folder :\nC:\\Program Files\\WindowsApps\\Microsoft.SeaofThieves_2.75.7351.2_x64__8wekyb3d8bbwe New folder:\nC:\\Program Files\\WindowsApps\\Microsoft.SeaofThieves_2.83.6356.2_x64__8wekyb3d8bbwe Renaming the target folder in the game's details has fixed the issue, but I'm not sure if the change was caused by the way this particular game handles title updates or if it's anything else. Metal Slug 2 was also added some time ago and the process is still tracked with no issue, but this could be due to it not having been updated since. ", "code": [], "labels": ["bug"]}
{"project": "nim-lang_Nim", "title": "Compiler error using parsecfg module in a macro", "description": "The following code crashes the compiler: The generated output is: <CODE> Is this an error in the compiler or is the parsecfg not meant to be used at compile time? ", "code": ["lib/pure/lexbase.nim(143, 8) Error: internal error: evalAux: returned nil nkInfix\nTraceback (most recent call last)\nnimrod.nim(79)           nimrod\nnimrod.nim(55)           HandleCmdLine\nmain.nim(308)            MainCommand\nmain.nim(73)             CommandCompileToC\nmodules.nim(193)         CompileProject\nmodules.nim(151)         compileModule\npasses.nim(192)          processModule\npasses.nim(136)          processTopLevelStmt\nsem.nim(311)             myProcess\nsem.nim(285)             SemStmtAndGenerateGenerics\nsemstmts.nim(1258)       semStmt\nsemexprs.nim(816)        semExprNoType\nsemexprs.nim(1884)       semExpr\nsemexprs.nim(773)        semDirectOp\nsemexprs.nim(757)        afterCallActions\nsem.nim(228)             semMacroExpr\nevals.nim(1481)          evalMacroCall\nevals.nim(1443)          eval\nevals.nim(1438)          tryEval\nevals.nim(1404)          evalAux\nevals.nim(1340)          evalAux\nevals.nim(994)           evalMagicOrCall\nevals.nim(444)           evalCall\nevals.nim(1404)          evalAux\nevals.nim(1404)          evalAux\nevals.nim(1340)          evalAux\nevals.nim(994)           evalMagicOrCall\nevals.nim(444)           evalCall\nevals.nim(1404)          evalAux\nevals.nim(1404)          evalAux\nevals.nim(1404)          evalAux\nevals.nim(1386)          evalAux\nevals.nim(124)           evalIf\nevals.nim(1340)          evalAux\nevals.nim(1312)          evalMagicOrCall\nevals.nim(1340)          evalAux\nevals.nim(1312)          evalMagicOrCall\nevals.nim(1430)          evalAux\nmsgs.nim(811)            InternalError\nmsgs.nim(788)            liMessage\nmsgs.nim(701)            handleError\n"], "labels": ["stdlib"]}
{"project": "ansible_ansible", "title": "Transient failure caused by new pipelining patch.", "description": "I've been testing a moderate sized playbook for fedora infrastructure.  the new requiretty + pipelining patch is causing a very strange problem. The playbook has 136 tasks to create and configure a certain host.  A second host gets 123 tasks and skips 13.  When I run the devel branch with pipelining on the host that has 136 tasks always fails.  The one with 123 tasks never has.  However, the task that fails is not stable.  In every run I've made so far it's been a different task.  (All of the tasks that failed thus far have run on both hosts but I think that's just a percentage chance.. I don't think the tasks necessarily have to run on both). The traceback I get back from the host is either a SyntaxError or  an IndentationError: <CODE> jimi pointed out that this is what happens if we pipe a module into python and python thinks it has a tty ( copy and paste a module into the interactive prompt and that's the error you get). Sure enough, if I set pipelining = False in the ansible.cfg, I can't provoke the error anymore.  If I switch to the stable-2.0 branch, I also can't provoke the error.  So it seems that something about the patch to use python to stream the module in pipelining mode is intermittently failing to do what it's supposed to.  Intermittently, the python that actually executes the module thinks it has a tty and runs in interactive mode causing the error. ", "code": ["<noc02.fedoraproject.org> SSH: EXEC ssh -C -vvv -o ControlMaster=auto -o ControlPersist=60s -o Port=22 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=root -o ConnectTimeout=90 -o ControlPath=/root/.ansible/cp/ansible-ssh-%h-%p-%r -tt noc02.fedoraproject.org LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 python -uc 'import sys; [sys.stdout.write(s) for s in iter(sys.stdin.readline, \"__EOF__942d747a0772c3284ffb5920e234bd57__\\n\")]'| LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 /usr/bin/python\nfatal: [noc01.phx2.fedoraproject.org]: FAILED! => {\"changed\": false, \"failed\": true, \"invocation\": {\"module_args\": {\"name\": \"root\", \"password\": \"$6$77Ba4HEk$X1ejN6W0yRy6NZeG0R2WoSS5d8EPiZJPukFrY7pklxlB.39o5mbKW3Sxd4WSs7VK4B4EVPLaBjDFBE7TSRtTY0\", \"state\": \"present\"}, \"module_name\": \"user\"}, \"msg\": \"  File \\\"<stdin>\\\", line 1\\r\\n    o\\\" ]\\r\\n       ^\\r\\nSyntaxError: EOL while scanning string literal\\r\\nTraceback (most recent call last):\\r\\n  File \\\"<string>\\\", line 1, in <module>\\r\\nIOError: [Errno 32] Broken pipe\\r\\nOpenSSH_6.6.1, OpenSSL 1.0.1e-fips 11 Feb 2013\\r\\ndebug1: Reading configuration data /root/.ssh/config\\r\\ndebug1: Reading configuration data /etc/ssh/ssh_config\\r\\ndebug1: /etc/ssh/ssh_config line 56: Applying options for *\\r\\ndebug1: auto-mux: Trying existing master\\r\\ndebug2: fd 3 setting O_NONBLOCK\\r\\ndebug2: mux_client_hello_exchange: master version 4\\r\\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\\r\\ndebug3: mux_client_request_session: entering\\r\\ndebug3: mux_client_request_alive: entering\\r\\ndebug3: mux_client_request_alive: done pid = 32625\\r\\ndebug3: mux_client_request_session: session request sent\\r\\ndebug1: mux_client_request_session: master session id: 2\\r\\ndebug3: mux_client_read_packet: read header failed: Broken pipe\\r\\ndebug2: Received exit status from master 1\\r\\nShared connection to noc01.phx2.fedoraproject.org closed.\\r\\n\", \"parsed\": false}\n"], "labels": ["bug"]}
{"project": "telegramdesktop_tdesktop", "title": "Automatically stop and resume music on incoming call", "description": "It'd be nice to automatically stop music players on incoming Telegram calls. I'm not sure how complicated this would be to implement cross-OS, but I assume that most environments have appropriate mechanisms available. Here's how KDE Connect does it (uses KDE's media controls via dbus): <URL>\nOn macOS it's safe to assume that everyone's using iTunes. This would be an awesome feature as I tend to not notice incoming calls when music is playing. ", "code": [], "labels": ["enhancement"]}
{"project": "rclone_rclone", "title": "restic serve with jottacloud: Leaking TCP Connections", "description": "Rclone is leaking TCP connections. (More than 1000 open connections so it's running into the file descriptor limit) rclone v1.43.1 Jottacloud rclone serve restic I haven't managed to reproduce this intentionally and it has only happened on 2 occasions so far but I'm still trying to do so. I already rechecked the Jottacloud backend but all connections opened there should get closed so I doubt it's related to this backend. Will update this if I manage to reproduce it. ", "code": [], "labels": ["bug"]}
{"project": "spring-projects_spring-boot", "title": "Upgrade to Spring Session Corn-RELEASE", "description": "\nNo description provided.\n ", "code": [], "labels": ["type: dependency-upgrade"]}
{"project": "ocaml_ocaml", "title": "Out of memory while compiling ocaml on alpha", "description": "Original bug ID: 1526\nReporter: administrator\nStatus: closed\nResolution: fixed\nPriority: normal\nSeverity: minor\nCategory: ~DO NOT USE (was: OCaml general) Full_Name: Marco Maggesi\nVersion: 3.06\nOS: debian linux on alpha\nSubmission from: sisiphos.math.unifi.it (150.217.33.46) I start the compilation of ocaml as follows ~$ ./configure\n~$ make -k world > log.world 2>&1 and the compilation abort here:\n...\nsh ./runocamldoc true -man -d stdlib_man -I ../parsing -I ../utils -I\n../typing\n-I ../driver -I ../bytecomp -I ../tools -I ../toplevel/ -I ../stdlib -I\n../other\nlibs/str -I ../otherlibs/dynlink -I ../otherlibs/unix -I ../otherlibs/num -I\n../\notherlibs/graph \n-t \"OCaml library\" -man-mini \n../stdlib/*.mli ../otherlibs/unix/unix.mli ../otherlibs/str/str.mli\n../otherlibs\n/bigarray/bigarray.mli ../otherlibs/num/num.mli\nFatal error: out of memory.\nmake[1]: *** [stdlib_man/Pervasives.o] Error 2\nmake[1]: Target all' not remade because of errors. make[1]: Leaving directory /home/maggesi/ocaml-3.06/ocamldoc' The previous versions of ocaml (e.g. 3.04) compiled without problems\non the very same box (a Compaq DS 10). I went futher and I installed anyway the ocaml bytecode compiler.\nBut then I tryied to compile Coq and the compilation ended with another\nend of memory. The system itself seems have no problem of memory: ~$ uname -a\nLinux sisiphos 2.4.18marco #1 Fri Aug 23 12:37:19 CEST 2002 alpha unknown\n~$ set -a\n~$ free\ntotal       used       free     shared    buffers     cached\nMem:        381584     369200      12384          0      10096     267016\n-/+ buffers/cache:      92088     289496\nSwap:       384048          0     384048 ", "code": [], "labels": ["bug"]}
{"project": "alvarotrigo_fullPage.js", "title": "Hi", "description": "[Ideally in jsfiddle.net or codepen.io, links to personal websites won't be reviewed unless isolated. Reported issues without a reproduction might get closed.] [Browser, operative system, device...] ", "code": [], "labels": ["question"]}
{"project": "qgis_QGIS", "title": "Open, import, export default paths should be stored by project", "description": "Feature description.\nRemember what the last-used path was on a per-project basis for filesystem operations. Additional context\nCurrently when I am switching between multiple projects, every time I go to import a layer, or export, or do anything with the file-system, the 'select location' window defaults to the last-used path, meaning I have to drill back to the current project. Every. Time. Simplest would be to reset the last-used locations to the project path on switch. Even more slick would be to remember the last-used paths for each action on a per-project basis. ", "code": [], "labels": ["Feature Request"]}
{"project": "Carthage_Carthage", "title": "Xcode build fails when using Carthage-managed dependencies", "description": "Cartfile <CODE> Carthage Output <CODE> Actual outcome\nXcode build failed when attempting to run the 'copy frameworks' script:\n/usr/local/bin/carthage copy-frameworks\nInput file:\n$(SRCROOT)/Carthage/Build/iOS/RxSwift.framework Error:\nFailed to read file or folder at /Users/adrianward/Documents/Software Development/Apollo/Carthage/Build/iOS/RxSwift.framework\nCommand PhaseScriptExecution failed with a nonzero exit code Removing the copy framework script resolves the issue Expected outcome\nBuild successfully ", "code": ["github \"ReactiveX/RxSwift\"\ngithub \"RxSwiftCommunity/RxDataSources\"\ngithub \"RxSwiftCommunity/Action\"\ngithub \"RxSwiftCommunity/RxRealm\"\n\ngithub \"realm/realm-cocoa\"\n\ngithub \"Quick/Quick\"\ngithub \"Quick/Nimble\"\n", "As expected\n"], "labels": ["stale"]}
{"project": "dart-lang_sdk", "title": "Failed to watch path, path (OS Error: No space left on device, errno = 28)", "description": "This issue was originally filed by thaniyaras...@gmail.com dev@dev:/dart/demo$ dart --version\nDart VM version: 1.8.3 (Mon Dec  1 08:42:49 2014) on \"linux_x64\"\ndev@dev:/dart/demo$ pub --version\nPub 1.8.3\ndev@dev:~/dart/demo$ ----------pubspec.yaml--------------\nname: demo\ndescription: A sample web application\ndependencies:\n\u00a0\u00a0browser: any dev@dev:~/dart/demo$ pub serve\nLoading source assets...\nServing demo web on http://localhost:8080\nBuild completed successfully\nthen all are working fine but when i add angular into pubspec.yaml ----------pubspec.yaml--------------\nname: demo\ndescription: A sample web application\ndependencies:\n\u00a0\u00a0browser: any\n\u00a0\u00a0angular: any dev@dev:~/dart/demo$ pub serve\nYour pubspec has changed, so we need to update your lockfile:\nResolving dependencies... (24.3s) \u00a0\u00a0\u00a0\u00a0pub --trace 'serve' and include the results in a bug report on <URL>\ndev@dev:~/dart/demo$ pub --trace 'serve'\nLoading source assets...\nFailed to watch path, path = '/home/dev/dart/demo/web/packages/source_span/src' (OS Error: No space left on device, errno = 28) ---- Log transcript ----\nFINE: Pub 1.8.3\nFINE: Clean up system cache temp directory /home/dev/.pub-cache/_temp.\nFINE: Loading asset environment...\nFINE: Loading package graph...\nFINE: Loading package graph finished (0.1s).\nFINE: Initializing barback...\nFINE: Serving packages on localhost:0.\nFINE: Providing sources for demo|lib.\nFINE: Loading source assets finished (0.0s).\nFINE: Provided sources.\nFINE: Loading transformers...\nFINE: Transformer dependencies:\nFINE: Loading transformers finished (0.0s).\nFINE: Initializing barback finished (0.0s).\nFINE: Loading asset environment finished (0.2s).\nFINE: Bound admin server to localhost:8079.\nFINE: Providing sources for demo|web.\nERR : Failed to watch path, path = '/home/dev/dart/demo/web/packages/source_span/src' (OS Error: No space left on device, errno = 28)\nFINE: Exception type: FileSystemException\nFINE: dart:async                                            _BoundSinkStream.listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 283  _LinuxDirectoryWatcher._listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 63   _LinuxDirectoryWatcher._LinuxDirectoryWatcher\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 127  _LinuxDirectoryWatcher._watchSubdir\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 70   _LinuxDirectoryWatcher._LinuxDirectoryWatcher.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                          _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                            _StreamImpl.listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 283  _LinuxDirectoryWatcher._listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 67   _LinuxDirectoryWatcher._LinuxDirectoryWatcher\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 127  _LinuxDirectoryWatcher._watchSubdir\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 70   _LinuxDirectoryWatcher._LinuxDirectoryWatcher.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                          _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                            _StreamImpl.listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 283  _LinuxDirectoryWatcher._listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 67   _LinuxDirectoryWatcher._LinuxDirectoryWatcher\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 127  _LinuxDirectoryWatcher._watchSubdir\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 70   _LinuxDirectoryWatcher._LinuxDirectoryWatcher.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                          _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                                              _StreamImpl.listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 283                                                                                    _LinuxDirectoryWatcher._listen\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 67                                                                                     _LinuxDirectoryWatcher._LinuxDirectoryWatcher\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/linux.dart 28                                                                                     LinuxDirectoryWatcher.LinuxDirectoryWatcher.<fn>\n\u00a0\u00a0\u00a0\u00a0| package:watcher/src/directory_watcher/resubscribable.dart 49                                                                            ResubscribableDirectoryWatcher.ResubscribableDirectoryWatcher.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                                              _StreamImpl.listen\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/barback/asset_environment.dart 784  AssetEnvironment._watchDirectorySources\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/barback/asset_environment.dart 716  AssetEnvironment._provideDirectorySources\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/barback/asset_environment.dart 257  AssetEnvironment.serveDirectory\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 209              ServeCommand._startServer.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                                                                                                            _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                                  scheduleMicrotask\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 207  ServeCommand._startServer\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 148  ServeCommand.onRunTransformerCommand.<fn>.join0.join1.<fn>.<fn>.join2.continue0\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 168  ServeCommand.onRunTransformerCommand.<fn>.join0.join1.<fn>.<fn>.join2\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 175  ServeCommand.onRunTransformerCommand.<fn>.join0.join1.<fn>.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                                                                                                _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                                  _Future.then\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 111  ServeCommand.onRunTransformerCommand.<fn>.join0.join1.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                                                                                                _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                                  _Future.then\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 105  ServeCommand.onRunTransformerCommand.<fn>.join0.join1\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 189  ServeCommand.onRunTransformerCommand.<fn>.join0\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 193  ServeCommand.onRunTransformerCommand.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                                                                                                _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                                   scheduleMicrotask\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/serve.dart 92    ServeCommand.onRunTransformerCommand\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command/barback.dart 63  onRun\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                                   Future.Future.sync\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/command.dart 206         PubCommand.run\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 164                 invokeCommand.<fn>.break0.join0\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 177                 invokeCommand.<fn>.break0\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 235                 invokeCommand.<fn>.continue0\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 239                 invokeCommand.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                                                                                                 _RawReceivePortImpl._handleMessage\n\u00a0\u00a0\u00a0\u00a0| ===== asynchronous gap ===========================\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                          scheduleMicrotask\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 145        invokeCommand\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 98         runPub.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:async                                                                                                          Future.Future.sync\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/utils.dart 98   captureErrors.<fn>\n\u00a0\u00a0\u00a0\u00a0| package:stack_trace/src/chain.dart 78                                                                               Chain.capture\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/lib/src/utils.dart 112  captureErrors\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 97         runPub\n\u00a0\u00a0\u00a0\u00a0| /mnt/data/b/build/slave/dart-editor-linux-stable/build/dart/sdk/lib/_internal/pub_generated/bin/pub.dart 84         main.<fn>\n\u00a0\u00a0\u00a0\u00a0| dart:isolate                                                                                                        _RawReceivePortImpl._handleMessage ---- End log transcript ----\nUnhandled exception:\nUncaught Error: Bad state: Future already completed\nStack Trace: dev@dev:~/dart/demo$ any solution ? ", "code": [], "labels": ["Type-Defect"]}
{"project": "bokeh_bokeh", "title": "Issue with webgl line plots on Windows only", "description": "I've found an apparent bug in Bokeh's line plots that only appears on Windows, when webgl is enabled, and (apparently, although this has been more difficult to show conclusively) only with certain types of data. The code to produce this case is as shown below (where I've attached bad_case.npz, as well as the two resulting output files on my system). A few other notes: import numpy as np\nfrom bokeh.plotting import figure, output_file, show\nnpzfile = np.load('bad_case.npz')\nf = npzfile['arr_0'] # Vector of frequency bins for spectrogram\ndB = npzfile['arr_1'] # Vector of power density for each frequency bin (all negative numbers but no NaNs)\nplot = figure(webgl=True)\noutput_file('spectrum_bad_webgl.html')\nplot.line(f,dB)\nshow(plot) # Renders the spectrogram correctly\nplot2 = figure()\noutput_file('spectrum_correct_no_webgl.html')\nplot2.line(f,dB)\nshow(plot2) # Bizarre scaling issue bad_case.zip ", "code": [], "labels": ["reso: completed", "type: discussion"]}
{"project": "vuejs_vetur", "title": "Methods in mixin not visible in vue component.", "description": "I created mixin and connected him to vue component.\nMethods in mixin not visible in vue component.\nI use only JavaScript \n ", "code": [], "labels": ["feature"]}
{"project": "eslint_eslint", "title": "Incorrect indent when using curly braces and switch case", "description": "Tell us about your environment Please show your full configuration: The indent rule doesn't work properly, when using curly braces inside a switch case:\nThis should be correct code with this config: But it seems like the indentation have to be like this to be accepted by ESLint: ", "code": [], "labels": ["triage", "archived due to age"]}
{"project": "lxc_lxd", "title": "boot.autostart blocks lxc/lxd commands", "description": "When having multiple containers start automatically at boot time, it appears LXD is blocked until all autostart containers have finished booting. This is best seen when containers have an autostart delay. I see this behavior when running 3 containers, each with the following configuration. 1:\nconfig:\nboot.autostart: \"true\"\nboot.autostart.delay: \"30\"\nboot.autostart.priority: \"100\" 2:\nboot.autostart: \"true\"\nboot.autostart.delay: \"5\"\nboot.autostart.priority: \"1\" 3:\nboot.autostart: \"true\"\nboot.autostart.delay: \"5\"\nboot.autostart.priority: \"0\" When the server has just booted (and container 1 has just started), 'lxc list' blocks until all containers are fully started and then returns the list of containers. ", "code": [], "labels": ["Easy", "Bug"]}
{"project": "vuetifyjs_vuetify", "title": "[Feature Request] Option to change language snippet in Data Iterable", "description": "Hey there,\nI\u00b4m working with the Data Tables component and need to translate some texts. Which works pretty neat with props like rowsPerPageText. I found a snippet which is not really easy to change athough and it is the amount of results \"1-5 of 75\". The code is generated in the mixin data-iterable.js in line 436 in a private variable for the pagination\n${this.pageStart + 1}-${stop} of ${this.itemsLength}\nThe word \"of\" is hard coded here and to change it there needs to be jQuery-ish scraping of innerHtml plus an watcher whenever the pagination changes again. Kind of bloated. So my request is: it would be good to have a prop to override the word here. Thanks for your excellent work though! ", "code": [], "labels": ["duplicate"]}
{"project": "carla-simulator_carla", "title": "Integrating Dynamic Vehicle Simulation model to Carla", "description": "Hi, Although Carla is a great environment simulation platform but an addition of a dynamic vehicle model would definitely be a big boost and that is why I decided to integrate one such model. I segregated a list of attributes that I would require between Carla and the Vehicle Model. Since I already have the necessary signals available in my vehicle simulation tool that is why i will only mention the signals important for CARLA. Some I have already found in Carla while I am looking for the rest. Signals required from Vehicle Simulation to Carla. There should be a possibility in Carla to find and overwrite these attributes externally: Then some signals would be required from Carla going into the vehicle model. This should be readable from Carla : Is it necessary to apply the vehichle control only through VehiclePhysicsControl() class ? Cant I access the attributes and write them externally without using this class ? ", "code": [], "labels": ["stale"]}
{"project": "LawnchairLauncher_Lawnchair", "title": "Lawnchair request 26", "description": "BUG: (v198) When selecting app icons to move them, Lawnchair freezes for about a second. (It's probably because of the new app shortcut dialogue. In case I didn't mention this earlier, also support Android Nougat app shortcuts, like Nova Launcher does) ", "code": [], "labels": ["duplicate"]}
{"project": "marionettejs_backbone.marionette", "title": "When view is closed during a model event, subsequent model events are still called", "description": "When more than one nested views listen to the same model and an outer view\ncloses an inner view, event callbacks on the inner view are continuing to fire,\ncausing thrown errors. See this JSFiddle (full screen) for a working example. Technically this could be considered a bug in Backbone, because the listeners\nfor a given event are replaced each time you stop listening to an event,\nmeaning that the listeners being processed during an event is effectively\ncached. Specifically, here is the code from backbone for the .off() method: <CODE> Note that on line 117 the events list is replaced with the retained list of\nevent handlers. It seems to me that the solution is more appropriate in Marionette because the\nproblem I'm encountering is a result of the actions of View.close() combined\nwith further callbacks running, not with the generic event mechanism. Marionette calls the following <CODE> from within View.close(), but any events bound (whether using .on() or\n.listenTo() which internally uses \"on\") are still cached. If the\ncallback/handler for the event uses \"this.ui\", then result will be a string\ninstead of a jQuery UI selection. My suggested solution is to check Marionette callbacks which use the listenTo\nmethod to see if the target has been closed first. If the target has been\nclosed, then the callback method should not be fired, because it is likely\nbased on the assumption that the target is still open / rendered. So the following code: <CODE> Would become (original line 199 becomes lines 199-202 and original line 205 becomes 208-211): <CODE> This solves the problem by always checking if a view is open before allowing\nevent callbacks to continue. By placing this code in the bindFromStrings and\nbindToFunction methods, all calls to bindEntityEvents (by default .model and\n.collection, but also supporting additional third party additions) are\nprotected. This has the obvious performance penalty of checking isClosed every time the\nmethod is called, but neatly fixes the problem. Before I attempt to submit a\npull request with this solution, I would like to know if this is the approach\nyou would like for solving this problem, or if you think Backbone should change\ntheir event handling to support .off() calls that effect running events. Requested diagnostic information: ", "code": ["102: // Remove one or many callbacks. If `context` is null, removes all\n103: // callbacks with that function. If `callback` is null, removes all\n104: // callbacks for the event. If `name` is null, removes all bound\n105: // callbacks for all events.\n106: off: function(name, callback, context) {\n107:   var retain, ev, events, names, i, l, j, k;\n108:   if (!this._events || !eventsApi(this, 'off', name, [callback, context])) return this;\n109:   if (!name && !callback && !context) {\n110:     this._events = {};\n111:     return this;\n112:   }\n113:   names = name ? [name] : _.keys(this._events);\n114:   for (i = 0, l = names.length; i < l; i++) {\n115:     name = names[i];\n116:     if (events = this._events[name]) {\n117:       this._events[name] = retain = [];\n118:       if (callback || context) {\n119:         for (j = 0, k = events.length; j < k; j++) {\n120:           ev = events[j];\n121:           if ((callback && callback !== ev.callback && callback !== ev.callback._callback) ||\n122:               (context && context !== ev.context)) {\n123:             retain.push(ev);\n124:           }\n125:         }\n126:       }\n127:       if (!retain.length) delete this._events[name];\n128:     }\n129:   }\n130:\n131:   return this;\n132: },\n", "962: // unbind UI elements\n963: this.unbindUIElements();\n964:\n965: // remove the view from the DOM\n966: this.remove();\n", "187: // Bind the event to handlers specified as a string of\n188: // handler names on the target object\n189: function bindFromStrings(target, entity, evt, methods){\n190:   var methodNames = methods.split(/\\s+/);\n191:\n192:   _.each(methodNames,function(methodName) {\n193:\n194:     var method = target[methodName];\n195:     if(!method) {\n196:       throwError(\"Method '\"+ methodName +\"' was configured as an event handler, but does not exist.\");\n197:     }\n198:\n199:     target.listenTo(entity, evt, method, target);\n200:   });\n201: }\n202:\n203: // Bind the event to a supplied callback function\n204: function bindToFunction(target, entity, evt, method){\n205:   target.listenTo(entity, evt, method, target);\n206: }\n", "187: // Bind the event to handlers specified as a string of\n188: // handler names on the target object\n189: function bindFromStrings(target, entity, evt, methods){\n190:   var methodNames = methods.split(/\\s+/);\n191:\n192:   _.each(methodNames,function(methodName) {\n193:\n194:     var method = target[methodName];\n195:     if(!method) {\n196:       throwError(\"Method '\"+ methodName +\"' was configured as an event handler, but does not exist.\");\n197:     }\n198:\n199:     target.listenTo(entity, evt, function() {\n200:       if(target.isClosed) return;\n201:       return method.apply(this, arguments);\n202:     }, target);\n203:   });\n204: }\n205:\n206: // Bind the event to a supplied callback function\n207: function bindToFunction(target, entity, evt, method){\n208:   target.listenTo(entity, evt, function() {\n209:     if(target.isClosed) return;\n210:     return method.apply(this, arguments);\n211:   }, target);\n212: }\n"], "labels": ["bug"]}
{"project": "microsoft_vscode", "title": "Reveal active file does not pass focus to the explorer", "description": "Commit: 2d79ffe I'm using Nord theme. It specifies \"list.focusBackground\": \"#88c0d099\": <URL> Stable tree uses that color:  Insider doesn't:  Repro: ", "code": [], "labels": ["bug", "file-explorer", "verified"]}
{"project": "espressif_arduino-esp32", "title": "Some functions defined in esp32-hal-uart.c are not declared in esp32-hal-uart.h", "description": "Some functions defined in esp32-hal-uart.c are not declared in esp32-hal-uart.h, They are <CODE> Is this intentional? Regards,\nAlessandro ", "code": ["void uartDetachRx(uart_t* uart)\n\nvoid uartDetachTx(uart_t* uart)\n\nvoid uartAttachRx(uart_t* uart, uint8_t rxPin, bool inverted)\n\nvoid uartAttachTx(uart_t* uart, uint8_t txPin, bool inverted)\n"], "labels": ["stale"]}
{"project": "fossasia_badgeyay", "title": "Sending Response from Error responses from Frontend", "description": "I'm submitting a ... Yes, I am working on it. ", "code": [], "labels": ["has-PR"]}
{"project": "kubernetes_kubernetes", "title": "No \"Terminating\" indication in kubectl get --output=json", "description": "/kind feature kubectl get and kubectl describe both distinguish Terminating and Running pods. However, shows status.phase as Running right up until the pod dies. This also makes it impossible to use --field-selector=...=Terminating to select only Terminating pods, and means Terminating pods show up in kubectl get --field-selector=status.phase.Running. Example: If this is the desired behavior for status.phase, it would be great to add a new field that does distinguish between Terminating and Running pods. ", "code": [], "labels": ["sig/cli", "kind/feature"]}
{"project": "spring-projects_spring-framework", "title": "JdkDynamicAopProxy constructs ReflectiveMethodInvocation with EmptyTargetSource.EMPTY_TARGET for static methods [SPR-15651]", "description": "Rob Winch opened SPR-15651 and commented The recent changes to EmptyTargetSource have broken Spring Security's tests. Spring Security relies on checking to see if a MethodInvocation.getThis() is null to determine if the method is static. This seems to be a safe assumption based on the javadoc which states: What's more is it would seem non-obvious for me to use the EmptyTargetSource.EMPTY_TARGET (which is not accessible, so I need to use EmptyTargetSource.INSTANCE.getTarget() from Spring Framework to compare against the result of MethodInvocation.getThis() from aopalliance. I think it makes sense to ensure that the construction of ReflectiveMethodInvocation contains target=null and targetClass=null for static methods. Affects: 5.0 RC2 Referenced from: commits spring-projects/spring-framework-issues@8011c93 ", "code": [], "labels": ["in: core", "type: bug"]}
{"project": "npm_npm", "title": "Could not install cordova ionic framework in UBUNTU using sudo npm install cordova ionic -g commond", "description": "Hi All, I am trying to install cordova ionic framework in my laptop running with Ubuntu 14.04 OS.\nI am attaching the error logs. Please help me out in fixing the issue Logs <CODE> ", "code": ["0 info it worked if it ends with ok\n1 verbose cli [ '/usr/bin/nodejs',\n1 verbose cli   '/usr/bin/npm',\n1 verbose cli   'install',\n1 verbose cli   'cordova',\n1 verbose cli   'ionic',\n1 verbose cli   '-g' ]\n2 info using npm@3.7.1\n3 info using node@v4.2.6\n4 silly loadCurrentTree Starting\n5 silly install loadCurrentTree\n6 silly install readGlobalPackageData\n7 silly fetchPackageMetaData cordova\n8 silly fetchPackageMetaData ionic\n9 silly fetchNamedPackageData cordova\n10 silly mapToRegistry name cordova\n11 silly mapToRegistry using default registry\n12 silly mapToRegistry registry https://registry.npmjs.org/\n13 silly mapToRegistry uri https://registry.npmjs.org/cordova\n14 silly fetchNamedPackageData ionic\n15 silly mapToRegistry name ionic\n16 silly mapToRegistry using default registry\n17 silly mapToRegistry registry https://registry.npmjs.org/\n18 silly mapToRegistry uri https://registry.npmjs.org/ionic\n19 verbose request uri https://registry.npmjs.org/cordova\n20 verbose request no auth needed\n21 info attempt registry request try #1 at 3:58:55 PM\n22 verbose request id 9b80e715d81163f3\n23 verbose etag \"E11XFPFZK7AS8NUO0D8LJ22IN\"\n24 http request GET https://registry.npmjs.org/cordova\n25 verbose request uri https://registry.npmjs.org/ionic\n26 verbose request no auth needed\n27 info attempt registry request try #1 at 3:58:55 PM\n28 verbose etag \"67N4ZHNF7NWJ26JQUHHB7HR46\"\n29 http request GET https://registry.npmjs.org/ionic\n30 http 304 https://registry.npmjs.org/cordova\n31 verbose headers { date: 'Sat, 06 Feb 2016 10:28:56 GMT',\n31 verbose headers   via: '1.1 varnish',\n31 verbose headers   'cache-control': 'max-age=300',\n31 verbose headers   etag: '\"E11XFPFZK7AS8NUO0D8LJ22IN\"',\n31 verbose headers   age: '24',\n31 verbose headers   connection: 'keep-alive',\n31 verbose headers   'x-served-by': 'cache-sin6926-SIN',\n31 verbose headers   'x-cache': 'HIT',\n31 verbose headers   'x-cache-hits': '1',\n31 verbose headers   'x-timer': 'S1454754536.827803,VS0,VE1',\n31 verbose headers   vary: 'Accept' }\n32 silly get cb [ 304,\n32 silly get   { date: 'Sat, 06 Feb 2016 10:28:56 GMT',\n32 silly get     via: '1.1 varnish',\n32 silly get     'cache-control': 'max-age=300',\n32 silly get     etag: '\"E11XFPFZK7AS8NUO0D8LJ22IN\"',\n32 silly get     age: '24',\n32 silly get     connection: 'keep-alive',\n32 silly get     'x-served-by': 'cache-sin6926-SIN',\n32 silly get     'x-cache': 'HIT',\n32 silly get     'x-cache-hits': '1',\n32 silly get     'x-timer': 'S1454754536.827803,VS0,VE1',\n32 silly get     vary: 'Accept' } ]\n33 verbose etag https://registry.npmjs.org/cordova from cache\n34 verbose get saving cordova to /home/bharath/.npm/registry.npmjs.org/cordova/.cache.json\n35 verbose correctMkdir /home/bharath/.npm correctMkdir not in flight; initializing\n36 http 304 https://registry.npmjs.org/ionic\n37 verbose headers { date: 'Sat, 06 Feb 2016 10:28:56 GMT',\n37 verbose headers   via: '1.1 varnish',\n37 verbose headers   'cache-control': 'max-age=300',\n37 verbose headers   etag: '\"67N4ZHNF7NWJ26JQUHHB7HR46\"',\n37 verbose headers   age: '214',\n37 verbose headers   connection: 'keep-alive',\n37 verbose headers   'x-served-by': 'cache-sin6923-SIN',\n37 verbose headers   'x-cache': 'HIT',\n37 verbose headers   'x-cache-hits': '2',\n37 verbose headers   'x-timer': 'S1454754536.962270,VS0,VE0',\n37 verbose headers   vary: 'Accept' }\n38 silly get cb [ 304,\n38 silly get   { date: 'Sat, 06 Feb 2016 10:28:56 GMT',\n38 silly get     via: '1.1 varnish',\n38 silly get     'cache-control': 'max-age=300',\n38 silly get     etag: '\"67N4ZHNF7NWJ26JQUHHB7HR46\"',\n38 silly get     age: '214',\n38 silly get     connection: 'keep-alive',\n38 silly get     'x-served-by': 'cache-sin6923-SIN',\n38 silly get     'x-cache': 'HIT',\n38 silly get     'x-cache-hits': '2',\n38 silly get     'x-timer': 'S1454754536.962270,VS0,VE0',\n38 silly get     vary: 'Accept' } ]\n39 verbose etag https://registry.npmjs.org/ionic from cache\n40 verbose get saving ionic to /home/bharath/.npm/registry.npmjs.org/ionic/.cache.json\n41 verbose correctMkdir /home/bharath/.npm correctMkdir not in flight; initializing\n42 silly install normalizeTree\n43 silly loadCurrentTree Finishing\n44 silly loadIdealTree Starting\n45 silly install loadIdealTree\n46 silly cloneCurrentTree Starting\n47 silly install cloneCurrentTreeToIdealTree\n48 silly cloneCurrentTree Finishing\n49 silly loadShrinkwrap Starting\n50 silly install loadShrinkwrap\n51 silly loadShrinkwrap Finishing\n52 silly loadAllDepsIntoIdealTree Starting\n53 silly install loadAllDepsIntoIdealTree\n54 silly resolveWithNewModule cordova@6.0.0 checking installable status\n55 silly cache add args [ 'cordova', null ]\n56 verbose cache add spec cordova\n57 silly resolveWithNewModule ionic@1.7.14 checking installable status\n58 silly cache add args [ 'ionic', null ]\n59 verbose cache add spec ionic\n60 silly cache add parsed spec Result {\n60 silly cache add   raw: 'cordova',\n60 silly cache add   scope: null,\n60 silly cache add   name: 'cordova',\n60 silly cache add   rawSpec: '',\n60 silly cache add   spec: 'latest',\n60 silly cache add   type: 'tag' }\n61 silly addNamed cordova@latest\n62 verbose addNamed \"latest\" is being treated as a dist-tag for cordova\n63 info addNameTag [ 'cordova', 'latest' ]\n64 silly mapToRegistry name cordova\n65 silly mapToRegistry using default registry\n66 silly mapToRegistry registry https://registry.npmjs.org/\n67 silly mapToRegistry uri https://registry.npmjs.org/cordova\n68 verbose addNameTag registry:https://registry.npmjs.org/cordova not in flight; fetching\n69 silly cache add parsed spec Result {\n69 silly cache add   raw: 'ionic',\n69 silly cache add   scope: null,\n69 silly cache add   name: 'ionic',\n69 silly cache add   rawSpec: '',\n69 silly cache add   spec: 'latest',\n69 silly cache add   type: 'tag' }\n70 silly addNamed ionic@latest\n71 verbose addNamed \"latest\" is being treated as a dist-tag for ionic\n72 info addNameTag [ 'ionic', 'latest' ]\n73 silly mapToRegistry name ionic\n74 silly mapToRegistry using default registry\n75 silly mapToRegistry registry https://registry.npmjs.org/\n76 silly mapToRegistry uri https://registry.npmjs.org/ionic\n77 verbose addNameTag registry:https://registry.npmjs.org/ionic not in flight; fetching\n78 verbose get https://registry.npmjs.org/cordova not expired, no request\n79 silly addNameTag next cb for cordova with tag latest\n80 silly addNamed cordova@6.0.0\n81 verbose addNamed \"6.0.0\" is a plain semver version for cordova\n82 verbose get https://registry.npmjs.org/ionic not expired, no request\n83 silly addNameTag next cb for ionic with tag latest\n84 silly addNamed ionic@1.7.14\n85 verbose addNamed \"1.7.14\" is a plain semver version for ionic\n86 silly mapToRegistry name ionic\n87 silly mapToRegistry using default registry\n88 silly mapToRegistry registry https://registry.npmjs.org/\n89 silly mapToRegistry uri https://registry.npmjs.org/ionic\n90 verbose addRemoteTarball https://registry.npmjs.org/ionic/-/ionic-1.7.14.tgz not in flight; adding\n91 verbose addRemoteTarball [ 'https://registry.npmjs.org/ionic/-/ionic-1.7.14.tgz',\n91 verbose addRemoteTarball   'af493d5df4688d917d778b0934d1739b9be6efe6' ]\n92 silly cache afterAdd cordova@6.0.0\n93 verbose afterAdd /home/bharath/.npm/cordova/6.0.0/package/package.json not in flight; writing\n94 verbose correctMkdir /home/bharath/.npm correctMkdir not in flight; initializing\n95 info retry fetch attempt 1 at 3:58:57 PM\n96 info attempt registry request try #1 at 3:58:57 PM\n97 http fetch GET https://registry.npmjs.org/ionic/-/ionic-1.7.14.tgz\n98 verbose afterAdd /home/bharath/.npm/cordova/6.0.0/package/package.json written\n99 http fetch 200 https://registry.npmjs.org/ionic/-/ionic-1.7.14.tgz\n100 silly fetchAndShaCheck shasum af493d5df4688d917d778b0934d1739b9be6efe6\n101 silly rollbackFailedOptional Starting\n102 silly rollbackFailedOptional Finishing\n103 silly runTopLevelLifecycles Starting\n104 silly runTopLevelLifecycles Finishing\n105 silly install printInstalled\n106 verbose stack Error: shasum check failed for /tmp/npm-19231-61302666/registry.npmjs.org/ionic/-/ionic-1.7.14.tgz\n106 verbose stack Expected: af493d5df4688d917d778b0934d1739b9be6efe6\n106 verbose stack Actual:   8ab3aa8d1113656748f44efa89c59e1e64a6e002\n106 verbose stack From:     https://registry.npmjs.org/ionic/-/ionic-1.7.14.tgz\n106 verbose stack     at /usr/lib/node_modules/npm/node_modules/sha/index.js:25:8\n106 verbose stack     at ReadStream.<anonymous> (/usr/lib/node_modules/npm/node_modules/sha/index.js:72:7)\n106 verbose stack     at emitNone (events.js:72:20)\n106 verbose stack     at ReadStream.emit (events.js:166:7)\n106 verbose stack     at endReadableNT (_stream_readable.js:905:12)\n106 verbose stack     at nextTickCallbackWith2Args (node.js:441:9)\n106 verbose stack     at process._tickCallback (node.js:355:17)\n107 verbose cwd /home/bharath\n108 error Linux 3.16.0-60-generic\n109 error argv \"/usr/bin/nodejs\" \"/usr/bin/npm\" \"install\" \"cordova\" \"ionic\" \"-g\"\n110 error node v4.2.6\n111 error npm  v3.7.1\n112 error shasum check failed for /tmp/npm-19231-61302666/registry.npmjs.org/ionic/-/ionic-1.7.14.tgz\n112 error Expected: af493d5df4688d917d778b0934d1739b9be6efe6\n112 error Actual:   8ab3aa8d1113656748f44efa89c59e1e64a6e002\n112 error From:     https://registry.npmjs.org/ionic/-/ionic-1.7.14.tgz\n113 error If you need help, you may report this error at:\n113 error     <https://github.com/npm/npm/issues>\n114 verbose exit [ 1, true ]\n"], "labels": ["support"]}
{"project": "ansible_ansible", "title": "win_regedit is not idempotent for multistring datatypes", "description": "From @jmighion on November 21, 2016 22:44 win_regedit <CODE> [defaults]\ninventory = ./hosts\nlog_path = ./ansible.log N/A The win_regedit module does not compare multistring data correctly to determine if it needs changing or not. For Windows, multistring values are null terminated strings <URL> . The comparison does not take that into account, so the provided data to the module contains \\0's which are not given by the OS when using Get-ItemProperty -Path $registryKey | Select-Object -ExpandProperty $registryValue. This means that even if the result would've been the same, the change is still made anyways, making this not idempotent. Run the following multiple times. Each time will report as changed. <CODE> <CODE> <CODE> Copied from original issue: ansible/ansible-modules-extras#3510 ", "code": ["ansible --version\nansible 2.2.0.0\n  config file = /Users/james/Documents/work/SCIF/git/windows_STIGs/ansible.cfg\n  configured module search path = Default w/o overrides\n", "  win_regedit:\n    key: 'HKLM:\\Path\\To\\Test\\Key'\n    value: ValueName\n    data: \"Line one\\0Line two\"\n    datatype: multistring\n", "ok: [ip.ip.ip.ip] => {\n    \"changed\": false, \n    \"data_changed\": false, \n    \"data_type_changed\": false, \n    \"invocation\": {\n        \"module_name\": \"win_regedit\"\n    }\n}\n", "changed: [ip.ip.ip.ip] => {\n    \"changed\": true, \n    \"data_changed\": true, \n    \"data_type_changed\": false, \n    \"invocation\": {\n        \"module_name\": \"win_regedit\"\n    }\n}\n"], "labels": ["support:core", "module", "windows", "bug", "affects_2.2"]}
{"project": "oracle_graal", "title": "[native-image] No parsing context available", "description": "Hi! When trying to build a native image with     native-image -jar project.jar \\ -H:Name=project-exec \\ --allow-incomplete-classpath \\ --initialize-at-build-time=org.jooq \\ --initialize-at-build-time=org.postgresql.Driver \\ --initialize-at-build-time=org.postgresql.util.SharedTimer \\ --initialize-at-build-time=org.slf4j \\ -H:-UseServiceLoaderFeature \\ -H:+TraceClassInitialization --auto-fallback \\ -H:+ReportExceptionStackTraces I get this error <CODE> I'm using graalvm 19.2.0.1\nShould I add a reflect-config.json file with some grpc definitions?\nAny help is welcome ", "code": ["Error: Error encountered while parsing io.grpc.netty.shaded.io.netty.handler.ssl.JdkAlpnApplicationProtocolNegotiator.<clinit>() \nParsing context: <no parsing context available> \n\ncom.oracle.graal.pointsto.util.AnalysisError$ParsingError: Error encountered while parsing io.grpc.netty.shaded.io.netty.handler.ssl.JdkAlpnApplicationProtocolNegotiator.<clinit>() \nParsing context: <no parsing context available> \n\n        at com.oracle.graal.pointsto.util.AnalysisError.parsingError(AnalysisError.java:138)\n        at com.oracle.graal.pointsto.flow.MethodTypeFlow.doParse(MethodTypeFlow.java:323)\n        at com.oracle.graal.pointsto.flow.MethodTypeFlow.ensureParsed(MethodTypeFlow.java:300)\n        at com.oracle.graal.pointsto.flow.MethodTypeFlow.addContext(MethodTypeFlow.java:107)\n        at com.oracle.graal.pointsto.BigBang$1.run(BigBang.java:384)\n        at com.oracle.graal.pointsto.util.CompletionExecutor.lambda$execute$0(CompletionExecutor.java:171)\n        at java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)\n        at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n        at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\nCaused by: org.graalvm.compiler.java.BytecodeParser$BytecodeParserError: java.lang.IllegalAccessError: class sun.security.ssl.ALPNExtension cannot access its superclass sun.security.ssl.HelloExtension\n        at parsing io.grpc.netty.shaded.io.netty.handler.ssl.JettyAlpnSslEngine.initAvailable(JettyAlpnSslEngine.java:44)\n        at parsing io.grpc.netty.shaded.io.netty.handler.ssl.JettyAlpnSslEngine.<clinit>(JettyAlpnSslEngine.java:34)\n        at org.graalvm.compiler.java.BytecodeParser.throwParserError(BytecodeParser.java:2470)\n        at com.oracle.svm.hosted.phases.SharedGraphBuilderPhase$SharedBytecodeParser.throwParserError(SharedGraphBuilderPhase.java:92)\n        at org.graalvm.compiler.java.BytecodeParser.iterateBytecodesForBlock(BytecodeParser.java:3272)\n        at org.graalvm.compiler.java.BytecodeParser.processBlock(BytecodeParser.java:3074)\n        at org.graalvm.compiler.java.BytecodeParser.build(BytecodeParser.java:976)\n        at org.graalvm.compiler.java.BytecodeParser.parseAndInlineCallee(BytecodeParser.java:2491)\n        at org.graalvm.compiler.java.BytecodeParser.inline(BytecodeParser.java:2391)\n        at org.graalvm.compiler.java.BytecodeParser.tryInline(BytecodeParser.java:2137)\n        at org.graalvm.compiler.java.BytecodeParser.appendInvoke(BytecodeParser.java:1809)\n        at org.graalvm.compiler.java.BytecodeParser.genInvokeStatic(BytecodeParser.java:1566)\n        at org.graalvm.compiler.java.BytecodeParser.genInvokeStatic(BytecodeParser.java:1546)\n        at org.graalvm.compiler.java.BytecodeParser.processBytecode(BytecodeParser.java:5125)\n        at org.graalvm.compiler.java.BytecodeParser.iterateBytecodesForBlock(BytecodeParser.java:3267)\n        at org.graalvm.compiler.java.BytecodeParser.processBlock(BytecodeParser.java:3074)\n        at org.graalvm.compiler.java.BytecodeParser.build(BytecodeParser.java:976)\n        at org.graalvm.compiler.java.BytecodeParser.buildRootMethod(BytecodeParser.java:870)\n        at org.graalvm.compiler.java.GraphBuilderPhase$Instance.run(GraphBuilderPhase.java:84)\n        at org.graalvm.compiler.phases.Phase.run(Phase.java:49)\n        at org.graalvm.compiler.phases.BasePhase.apply(BasePhase.java:197)\n        at org.graalvm.compiler.phases.BasePhase.apply(BasePhase.java:139)\n        at com.oracle.svm.hosted.substitute.UnsafeAutomaticSubstitutionProcessor.getStaticInitializerGraph(UnsafeAutomaticSubstitutionProcessor.java:905)\n        at com.oracle.svm.hosted.substitute.UnsafeAutomaticSubstitutionProcessor.computeSubstitutions(UnsafeAutomaticSubstitutionProcessor.java:321)\n        at com.oracle.svm.hosted.SVMHost.registerType(SVMHost.java:199)\n        at com.oracle.graal.pointsto.meta.AnalysisUniverse.createType(AnalysisUniverse.java:262)\n        at com.oracle.graal.pointsto.meta.AnalysisUniverse.lookupAllowUnresolved(AnalysisUniverse.java:203)\n        at com.oracle.graal.pointsto.meta.AnalysisUniverse.lookup(AnalysisUniverse.java:180)\n        at com.oracle.graal.pointsto.meta.AnalysisMethod.getDeclaringClass(AnalysisMethod.java:342)\n        at com.oracle.graal.pointsto.meta.AnalysisMethod.getSignature(AnalysisMethod.java:311)\n        at com.oracle.graal.pointsto.flow.MethodFlowsGraph.<init>(MethodFlowsGraph.java:98)\n        at com.oracle.graal.pointsto.flow.MethodTypeFlow.<init>(MethodTypeFlow.java:75)\n        at com.oracle.graal.pointsto.meta.AnalysisMethod.<init>(AnalysisMethod.java:132)\n        at com.oracle.graal.pointsto.meta.AnalysisUniverse.createMethod(AnalysisUniverse.java:410)\n        at com.oracle.graal.pointsto.meta.AnalysisUniverse.lookupAllowUnresolved(AnalysisUniverse.java:398)\n        at com.oracle.graal.pointsto.infrastructure.WrappedConstantPool.lookupMethod(WrappedConstantPool.java:116)\n        at org.graalvm.compiler.java.BytecodeParser.lookupMethod(BytecodeParser.java:4123)\n        at org.graalvm.compiler.java.BytecodeParser.genInvokeStatic(BytecodeParser.java:1543)\n        at org.graalvm.compiler.java.BytecodeParser.processBytecode(BytecodeParser.java:5125)\n        at org.graalvm.compiler.java.BytecodeParser.iterateBytecodesForBlock(BytecodeParser.java:3267)\n        at org.graalvm.compiler.java.BytecodeParser.processBlock(BytecodeParser.java:3074)\n        at org.graalvm.compiler.java.BytecodeParser.build(BytecodeParser.java:976)\n        at org.graalvm.compiler.java.BytecodeParser.buildRootMethod(BytecodeParser.java:870)\n        at org.graalvm.compiler.java.GraphBuilderPhase$Instance.run(GraphBuilderPhase.java:84)\n        at org.graalvm.compiler.phases.Phase.run(Phase.java:49)\n        at org.graalvm.compiler.phases.BasePhase.apply(BasePhase.java:197)\n        at org.graalvm.compiler.phases.Phase.apply(Phase.java:42)\n        at org.graalvm.compiler.phases.Phase.apply(Phase.java:38)\n        at com.oracle.graal.pointsto.flow.MethodTypeFlowBuilder.parse(MethodTypeFlowBuilder.java:221)\n        at com.oracle.graal.pointsto.flow.MethodTypeFlowBuilder.apply(MethodTypeFlowBuilder.java:340)\n        at com.oracle.graal.pointsto.flow.MethodTypeFlow.doParse(MethodTypeFlow.java:310)\n        ... 9 more\nCaused by: java.lang.IllegalAccessError: class sun.security.ssl.ALPNExtension cannot access its superclass sun.security.ssl.HelloExtension\n        at java.lang.ClassLoader.defineClass1(Native Method)\n        at java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n        at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n        at java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n        at java.lang.Class.forName0(Native Method)\n        at java.lang.Class.forName(Class.java:348)\n        at com.oracle.svm.hosted.ImageClassLoader.forName(ImageClassLoader.java:404)\n        at com.oracle.svm.hosted.ImageClassLoader.findClassByName(ImageClassLoader.java:394)\n        at com.oracle.svm.hosted.snippets.ReflectionPlugins.processForName(ReflectionPlugins.java:210)\n        at com.oracle.svm.hosted.snippets.ReflectionPlugins.access$100(ReflectionPlugins.java:65)\n        at com.oracle.svm.hosted.snippets.ReflectionPlugins$2.apply(ReflectionPlugins.java:159)\n        at org.graalvm.compiler.nodes.graphbuilderconf.InvocationPlugin.execute(InvocationPlugin.java:217)\n        at org.graalvm.compiler.java.BytecodeParser.tryInvocationPlugin(BytecodeParser.java:2092)\n        at org.graalvm.compiler.java.BytecodeParser.appendInvoke(BytecodeParser.java:1801)\n        at org.graalvm.compiler.java.BytecodeParser.genInvokeStatic(BytecodeParser.java:1566)\n        at org.graalvm.compiler.java.BytecodeParser.genInvokeStatic(BytecodeParser.java:1546)\n        at org.graalvm.compiler.java.BytecodeParser.processBytecode(BytecodeParser.java:5125)\n        at org.graalvm.compiler.java.BytecodeParser.iterateBytecodesForBlock(BytecodeParser.java:3267)\n        ... 55 more\n"], "labels": ["native-image"]}
{"project": "dotnet_aspnetcore", "title": "Question: How to manage Server-side connections ?", "description": "From @moataz1991 on Tuesday, 26 February 2019 13:13:16 Hello as the question states , how can i manage clients connections ?\nlike when someone connects and filled login info then he should receive session and the server can disconnect him and return him to some page and release resources ? thanks Copied from original issue: aspnet/Blazor#1794 ", "code": [], "labels": ["question"]}
{"project": "pypa_pip", "title": "Unable to ignore \"DEPRECATION:...\" warnings", "description": "The discussion on #3109 suggests that the environment variable PYTHONWARNINGS can be used to ignore warnings issued by pip. This method however doesn't seem to work for deprecation warnings. To illustrate, assume the warning issued when --download-cache is used: <CODE> Setting PYTHONWARNINGS has no effect: <CODE> Trying to change the filter didn't help: <CODE> I think the problem could be on deprecation.py (<URL>, which issues the warning using logger.warning(), instead of using Python's warning module: <CODE> ", "code": ["$ pip install pytest --download-cache /tmp\nDEPRECATION: --download-cache has been deprecated and will be removed in the future. Pip now automatically uses and configures its cache.\n...\n", "PYTHONWARNINGS=\"ignore:DEPRECATION\" pip install pytest --download-cache /tmp\nDEPRECATION: --download-cache has been deprecated and will be removed in the future. Pip now automatically uses and configures its cache.\n...\n", "PYTHONWARNINGS=\"ignore:--download-cache\" pip install pytest --download-cache /tmp\nDEPRECATION: --download-cache has been deprecated and will be removed in the future. Pip now automatically uses and configures its cache.\n...\n", "53            if issubclass(category, DeprecationWarning):\n54                logger.error(log_message)\n55            else:\n56                logger.warning(log_message)  # <.---- here\n"], "labels": ["S: auto-locked"]}
{"project": "Azure_acs-engine", "title": "net.ipv4.ip_forward not set", "description": "I think a side effect of #2973 might be that net.ipv4.ip_forward is no longer set on nodes. I think installing the docker package had done that. not unless I've missed something ISSUE v0.19.0 Orchestrator and version (e.g. Kubernetes, DC/OS, Swarm) <CODE> Also notable: <CODE> What happened: Pods scheduled on workers weren't coming up properly. kube-dns, kube-dashboard, etc. Log messages were <CODE> What you expected to happen: <CODE> How to reproduce it (as minimally and precisely as possible): Anything else we need to know: when building with kubenet + containerd i saw similar behavior of ip_forward=0, but I didn't go through as full of a setup to verify that enabling it fixes things. ", "code": ["            \"orchestratorType\": \"Kubernetes\",\n            \"orchestratorRelease\": \"1.11\",\n", "                \"containerRuntime\": \"containerd\",\n                \"networkPlugin\": \"cilium\",\n                \"networkPolicy\": \"cilium\",\n", "I0701 01:11:04.178909       1 logs.go:41] skydns: failure to forward request \"read udp 172.17.1.28:38601->168.63.129.16:53: i/o timeout\"\n", "azureuser@k8s-master-27708130-0:~$ sysctl net.ipv4.ip_forward\nnet.ipv4.ip_forward = 0\nazureuser@k8s-master-27708130-0:~$ kubectl get nodes\nNAME                           STATUS     ROLES     AGE       VERSION\nk8s-main-27708130-vmss000000   NotReady   agent     3h        v1.11.0\nk8s-main-27708130-vmss000001   NotReady   agent     3h        v1.11.0\nk8s-master-27708130-0          NotReady   master    3h        v1.11.0\nazureuser@k8s-master-27708130-0:~$ kubectl -n kube-system get pods\nNAME                                            READY     STATUS    RESTARTS   AGE\nheapster-6786b686d4-dwd86                       0/2       Pending   0          3h\nkube-addon-manager-k8s-master-27708130-0        1/1       Running   0          3h\nkube-apiserver-k8s-master-27708130-0            1/1       Running   0          3h\nkube-controller-manager-k8s-master-27708130-0   1/1       Running   0          3h\nkube-dns-v20-6bddbcb99c-hjqd6                   0/3       Pending   0          3h\nkube-dns-v20-6bddbcb99c-zfkk8                   0/3       Pending   0          3h\nkube-proxy-6kw7g                                1/1       Running   0          3h\nkube-proxy-ddwlw                                1/1       Running   0          3h\nkube-proxy-qvjz7                                1/1       Running   0          3h\nkube-scheduler-k8s-master-27708130-0            1/1       Running   0          3h\nkubernetes-dashboard-5c5b4696f-47dt2            0/1       Pending   0          3h\nmetrics-server-855846b948-xsfxz                 0/1       Pending   0          3h\ntiller-deploy-bcf659768-2dbnz                   0/1       Pending   0          3h\n"], "labels": ["stale"]}
{"project": "pimcore_pimcore", "title": "bugfix: localized object relation data lost in field collection", "description": "see #1536 ", "code": [], "labels": ["Bug"]}
{"project": "npm_npm", "title": "npm error ?  rror while loading shared libraries:libgconf-2.so.4 : cannot open shared object file: No such file or directory", "description": "i want build a smart mirror so i install npm in the folder MagicMirror\nand if i want to start them i get the fault that a data is missing maybe told me what i did wrong.. which library should i download now ?\ni have many screen\u2019s and i hope you can help me :/\n(i used the multiupload picload.org)\n<URL>\n<URL>\n<URL>\n<URL> thats my npm-debug.log i get the error if i start npm: <CODE> maybe i don't have the access to install any thing cause the node_modules isn't for pi ? ", "code": ["npm start\n\nmagicmirror@2.0.0 start /home/pi/MagicMirror\nelectron js/electron.js\n\n/home/pi/MagicMirror/node_modules/electron-prebuilt/dist/electron: error while loading shared libraries: libXss.so.1: cannot open shared object file: No such file or directory\n\nnpm ERR! Linux 4.4.21-v7+\nnpm ERR! argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"start\"\nnpm ERR! node v6.8.1\nnpm ERR! npm  v3.10.9\nnpm ERR! file sh\nnpm ERR! code ELIFECYCLE\nnpm ERR! errno ENOENT\nnpm ERR! syscall spawn\nnpm ERR! magicmirror@2.0.0 start: `electron js/electron.js`\nnpm ERR! spawn ENOENT\nnpm ERR! \nnpm ERR! Failed at the magicmirror@2.0.0 start script 'electron js/electron.js'.\nnpm ERR! Make sure you have the latest version of node.js and npm installed.\nnpm ERR! If you do, this is most likely a problem with the magicmirror package,\nnpm ERR! not with npm itself.\nnpm ERR! Tell the author that this fails on your system:\nnpm ERR!     electron js/electron.js\nnpm ERR! You can get information on how to open an issue for this project with:\nnpm ERR!     npm bugs magicmirror\nnpm ERR! Or if that isn't available, you can get their info via:\nnpm ERR!     npm owner ls magicmirror\nnpm ERR! There is likely additional logging output above.\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     /home/pi/MagicMirror/npm-debug.log\n"], "labels": ["bot-closed", "support"]}
{"project": "jellyfin_jellyfin", "title": "PIN login not working after 10.4.0 update", "description": "Describe the bug Loging in using PIN in local network is not working after 10.4.0 update. Tried from the same subnet as the server, with and without local network setting filed. Password works fine. To Reproduce Expected behavior PIN login should be working in local subnets set in settings. Logs <CODE> System (please complete the following information): ", "code": ["[2019-10-07 15:13:46.730 +02:00] [ERR] Error authenticating with provider \"Default\"\nMediaBrowser.Controller.Authentication.AuthenticationException: Invalid username or password\n   at Emby.Server.Implementations.Library.DefaultAuthenticationProvider.Authenticate(String username, String password, User resolvedUser)\n   at Emby.Server.Implementations.Library.UserManager.AuthenticateWithProvider(IAuthenticationProvider provider, String username, String password, User resolvedUser)\n[2019-10-07 15:13:46.733 +02:00] [INF] Authentication request for \"User\" \"has been denied\".\n[2019-10-07 15:13:46.779 +02:00] [ERR] [IP] Invalid user or password entered.\n"], "labels": ["bug", "regression"]}
{"project": "TrinityCore_TrinityCore", "title": "[3.3.5] DB/Quest: improve Alliance's \"Morrowgrain Research\" quest chain", "description": "Description: Strangely enough, those issues only apply to the Alliance versions of the quests. The Horde side is already fine. Branch(es): 3.3.5 TC hash/commit:  d0c377f TDB version:  335.61 Suggested fix: ", "code": [], "labels": ["Comp-Database", "Feedback-PatchFix"]}
{"project": "phan_phan", "title": "Adding `const true = false` will mess up ContextNode resolving the value of the constant", "description": "E.g. This affects detecting duplicate array keys. ", "code": [], "labels": ["bug"]}
{"project": "ionic-team_stencil", "title": "src/global not included properly in dist/", "description": "EDIT: After poking around more, it seems that it's related to the CSS variables defined in src/global/variables.css. Based on the Stencil docs here. I've added the recommended globalStyle: 'src/global/variables.css' line and <CODE> to stencil.config.ts. Still no luck. Does React not like CSS variables? These work when using them in the stencil project, but not when built into dist/ and used in a React project. I've built two test components. They work in a vanilla JS / HTML site by copying the build/ directory from the www/ output target created by npm run build. Following the Stencil docs and this  Medium article, I've managed to get the NPM package imported and the Polyfill lines included. This doesn't produce any errors when running npm start. The components load but the CSS for them doesn't work. The correct CSS appears in the developer tools - although it appears on a darker background (below) and can't be edited (I also couldn't figure out why this was either).  The medium article's example used \"types\": \"dist/types/components.d.ts\" rather than what I had - \"types\": \"dist/types/index.d.ts\" - changing this had no effect. I also followed this  hackernoon article which suggested referencing the CSS and JS files from a CDN in the public/index.html file - I referenced the same JS and CSS files that I used in the vanilla JS / HTML site using the NPM UNPKG CDN but this did not work either. I've tried changing the esmLoaderPath property value from '../loader' to 'loader' but this also didn't work. I've tried deleting dist/ , www/ and .stencil/ and rebuilding and re-publishing but this has also had no effect. Checking the Stencil GitHub issues page didn't appear to have anything either. I've been developing / testing in Chrome, but have also checked Firefox - same issue. stencil.config.ts: <CODE> package.json: <CODE> React index.js: <CODE> React App.js: <CODE> Git repo for Stencil project: <URL> Git repo for React project: <URL> Please let me know if you cannot access these repositories.  They should work - I've tested them in incognito mode and they worked. I posted this on StackOverflow yesterday as well (here) but have not received any help yet. ", "code": ["copy: [\n    { \n      src: 'global' \n    }\n  ]\n", "import { Config } from '@stencil/core';\n\nexport const config: Config = {\n  namespace: 'poc',\n  globalStyle: 'src/global/variables.css',\n  outputTargets: [\n    {\n      type: 'dist',\n      esmLoaderPath: 'loader'\n    },\n    {\n      type: 'docs-readme'\n    },\n    {\n      type: 'www',\n      serviceWorker: null // disable service workers\n    }\n  ]\n};\n", "{\n  \"name\": \"poc\",\n  \"version\": \"0.0.6\",\n  \"description\": \"Stencil Component Starter\",\n  \"main\": \"dist/index.js\",\n  \"module\": \"dist/index.mjs\",\n  \"es2015\": \"dist/esm/index.mjs\",\n  \"es2017\": \"dist/esm/index.mjs\",\n  \"types\": \"dist/types/components.d.ts\",\n  \"collection\": \"dist/collection/collection-manifest.json\",\n  \"collection:main\": \"dist/collection/index.js\",\n  \"unpkg\": \"dist/poc/poc.js\",\n  \"files\": [\n    \"dist/\",\n    \"loader/\"\n  ],\n  \"scripts\": {\n    \"build\": \"stencil build --docs\",\n    \"start\": \"stencil build --dev --watch --serve\",\n    \"test\": \"stencil test --spec --e2e\",\n    \"test.watch\": \"stencil test --spec --e2e --watchAll\",\n    \"generate\": \"stencil generate\"\n  },\n  \"devDependencies\": {\n    \"@stencil/core\": \"^1.7.5\",\n    \"@types/jest\": \"^24.0.22\",\n    \"@types/puppeteer\": \"1.20.2\",\n    \"jest\": \"^24.9.0\",\n    \"jest-cli\": \"24.8.0\",\n    \"puppeteer\": \"1.20.0\"\n  },\n  \"license\": \"MIT\"\n}\n", "import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport * as serviceWorker from './serviceWorker';\n\nimport { applyPolyfills, defineCustomElements } from 'uwe-ds-poc/dist/loader';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: \nserviceWorker.unregister();\n\napplyPolyfills().then(() => {\n    defineCustomElements(window);\n});\n", "import React from 'react';\nimport './App.css';\nimport 'uwe-ds-poc';\n\nfunction App() {\n    return (\n        <div>\n\n            <h1>Testing UWE Design System POC</h1>\n\n            <uwe-heading value=\"Business\"></uwe-heading>\n\n            <br/><br/>\n\n            <uwe-button type=\"reset\" value=\"Open Days\"></uwe-button>\n\n        </div>\n    );\n}\n\nexport default App;\n"], "labels": ["triage"]}
{"project": "lucas-clemente_quic-go", "title": "Yet another flaky proxy test", "description": "<CODE> ", "code": ["UDP Proxy Proxy tests no packet drop [It] relays packets from the server to the client \n/home/travis/gopath/src/github.com/lucas-clemente/quic-go/integrationtests/proxy/udp_proxy_test.go:181\n  Expected\n      <uint64>: 0\n  to equal\n      <uint64>: 1\n  /home/travis/gopath/src/github.com/lucas-clemente/quic-go/integrationtests/proxy/udp_proxy_test.go:150\n  Full Stack Trace\n    /home/travis/gopath/src/github.com/onsi/gomega/internal/assertion/assertion.go:69 +0x233\n  github.com/onsi/gomega/internal/assertion.(*Assertion).To(0x189de120, 0x8478f40, 0x18828ff8, 0x0, 0x0, 0x0, 0x189de120)\n    /home/travis/gopath/src/github.com/onsi/gomega/internal/assertion/assertion.go:35 +0x80\n  github.com/lucas-clemente/quic-go/integrationtests/proxy.glob..func2.5.3.3()\n    /home/travis/gopath/src/github.com/lucas-clemente/quic-go/integrationtests/proxy/udp_proxy_test.go:150 +0x461\n  github.com/onsi/ginkgo/internal/leafnodes.(*runner).runSync(0x18948c80, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)\n    /home/travis/gopath/src/github.com/lucas-clemente/quic-go/integrationtests/proxy/udpproxy_suite_test.go:12 +0x57\n  testing.tRunner(0x1886bc80, 0x8382880)\n    /home/travis/.gimme/versions/go1.7rc5.linux.amd64/src/testing/testing.go:610 +0x8c\n  created by testing.(*T).Run\n    /home/travis/.gimme/versions/go1.7rc5.linux.amd64/src/testing/testing.go:646 +0x2a5\n\n"], "labels": ["bug"]}
{"project": "golang_go", "title": "go/fmt: `go fmt` formats two maps with same key/value pair differently depending on how the key is placed", "description": "go version go1.9.3 linux/amd64 I am not sure, but I think it will be reproduced because it is getting reproduced in Go-Playground. Operating System: Linux\nProcessor architecture: AMD64 <CODE> I have created two maps with same key-value pairs, just written them in different order. One gets formatted correctly while other doesn't. Here is the Go-Playground link: <URL> Both maps in the above sample should be formatted in the same way (the way second sample gets formatted). Both maps formats differently. My Observation: It depends more on the length of the surrounding (above/below) key than on the difference in the length of the \"victim\" key and surrounding key. (but affected by both) ", "code": ["$ go env\nGOARCH=\"amd64\"\nGOBIN=\"\"\nGOEXE=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"linux\"\nGOOS=\"linux\"\nGOPATH=\"/home/abhishek/GoWorkspace\"\nGORACE=\"\"\nGOROOT=\"/usr/local/go\"\nGOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"\nGCCGO=\"gccgo\"\nCC=\"gcc\"\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build268663230=/tmp/go-build -gno-record-gcc-switches\"\nCXX=\"g++\"\nCGO_ENABLED=\"1\"\nCGO_CFLAGS=\"-g -O2\"\nCGO_CPPFLAGS=\"\"\nCGO_CXXFLAGS=\"-g -O2\"\nCGO_FFLAGS=\"-g -O2\"\nCGO_LDFLAGS=\"-g -O2\"\nPKG_CONFIG=\"pkg-config\"\n"], "labels": ["FrozenDueToAge"]}
{"project": "emqx_emqx", "title": "Logging not working", "description": "Logging to file is not working, emqx setting is set to ", "code": [], "labels": ["BUG"]}
{"project": "afollestad_material-dialogs", "title": "Dialog buttons are not vertically centered", "description": "I thought something was wrong, so I went ahead and draw black squares to see how the margin was being respected. It turns out, the margin on the right side is different than bottom (bottom is larger).  Material design states that everything should be 8dp:\n ", "code": [], "labels": ["bug"]}
{"project": "inorichi_tachiyomi", "title": "Metadata for local manga", "description": "Can you add the ability to grab metadata for local manga, maybe by searching titles on sites? i'd like to have the plot/genres and other stuff in my local manga as well. ", "code": [], "labels": ["feature"]}
{"project": "gorhill_uBlock", "title": "Error extension in Chromium with HTTPS Everywhere", "description": "Hello, Error extension in Chromium (64.0.3282.119) with HTTPS Everywhere (2018.4.11) \"Warning:\nThis extension failed to redirect a network request to chrome-extension://cjpalhdlnbpafiamejdnhcphjbkeiagm/web_accessible_resources/59fb24a2d12455d15bea20980e8a6801.js?secret=rdfcfnod2xg7 because another extension (HTTPS Everywhere) redirected it to <URL>\" observice not all time ", "code": [], "labels": ["duplicate"]}
{"project": "microsoft_ChakraCore", "title": "navigator.plugins object's named property become non-enumerable on certain circumstances", "description": "navigator.plugins object behaves in an odd way in certain edge cases. I suppose the specification relevant for the navigator.plugins object is <URL>, and  <URL> . Since these do not specify whether the object should \"support named property setters\"  and what \"named property visibility algorithm\" should the object use, I suppose the behavior of the object can be largely platform-dependent. However, even assuming this, there seem to be some weirdness coming into play in situations described below: When the following script is executed: the named property \"Edge PDF Viewer\", which is enumerable at beginning, suddenly becomes a non-enumerable property of the plugins object. This is weird, because in usual situation where one defines some properties on the plugin object and deletes it afterwards, it recovers the exact same property descriptor which it had at the beginning. However, in this case, it recovers a descriptor that is the same to the original one except the enumerable key changed from true to false. 1e9 can be changed to any number that exceeds navigator.plugins.length. The issue disappears when changing it to a number less than navigator.plugins.length. Also, if the temporary property descriptor is changed to have both writable and enumerable attribute, the issue disappears as well: [Edit - changed misspelled \"Edge PDF Plugin\"s to \"Edge PDF Viewer\"] ", "code": [], "labels": ["External"]}
{"project": "npm_npm", "title": "How to handle this error??", "description": "error ts1148: cannot compile modules unless the '--module' flag is provided. ", "code": [], "labels": ["support"]}
{"project": "microsoft_ChakraCore", "title": "Are public nightly builds of ChakraCore available somewhere?", "description": "It would be great, if Chakra will provide nightly builds (with ch), same as do Firefox SpiderMonkey (<URL> and others).\nIt will provide simple way to test big libraries with nightly builds and react early on potential Chakra, library or compatibility issues. ", "code": [], "labels": ["Question"]}
{"project": "iissnan_hexo-theme-next", "title": "[Bug]han.woff2 failed", "description": "Request complete.  NexT Version: <CODE> NexT Scheme: <CODE> ", "code": ["[x] Latest Master branch.\n[] Latest Release version.\n[] Old version - \n", "[] All schemes\n[] Muse\n[] Mist\n[x] Pisces\n[] Gemini\n"], "labels": ["Bug"]}
{"project": "rust-lang_rust", "title": "The \"ctime\" field from stat is not time of file creation.", "description": " ", "code": [], "labels": ["E-easy"]}
{"project": "golang_go", "title": "runtime: TestGdbPython flaky on linux/arm64 and linux/s390x builders", "description": "The TestGdbPython test sometimes fails with: --- FAIL: TestGdbPython (0.37s)\nruntime-gdb_test.go:46: gdb version 7.9\nruntime-gdb_test.go:171: goroutine 2 bt failed: Python Exception <class 'gdb.error'> Attempt to assign to an unmodifiable value.:\nError occurred in Python command: Attempt to assign to an unmodifiable value.\nFAIL\nFAIL    runtime 25.005s Recent failures on linux/arm64:\n<URL>\n<URL> Recent failures on linux/s390x:\n<URL>\n<URL> ", "code": [], "labels": ["FrozenDueToAge", "Testing"]}
{"project": "joomla_joomla-cms", "title": "Override Joomla's core image - tooltip.png not working", "description": "Insert  into code, as per <URL>!_website Add own tooltip.png image into /templates/template_name/images/system as per <URL>!_core#Further_tips Own image should show instead of Joomla default blue one.\n Joomla default image still shows.\n PHP Built On\tLinux ukm2.siteground.biz 3.12.18-clouder0 #26 SMP Tue Jul 12 09:43:48 EEST 2016 x86_64\nDatabase Version\t5.6.28-76.1-log\nDatabase Collation\tutf8_general_ci\nDatabase Connection Collation\tutf8mb4_general_ci\nPHP Version\t5.3.29\nWeb Server\tApache\nWebServer to PHP Interface\tcgi-fcgi\nJoomla! Version\tJoomla! 3.6.5 Stable [ Noether ] 1-December-2016 22:46 GMT\nJoomla! Platform Version\tJoomla Platform 13.1.0 Stable [ Curiosity ] 24-Apr-2013 00:00 GMT\nUser Agent\tMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36 I am happy to take a look to see if I can see anything obvious that is stopping it from working, but I would need pointing to the correct file. ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "Beep6581_RawTherapee", "title": "OpenCl", "description": "Originally reported on Google Code with ID 1694 <CODE> Reported by heckflosse@i-weyrich.de on 2013-01-24 23:20:08 ", "code": ["As I mentioned in my presentation (http://rawtherapee.com/forum/viewtopic.php?f=9&t=4421)\nOpenCl is one of my main interests, because it can outperform actual multi-core-cpu-systems\nby factor 20 or more by simply using the GPU of the Graphic-Card.\nI made a simple test in implementing dcdamping-part of RL-Deconv to my GeForce Gt640,\nand it took less than 5% of the time, as my 8-Core-4Ghz-Machine took for the same thing,\nbut dcdamping was very easy to convert...\n\nMy next step will be the making of a GPU-Version of gaussian blur, which gives the\nsame results as the Young-van Vliet Implementation, which is used in RT actually. \nThat should also be no problem...\n\nI also plan to create a framework, which is usable in a project like Rt. It should\nperform well at different systems with different GPUs, which have different capabilities\netc.\n\nI already have some ideas, how to design that framework, but because I've only one\nmachine at the moment (8-core-Amd with GeForce Gt640), I would be glad, if there would\nbe somebody, who also has a OpenCl 1.1 capable GPU (not necessary different from mine),\nto contribute this work.\n\nWould also be nice, if we could make a OpenCl-Branch in RT-Repository, so we could\ntest without influence to the default branch.\n\nThis will be a large process, but it's very interesting and has a lot of potential,\nnot only to speed up RT, also to broaden your mind. If somebody of the team is interested\nin this theme, I offer my assistance.\n\nIngo\n\n"], "labels": ["performance"]}
{"project": "tootsuite_mastodon", "title": "problem with handling about control code for bi-directional text", "description": "Last day,  I found collapsed strings in system oriented messages by tainted username including a unicode control code for bi-directional text like as follows. <URL>\nThe bottom is correct viewing of when a post is favourited, and upper is collapsed string like an anagram. Following is an explaining the behavior in English strings. RLO is the control code of right-to-left override (U+202E).\n\"foo[RLO] favourited your status\"  --> \"foosutats ruoy detiruovaf\" It's too strange view! For reference about RLO/LRO - UNICODE BIDIRECTIONAL ALGORITHM\n<URL> Therefor, I propose some countermeasures for avoiding this behavior. Please consider about this problem. Regards. ", "code": [], "labels": ["duplicate"]}
{"project": "spring-projects_spring-boot", "title": "Update Eclipse Oomph setup to use Eclipse 2019-03 and latest Spring Boot tooling", "description": "\nNo description provided.\n ", "code": [], "labels": ["type: task"]}
{"project": "mozilla_geckodriver", "title": "Click on item from the list does not work properly", "description": "Navigate to MakeMyTrip.com\nType chan on the From field\nWait for the list of suggestions\nFind the list of elements and from the list Select Changchun, China\nBut the code always selects the 1st option in the list The same code works completely fine and selects Changchun, China when I run it on Chrome.\nIt looks like the issue is with geckodriver in understanding the DOM. Here is the code:\npublic class MakeMyTrip {\nWebDriver driver;\nString baseUrl; <CODE> } If you can let me know what options I can provide to FirefoxDriver to produce logs, then I can provide them also.\nThe below provided when filing bugs only shows for capabilities, but I am running the code locally without using capabilities. ", "code": ["@Before\npublic void setUp() throws Exception {\n\tSystem.setProperty(\"webdriver.gecko.driver\", \"geckodriver location\");\n\tbaseUrl = \"https://www.makemytrip.com/\";\n\tdriver = new FirefoxDriver();\n\tdriver.manage().window().maximize();\n\tdriver.manage().timeouts().implicitlyWait(10, TimeUnit.SECONDS);\n}\n\n@Test\npublic void test() throws InterruptedException {\n\tdriver.get(baseUrl);\n\tWebElement searchField = driver.findElement(By.id(\"hp-widget__sfrom\"));\n\tsearchField.clear();\n\tsearchField.sendKeys(\"chan\");\n\n\tThread.sleep(3000);\n\tWebElement filter = driver.findElement(By.xpath(\"//div[@class='locationFilter autocomplete_from']\"));\n\n\tList<WebElement> locationList = filter.findElements(By.className(\"ui-menu-item\"));\n\n\tfor (WebElement e : locationList) {\n\t\tSystem.out.println(e.getAttribute(\"aria-label\"));\n\t\tif (e.getAttribute(\"aria-label\").equals(\"Search Result : Changchun, China\")) {\n\t\t\tSystem.out.println(\"Inside if condition\");\n\t\t\te.click();\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n@After\npublic void tearDown() throws Exception {\n\tThread.sleep(3000);\n\tdriver.quit();\n}\n"], "labels": ["needs investigation"]}
{"project": "fatedier_frp", "title": "upstream prematurely closed connection while reading response header from upstream", "description": "\u6211\u7528nginx\u548cfrp\u914d\u5408\u4f7f\u7528\uff0c\u5728\u5fae\u4fe1\u4e2d\u83b7\u53d6\u5fae\u4fe1\u7528\u6237\u4fe1\u606f\u65f6\u5c31\u51fa\u73b0\u8fd9\u6837\u7684\u9519\u8bef ", "code": [], "labels": ["FrozenDueToAge"]}
{"project": "dgraph-io_dgraph", "title": "Support a better mutation format, potentially JSON-LD", "description": "For mutations. Also ensure that it can work with facets. ", "code": [], "labels": ["improvement"]}
{"project": "olifolkerd_tabulator", "title": "[BUG] formatter:\"money\"", "description": "When I used \"formatter:'money'\" in columns, there was bug in a screen.\n{title:\"price\", field:\"price\", sorter:\"number\", formatter:\"money\", align:\"right\",width:100,editor:editOption},\nWhen I had \"addRow\", the result was \"NaN\" in the result screen. It need change the \"money\" formatter code.\n----------  now ----------------------------- ---------- to be ------------------------------- ", "code": [], "labels": ["Bug"]}
{"project": "spring-projects_spring-framework", "title": "Cache Abstraction: Improve unless condition with optional [SPR-15449]", "description": "Michael Simons opened SPR-15449 and commented The unless condition should use the null safe operator. Referenced from: pull request #1387, and commits 135651d ", "code": [], "labels": ["type: documentation"]}
{"project": "bumptech_glide", "title": "Glide Gifs OOM", "description": "Hello,\nI have Listview+ViewHolder with gifs. When i use my app normally it works well but when i try to scroll up/down repeatedly or on a fast scroll down at starting, i get oom exception. I know this is a rare situation but i need to fix this. My gifs sizes : 13.6kb,19.3kbi19.3kb,1.0mb,1.2mb,1.6mb,1.7mb,1.7mb. ", "code": [], "labels": ["question"]}
{"project": "pypa_pip", "title": "pip --download fails with too long file names on virtualization", "description": "We have a Vagrant box (via Virtualbox) with Ubuntu precise64 on it.  Using the following command fails: <CODE> The error is this: <CODE> The current implementation to store the full URI of the package as a file name starts breaking down when the filename is too long when used on virtualized environments. In this case, /var/cache/pip is a symlink to /tmp/vagrant-cache which is a share to /home/peter/.vagrant.d/cache/hashicorp/precise64. ", "code": ["sudo pip install --download-cache=/var/cache/pip -r /vagrant/requirements/development-requirements.txt\n", "Downloading/unpacking django-debug-toolbar-template-timings==0.6 (from -r /vagrant/requirements/development-requirements.txt (line 3))\n  Downloading django-debug-toolbar-template-timings-0.6.zip\n  Storing download in cache at /var/cache/pip/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fsource%2Fd%2Fdjango-debug-toolbar-template-timings%2Fdjango-debug-toolbar-template-timings-0.6.zip\nCleaning up...\nException:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main\n    status = self.run(options, args)\n  File \"/usr/local/lib/python2.7/dist-packages/pip/commands/install.py\", line 278, in run\n    requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)\n  File \"/usr/local/lib/python2.7/dist-packages/pip/req.py\", line 1197, in prepare_files\n    do_download,\n  File \"/usr/local/lib/python2.7/dist-packages/pip/req.py\", line 1375, in unpack_url\n    self.session,\n  File \"/usr/local/lib/python2.7/dist-packages/pip/download.py\", line 586, in unpack_http_url\n    cache_download(cache_file, temp_location, content_type)\n  File \"/usr/local/lib/python2.7/dist-packages/pip/util.py\", line 609, in cache_download\n    fp = open(target_file+'.content-type', 'w')\nIOError: [Errno 71] Protocol error: '/var/cache/pip/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fsource%2Fd%2Fdjango-debug-toolbar-template-timings%2Fdjango-debug-toolbar-template-timings-0.6.zip.content-type'\n"], "labels": ["S: auto-locked"]}
{"project": "vector-im_riot-android", "title": "When I have jumped to the last unread message and then turn my phone to landscape mode, it jumps back to the most recent message of the room instead of staying at the last unread message in landscape mode", "description": "reported by @LAzz:matrix.org\n<URL> ", "code": [], "labels": ["bug", "P3"]}
{"project": "godotengine_godot", "title": "Cannot use constant variable of other class as contant value of current class", "description": "", "code": [], "labels": ["archived"]}
{"project": "kubernetes_website", "title": "Automate Syncing Generated Swagger docs into Docs branch", "description": "\nNo description provided.\n ", "code": [], "labels": ["lifecycle/rotten", "P2"]}
{"project": "rust-lang_rfcs", "title": "Localized file names and actual display names", "description": " Issue by pornel\nFriday Jan 23, 2015 at 22:38 GMT For earlier discussion, see rust-lang/rust#21569 This issue was labelled with: A-io, A-libs, A-mac-osx in the Rust repository In OS X you're not supposed to display POSIX paths to users. User-facing file names are supposed to use \"display name\" ([NSFilemanager displayNameAtPath:] and friends). Rust's path.display() and Display guidelines sound like they're exactly for this purpose, but unfortunately path.display() falls short on OS X and probably can't be fixed without breaking at least some Cargo build scripts. However, in OS X \"display path\" is seriously only for display and it's a one-way function: I'd be lovely if Rust had built-in support for this and encouraged doing the right thing on OS X and other OSes that have localized paths. Suggestions: ", "code": [], "labels": ["T-libs"]}
{"project": "osmandapp_Osmand", "title": "Alerts about maxspeed change", "description": "Pls, add alerts about changing the maxspeed on road ", "code": [], "labels": ["Nice to Have"]}
{"project": "certbot_certbot", "title": "Fix test_letsencrypt_auto_certonly_standalone.sh test to work with cryptography OCSP", "description": "The relevant lines of this file are <URL> There are a few problems with this code. After thinking about this a little bit, it's my opinion that instead of fixing the test here, we should remove them from this file and put them in our main integration tests. The thing that was previously nice about having this test in our test farm test was we got to test with the various versions of openssl used on these different platforms, however, now this isn't so easy. We will have pinned a version of cryptography that allows us to use cryptography rather than shelling out to OpenSSL and our \"oldest\" requirements don't work on various distros. We could either install unpinned dependencies like pip install cryptography<2.5 or create a 3rd set of pinnings which could be used for these tests, but both seem like a bad idea to me. Instead, if we put a test in our main integration tests, they'd be run with both new and old versions of our dependencies allowing us to continue testing with openssl on some platforms. This certainly isn't as thorough, but it's better than nothing and seems sufficient to me especially with the way we're using OCSP checks. We should be able to request the OCSP status of a certificate we revoked from boulder. jsha told me that we should be able to get a revoked response in <= 5s. If (and only if) running certbot certificates like is done in the tests linked above still prints TEST_CERT if it's unable to reach boulder, I think we should add this test to our integration tests as well. If not, we can probably just delete these files assuming they're not used elsewhere. ", "code": [], "labels": ["has pr"]}
{"project": "home-assistant_home-assistant", "title": "check_config no longer updates .HA_VERSION", "description": "Home Assistant release with the issue: 0.69.1\nLast working Home Assistant release (if known): < 0.65.0 (almost surely introduced by\nOperating environment (Hass.io/Docker/Windows/etc.): Docker\nComponent/platform: check_config script\nDescription of problem: Prior to 0.65.0, running check_config would update .HA_VERSION.   This no longer is occurring increasing the risk of running check_config against an incorrect version of Home Assistant. Problem-relevant configuration.yaml entries and (fill out even if it seems unimportant):\nTraceback (if applicable):\nAdditional information: Ideally, the behavior returns to the original.  If you run check_config with a Home Assistant version that does not match .HA_VERSION, the file is updated with the version that check_config is run with. ", "code": [], "labels": ["auto-closed", "waiting-for-reply"]}
{"project": "mgcrea_angular-strap", "title": "Popover causes IE (10, 11) to scroll to the top of the page.", "description": "This issue is happening in IE 10 & 11.  Chrome and Firefox work as expected. If the element that triggers the popover is below the \"fold\", when the popover is initially show (at 0,0 in 2.0.2 and -9999, -9999 in 2.0.3), IE 10/11 will scroll up to the popover's location.  If the element that triggers the popover is wrapped by a relative container, whose top/left is on screen, IE will not scroll. Here is a plunkr demonstating the issue: <URL> The documentation does not have this issue because the triggering elements are wrapped by a div with class bs-example which is relatively positioned. Example use case: we are using the popover in a table with 100 elements.  The table is wrapped in a col-md-* which is relatively positioned.  When the user scrolls down to view the  the end of the table and triggers the popover, IE scrolls to the top of the page. ", "code": [], "labels": ["outdated", "stale"]}
{"project": "cockroachdb_cockroach", "title": "circleci: failed tests: TestEagerReplication", "description": "The following test appears to have failed: #19564: <CODE> Please assign, take a look and update the issue accordingly. ", "code": ["I160623 21:51:17.244381 storage/replica.go:1786  applying command with forced error: storage/replica.go:1707: no-op on empty Raft entry\nE160623 21:51:17.244650 storage/replica.go:1797  [node=1,store=1,range=5] error executing raft command: storage/replica.go:1707: no-op on empty Raft entry\nI160623 21:51:17.244776 storage/replica_command.go:1575  range 5: new leader lease replica {1 1 1} 1970-01-01 00:00:00 +0000 UTC 900.000123ms following replica {0 0 0} 1970-01-01 00:00:00 +0000 UTC 0 [physicalTime=1970-01-01 00:00:00.000000123 +0000 UTC]\nW160623 21:51:17.245413 storage/store.go:1893  conflicting intents on [/Meta2/Table/14 /Meta2/Max]: resolved? false\nI160623 21:51:17.247339 storage/engine/rocksdb.go:185  closing in-memory rocksdb instance\n--- FAIL: TestEagerReplication (0.08s)\n    replicate_test.go:45: expected 5 replicas in purgatory, but found 4\n=== RUN   Example_rebalancing\nW160623 21:51:17.247597 gossip/gossip.go:898  not connected to cluster; use --join to specify a connected node\nI160623 21:51:17.346579 stopper.go:352  draining; tasks left:\n49     gossip/infostore.go:288\nI160623 21:51:17.346644 stopper.go:352  draining; tasks left:\n48     gossip/infostore.go:288\nI160623 21:51:17.346691 stopper.go:352  draining; tasks left:\n47     gossip/infostore.go:288\nI160623 21:51:17.346731 stopper.go:352  draining; tasks left:\n--\nI160623 21:51:17.348578 stopper.go:352  draining; tasks left:\n2      gossip/infostore.go:288\nI160623 21:51:17.348648 stopper.go:352  draining; tasks left:\n1      gossip/infostore.go:288\n--- PASS: Example_rebalancing (0.10s)\nFAIL\nFAIL    github.com/cockroachdb/cockroach/storage    43.563s\n=== RUN   TestBatchBasics\nI160623 21:50:34.153807 storage/engine/rocksdb.go:142  opening in memory rocksdb instance\nI160623 21:50:34.155726 storage/engine/rocksdb.go:185  closing in-memory rocksdb instance\n--- PASS: TestBatchBasics (0.02s)\n=== RUN   TestBatchRepr\nI160623 21:50:34.171225 storage/engine/rocksdb.go:142  opening in memory rocksdb instance\nI160623 21:50:34.172683 storage/engine/rocksdb.go:185  closing in-memory rocksdb instance\n--- PASS: TestBatchRepr (0.01s)\n=== RUN   TestBatchGet\nI160623 21:50:34.184040 storage/engine/rocksdb.go:142  opening in memory rocksdb instance\n\n"], "labels": ["O-robot", "C-test-failure"]}
{"project": "mailcow_mailcow-dockerized", "title": "set password for rpamd fail", "description": "Hey, set rspamd password in mailcow UI fails with error message 'An unknown error occured' In logs i dont see any entry. youve an idea? greetings\nSam ", "code": [], "labels": ["dunno"]}
{"project": "Homebrew_brew", "title": "S3DownloadStrategy disappeared", "description": "Please note that we will close your issue without comment if you delete, do not read or do not fill out the issue checklist below and provide ALL the requested information. If you repeatedly fail to use the issue template, we will block you from ever submitting issues to Homebrew again. Download a formula from a tap hosted in a private S3 bucket.  Tried with :using => :s3 and :using => S3DownloadStrategy as documented here and here. However, the S3DownloadStrategy seems to have been removed in 599ecc9. Therefore, unsurprisingly, the formula does not install correctly with either approach. The formula should install correctly. brew install my-s3-hosted-tap/my-formula I can obviously submit a PR to make the docs consistent, but is this intended, and if so what is the correct way to host formulae on S3, if supported at all? ", "code": [], "labels": ["outdated"]}
{"project": "kubesphere_kubesphere", "title": "\u8d44\u6e90\u4e0d\u591f\u5bfc\u81f4pod\u72b6\u6001\u4e3aoutofmemory\uff0c\u7136\u540e\u8d44\u6e90\u591f\u4e86\u540e\u8be5pod\u4ecd\u7136\u5728\u524d\u7aef\u663e\u793a", "description": "\u6d4b\u8bd5\u4e4b\u524d\u8d44\u6e90\u4e0d\u591f\uff0c\u5bfc\u81f4\u6709\u4e00\u4e9bpod\u72b6\u6001\u662foutof memory\uff0c\u540e\u6765\u8d44\u6e90\u53c8\u591f\u4e86\uff0c\u4f46\u662f\u4e4b\u524d\u7684pod\u4ecd\u5728\u524d\u7aef\u8fdb\u884c\u4e86\u663e\u793a\uff0c\u5efa\u8bae\u524d\u7aef\u4e0d\u4e88\u663e\u793a\n ", "code": [], "labels": ["area/console"]}
{"project": "doctrine_orm", "title": "DDC-2907: [GH-907] [DDC-1632] OneToMany Fetch eager", "description": "Jira issue originally created by user @doctrinebot: This issue is created automatically through a Github pull request on behalf of nenadalm: Url: #907 Message: version for 2.3:\n#905 ", "code": [], "labels": ["Bug"]}
{"project": "duplicati_duplicati", "title": "64 bit version installs in x86 (32 bit) Program Files Folder in Win7", "description": "From imi...@gmail.com on October 25, 2009 15:40:54 What steps will reproduce the problem? 1. Download and Install Duplicati 1.0 Windows 64 bit 2. 3. What is the expected output? What do you see instead? Expected that the program would be installed in C:\\Program Files\\ which is\nthe 64 bit folder in Windows 7. Instead, the installation placed duplicati\nin C:\\Program Files (X86) - which is where 32 bit apps go. What version of the product are you using? On what operating system? duplicati 1.0 64 bit + Windows 7 Professional 64 bit Please provide any additional information below. Original issue: <URL> ", "code": [], "labels": ["bug"]}
{"project": "CleverRaven_Cataclysm-DDA", "title": "Bitmap ASCII font, #FF00FF color issue", "description": "I happen to be one of those people who prefers ASCII to tiles, and I happen to prefer bitmap ASCII fonts to TrueType fonts. For this reason I use a Dwarf Fortress tileset as the font in C:DDA, and I've recently been rather dumbfounded when I was assaulted by a pitch black square that was supposed to be a \"mi-go\". Looking it up on the wiki, the tile for the \"mi-go\" is supposed to be a bright pink (#FF00FF) '&'. That made suspect what the problem actually is. In bitmap fonts, transparency is supported, but background and foreground colors are applied with a mask. Any pure-white (#FFFFFF) pixel gets the foreground color, any bright-pink (#FF00FF) pixel gets the background color. It seems that, for whatever reason, the background color and the foreground color are applied in sequence, to the same tile. The pink '&' I was supposed to see, became a full-pink tile when the foreground color was applied, and then became full-black when the background color was. It's possible to fix this 'properly' by making the tile-loader split the fore/back color masks and combine them in one step, but a much simpler solution is probably preferable here. Can the \"pink\" color for tiles be changed to #FE00FE by default? Or #FE00FF, or any other one-point variation. This way, when the pink color is assigned to the foreground mask, it will not blend with the background mask. It's possible to do so manually in \"colors.json\", but it's a small enough thing that it might as well be added by default. Hardly anyone will ever see it, and it'll be one less thing to look out for for anybody using bitmap fonts. ", "code": [], "labels": ["Info / User Interface", "Good First Issue", "<Bug>"]}
{"project": "babel_babel", "title": "Scope renaming bug in shorthand object syntax", "description": "Given: Use Scope#rename to rename the x identifier. It comes out with: Note that the returned object now has a different key, which is definitely a bug. Try it on AST Explorer. ", "code": [], "labels": ["outdated", "i: bug"]}
{"project": "strongloop_loopback", "title": "Prototype versus instance methods", "description": "Edit and publish <URL> ", "code": [], "labels": ["doc", "stale"]}
{"project": "MarlinFirmware_Marlin", "title": "[FR] Adding Nextion HMI Display support", "description": "How about to add the Nextion display support as a standard lcd feature?\nI do know, there is the marlinkimbra with that feature, but would be good to have it in the main line. ", "code": [], "labels": ["T: Feature Request"]}
{"project": "sequelize_sequelize", "title": "Sync problem when foreign key is part of composite primary key", "description": "When a foreign key is part of composite primary key, then the create script for the table in built wrong. The script look like this: ", "code": [], "labels": ["Question"]}
{"project": "WP-API_WP-API", "title": "?post_parent=ID is ignored on /media endpoint", "description": "Issue: site/wp-json/wp/v2/media?post_parent=ID returns the same result as site/wp-json/wp/v2/media There is no way to get attached images now, since _embedded['<URL>'] was removed. I am using beta7. ", "code": [], "labels": ["Bug"]}
{"project": "NativeScript_NativeScript", "title": "Calling .focus()-function on \"ui/search-bar\".SearchBar doesn't show keayboard but returns true", "description": "When calling .focus() no keyboard is shown for the searchBar. NativeScript CLI: 1.7.0\nPlatform: Android 5.1.1 ", "code": [], "labels": ["os: android"]}
{"project": "rancher_rancher", "title": "Repeated warnings relating to parsing backend token in logs in Shibboleth auth enabled setup.", "description": "Rancher server version - v1.6.24-rc4 Steps to reproduce the problem:\nEnable Shibboleth (PingFederator)  auth. Following errors are seen in logs repeatedly: <CODE> ", "code": ["time=\"2018-11-13T17:25:18Z\" level=warning msg=\"Error parsing backend token: crypto/rsa: verification error. Failing auth. Token parameter: eyJhbGciOiJSUzI1NiJ9.eyJyZXBvcnRlZFV1aWQiOiI5NmY1ZGQxYi03MzI5LTQ0YjAtNDk2Zi1hZDQzZTRlMThkZDEiLCJzdWIiOiJjYXR0bGUiLCJraWQiOiJkZWZhdWx0IiwiaXNzIjoiaHR0cDpcL1wvY2F0dGxlLmlvIiwiZXhwIjoxNTQyMTMwMjE4LCJpYXQiOjE1NDIxMjk5MTh9.JF-kR--6wqyRqS4ETT_-SCuoxcGn-u1zcSXlpwlMFsW8kPzmXlPZoA2ujnjUlULS1JHhOZbuQYhLKi3-QWKZzLEPg6bxs8U4WbU64bxk7iypWvcnIb0A1p7kHesbex-68ZLBUM6gMHZik3qTOmUO3aj44RWma-UiAIHKFPqWeClORN6MdBxG6khsomn1jKWSyBXK6vEntZ3KqV1RXXooQ000hb85L-RrjYRWsxklfq2mCedgMTE10SeS9gii-ppgfra5VJErrzuBK3lqR4r3zNZLXWzkoaxy9KxFUoXgxCVPmA1Q9_JkSXY15xAvjS1_N1kvznm1b_fxRxDBGmQY_Q\" \ntime=\"2018-11-13T17:25:21Z\" level=info msg=\"Handling backend connection request.\" \ntime=\"2018-11-13T17:25:21Z\" level=warning msg=\"Error parsing backend token: crypto/rsa: verification error. Failing auth. Token parameter: eyJhbGciOiJSUzI1NiJ9.eyJyZXBvcnRlZFV1aWQiOiI1ZGExYmRhYS03ZDJhLTRmMmUtNDQ0ZS05YmVjMTUwYzk3NTQiLCJzdWIiOiJjYXR0bGUiLCJraWQiOiJkZWZhdWx0IiwiaXNzIjoiaHR0cDpcL1wvY2F0dGxlLmlvIiwiZXhwIjoxNTQyMTMwMjIxLCJpYXQiOjE1NDIxMjk5MjF9.g4KdvdztV_BwWPYlj1odUGQ5jKxr3xmT_WxHNNVGT_VYcMfREeSAlYDlG6pYo678eTq-ePwURAiiflYH6hP3bLXDAXOUW05YrPVEG2k6t3J3Yvip7DbkI2Rpjp7LaieZ4mrJUQbKGSRDhD8CNGzKZ01-Tx476hq00qDnAKphZnhtNIKXXZRi79eiPPDLwE0u9G9ysruwpPKNhd5IKxQDUs5wO99bgPEhKcrJf0QzhioGKzXBgBYbajJaRX0D_OibU4Mu52YsZRzt_lxJ2hBUuTyycYTqrczOmUn7jcfFUKYBD-gbOsic2pWpG0Rr6dyt3N2Z4BOqS-eB-H3SzBzyYQ\" \ntime=\"2018-11-13T17:25:23Z\" level=info msg=\"Handling backend connection request.\" \ntime=\"2018-11-13T17:25:23Z\" level=warning msg=\"Error parsing backend token: crypto/rsa: verification error. Failing auth. Token parameter: eyJhbGciOiJSUzI1NiJ9.eyJyZXBvcnRlZFV1aWQiOiI5NmY1ZGQxYi03MzI5LTQ0YjAtNDk2Zi1hZDQzZTRlMThkZDEiLCJzdWIiOiJjYXR0bGUiLCJraWQiOiJkZWZhdWx0IiwiaXNzIjoiaHR0cDpcL1wvY2F0dGxlLmlvIiwiZXhwIjoxNTQyMTMwMjIzLCJpYXQiOjE1NDIxMjk5MjN9.V-_CYkCFHMMZKTJDJJAsVV-5I0Mn6hAgDVINbTr0T2hnAJkTRsoFscvopftwlgK1Hh1pRXl0C_G7fiB__nDqytGuvNMlg7Pt5jAkNsBbzlf6cifhPRJlvHKP7k3GNWKrLywinCk-f6Cr1aHBQxfbJsfLKQVnyJ0OeTgEx5FgErLBbPQA18mhZfrKPZtx2LiJfurVJVjnRBvH_lXPLNB8vkp-TZzw1_MIVtJgiDplwIzECEVwZy75q3HvYc4ZvCM87w6Erhh0pjQf9fkZ-HWppqzR8-bN0dyqW6bSvB9B4b1GnNHn9V9dSQIcV16g--8OZ2_d69xI2mDVgtnWjCJuaQ\" \ntime=\"2018-11-13T17:25:26Z\" level=info msg=\"Handling backend connection request.\" \ntime=\"2018-11-13T17:25:26Z\" level=warning msg=\"Error parsing backend token: crypto/rsa: verification error. Failing auth. Token parameter: eyJhbGciOiJSUzI1NiJ9.eyJyZXBvcnRlZFV1aWQiOiI1ZGExYmRhYS03ZDJhLTRmMmUtNDQ0ZS05YmVjMTUwYzk3NTQiLCJzdWIiOiJjYXR0bGUiLCJraWQiOiJkZWZhdWx0IiwiaXNzIjoiaHR0cDpcL1wvY2F0dGxlLmlvIiwiZXhwIjoxNTQyMTMwMjI2LCJpYXQiOjE1NDIxMjk5MjZ9.QXGcAO2XBsIXEA7Bjh3WDamkDKTeYQWPujK7c_hFv5MB_pPNPxDcN8AlOIEKJElHSHrdG-uZk05qSWDQWWi9m51ouSAaqkUQrZRXsaJwaF4j-_VN1i23ATzQyhnAZERxYKGXQklTDeshSi911wTdjCiXykXYDJ7cfpMXkJZ3KjNUb-RPKBNttSxm7enl8bMbw0XZh1OM1QNN8mZM1iFq03NAl04Ew1Q3Th3t0-dTY3Ksv6A1X1wFHD0vKIG467LzLxVALR5bLdRG5KohPpWmZ_njgu9Qdg4jgJhqC6_e6X-TDr2agWsD249zzeMdLz6SaHC5oVVKkcJuTDvBySOQlw\" \ntime=\"2018-11-13T17:25:28Z\" level=info msg=\"Handling backend connection request.\" \ntime=\"2018-11-13T17:25:28Z\" level=warning msg=\"Error parsing backend token: crypto/rsa: verification error. Failing auth. Token parameter: eyJhbGciOiJSUzI1NiJ9.eyJyZXBvcnRlZFV1aWQiOiI5NmY1ZGQxYi03MzI5LTQ0YjAtNDk2Zi1hZDQzZTRlMThkZDEiLCJzdWIiOiJjYXR0bGUiLCJraWQiOiJkZWZhdWx0IiwiaXNzIjoiaHR0cDpcL1wvY2F0dGxlLmlvIiwiZXhwIjoxNTQyMTMwMjI4LCJpYXQiOjE1NDIxMjk5Mjh9.Rd3n1iEHSkCg1DFZ7nj0KzIOwSf-TPE7xsQq1_N3Va4M3irYT7cRKiXceTlMtL7Ybe86bHFTDM4IlUPQScOMA_RD6E3NrKRt9evOMTqUGL0bQPtobry3Ofrq6NGGitXPyBjjUq80ZxU2M5vaNeFbo8KmA8ziFu1N-rxd4Qjrs_4TttjEFTLDkFhlioyaRSZ2pkPhC5gl1A-QJqcsQYhv9RMewQrBf3IbS-cB9Z-x8VdEd21idsubi_mw0wlNgMOf8lrk-C872VLR6TTVxMgMiXV0M2f51giEnpm-b7nhLz-ko_Ayi56ZMFaamvdjM9vSZ0OkmvU6Z9dpklwMdNvVlw\" \ntime=\"2018-11-13T17:25:31Z\" level=info msg=\"Handling backend connection request.\" \ntime=\"2018-11-13T17:25:31Z\" level=warning msg=\"Error parsing backend token: crypto/rsa: verification error. Failing auth. Token parameter: eyJhbGciOiJSUzI1NiJ9.eyJyZXBvcnRlZFV1aWQiOiI1ZGExYmRhYS03ZDJhLTRmMmUtNDQ0ZS05YmVjMTUwYzk3NTQiLCJzdWIiOiJjYXR0bGUiLCJraWQiOiJkZWZhdWx0IiwiaXNzIjoiaHR0cDpcL1wvY2F0dGxlLmlvIiwiZXhwIjoxNTQyMTMwMjMxLCJpYXQiOjE1NDIxMjk5MzF9.AH70ok6vM7zDBlHOrYkjPTKYjxMiCd64bk6Z2SS1GNtltSFJARf6bEXG1VfTYScB-bNjaAY7PpkmMaxc2Le53VLzODR64JUWiubuRMEdQHNKBZIiX56s_fCtvwhzRe9vfabEjBbW4zA7yPmVnjNae1tSsvh93t0veWagYl-FDUEKTXw9SjkO0lV5VukKA5QGCozWz8bDmiNNIw6dVQmhAVbOBbKFLqMauySmUBUcxBCoi68rGVdnroUd6BEKgRBvh5RhWGcCb4DhfBbTC8qzMbb--C0DQls5fM0r52yiofcnQAXJCI0TRlk4g8kf83F0vaztpRtl4sdsxdLdGie5Jg\" \n"], "labels": ["version/1.6", "kind/enhancement"]}
{"project": "cherrypy_cherrypy", "title": "ImportError: No module named filter.basefilter", "description": "Originally reported by: twiiqer tweaker (Bitbucket: twiiqer, GitHub: Unknown) I am using the latest version of cherrypy (3.2.3) the one which is available in \"Downloads\" section. Now, I want to hv some filters now I am using : from cherrypy.filters.basefilter import BaseFilter also I tried old one, from cherrypy.lib.filter.basefilter import BaseFilter But in both case I get error:\nImportError: No module named filter.basefilter ", "code": [], "labels": ["major", "bug"]}
{"project": "spring-cloud_spring-cloud-sleuth", "title": "Feign interceptor does not send ClientSentEvent", "description": "so the RPC annotations do not get added properly (whereas RestTemplate works fine). ", "code": [], "labels": ["bug"]}
{"project": "apache_dubbo", "title": "ApplicationModel basic metadata lose", "description": "Pls. provide [GitHub address] to reproduce this issue. What do you expected from the above steps\uff1f\nfine What actually happens?\nNPE If there is an exception, please attach the exception trace: <CODE> \n\u53d1\u751f\u8fd9\u4e2a\u95ee\u9898\u7684\u4e3b\u8981\u539f\u56e0\u662f\u5f53\u4f7f\u7528dubbo.provider/consumer\u6307\u5b9a\u5206\u7ec4/\u7248\u672c\u4fe1\u606f\u65f6\u5019\uff0c\u5206\u7ec4/\u7248\u672c\u7b49default\u5143\u6570\u636e\u6ca1\u6b63\u786e\u7684\u5b58\u5165\u5230ApplicationModel\u4e2d\u3002 ", "code": ["java.lang.NullPointerException: null\n\tat org.apache.dubbo.rpc.protocol.rest.RestProtocol.doExport(RestProtocol.java:99) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.rpc.protocol.AbstractProxyProtocol.export(AbstractProxyProtocol.java:78) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.qos.protocol.QosProtocolWrapper.export(QosProtocolWrapper.java:63) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:61) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper.export(ProtocolFilterWrapper.java:122) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.rpc.Protocol$Adaptive.export(Protocol$Adaptive.java) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.registry.integration.RegistryProtocol.lambda$doLocalExport$2(RegistryProtocol.java:245) ~[dubbo-2.7.3.jar:2.7.3]\n\tat java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660) ~[na:1.8.0_102]\n\tat org.apache.dubbo.registry.integration.RegistryProtocol.doLocalExport(RegistryProtocol.java:243) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.registry.integration.RegistryProtocol.export(RegistryProtocol.java:209) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.qos.protocol.QosProtocolWrapper.export(QosProtocolWrapper.java:61) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:59) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper.export(ProtocolFilterWrapper.java:120) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.rpc.Protocol$Adaptive.export(Protocol$Adaptive.java) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.config.ServiceConfig.doExportUrlsFor1Protocol(ServiceConfig.java:607) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.config.ServiceConfig.doExportUrls(ServiceConfig.java:457) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.config.ServiceConfig.doExport(ServiceConfig.java:415) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.config.ServiceConfig.export(ServiceConfig.java:378) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.config.spring.ServiceBean.export(ServiceBean.java:336) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.config.spring.ServiceBean.onApplicationEvent(ServiceBean.java:114) ~[dubbo-2.7.3.jar:2.7.3]\n\tat org.apache.dubbo.config.spring.ServiceBean.onApplicationEvent(ServiceBean.java:60) ~[dubbo-2.7.3.jar:2.7.3]\n"], "labels": ["type/bug"]}
{"project": "arendst_Tasmota", "title": "APP: Button1 multi-press 1 automatically turns Shelly1 on and off", "description": "Hi, i have a Shelly 1 device flashed with Tasmota 6.2.1. The Shelly 1 is installed behind the switch right to the door and turns the light on and off. All works fine, i can turn it on with the switch and off with homebridge.\nBut from time to time the device goes automatically on and off. One time it goes after maybe 3 mins on or off, other times after may 11 min. Its completly random.\nI have check the log and when \"APP: Button1 multi-press 1\" \"SCR: Button\" appears, the device turns automatically on or off. <CODE> So the question is, what is \"Button1 multi-press 1\" and how can i fix it? ", "code": ["13:20:50 APP: Button1 multi-press 1\n13:20:50 SRC: Button\n13:20:50 RSL: RESULT = {\"POWER\":\"ON\"}\n13:20:50 RSL: POWER = ON\n13:20:50 CFG: Saved to flash at F8, Count 172, Bytes 3584\n13:20:53 WIF: Checking connection...\n13:20:53 WIF: Connected\n13:21:13 WIF: Checking connection...\n13:21:13 WIF: Connected\n13:21:30 APP: Button1 multi-press 1\n13:21:31 SRC: Button\n13:21:31 RSL: RESULT = {\"POWER\":\"OFF\"}\n13:21:31 RSL: POWER = OFF\n"], "labels": ["troubleshooting"]}
{"project": "ansible_ansible", "title": "error when trying to use with_items with apt module", "description": "Bug Report ansible 1.7 (devel 226dacc) last updated 2014/07/28 21:56:28 (GMT +300) managing host: Ubuntu 14.04 64bit\nmanaged host: Ubuntu 10.04 32bit (python 2.6.5 + python-apt 0.7.94) Getting an error message while using with_items with the apt module. According to feature request #7863 and fix #8292, with_items should be used like this: <CODE> deb packages getting installed error message: <CODE> ", "code": ["    - name: install debs\n      apt: deb=/tmp/{{ item }} state=installed\n      with_items:\n        - linux-headers-3.11.6-031106_3.11.6-031106.201310181453_all.deb\n        - linux-headers-3.11.6-031106-generic_3.11.6-031106.201310181453_i386.deb\n        - linux-image-3.11.6-031106-generic_3.11.6-031106.201310181453_i386.deb\n", "TASK: [install debs] ********************************************************** \nfailed: [host1] => (item=linux-headers-3.11.6-031106_3.11.6-031106.201310181453_all.deb,linux-headers-3.11.6-031106-generic_3.11.6-031106.201310181453_i386.deb,linux-image-3.11.6-031106-generic_3.11.6-031106.201310181453_i386.deb) => {\"failed\": true, \"item\": \"linux-headers-3.11.6-031106_3.11.6-031106.201310181453_all.deb,linux-headers-3.11.6-031106-generic_3.11.6-031106.201310181453_i386.deb,linux-image-3.11.6-031106-generic_3.11.6-031106.201310181453_i386.deb\", \"parsed\": false}\ninvalid output was: SUDO-SUCCESS-mwctpznrbdkgnukozzhwfjskdskanudn\nTraceback (most recent call last):\n  File \"<stdin>\", line 1865, in <module>\n  File \"<stdin>\", line 523, in main\n  File \"<stdin>\", line 302, in install_deb\n  File \"/usr/lib/python2.6/dist-packages/apt/debfile.py\", line 285, in compare_to_version_in_cache\n    if pkgname in self._cache:\nTypeError: argument of type 'NoneType' is not iterable\n\n\nFATAL: all hosts have already failed -- aborting\n"], "labels": ["P4", "bug", "packaging"]}
{"project": "nilsteampassnet_TeamPass", "title": "Table 'teampass.teampass_restriction_to_roles' doesn't exist", "description": "User should be able to log in and see the empty folder blank page with error message\nTable 'teampass.teampass_restriction_to_roles' doesn't exist2KC7WpeXl5dufP2hmn8f9KlExlBen5P8pOvFUCExzXG3cOc8z5mx6x09+6qkjN4V2Ie5JaeNhjik6t2ogllsIa9INzatqPXJ4ug8rLrU2eckcUfqUo3g8ktp5Yfnxnxl48wHfA1NQUyhpePRz6VA/ldXVEhyIMqDPw== Operating system: Ubuntu 16.04 Web server: Apache 2.4 Database: Mysql 5.7 PHP version: 7 Teampass version: 2.1.27.11 Teampass configuration file: Updated from an older Teampass or fresh install:\nPLEASE attach to this message the file /includes/config/tp.config.php. Browser: Chrome Operating system: Windows 10 <CODE> from the application when logged in as administrator <CODE> ", "code": ["Query: SELECT i.id_tree, r.item_id FROM teampass_items as i INNER JOIN teampass_restriction_to_roles as r ON (r.item_id=i.id) WHERE r.role_id=1 ORDER BY i.id_tree ASC<br />Error: Table 'teampass.teampass_restriction_to_roles' doesn't exist<br />@ /\n", "Insert the log here and especially the answer of the query that failed.\n"], "labels": ["bug"]}
{"project": "desktop_desktop", "title": "Users can see what's new via in-app release notes", "description": "We talked about this a little at our mini summit but I forgot to record it. We'd like to do a better job of telling users about what changes between updates. One part of that would be displaying the release notes in app. ", "code": [], "labels": ["enhancement"]}
{"project": "bokeh_bokeh", "title": "Better styling in donut plot (web browser market share).", "description": "Copied from the merged PR #625: I have tested the example and I have some styling comments: ", "code": [], "labels": ["reso: completed", "enhancement"]}
{"project": "crystal-lang_crystal", "title": "Class variable with initializer shouldn't give error because of reading", "description": "Output: <CODE> ", "code": ["Error in ./foo.cr:11: instantiating 'Foo:Class#x()'\n\n  @@x : Int32 = Foo.x\n                    ^\n\nin ./foo.cr:18: class variable '@@x' of Foo is read here before it was initialized, rendering it nilable, but its type is Baz\n\n    @@x\n    ^\n"], "labels": ["kind:bug", "topic:compiler"]}
{"project": "ipfs_go-ipfs", "title": "In commandline help outputs, order of `SUBCOMMANDS` list changes each run", "description": "Versions: Ubuntu 16.04 Type (bug, feature, meta, test failure, question): bug Area (api, commands, daemon, fuse, etc): commands Priority (from P0: functioning, to P4: operations on fire): P0(?) Description: When running ipfs swarm, the output is: <CODE> When running the command again: <CODE> The order of SUBCOMMANDS list had changed. ", "code": ["USAGE\n  ipfs swarm - Swarm inspection tool.\n\n  'ipfs swarm' is a tool to manipulate the network swarm. The swarm is the\n  component that opens, listens for, and maintains connections to other\n  ipfs peers in the internet.\n\nSUBCOMMANDS\n  ipfs swarm filters                 - Manipulate address filters.\n  ipfs swarm peers                   - List peers with open connections.\n  ipfs swarm addrs                   - List known addresses. Useful for debugging.\n  ipfs swarm connect <address>...    - Open connection to a given address.\n  ipfs swarm disconnect <address>... - Close connection to a given address.\n\nUse 'ipfs swarm --help' for more information about this command.\n", "USAGE\n  ipfs swarm - Swarm inspection tool.\n\n  'ipfs swarm' is a tool to manipulate the network swarm. The swarm is the\n  component that opens, listens for, and maintains connections to other\n  ipfs peers in the internet.\n\nSUBCOMMANDS\n  ipfs swarm connect <address>...    - Open connection to a given address.\n  ipfs swarm disconnect <address>... - Close connection to a given address.\n  ipfs swarm filters                 - Manipulate address filters.\n  ipfs swarm peers                   - List peers with open connections.\n  ipfs swarm addrs                   - List known addresses. Useful for debugging.\n\nUse 'ipfs swarm --help' for more information about this command.\n"], "labels": ["difficulty:easy", "bug"]}
{"project": "NodeBB_NodeBB", "title": "Navigation button titles not translated", "description": " Happens on a fresh install.\nFixed by going to ACP > General > Navigation and clicking the save button. ", "code": [], "labels": ["bug"]}
{"project": "aws_aws-sdk-js", "title": "AWS authorizer header case sensitive", "description": "Confirm by changing [ ] to [x] below: I have 2 stages setup on same AWS account. One endpoint is edge endpoint and another one is regional endpoint. If i send Authorization header as 'Authorization', they are received as 'Authorization' at both stage authorizer via lambda.\nHowever, if i send header as 'authorization', it gets converted into 'Authorization' for edge endpoint but regional endpoint gets it as 'authorization'. I want to understand how AWS treats request headers while sending them to lambda/authorizer. Seems AWS is making changes in request headers based on some configuration. ", "code": [], "labels": ["guidance"]}
{"project": "spring-projects_spring-boot", "title": "Clarify what JmsListenerContainerFactory is created by default", "description": "After #3150  and #3390 commits, Jms local transaction works different. in 1.2.4, if there is a JDBC Transaction, it sync transactions internally, as documented, but in 1.2.5 snapshot, this feature is gone. ", "code": [], "labels": ["type: documentation"]}
{"project": "radareorg_radare2", "title": "afvn is not working", "description": "Tested in Visual mode using :afvn ... in a function with local variables ", "code": [], "labels": ["RAnal"]}
{"project": "spesmilo_electrum", "title": "How do Electrum client handle forks", "description": "I have been searching and looking up for an answer to this question for about three days and even searching within code (i am not a python programmer though) to get how Electrum clients handle forks. What i have experienced is that, server nodes doesn't inform clients with forks they already encountered, but instead they solve the fork at their side and send the next (new) block header to the client which will never be verified by the client local main chain. I was expecting that the server nodes will send the header (with same height) forks to the client so they start forking themselves, but that never happened.\nEdit: I am currently working on bitcoin testnet. ", "code": [], "labels": ["question"]}
{"project": "cilium_cilium", "title": "panic in event queue with waitGroup", "description": "The issue #8805 was found by accident as I didn't realize I was reusing the same event 2 times. The panic I was trying to trigger originally can be achieved with the following patch: compile and test: This occurs because the wait group is waiting while at the same time that wait group has more deltas being added to its internal counter. ", "code": [], "labels": ["priority/high"]}
{"project": "bitcoin_bitcoin", "title": "[msvc] number of sections exceeded object file format limit: compile with /bigobj", "description": "Only happening in Debug mode <CODE> Probably easy to fix, will check later. ", "code": ["\n\"C:\\Sources\\bitcoin\\build_msvc\\bitcoin.sln\" (default target) (1) ->\n\"C:\\Sources\\bitcoin\\build_msvc\\libbitcoinconsensus\\libbitcoinconsensus.vcxproj\" (default target) (2) ->\n(Lib target) ->\n  sha256_sse4.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation\n that consumes this library [C:\\Sources\\bitcoin\\build_msvc\\libbitcoinconsensus\\libbitcoinconsensus.vcxproj]\n\n\n\"C:\\Sources\\bitcoin\\build_msvc\\bitcoin.sln\" (default target) (1) ->\n\"C:\\Sources\\bitcoin\\build_msvc\\testconsensus\\testconsensus.vcxproj\" (default target) (3) ->\n\"C:\\Sources\\bitcoin\\build_msvc\\libbitcoin_util\\libbitcoin_util.vcxproj\" (default target) (4) ->\n  sync.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that c\nonsumes this library [C:\\Sources\\bitcoin\\build_msvc\\libbitcoin_util\\libbitcoin_util.vcxproj]\n  compat_strnlen.obj : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operat\nion that consumes this library [C:\\Sources\\bitcoin\\build_msvc\\libbitcoin_util\\libbitcoin_util.vcxproj]\n\n\n\"C:\\Sources\\bitcoin\\build_msvc\\bitcoin.sln\" (default target) (1) ->\n\"C:\\Sources\\bitcoin\\build_msvc\\bitcoind\\bitcoind.vcxproj\" (default target) (6) ->\n\"C:\\Sources\\bitcoin\\build_msvc\\libbitcoin_wallet\\libbitcoin_wallet.vcxproj\" (default target) (10) ->\n(ClCompile target) ->\n  C:\\Sources\\bitcoin\\src\\wallet\\wallet.cpp : fatal error C1128: number of sections exceeded object file format limit: compile with /bigobj [C:\\Sources\\bitc\noin\\build_msvc\\libbitcoin_wallet\\libbitcoin_wallet.vcxproj]\n\n    3 Warning(s)\n    1 Error(s)\n"], "labels": ["Windows"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Create a manipulation-log", "description": "When I\u2019m developing stuff here on our local servers and \nchange the database-layout, insert stuff and create \nIndexes I always have to keep track of this manually, to \napply these changes to the live-database afterwards. Would be great to have a log where all these things for \nthe active database could be recorded, only \nmanipulating queries. I could remove unwanted lines \nafterwards and would have a sql-update-script that \ncontains everything I need for the live-update. - Original URL: <URL>\n- Original author: temporary ", "code": [], "labels": ["enhancement", "duplicate"]}
{"project": "eclipse-theia_theia", "title": "Handle terminal restoration for tasks that have completed execution", "description": "When we run tasks using a terminal process, we can have the task's output shown in a terminal, as it executes. If the client disconnects (e.g. reload web page), we are in general able to restore task-terminals without losing output. However, if a task has terminated and its output is shown in a terminal, we will not be able to re-connect with its process in the backend, and will fail restoring its previous content.  Maybe we should preserve, in the backend, the final terminal output for a task, and restore that in the case above? ", "code": [], "labels": ["enhancement", "tasks", "bug"]}
{"project": "microsoft_TypeScript", "title": "Weird interaction between default arguments and strict-null", "description": "TypeScript Version:  Version 2.0.5 Code (with --strictNullChecks on) Note that the second parameter (z) is necessary to trigger this behavior; if you drop z from this example, then the first param x has a ? as you'd expect. (So it's even possible this is just a bug in how the function type is printed...?) ", "code": [], "labels": ["Bug", "Fixed"]}
{"project": "LonamiWebs_Telethon", "title": "Two Client", "description": "i need to connect a session file with two file but if i run second source , first source dont get any update my first source: client = TelegramClient(\"./Sessions/{}.session\".format(text), config.apis[str(text)][\"api_id\"], config.apis[str(text)][\"api_hash\"], update_workers=2, spawn_read_thread=False)\nclient.start() @client.on(events.NewMessage)\ndef my_event_handler(event):\nprint(event)\nclient.idle() second source: client = TelegramClient(\"./Sessions/{}.session\".format(text), config.apis[str(text)][\"api_id\"], config.apis[str(text)][\"api_hash\"], update_workers=2, spawn_read_thread=False)\nclient.connect ", "code": [], "labels": ["duplicate"]}
{"project": "rails_rails", "title": "SchemaStatements#add_reference doesn't allow for :uuid foreign key", "description": "add_reference assumes that the primary key of the referenced table is an :integer, and from my reading of the source there doesn't seem to be any way to override this. This is a problem when the referenced table was created with id: :uuid. The workaround is to add a correctly-typed foreign key column and index appropriately by hand rather than use the add_reference shortcut. My suggestion is that the options hash of add_reference should accept an option to override the type of the foreign key column (:type or perhaps :id_type). Or maybe it could infer the key's type from schema.rb or something. Obviously the question of whether this important enough to warrant fixing isn't mine to answer so I'll leave it to you \ud83c\udf63. I'm happy to contribute a patch. ", "code": [], "labels": ["stale"]}
{"project": "dotnet_corefx", "title": "34 System.Net.Http.Functional tests are timing out on arm64", "description": "<URL> Configuration: netcoreapp-Windows_NT-Release-arm64-Windows.10.Arm64.Open Should we increase the timeout on arm64? <CODE> @davidsh, @wfurt, @scalablecory, @eiriktsarpalis, @karelz ", "code": ["Discovering: System.Net.Http.Functional.Tests (method display = ClassAndMethod, method display options = None)\n  Discovered:  System.Net.Http.Functional.Tests (found 785 of 1134 test cases)\n  Starting:    System.Net.Http.Functional.Tests (parallel test collections = on, max threads = 8)\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientEKUTest.HttpClient_ClientEKUServerAuth_Fails [SKIP]\n      Condition(s) not met: \"CanTestCertificates\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientEKUTest.HttpClient_NoEKUServerAuth_Ok [SKIP]\n      Condition(s) not met: \"CanTestCertificates\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientEKUTest.HttpClient_NoEKUClientAuth_Ok [SKIP]\n      Condition(s) not met: \"CanTestClientCertificates\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientEKUTest.HttpClient_ServerEKUClientAuth_Fails [SKIP]\n      Condition(s) not met: \"CanTestClientCertificates\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClient_SelectedSites_Test.RetrieveSite_Succeeds [SKIP]\n      Condition(s) not met: \"IsSelectedSitesTestEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClient_SelectedSites_Test.RetrieveSite_Debug_Helper [SKIP]\n      Condition(s) not met: \"IsSelectedSitesTestEnabled\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClient_SelectedSites_Test.RetrieveSite_Succeeds [SKIP]\n      Condition(s) not met: \"IsSelectedSitesTestEnabled\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClient_SelectedSites_Test.RetrieveSite_Debug_Helper [SKIP]\n      Condition(s) not met: \"IsSelectedSitesTestEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http2.UnreadResponseMessage_Collectible [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http2.ManyClients_ManyGets [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http2.SingleClient_ManyGets_Async [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http2.MakeAndFaultManyRequests [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http2.SingleClient_ManyGets_Sync [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_NoVersion.MakeAndFaultManyRequests [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_NoVersion.CreateAndDestroyManyClients [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_NoVersion.ManyClients_ManyGets [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_NoVersion.SingleClient_ManyGets_Sync [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_NoVersion.UnreadResponseMessage_Collectible [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_NoVersion.SingleClient_ManyGets_Async [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientEKUTest.HttpClient_ServerEKUClientAuth_Fails [SKIP]\n      Condition(s) not met: \"CanTestClientCertificates\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientEKUTest.HttpClient_NoEKUClientAuth_Ok [SKIP]\n      Condition(s) not met: \"CanTestClientCertificates\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientEKUTest.HttpClient_NoEKUServerAuth_Ok [SKIP]\n      Condition(s) not met: \"CanTestCertificates\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientEKUTest.HttpClient_ClientEKUServerAuth_Fails [SKIP]\n      Condition(s) not met: \"CanTestCertificates\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http11.UnreadResponseMessage_Collectible [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http11.MakeAndFaultManyRequests [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http11.ManyClients_ManyPosts_Async [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http11.SingleClient_ManyGets_Async [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http11.SingleClient_ManyGets_Sync [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientMiniStress_Http11.ManyClients_ManyGets [SKIP]\n      Condition(s) not met: \"IsStressModeEnabled\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_Authentication_Test.Credentials_DomainJoinedServerUsesKerberos_UseIpAddressAndHostHeader_Success [SKIP]\n      Condition(s) not met: \"IsDomainJoinedServerAvailable\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_Authentication_Test.Proxy_DomainJoinedProxyServerUsesKerberos_Success [SKIP]\n      Condition(s) not met: \"IsDomainJoinedServerAvailable\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandler_Authentication_Test.Credentials_ServerUsesWindowsAuthentication_Success [SKIP]\n      Condition(s) not met: \"IsWindowsServerAvailable\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandler_Authentication_Test.Credentials_DomainJoinedServerUsesKerberos_Success [SKIP]\n      Condition(s) not met: \"IsDomainJoinedServerAvailable\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandler_Authentication_Test.Credentials_DomainJoinedServerUsesKerberos_UseIpAddressAndHostHeader_Success [SKIP]\n      Condition(s) not met: \"IsDomainJoinedServerAvailable\"\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandler_Authentication_Test.Proxy_DomainJoinedProxyServerUsesKerberos_Success [SKIP]\n      Condition(s) not met: \"IsDomainJoinedServerAvailable\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_Authentication_Test.Credentials_ServerUsesWindowsAuthentication_Success [SKIP]\n      Condition(s) not met: \"IsWindowsServerAvailable\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_Authentication_Test.Credentials_DomainJoinedServerUsesKerberos_Success [SKIP]\n      Condition(s) not met: \"IsDomainJoinedServerAvailable\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_Finalization_Http2_Test.IncompleteResponseStream_ResponseDropped_CancelsRequestToServer [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Finalization.cs(34,0): at System.Net.Http.Functional.Tests.HttpClientHandler_Finalization_Test.IncompleteResponseStream_ResponseDropped_CancelsRequestToServer()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_Cookies_Http2.GetAsync_AddMultipleCookieHeaders_CookiesSent [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Cookies.cs(150,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Cookies.GetAsync_AddMultipleCookieHeaders_CookiesSent()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.HPackTest.HPack_HeaderEncoding(headerName: \":method\", expectedValue: \"POST\", expectedEncoding: [131]) [FAIL]\n      System.TimeoutException : WhenAllOrAnyFailed timed out after 60000ms\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(75,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(186,0): at System.Net.Test.Common.Http2LoopbackServer.CreateClientAndServerAsync(Func`2 clientFunc, Func`2 serverFunc, Int32 timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HPackTest.cs(38,0): at System.Net.Http.Functional.Tests.HPackTest.HPack_HeaderEncoding(String headerName, String expectedValue, Byte[] expectedEncoding)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_ConnectionPooling_Test.Http2_SmallConnectionTimeout_SubsequentRequestUsesDifferentConnection(timeoutPropertyName: \"PooledConnectionLifetime\") [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(207,0): at System.Net.Test.Common.Http2LoopbackServerFactory.CreateServerAsync(Func`3 funcAsync, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/SocketsHttpHandlerTest.cs(1606,0): at System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_ConnectionPooling_Test.Http2_SmallConnectionTimeout_SubsequentRequestUsesDifferentConnection(String timeoutPropertyName)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_Cancellation_Test_Http2.PostAsync_CancelDuringRequestContentSend_TaskCanceledQuickly(chunkedTransfer: False, mode: Token) [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Cancellation.cs(45,0): at System.Net.Http.Functional.Tests.HttpClientHandler_Cancellation_Test.PostAsync_CancelDuringRequestContentSend_TaskCanceledQuickly(Boolean chunkedTransfer, CancellationMode mode)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Headers_Http2.SendAsync_WithZeroLengthHeaderName_Throws [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Headers.cs(272,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Headers.SendAsync_WithZeroLengthHeaderName_Throws()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Http2.PostAsync_ManyDifferentRequestHeaders_SentCorrectly [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(789,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.PostAsync_ManyDifferentRequestHeaders_SentCorrectly()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.SetDelegate_ConnectionSucceeds(acceptedProtocol: Tls, requestOnlyThisProtocol: False) [FAIL]\n      System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(71,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.AcceptAllCerts.cs(77,0): at System.Net.Http.Functional.Tests.HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.<>c__DisplayClass4_0.<<SetDelegate_ConnectionSucceeds>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.AcceptAllCerts.cs(75,0): at System.Net.Http.Functional.Tests.HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.SetDelegate_ConnectionSucceeds(SslProtocols acceptedProtocol, Boolean requestOnlyThisProtocol)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_SslProtocols_Test.GetAsync_NoSpecifiedProtocol_DefaultsToTls12 [FAIL]\n      System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(71,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.SslProtocols.cs(250,0): at System.Net.Http.Functional.Tests.HttpClientHandler_SslProtocols_Test.<>c__DisplayClass11_0.<<GetAsync_NoSpecifiedProtocol_DefaultsToTls12>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.SslProtocols.cs(248,0): at System.Net.Http.Functional.Tests.HttpClientHandler_SslProtocols_Test.GetAsync_NoSpecifiedProtocol_DefaultsToTls12()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandler_SslProtocols_Test.GetAsync_NoSpecifiedProtocol_DefaultsToTls12 [FAIL]\n      System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(71,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.SslProtocols.cs(250,0): at System.Net.Http.Functional.Tests.HttpClientHandler_SslProtocols_Test.<>c__DisplayClass11_0.<<GetAsync_NoSpecifiedProtocol_DefaultsToTls12>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.SslProtocols.cs(248,0): at System.Net.Http.Functional.Tests.HttpClientHandler_SslProtocols_Test.GetAsync_NoSpecifiedProtocol_DefaultsToTls12()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_Cookies_Http2.GetAsync_DefaultCoookieContainer_NoCookieSent [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Cookies.cs(46,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Cookies.GetAsync_DefaultCoookieContainer_NoCookieSent()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.HPackTest.HPack_HeaderEncoding(headerName: \":path\", expectedValue: \"/\", expectedEncoding: [132]) [FAIL]\n      System.TimeoutException : WhenAllOrAnyFailed timed out after 60000ms\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(75,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(186,0): at System.Net.Test.Common.Http2LoopbackServer.CreateClientAndServerAsync(Func`2 clientFunc, Func`2 serverFunc, Int32 timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HPackTest.cs(38,0): at System.Net.Http.Functional.Tests.HPackTest.HPack_HeaderEncoding(String headerName, String expectedValue, Byte[] expectedEncoding)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_ConnectionPooling_Test.Http2_SmallConnectionTimeout_SubsequentRequestUsesDifferentConnection(timeoutPropertyName: \"PooledConnectionIdleTimeout\") [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(207,0): at System.Net.Test.Common.Http2LoopbackServerFactory.CreateServerAsync(Func`3 funcAsync, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/SocketsHttpHandlerTest.cs(1606,0): at System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_ConnectionPooling_Test.Http2_SmallConnectionTimeout_SubsequentRequestUsesDifferentConnection(String timeoutPropertyName)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_Http2.Http2_ServerSendsValidSettingsValues_Success [FAIL]\n      Cannot acquire the global certificate mutex.\n      Expected: True\n      Actual:   False\n      Stack Trace:\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(70,0): at System.Net.Test.Common.Configuration.Certificates.GetCertificate(String certificateFileName)\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(38,0): at System.Net.Test.Common.Configuration.Certificates.GetServerCertificate()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(41,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(103,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Http2.cs(192,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Http2.Http2_ServerSendsValidSettingsValues_Success()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_Http2_TrailingHeaders_Test.Http2GetAsync_TrailerHeaders_TrailingHeaderNoBody [FAIL]\n      Cannot acquire the global certificate mutex.\n      Expected: True\n      Actual:   False\n      Stack Trace:\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(70,0): at System.Net.Test.Common.Configuration.Certificates.GetCertificate(String certificateFileName)\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(38,0): at System.Net.Test.Common.Configuration.Certificates.GetServerCertificate()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(41,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(103,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/System.Net.Http/tests/FunctionalTests/SocketsHttpHandlerTest.cs(906,0): at System.Net.Http.Functional.Tests.SocketsHttpHandler_Http2_TrailingHeaders_Test.Http2GetAsync_TrailerHeaders_TrailingHeaderNoBody()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Headers_Http2.GetAsync_MissingExpires_ReturnNull [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(42,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Headers.cs(151,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Headers.GetAsync_MissingExpires_ReturnNull()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(address: 127.0.0.1, useSsl: True) [FAIL]\n      Cannot acquire the global certificate mutex.\n      Expected: True\n      Actual:   False\n      Stack Trace:\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(70,0): at System.Net.Test.Common.Configuration.Certificates.GetCertificate(String certificateFileName)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(154,0): at System.Net.Test.Common.LoopbackServer.AcceptConnectionAsync(Func`2 funcAsync)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(84,0): at System.Net.Test.Common.LoopbackServer.<>c__DisplayClass11_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(506,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(IPAddress address, Boolean useSsl)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(address: 127.0.0.1, useSsl: True) [FAIL]\n      Cannot acquire the global certificate mutex.\n      Expected: True\n      Actual:   False\n      Stack Trace:\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(70,0): at System.Net.Test.Common.Configuration.Certificates.GetCertificate(String certificateFileName)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(154,0): at System.Net.Test.Common.LoopbackServer.AcceptConnectionAsync(Func`2 funcAsync)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(84,0): at System.Net.Test.Common.LoopbackServer.<>c__DisplayClass11_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(506,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(IPAddress address, Boolean useSsl)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Http2.Dispose_DisposingHandlerCancelsActiveOperationsWithoutResponses [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(44,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(215,0): at System.Net.Test.Common.Http2LoopbackServerFactory.CreateServerAsync(Func`3 funcAsync, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(1550,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.Dispose_DisposingHandlerCancelsActiveOperationsWithoutResponses()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.SetDelegate_ConnectionSucceeds(acceptedProtocol: Tls, requestOnlyThisProtocol: True) [FAIL]\n      System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(71,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.AcceptAllCerts.cs(77,0): at System.Net.Http.Functional.Tests.HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.<>c__DisplayClass4_0.<<SetDelegate_ConnectionSucceeds>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.AcceptAllCerts.cs(75,0): at System.Net.Http.Functional.Tests.HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.SetDelegate_ConnectionSucceeds(SslProtocols acceptedProtocol, Boolean requestOnlyThisProtocol)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.HPackTest.HPack_HeaderEncoding(headerName: \"content-type\", expectedValue: \"text/plain; charset=utf-8\", expectedEncoding: [15, 16, 25, 116, 101, ...]) [FAIL]\n      System.AggregateException : One or more errors occurred. (A task was canceled.) (One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)))\n      ---- System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      ---- System.AggregateException : One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..))\n      -------- System.AggregateException : One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)\n      ------------ System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      ---------------- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(109,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(71,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(186,0): at System.Net.Test.Common.Http2LoopbackServer.CreateClientAndServerAsync(Func`2 clientFunc, Func`2 serverFunc, Int32 timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HPackTest.cs(38,0): at System.Net.Http.Functional.Tests.HPackTest.HPack_HeaderEncoding(String headerName, String expectedValue, Byte[] expectedEncoding)\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace #1 (System.Threading.Tasks.TaskCanceledException) -----\n        \n        ----- Inner Stack Trace #2 (System.AggregateException) -----\n        \n        ----- Inner Stack Trace -----\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2733,0): at System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2599,0): at System.Threading.Tasks.Task.Wait()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(56,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(103,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/System.Net.Http/tests/FunctionalTests/HPackTest.cs(54,0): at System.Net.Http.Functional.Tests.HPackTest.<>c__DisplayClass7_0.<<HPack_HeaderEncoding>b__1>d.MoveNext()\n        ----- Inner Stack Trace -----\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(843,0): at System.Net.Security.SslStream.<ThrowIfExceptional>g__ThrowExceptional|141_0(ExceptionDispatchInfo e)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(437,0): at System.Net.Security.SslStream.InternalEndProcessAuthentication(LazyAsyncResult lazyResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(407,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(443,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__70_1(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(513,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_Cookies_Http2.GetAsync_ReceiveInvalidSetCookieHeader_ValidCookiesAdded [FAIL]\n      System.AggregateException : One or more errors occurred. (A task was canceled.) (One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)))\n      ---- System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      ---- System.AggregateException : One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..))\n      -------- System.AggregateException : One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)\n      ------------ System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      ---------------- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(109,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(77,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Cookies.cs(482,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Cookies.<GetAsync_ReceiveInvalidSetCookieHeader_ValidCookiesAdded>b__22_0(GenericLoopbackServer server, Uri url)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(44,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(215,0): at System.Net.Test.Common.Http2LoopbackServerFactory.CreateServerAsync(Func`3 funcAsync, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Cookies.cs(466,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Cookies.GetAsync_ReceiveInvalidSetCookieHeader_ValidCookiesAdded()\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace #1 (System.Threading.Tasks.TaskCanceledException) -----\n        \n        ----- Inner Stack Trace #2 (System.AggregateException) -----\n        \n        ----- Inner Stack Trace -----\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2733,0): at System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2599,0): at System.Threading.Tasks.Task.Wait()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(56,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(103,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(148,0): at System.Net.Test.Common.Http2LoopbackServer.HandleRequestAsync(HttpStatusCode statusCode, IList`1 headers, String content)\n        ----- Inner Stack Trace -----\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(843,0): at System.Net.Security.SslStream.<ThrowIfExceptional>g__ThrowExceptional|141_0(ExceptionDispatchInfo e)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(404,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(443,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__70_1(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(546,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_Http2.PostAsyncDuplex_RequestContentExceptionAfterResponseEndReceivedButBeforeConsumed_ResetsStreamAndThrowsOnResponseStreamRead [FAIL]\n      System.AggregateException : One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)\n      ---- System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      -------- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2733,0): at System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2599,0): at System.Threading.Tasks.Task.Wait()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(56,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(103,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Http2.cs(2219,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Http2.PostAsyncDuplex_RequestContentExceptionAfterResponseEndReceivedButBeforeConsumed_ResetsStreamAndThrowsOnResponseStreamRead()\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace -----\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(843,0): at System.Net.Security.SslStream.<ThrowIfExceptional>g__ThrowExceptional|141_0(ExceptionDispatchInfo e)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(404,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(443,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__70_1(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(546,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.SocketsHttpHandler_Http2_TrailingHeaders_Test.Http2GetAsyncResponseHeadersReadOption_TrailingHeaders_Available [FAIL]\n      System.AggregateException : One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)\n      ---- System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      -------- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2733,0): at System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2599,0): at System.Threading.Tasks.Task.Wait()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(56,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(103,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/System.Net.Http/tests/FunctionalTests/SocketsHttpHandlerTest.cs(862,0): at System.Net.Http.Functional.Tests.SocketsHttpHandler_Http2_TrailingHeaders_Test.Http2GetAsyncResponseHeadersReadOption_TrailingHeaders_Available()\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace -----\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(843,0): at System.Net.Security.SslStream.<ThrowIfExceptional>g__ThrowExceptional|141_0(ExceptionDispatchInfo e)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(404,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(443,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__70_1(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(546,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Headers_Http2.SendAsync_Expires_Success(value: \"Thu, 01 Dec 1994 16:00:00 GMT\", isValid: True) [FAIL]\n      System.AggregateException : One or more errors occurred. (A task was canceled.) (One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)))\n      ---- System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      ---- System.AggregateException : One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..))\n      -------- System.AggregateException : One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)\n      ------------ System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      ---------------- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(109,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/GenericLoopbackServer.cs(31,0): at System.Net.Test.Common.LoopbackServerFactory.<>c__DisplayClass5_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(44,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(215,0): at System.Net.Test.Common.Http2LoopbackServerFactory.CreateServerAsync(Func`3 funcAsync, Int32 millisecondsTimeout)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(44,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Headers.cs(171,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Headers.SendAsync_Expires_Success(String value, Boolean isValid)\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace #1 (System.Threading.Tasks.TaskCanceledException) -----\n        \n        ----- Inner Stack Trace #2 (System.AggregateException) -----\n        \n        ----- Inner Stack Trace -----\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2733,0): at System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2599,0): at System.Threading.Tasks.Task.Wait()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(56,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(103,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(148,0): at System.Net.Test.Common.Http2LoopbackServer.HandleRequestAsync(HttpStatusCode statusCode, IList`1 headers, String content)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Headers.cs(186,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Headers.<>c__DisplayClass8_0.<<SendAsync_Expires_Success>b__1>d.MoveNext()\n        ----- Inner Stack Trace -----\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(404,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(443,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__70_1(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(546,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(address: ::1, useSsl: True) [FAIL]\n      Cannot acquire the global certificate mutex.\n      Expected: True\n      Actual:   False\n      Stack Trace:\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(70,0): at System.Net.Test.Common.Configuration.Certificates.GetCertificate(String certificateFileName)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(154,0): at System.Net.Test.Common.LoopbackServer.AcceptConnectionAsync(Func`2 funcAsync)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(84,0): at System.Net.Test.Common.LoopbackServer.<>c__DisplayClass11_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(506,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(IPAddress address, Boolean useSsl)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Http2.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(address: 127.0.0.1, useSsl: True) [FAIL]\n      Cannot acquire the global certificate mutex.\n      Expected: True\n      Actual:   False\n      Stack Trace:\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(70,0): at System.Net.Test.Common.Configuration.Certificates.GetCertificate(String certificateFileName)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(154,0): at System.Net.Test.Common.LoopbackServer.AcceptConnectionAsync(Func`2 funcAsync)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(84,0): at System.Net.Test.Common.LoopbackServer.<>c__DisplayClass11_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(506,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(IPAddress address, Boolean useSsl)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.PlatformHandler_HttpClientHandlerTest.Ctor_ExpectedDefaultPropertyValues_UapPlatform [SKIP]\n      Condition(s) not met: \"IsUap\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.SetDelegate_ConnectionSucceeds(acceptedProtocol: Tls | Tls11 | Tls12, requestOnlyThisProtocol: False) [FAIL]\n      System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(77,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.AcceptAllCerts.cs(77,0): at System.Net.Http.Functional.Tests.HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.<>c__DisplayClass4_0.<<SetDelegate_ConnectionSucceeds>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.AcceptAllCerts.cs(75,0): at System.Net.Http.Functional.Tests.HttpClientHandler_DangerousAcceptAllCertificatesValidator_Test.SetDelegate_ConnectionSucceeds(SslProtocols acceptedProtocol, Boolean requestOnlyThisProtocol)\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(address: ::1, useSsl: True) [FAIL]\n      System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      ---- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(404,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(434,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__69_2(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(546,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(154,0): at System.Net.Test.Common.LoopbackServer.AcceptConnectionAsync(Func`2 funcAsync)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(84,0): at System.Net.Test.Common.LoopbackServer.<>c__DisplayClass11_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(506,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(IPAddress address, Boolean useSsl)\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.SocketsHttpHandler_HttpClientHandlerTest.Ctor_ExpectedDefaultPropertyValues_UapPlatform [SKIP]\n      Condition(s) not met: \"IsUap\"\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_Cookies_Http2.GetAsyncWithRedirect_SetCookieContainer_CorrectCookiesSent [FAIL]\n      System.TimeoutException : Task timed out after 00:01:00\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(44,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Cookies.cs(306,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Cookies.GetAsyncWithRedirect_SetCookieContainer_CorrectCookiesSent()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_Http2.DynamicTableSizeUpdate_Exceeds_Settings_Throws [FAIL]\n      System.TimeoutException : WhenAllOrAnyFailed timed out after 60000ms\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(77,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks, Int32 millisecondsTimeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(186,0): at System.Net.Test.Common.Http2LoopbackServer.CreateClientAndServerAsync(Func`2 clientFunc, Func`2 serverFunc, Int32 timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Http2.cs(3134,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Http2.DynamicTableSizeUpdate_Exceeds_Settings_Throws()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandler_Http2_TrailingHeaders_Test.Http2GetAsync_TrailerHeaders_TrailingPseudoHeadersThrow [FAIL]\n      Cannot acquire the global certificate mutex.\n      Expected: True\n      Actual:   False\n      Stack Trace:\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(70,0): at System.Net.Test.Common.Configuration.Certificates.GetCertificate(String certificateFileName)\n        /_/src/Common/tests/System/Net/Configuration.Certificates.cs(38,0): at System.Net.Test.Common.Configuration.Certificates.GetServerCertificate()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(41,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(131,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(99,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/System.Net.Http/tests/FunctionalTests/SocketsHttpHandlerTest.cs(840,0): at System.Net.Http.Functional.Tests.SocketsHttpHandler_Http2_TrailingHeaders_Test.Http2GetAsync_TrailerHeaders_TrailingPseudoHeadersThrow()\n        --- End of stack trace from previous location where exception was thrown ---\n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Headers_Http2.SendAsync_Expires_Success(value: \"-1\", isValid: False) [FAIL]\n      System.AggregateException : One or more errors occurred. (A task was canceled.) (One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)))\n      ---- System.Threading.Tasks.TaskCanceledException : A task was canceled.\n      ---- System.AggregateException : One or more errors occurred. (One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..))\n      -------- System.AggregateException : One or more errors occurred. (Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..)\n      ------------ System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      ---------------- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(109,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/GenericLoopbackServer.cs(31,0): at System.Net.Test.Common.LoopbackServerFactory.<>c__DisplayClass5_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(44,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(215,0): at System.Net.Test.Common.Http2LoopbackServerFactory.CreateServerAsync(Func`3 funcAsync, Int32 millisecondsTimeout)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(44,0): at System.Threading.Tasks.TaskTimeoutExtensions.TimeoutAfter(Task task, TimeSpan timeout)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Headers.cs(171,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Headers.SendAsync_Expires_Success(String value, Boolean isValid)\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace #1 (System.Threading.Tasks.TaskCanceledException) -----\n        \n        ----- Inner Stack Trace #2 (System.AggregateException) -----\n        \n        ----- Inner Stack Trace -----\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2733,0): at System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/Task.cs(2599,0): at System.Threading.Tasks.Task.Wait()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackConnection.cs(56,0): at System.Net.Test.Common.Http2LoopbackConnection..ctor(Socket socket, Http2Options httpOptions)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(89,0): at System.Net.Test.Common.Http2LoopbackServer.AcceptConnectionAsync()\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(131,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionGetSettingsAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(97,0): at System.Net.Test.Common.Http2LoopbackServer.EstablishConnectionAsync(SettingsEntry[] settingsEntries)\n        /_/src/Common/tests/System/Net/Http/Http2LoopbackServer.cs(148,0): at System.Net.Test.Common.Http2LoopbackServer.HandleRequestAsync(HttpStatusCode statusCode, IList`1 headers, String content)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.Headers.cs(186,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest_Headers.<>c__DisplayClass8_0.<<SendAsync_Expires_Success>b__1>d.MoveNext()\n        ----- Inner Stack Trace -----\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(404,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(443,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__70_1(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(546,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Http2.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(address: ::1, useSsl: True) [FAIL]\n      System.IO.IOException : Unable to read data from the transport connection: An established connection was aborted by the software in your host machine..\n      ---- System.Net.Sockets.SocketException : An established connection was aborted by the software in your host machine.\n      Stack Trace:\n        /_/src/System.Net.Security/src/System/Net/FixedSizeReader.cs(57,0): at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.Implementation.cs(404,0): at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(288,0): at System.Net.Security.SslStream.EndAuthenticateAsServer(IAsyncResult asyncResult)\n        /_/src/System.Net.Security/src/System/Net/Security/SslStream.cs(434,0): at System.Net.Security.SslStream.<>c.<AuthenticateAsServerAsync>b__69_2(IAsyncResult iar)\n        /_/src/System.Private.CoreLib/shared/System/Threading/Tasks/FutureFactory.cs(546,0): at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(154,0): at System.Net.Test.Common.LoopbackServer.AcceptConnectionAsync(Func`2 funcAsync)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(83,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Threading/Tasks/TaskTimeoutExtensions.cs(111,0): at System.Threading.Tasks.TaskTimeoutExtensions.WhenAllOrAnyFailed(Task[] tasks)\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(84,0): at System.Net.Test.Common.LoopbackServer.<>c__DisplayClass11_0.<<CreateClientAndServerAsync>b__0>d.MoveNext()\n        --- End of stack trace from previous location where exception was thrown ---\n        /_/src/Common/tests/System/Net/Http/LoopbackServer.cs(69,0): at System.Net.Test.Common.LoopbackServer.CreateServerAsync(Func`2 funcAsync, Options options)\n        /_/src/System.Net.Http/tests/FunctionalTests/HttpClientHandlerTest.cs(506,0): at System.Net.Http.Functional.Tests.HttpClientHandlerTest.GetAsync_SecureAndNonSecureIPBasedUri_CorrectlyFormatted(IPAddress address, Boolean useSsl)\n        --- End of stack trace from previous location where exception was thrown ---\n        ----- Inner Stack Trace -----\n        \n    System.Net.Http.Functional.Tests.SocketsHttpHandlerTest_HttpClientHandlerTest_Http2.Ctor_ExpectedDefaultPropertyValues_UapPlatform [SKIP]\n      Condition(s) not met: \"IsUap\"\n  Finished:    System.Net.Http.Functional.Tests\n=== TEST EXECUTION SUMMARY ===\n   System.Net.Http.Functional.Tests  Total: 2029, Errors: 0, Failed: 34, Skipped: 40, Time: 533.224s\n----- end Sun 09/01/2019  9:34:23.80 ----- exit code 1 ----------------------------------------------------------\n"], "labels": ["arch-arm64", "test bug", "area-System.Net.Http", "os-windows"]}
{"project": "telerik_kendo-ui-core", "title": "Adaptive rendering demo for the Grid is missing", "description": "\nNo description provided.\n ", "code": [], "labels": ["SEV: Medium", "Bug"]}
{"project": "NixOS_nixpkgs", "title": "matplotlib is missing GSettings", "description": "When opening the file picker of a matplotlib (gtk3 backend) window the process crashes with this error:\nGLib-GIO-ERROR **: No GSettings schemas are installed on the system\nI think it needs wrapGAppsHook but I'm not really sure how that works. <CODE> NixOS version: 17.09pre106117.c90998d5cf ", "code": ["$ nix-shell -p 'pythonPackages.matplotlib.override {enableGtk3=true;}' --run 'python -c \"import matplotlib.pyplot as plt; plt.plot([1,2,3],[4,5,6]); plt.show()\"'\n"], "labels": ["6.topic: python"]}
{"project": "tridactyl_tridactyl", "title": "Shouldn't ;t be bound to `hint -W tabopen`?", "description": "It'd make sense since we have ;o ;O ;T. Was it just an oversight? ", "code": [], "labels": ["enhancement"]}
{"project": "andresriancho_w3af", "title": "w3af hangs when performing full_audit", "description": "W3af starts scanning in full_audit mode, but the scan never ended even after 24 hrs and it gets hung at the same step again and again and I can see the following when I Ctrl+C. Under log tab its stuck at this After that there are no logs Kali Linux, using w3af 1.6 downloaded from git repository The user provided the following email address for contact: legolas.aoe2@gmail.com <CODE> ", "code": ["  Python version: 2.7.3 (default, Jan  2 2013, 16:53:07) [GCC 4.7.2]\n  GTK version: 2.24.10\n  PyGTK version: 2.24.0\n  w3af version:\n    w3af - Web Application Attack and Audit Framework\n    Version: 1.6\n    Revision: 3ef1aa4e9e - 25 Sep 2013 13:10\n    Author: Andres Riancho and the w3af team.\n"], "labels": ["priority:medium", "bug"]}
{"project": "microsoft_vscode", "title": "python code hints won't show sometimes", "description": "Issue Type: Bug python 3.6\ncreate file below:\n-project\n---directory1\n------a1.py\n---directory2\n------a2.py\nwhere in a2.py ,write a function of a1,then run a2.py ,,,,it can run correctly\nbut!!!!\nint a2,i can never see the code hints of function a1,. otherwise, vscode have ofen lost code hints when i write python. In order to get code hints, I have to restart vscode, sometimes vscode can rework correctly.\nthat's why??? VS Code version: Code 1.28.1 (3368db6, 2018-10-11T18:13:53.910Z)\nOS version: Windows_NT x64 10.0.17134 ", "code": [], "labels": ["*caused-by-extension", "integrated-terminal"]}
{"project": "dotnet_roslyn", "title": "TypeLoadException is thrown when ref struct is used in let clause", "description": "Version Used:\nMicrosoft Visual Studio: Community 2019 Version 16.3.7\nMicrosoft .NET Core SDK 3.0.100(x64) from Visual Studio: version 3.0.100.014277 Steps to Reproduce: Expected Behavior:\nTo my knowledge, let clauses are converted to some classes and query expressions are converted to Enumerable method calls, which using generics. A ref struct must not be class member nor generic type argument, so I think a compile error should occur. Actual Behavior:\nThe code can be compiled.\nIf I execute the code, a TypeLoadException is thrown when calling Foo() method: <CODE> Note: If I create a project using .NET Framework, the exception is not thrown. ", "code": ["System.TypeLoadException: 'The generic type '<>f__AnonymousType0`2' was used with an invalid instantiation in assembly 'DotNetCoreConsoleProject, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null'.'\n"], "labels": ["Bug", "Area-Compilers"]}
{"project": "spree_spree", "title": "When adding a new non admin user as an admin receives NoMethodError Ruby 2.1.0 rails 4.0.3", "description": "<CODE> Request Parameters: {\"utf8\"=>\"\u2713\",\n\"authenticity_token\"=>\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~=\",\n\"user\"=>{\"email\"=>\"sample@sample.com\",\n\"spree_role_ids\"=>[\"\"],\n\"password\"=>\"[FILTERED]\",\n\"password_confirmation\"=>\"[FILTERED]\"},\n\"button\"=>\"\"} <CODE> ", "code": ["Showing /Users/~~~~~~~~~/.rvm/gems/ruby-2.1.0/bundler/gems/spree-10ad76cf7cfc/backend/app/views/spree/admin/shared/_address_form.html.erb where line #52 raised:\n\nundefined method `states' for nil:NilClass\nExtracted source (around line #52):\n49\n50\n51\n52\n53\n54\n55\n\n       <%= f.label :state_id, Spree.t(:state) %>\n       <span id=\"<%= s_or_b %>state\">\n         <%= f.text_field :state_name,\n               :style => \"display: #{f.object.country.states.empty? ? 'block' : 'none' };\",\n              :disabled => !f.object.country.states.empty?, :class => 'fullwidth state_name' %>\n         <%= f.collection_select :state_id, f.object.country.states.sort, :id, :name, {:include_blank => true}, {:class => 'select2 fullwidth', :style => \"display: #{f.object.country.states.empty? ? 'none' : 'block' };\", :disabled => f.object.country.states.empty?} %>\n       </span>\n~~~~~~~~~~~~~~~~~~~~FULL TRACE~~~~~~~~~~~~~~~~~~~~~~~\n/Users/~~~~~~~~~~/.rvm/gems/ruby-2.1.0/bundler/gems/spree-10ad76cf7cfc/backend/app/views/spree/admin/shared/_address_form.html.erb:52:in `_64ffc214eeeb6b4e22e8aed0619bfb2f'\nactionpack (4.0.3) lib/action_view/template.rb:143:in `block in render'\nactivesupport (4.0.3) lib/active_support/notifications.rb:161:in `instrument'\nactionpack (4.0.3) lib/action_view/template.rb:141:in `render'\ndeface (1.0.0) lib/deface/action_view_extensions.rb:41:in `render'\nactionpack (4.0.3) lib/action_view/renderer/partial_renderer.rb:306:in `render_partial'\nactionpack (4.0.3) lib/action_view/renderer/partial_renderer.rb:279:in `block in render'\nactionpack (4.0.3) lib/action_view/renderer/abstract_renderer.rb:38:in `block in instrument'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `block in instrument'\nactivesupport (4.0.3) lib/active_support/notifications/instrumenter.rb:20:in `instrument'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `instrument'\nactionpack (4.0.3) lib/action_view/renderer/abstract_renderer.rb:38:in `instrument'\nactionpack (4.0.3) lib/action_view/renderer/partial_renderer.rb:278:in `render'\nactionpack (4.0.3) lib/action_view/renderer/renderer.rb:47:in `render_partial'\nactionpack (4.0.3) lib/action_view/renderer/renderer.rb:21:in `render'\nactionpack (4.0.3) lib/action_view/helpers/rendering_helper.rb:24:in `render'\n/Users/~~~~~~~~~/.rvm/gems/ruby-2.1.0/bundler/gems/spree-10ad76cf7cfc/backend/app/views/spree/admin/users/_addresses_form.html.erb:6:in `block in _490edd1e1849ad91e0601ddc2551c33d'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:38:in `block in capture'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:200:in `with_output_buffer'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:38:in `capture'\nactionpack (4.0.3) lib/action_view/helpers/form_helper.rb:1864:in `block in fields_for_nested_model'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:38:in `block in capture'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:200:in `with_output_buffer'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:38:in `capture'\nactionpack (4.0.3) lib/action_view/helpers/form_helper.rb:699:in `fields_for'\nactionpack (4.0.3) lib/action_view/helpers/form_helper.rb:1863:in `fields_for_nested_model'\nactionpack (4.0.3) lib/action_view/helpers/form_helper.rb:1853:in `fields_for_with_nested_attributes'\nactionpack (4.0.3) lib/action_view/helpers/form_helper.rb:1521:in `fields_for'\n/Users/~~~~~~~/.rvm/gems/ruby-2.1.0/bundler/gems/spree-10ad76cf7cfc/backend/app/views/spree/admin/users/_addresses_form.html.erb:4:in `_490edd1e1849ad91e0601ddc2551c33d'\nactionpack (4.0.3) lib/action_view/template.rb:143:in `block in render'\nactivesupport (4.0.3) lib/active_support/notifications.rb:161:in `instrument'\nactionpack (4.0.3) lib/action_view/template.rb:141:in `render'\ndeface (1.0.0) lib/deface/action_view_extensions.rb:41:in `render'\nactionpack (4.0.3) lib/action_view/renderer/partial_renderer.rb:306:in `render_partial'\nactionpack (4.0.3) lib/action_view/renderer/partial_renderer.rb:279:in `block in render'\nactionpack (4.0.3) lib/action_view/renderer/abstract_renderer.rb:38:in `block in instrument'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `block in instrument'\nactivesupport (4.0.3) lib/active_support/notifications/instrumenter.rb:20:in `instrument'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `instrument'\nactionpack (4.0.3) lib/action_view/renderer/abstract_renderer.rb:38:in `instrument'\nactionpack (4.0.3) lib/action_view/renderer/partial_renderer.rb:278:in `render'\nactionpack (4.0.3) lib/action_view/renderer/renderer.rb:47:in `render_partial'\nactionpack (4.0.3) lib/action_view/renderer/renderer.rb:21:in `render'\nactionpack (4.0.3) lib/action_view/helpers/rendering_helper.rb:24:in `render'\n/Users/~~~~~~~/.rvm/gems/ruby-2.1.0/bundler/gems/spree-10ad76cf7cfc/backend/app/views/spree/admin/users/edit.html.erb:30:in `block in _d6b2ef252388d9856f1bc3d9eec9c795'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:38:in `block in capture'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:200:in `with_output_buffer'\nactionpack (4.0.3) lib/action_view/helpers/capture_helper.rb:38:in `capture'\nactionpack (4.0.3) lib/action_view/helpers/form_helper.rb:435:in `form_for'\n/Users/~~~~~~~~/.rvm/gems/ruby-2.1.0/bundler/gems/spree-10ad76cf7cfc/backend/app/views/spree/admin/users/edit.html.erb:29:in `_d6b2ef252388d9856f1bc3d9eec9c795'\nactionpack (4.0.3) lib/action_view/template.rb:143:in `block in render'\nactivesupport (4.0.3) lib/active_support/notifications.rb:161:in `instrument'\nactionpack (4.0.3) lib/action_view/template.rb:141:in `render'\ndeface (1.0.0) lib/deface/action_view_extensions.rb:41:in `render'\nactionpack (4.0.3) lib/action_view/renderer/template_renderer.rb:49:in `block (2 levels) in render_template'\nactionpack (4.0.3) lib/action_view/renderer/abstract_renderer.rb:38:in `block in instrument'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `block in instrument'\nactivesupport (4.0.3) lib/active_support/notifications/instrumenter.rb:20:in `instrument'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `instrument'\nactionpack (4.0.3) lib/action_view/renderer/abstract_renderer.rb:38:in `instrument'\nactionpack (4.0.3) lib/action_view/renderer/template_renderer.rb:48:in `block in render_template'\nactionpack (4.0.3) lib/action_view/renderer/template_renderer.rb:56:in `render_with_layout'\nactionpack (4.0.3) lib/action_view/renderer/template_renderer.rb:47:in `render_template'\nactionpack (4.0.3) lib/action_view/renderer/template_renderer.rb:17:in `render'\nactionpack (4.0.3) lib/action_view/renderer/renderer.rb:42:in `render_template'\nactionpack (4.0.3) lib/action_view/renderer/renderer.rb:23:in `render'\nactionpack (4.0.3) lib/abstract_controller/rendering.rb:127:in `_render_template'\nactionpack (4.0.3) lib/action_controller/metal/streaming.rb:219:in `_render_template'\nactionpack (4.0.3) lib/abstract_controller/rendering.rb:120:in `render_to_body'\nactionpack (4.0.3) lib/action_controller/metal/rendering.rb:33:in `render_to_body'\nactionpack (4.0.3) lib/action_controller/metal/renderers.rb:26:in `render_to_body'\nactionpack (4.0.3) lib/abstract_controller/rendering.rb:97:in `render'\nactionpack (4.0.3) lib/action_controller/metal/rendering.rb:16:in `render'\nactionpack (4.0.3) lib/action_controller/metal/instrumentation.rb:41:in `block (2 levels) in render'\nactivesupport (4.0.3) lib/active_support/core_ext/benchmark.rb:12:in `block in ms'\n/Users/~~~~~~~~/.rvm/rubies/ruby-2.1.0/lib/ruby/2.1.0/benchmark.rb:294:in `realtime'\nactivesupport (4.0.3) lib/active_support/core_ext/benchmark.rb:12:in `ms'\nactionpack (4.0.3) lib/action_controller/metal/instrumentation.rb:41:in `block in render'\nactionpack (4.0.3) lib/action_controller/metal/instrumentation.rb:84:in `cleanup_view_runtime'\nactiverecord (4.0.3) lib/active_record/railties/controller_runtime.rb:25:in `cleanup_view_runtime'\nactionpack (4.0.3) lib/action_controller/metal/instrumentation.rb:40:in `render'\n/Users/~~~~~~~~~/.rvm/gems/ruby-2.1.0/bundler/gems/spree-10ad76cf7cfc/backend/app/controllers/spree/admin/users_controller.rb:36:in `create'\nactionpack (4.0.3) lib/action_controller/metal/implicit_render.rb:4:in `send_action'\nactionpack (4.0.3) lib/abstract_controller/base.rb:189:in `process_action'\nactionpack (4.0.3) lib/action_controller/metal/rendering.rb:10:in `process_action'\nactionpack (4.0.3) lib/abstract_controller/callbacks.rb:18:in `block in process_action'\nactivesupport (4.0.3) lib/active_support/callbacks.rb:503:in `_run__2745871861293543575__process_action__callbacks'\nactivesupport (4.0.3) lib/active_support/callbacks.rb:80:in `run_callbacks'\nactionpack (4.0.3) lib/abstract_controller/callbacks.rb:17:in `process_action'\nactionpack (4.0.3) lib/action_controller/metal/rescue.rb:29:in `process_action'\nactionpack (4.0.3) lib/action_controller/metal/instrumentation.rb:31:in `block in process_action'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `block in instrument'\nactivesupport (4.0.3) lib/active_support/notifications/instrumenter.rb:20:in `instrument'\nactivesupport (4.0.3) lib/active_support/notifications.rb:159:in `instrument'\nactionpack (4.0.3) lib/action_controller/metal/instrumentation.rb:30:in `process_action'\nactionpack (4.0.3) lib/action_controller/metal/params_wrapper.rb:245:in `process_action'\nactiverecord (4.0.3) lib/active_record/railties/controller_runtime.rb:18:in `process_action'\nactionpack (4.0.3) lib/abstract_controller/base.rb:136:in `process'\nactionpack (4.0.3) lib/abstract_controller/rendering.rb:44:in `process'\nactionpack (4.0.3) lib/action_controller/metal.rb:195:in `dispatch'\nactionpack (4.0.3) lib/action_controller/metal/rack_delegation.rb:13:in `dispatch'\nactionpack (4.0.3) lib/action_controller/metal.rb:231:in `block in action'\nactionpack (4.0.3) lib/action_dispatch/routing/route_set.rb:80:in `call'\nactionpack (4.0.3) lib/action_dispatch/routing/route_set.rb:80:in `dispatch'\nactionpack (4.0.3) lib/action_dispatch/routing/route_set.rb:48:in `call'\nactionpack (4.0.3) lib/action_dispatch/journey/router.rb:71:in `block in call'\nactionpack (4.0.3) lib/action_dispatch/journey/router.rb:59:in `each'\nactionpack (4.0.3) lib/action_dispatch/journey/router.rb:59:in `call'\nactionpack (4.0.3) lib/action_dispatch/routing/route_set.rb:680:in `call'\nrailties (4.0.3) lib/rails/engine.rb:511:in `call'\nrailties (4.0.3) lib/rails/railtie/configurable.rb:30:in `method_missing'\nactionpack (4.0.3) lib/action_dispatch/journey/router.rb:71:in `block in call'\nactionpack (4.0.3) lib/action_dispatch/journey/router.rb:59:in `each'\nactionpack (4.0.3) lib/action_dispatch/journey/router.rb:59:in `call'\nactionpack (4.0.3) lib/action_dispatch/routing/route_set.rb:680:in `call'\nomniauth (1.2.1) lib/omniauth/strategy.rb:186:in `call!'\nomniauth (1.2.1) lib/omniauth/strategy.rb:164:in `call'\nomniauth (1.2.1) lib/omniauth/strategy.rb:186:in `call!'\nomniauth (1.2.1) lib/omniauth/strategy.rb:164:in `call'\nomniauth (1.2.1) lib/omniauth/strategy.rb:186:in `call!'\nomniauth (1.2.1) lib/omniauth/strategy.rb:164:in `call'\nomniauth (1.2.1) lib/omniauth/strategy.rb:186:in `call!'\nomniauth (1.2.1) lib/omniauth/strategy.rb:164:in `call'\nwarden (1.2.3) lib/warden/manager.rb:35:in `block in call'\nwarden (1.2.3) lib/warden/manager.rb:34:in `catch'\nwarden (1.2.3) lib/warden/manager.rb:34:in `call'\nrack (1.5.2) lib/rack/etag.rb:23:in `call'\nrack (1.5.2) lib/rack/conditionalget.rb:35:in `call'\nrack (1.5.2) lib/rack/head.rb:11:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/params_parser.rb:27:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/flash.rb:241:in `call'\nrack (1.5.2) lib/rack/session/abstract/id.rb:225:in `context'\nrack (1.5.2) lib/rack/session/abstract/id.rb:220:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/cookies.rb:486:in `call'\nactiverecord (4.0.3) lib/active_record/query_cache.rb:36:in `call'\nactiverecord (4.0.3) lib/active_record/connection_adapters/abstract/connection_pool.rb:626:in `call'\nactiverecord (4.0.3) lib/active_record/migration.rb:369:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/callbacks.rb:29:in `block in call'\nactivesupport (4.0.3) lib/active_support/callbacks.rb:373:in `_run__377794640518503381__call__callbacks'\nactivesupport (4.0.3) lib/active_support/callbacks.rb:80:in `run_callbacks'\nactionpack (4.0.3) lib/action_dispatch/middleware/callbacks.rb:27:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/reloader.rb:64:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/remote_ip.rb:76:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/debug_exceptions.rb:17:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/show_exceptions.rb:30:in `call'\nrailties (4.0.3) lib/rails/rack/logger.rb:38:in `call_app'\nrailties (4.0.3) lib/rails/rack/logger.rb:20:in `block in call'\nactivesupport (4.0.3) lib/active_support/tagged_logging.rb:67:in `block in tagged'\nactivesupport (4.0.3) lib/active_support/tagged_logging.rb:25:in `tagged'\nactivesupport (4.0.3) lib/active_support/tagged_logging.rb:67:in `tagged'\nrailties (4.0.3) lib/rails/rack/logger.rb:20:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/request_id.rb:21:in `call'\nrack (1.5.2) lib/rack/methodoverride.rb:21:in `call'\nrack (1.5.2) lib/rack/runtime.rb:17:in `call'\nactivesupport (4.0.3) lib/active_support/cache/strategy/local_cache.rb:83:in `call'\nrack (1.5.2) lib/rack/lock.rb:17:in `call'\nactionpack (4.0.3) lib/action_dispatch/middleware/static.rb:64:in `call'\nrack (1.5.2) lib/rack/sendfile.rb:112:in `call'\nrailties (4.0.3) lib/rails/engine.rb:511:in `call'\nrailties (4.0.3) lib/rails/application.rb:97:in `call'\nrack (1.5.2) lib/rack/lock.rb:17:in `call'\nrack (1.5.2) lib/rack/content_length.rb:14:in `call'\nrack (1.5.2) lib/rack/handler/webrick.rb:60:in `service'\n/Users/~~~~~~~~~/.rvm/rubies/ruby-2.1.0/lib/ruby/2.1.0/webrick/httpserver.rb:138:in `service'\n/Users/~~~~~~~~~/.rvm/rubies/ruby-2.1.0/lib/ruby/2.1.0/webrick/httpserver.rb:94:in `run'\n/Users/~~~~~~~~~/.rvm/rubies/ruby-2.1.0/lib/ruby/2.1.0/webrick/server.rb:295:in `block in start_thread'\n\n", ""], "labels": ["worksforme"]}
{"project": "telegramdesktop_tdesktop", "title": "Written accent randomly can't be written in Telegram Desktop (@Ubuntu)", "description": "Pressing written accent + a vowel should write on chat \u00e1, \u00e9, \u00ed, \u00f3, \u00fa Instead, I get a, e, i, o, u without the written accent Operating system: Ubuntu 14.04 trusty Version of Telegram Desktop: 1.1.23 Used theme: Vanilla (Night mode) A common solution is installing dbus and setting is as the input mode on Ubuntu settings, but it doesn't fix the problem for me. ", "code": [], "labels": ["duplicate"]}
{"project": "grpc_grpc", "title": "gRPC install does not work with python-dbg", "description": "Environments: Ubuntu 14 LTS, Debian Jessie Installation of python2.7-dbg and grpc works, but fails when trying to run the hello world server example. <CODE> Expected: I am able to run the server Actual:\nError: <CODE> ", "code": ["apt-get install python 2.7-dbg\npython2.7-dbg -m virtualenv grpcdbgenv\ncd grpcdbgenv\nsource bin/activate\npip install grpcio\ngit clone https://github.com/grpc/grpc\ncd grpc/src/examples/python/helloworld\npython greeter_server.py\n", "$ python greeter_server.py \nTraceback (most recent call last):\n  File \"greeter_server.py\", line 34, in <module>\n    import helloworld_pb2\n  File \"/usr/local/google/home/kailashs/foost/grpcioexp/grpc/examples/python/helloworld/helloworld_pb2.py\", line 109, in <module>\n    from grpc.beta import implementations as beta_implementations\n  File \"/usr/local/google/home/kailashs/foost/grpcioexp/local/lib/python2.7/site-packages/grpc/beta/implementations.py\", line 38, in <module>\n    from grpc._adapter import _intermediary_low\n  File \"/usr/local/google/home/kailashs/foost/grpcioexp/local/lib/python2.7/site-packages/grpc/_adapter/_intermediary_low.py\", line 57, in <module>\n    from grpc._adapter import _low\n  File \"/usr/local/google/home/kailashs/foost/grpcioexp/local/lib/python2.7/site-packages/grpc/_adapter/_low.py\", line 34, in <module>\n    from grpc._cython import cygrpc\nImportError: /usr/local/google/home/kailashs/foost/grpcioexp/local/lib/python2.7/site-packages/grpc/_cython/cygrpc.so: undefined symbol: Py_InitModule4_64\n"], "labels": ["lang/Python", "kind/bug", "priority/P2"]}
{"project": "influxdata_influxdb", "title": "firstTimestamp and lastTimestamp method, date difference", "description": "Proposal:\nProvide first_timestamp() and last_timestamp() which return the first and last timestamps matching the query (independent of group by time) and a date_difference(start_time, stop_time) method that simply returns the amount of time between two timestamps. This is different from elapsed() since it takes in timestamps and not fields. Current behavior:\nThere is not currently a way to query the length of time something has been present in InfluxDB. The first() and last() methods only return the first or last timestamp if the other is not present. Otherwise the timestamps align to epoch time. This makes it impossible to subtract this time. That is, select first(myField), last(myField) ...\nreturns the first and last values at epoch. Desired behavior:\nI'd like methods that allow me to directly query the first and last timestamp matching my criteria, not the first and last values, such that I can then use the first and last timestamps with something like the elapsed() function. I'd like these methods to work independently of group by time. Similarly, I'd like to be able to access the timestamps represented by a given time group, so that I can also use the intervals represented by time groups in queries. See below example for clarification. Alternatives considered:\nDescribe other solutions or features you considered. Use case:\nWhy is this important (helps with prioritizing requests)? New / old: Imagine I'm logging wifi traffic and I'd like to know which devices are both currently present and new and which devices are both currently present and have already been seen on this network. The MAC address of each device is a tag in InfluxDB. I'd like to visualize a stacked chart whose total height is the number of devices connected to my network at a given time with a segment of the total height representing the number of new devices appearing for the first time in that time group. I would like to be able to write a query that returns the distinct count of new and old MAC addresses for every one hour interval, where an address is considered new if the first timestamp it appears is within that specific interval. For example, if I had the following raw data: I would like to be able to write a query that returns: This is useful any time we want to study churn. One can imagine the industrial applications with inventory :) ", "code": [], "labels": ["wontfix"]}
{"project": "qgis_QGIS", "title": "Hidden Group legend items still occupies space in the legend", "description": "Author Name: Alexandre Neto (@SrNetoChan)\nOriginal Redmine Issue: 11331\nAffected QGIS version: master\nRedmine category:map_composer/printing The current master made possible to show map canvas layer groups in the legend (nice!). But if you want to hide the group title it still occupies space in the legend. To remove that space one needs to remove the group item entirely, but if you want to keep it's layers you need to take them out of the group by drag and drop before removing the group layer, otherwise they all disappear. No sure if this is intended or not. This is quite boring to do if you have lots of layers grouped just for data organization only, and don't what to see the groups in the composer legend. Since this is a new feature and I have marked it as blocker. To replicate, just had some layers, create a group from some of them and put it in bellow the other not grouped layers. After that, create a legend in the composer and choose Hidden for the group item. See the attached images. ", "code": [], "labels": ["Print Layouts", "Bug"]}
{"project": "vnpy_vnpy", "title": "\u8dd1\u56de\u6d4b\u6b63\u5e38\u4f46\u5728\u5b9e\u76d8\u4e2d\u5e73\u4ed3\u6307\u4ee4\u53d8\u6210\u4e86\u5f00\u4ed3\u6307\u4ee4", "description": "\u4e09\u9009\u4e00\uff1aBug \u7b56\u7565\u8bbe\u7f6e\u56fa\u5b9a\u6301\u4ed31\u5206\u949f\u540e\u5e73\u4ed3\uff0c\u56de\u6d4b\u6210\u4ea4\u660e\u7ec6\u6b63\u5e38\u3002\n \u4f46\u662f\u5b9e\u76d8\u4e2d\uff0c1\u5206\u949f\u540e\u53d1\u51fa\u7684\u5e76\u4e0d\u662f\u5e73\u4ed3\u6307\u4ee4\uff0c\u800c\u662f\u5f00\u4ed3\u6307\u4ee4\uff0c\u8fd9\u6837\u5c31\u591a\u4e86\u4e00\u4e2a\u53cd\u5411\u7684\u4ed3\u4f4d\u3002\u4e0d\u77e5\u9053\u95ee\u9898\u51fa\u5728\u54ea\u91cc\uff1f\n\n ", "code": [], "labels": ["help wanted"]}
{"project": "WallarooLabs_wallaroo", "title": "Test that new outgoing boundaries are NOT created every time a source reconnects", "description": "As discussed in <URL> and addressed in #1006, we need to test that when a source reconnects, it doesn't lead to new outgoing boundaries being created, in addition to the already existing ones connecting to the same sources. We can test this with unit tests by mocking the components involved. We can also test this with an instrumented test, by adding ifdef'd code to print out whenever new connections are formed (this might already be covered in ifdef \"trace\"), and look for these statements in the workers' STDOUT after causing multiple source connections. This can be done with the following steps: @nitbix can you provide some additional info on where the components involved with this bug are located? ", "code": [], "labels": ["priority: low", "test"]}
{"project": "golang_go", "title": "cmd/gc: incorrect error message", "description": "The following incorrect program <CODE> produces this error message when compiled <CODE> Which I believe is wrong, the final parameter does have a type, bool, what is lacks is a name. ", "code": ["package main\n\nfunc f(a, b string, bool) bool {\n        return true\n}\n\nfunc main() {\n        println(f(true))\n}\n", "lucky(~/src) % go build q.go                                                                                                                                    \n# command-line-arguments\n./q.go:3: final function parameter must have type\n"], "labels": ["FrozenDueToAge"]}
{"project": "suziwen_markdownxiaoshujiang", "title": "\u80fd\u5426\u5f00\u53d1\u4e2aonenote\u7684\u540c\u6b65\u63a5\u53e3\u5462\uff1f", "description": "\nNo description provided.\n ", "code": [], "labels": ["duplicate"]}
{"project": "goharbor_harbor", "title": "Confusing text in new project dialog", "description": "The label \"Public/Private\" not clear to me that the new project is \"public\" or not, when the check box is checked  ", "code": [], "labels": ["area/ui", "UX"]}
{"project": "redisson_redisson", "title": "Config can not handle underscore in host", "description": "Redisson 3.1.0   ", "code": [], "labels": ["bug"]}
{"project": "eclipsesource_tabris-js", "title": "Make preventDefault() work on Popovers too", "description": "When using preventDefault() on the apps backnavigation event the app wont close, but a Popover on it does.\nThe back key is intercepted in Activity.onKeyDown but since the Popover is a special window not tied to the activity it might require special care. backnavigation.preventDefault() should work on non activity windows as well. ", "code": [], "labels": ["bug", "android"]}
{"project": "akka_akka", "title": "Typed StashBuffer, allign with other factory methods on Behaviors?", "description": "We have Behaviors.withTimer, Behaviors.setup etc where as stash buffers are instantiated independently and the ActorContext passed into unstash. The stash buffer isn't thread sage and isn't meant to be shared across different ActorContexts so passing it in multiple times is misleading. A few alternative options: ", "code": [], "labels": ["t:typed", "1 - triaged"]}
{"project": "IdentityServer_IdentityServer4", "title": "custom claim that added in `IExtensionGrantValidator`   don't included in the access_token", "description": "openid do appare in response\nbut wechatminiapp-openid not included in the access_token ", "code": [], "labels": ["question"]}
{"project": "urho3d_Urho3D", "title": "ParticleEffect has no clone method", "description": "Material has cloneMaterial method, but ParticleEffect has no such method. ", "code": [], "labels": ["enhancement"]}
{"project": "dart-lang_sdk", "title": "Stack trace say \"package:compiler/src/resolution/members.dart\", not the actual file name", "description": "I'm finding it hard to debug errors as the VM no longer prints the file name but the package URI. ", "code": [], "labels": ["closed-as-intended", "Type-Defect", "area-vm"]}
{"project": "flutter_flutter", "title": "Calling reset() on a form doesn't reset text field contents", "description": "Calling reset() on a form containing text fields will reset the data associated with each field to the initial value, but not the visible contents of the text field. Expected: the field contents are all reset to the empty string.\nActual: the field contents remain unchanged on screen. Note: Instrumenting reset() on the form field shows that it's called at that the _value field is reset to the initial value. <CODE> ", "code": ["[\u2713] Flutter (on Mac OS X 10.12.6 16G29, locale en-AU, channel master)\n    \u2022 Flutter at /Users/cbracken/src/flutter/flutter\n    \u2022 Framework revision 1e0b1f11c8 (2 hours ago), 2017-08-21 13:41:54 -0700\n    \u2022 Engine revision 600567ef15\n    \u2022 Tools Dart version 1.25.0-dev.11.0\n"], "labels": ["framework"]}
{"project": "elastic_elasticsearch", "title": "[CI] :qa:full-cluster-restart:v7.3.2#upgradedClusterTest Failed on Windows", "description": "The test goal failed with this error: <CODE> Not sure where this is coming from, but it seems first a cluster fails to form and then the cleanup fails because Gradle tries to delete files still in use by a running test cluster. Build Scan ", "code": ["\n* Where:\n--\nBuild file 'C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build.gradle' line: 63\n\u00a0\n* What went wrong:\nExecution failed for task ':qa:full-cluster-restart:v7.3.2#upgradedClusterTest'.\n> Unable to delete directory 'C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro'\nFailed to delete some children. This might happen because a process has files open or has its working directory set in the target directory.\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-cli-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-core-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-geo-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-launchers-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-plugin-classloader-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-secure-sm-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\elasticsearch-x-content-7.3.2-SNAPSHOT.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\HdrHistogram-2.1.9.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\hppc-0.8.1.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\jackson-core-2.8.11.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\jackson-dataformat-cbor-2.8.11.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\jackson-dataformat-smile-2.8.11.jar\n- C:\\Users\\jenkins\\workspace\\elastic+elasticsearch+master+multijob-windows-compatibility\\os\\windows-2016\\qa\\full-cluster-restart\\build\\testclusters\\v7.3.2-0\\distro\\lib\\jackson-dataformat-yaml-2.8.11.jar\n\n"], "labels": [":Core/Infra/Build", ">test-failure"]}
{"project": "joomla_joomla-cms", "title": "Better handle Joomal Upgrades when \"crazy\" webhosts restrict /logs folders (or others)", "description": "Certain web hosts (Famously 1&1) maintain their own folders within a customers webspace - for 1&1 the example is /logs which is owned by the root user and is unwritable by their paying customer. This causes issue when upgrading Joomla from within Joomla (e.g. 3.3.3 to 3.4.3) using the com_joomlaupdate and errors half way through the writing files directly with an unwritable with /logs/index.html These leaves the upgrade in a half completed state - after upgrading the version number - and so most Joomla admins just assume all is ok as Joomla is now reporting the new version number - but most of their site is still running old version code, left ignored, this can lead to issues in the future of their site. @nikosdion has already handled this in Akeeba Kickstart but this change has to be made to Joomla core also. Ideally the upgrade should continue and report at the end, any files/folders it was unable to overwrite/write to - with some helpful explanation that the upgrade failed in part due to these. At the moment the 1&1 /logs folder issue is the only one I can give you to explain this issue - but I know @nikosdion probably has other examples. Basically any non-writable file/folder in a webspace, that is also the name of a Joomla core file/folder will cause an upgrade to fail when using the internal core com_joomlaupdate Thanks to a paying myJoomla.com customer for bringing this to the forefront again today after they came across this issue and left their site half upgraded and half not, and for @nikosdion for agreeing to look at this once the issue was raised here. At the moment - upgrading Joomla from within Joomla - on any 1&1 hosting is impossible - making this quite an important fix for those customers. ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "gradle_gradle", "title": "codenarcMain and codenarcTest tasks fails in JAVA 9", "description": "Hi,\nI get bellow error. Please see git repository I am executing .gradlew codenarcMain or .gradlew codenarcTest with java 9 compiler. Execution failed for task ':codenarcMain'.\njava.lang.NoClassDefFoundError: Unable to load class groovy.xml.jaxb.JaxbGroovyMethods due to missing dependency javax/xml/bind/JAXBContext ", "code": [], "labels": ["from:contributor"]}
{"project": "ValveSoftware_steam-for-linux", "title": "Update screen really pisses me off", "description": "The steam's been on for 3 days on my computer, now I wanted to play something and had to plug a device and restart. The thing's loading every update it can find. Can't skip it. As the grand finale it messed up the update and doesn't start up anymore. steamui.so failed to load. + jammed and lost the keyboard. Had to reboot my machine. ", "code": [], "labels": ["reviewed"]}
{"project": "framework7io_framework7", "title": "[IOS] Not able to scroll the page when accordion is opened", "description": "This is a (multiple allowed): We used framework7 accordion component in our application with IOS theme. We should be able to scroll the page to view the accordion content, if the content is larger than the page height. We're not able to scroll the page when the accordion is opened and the accordion content stretches larger than the page height.[This happens only in IOS-Safari] ", "code": [], "labels": ["outdated"]}
{"project": "status-im_status-react", "title": "Disable all translations except English for Beta", "description": "As a user I want to have good user experience when using the app , so UI should not be glitched or overlapped while being not properly localized for my language Type: Bug Summary: Disable all translations except English for Beta so we have good user experience Status UI is English only Status UI is localized when system language is changed, but this needs to be redone . As result we have a lot of glitches and overlaps which is not nice ", "code": [], "labels": ["bug"]}
{"project": "yiisoft_yii", "title": "CListView require(): Filename cannot be empty", "description": "When _view.php is missing, i get not clean error message: require(): Filename cannot be empty ", "code": [], "labels": ["Won't Fix"]}
{"project": "ballerina-platform_ballerina-lang", "title": "Moving transport to jdk 9", "description": "Description:\nAt the moment it only supports JDK 8. ", "code": [], "labels": ["Area/StandardLibs"]}
{"project": "zephyrproject-rtos_zephyr", "title": "Coverity issue seen with CID: 178234", "description": "Static code scan issues seen in File: /subsys/net/lib/coap/coap.c\nCategory: Null pointer dereferences\nFunction: coap_packet_get_payload\nComponent: Networking\nPlease fix or provide comments to square it off in coverity in the link: <URL> ", "code": [], "labels": ["priority: medium", "bug", "area: Networking", "Coverity"]}
{"project": "containers_libpod", "title": "No documentation on system event type", "description": "Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line) /kind bug Description system event type is not documented in <URL> even though current podman sends these events through varlink API. Would it be also possible to explain when some events are delivered? (I am currently trying to find out when system event with status = refresh is sent. Output of podman version: <CODE> ", "code": ["Version:            1.5.1\nRemoteAPI Version:  1\nGo Version:         go1.12.7\nOS/Arch:            linux/amd64\n"], "labels": ["kind/bug"]}
{"project": "orientechnologies_orientdb", "title": "OObjectEntitySerializer fails identifying binary fields", "description": "OObjectEntitySerializer.getTypeByClass should return OType.BINARY either for byte[] or Byte[] fields, but both are identified as OType.EMBEDDEDLIST. The following unit test demonstrates the bug. <CODE> ", "code": ["public class OObjectEntitySerializerTest {\n\n    // Both test fail because\n    // (genericMultiValueType.isPrimitive() && Byte.class.isAssignableFrom(genericMultiValueType)\n    // can never be true\n\n    @Test\n    public void testGetTypeByClass_PrimitiveBytes() throws NoSuchFieldException, SecurityException {\n\n        // exercise\n        OType oType = OObjectEntitySerializer.getTypeByClass(FooEntity.class, \"primitiveBytes\",\n                FooEntity.class.getField(\"primitiveBytes\"));\n\n        // verify\n        Assert.assertEquals(OType.BINARY, oType);\n    }\n\n    @Test\n    public void testGetTypeByClass_WrappingBytes() throws NoSuchFieldException, SecurityException {\n\n        // exercise\n        OType oType = OObjectEntitySerializer.getTypeByClass(FooEntity.class, \"wrappingBytes\",\n                FooEntity.class.getField(\"wrappingBytes\"));\n\n        // verify\n        Assert.assertEquals(OType.BINARY, oType);\n    }\n\n    public static class FooEntity {\n        public byte[] primitiveBytes;\n        public Byte[] wrappingBytes;\n    }\n}\n"], "labels": ["bug"]}
{"project": "ansible_molecule", "title": "devel: consolidate linting into a single job (tox target)", "description": "At this moment in order to preform only linting a developer would have to run this command: <CODE> This is insanely long command and I really doubt anyone is actively using it. Also is takes a huge amount of disk space as it creates 4 different environments without any practical reasons, especially as it makes no sense to run linting with 3 different intepretes, using the latest supported version is more than enough. PS.  Please note that the alternative of using the oldest interpreter (py27) is not as good as the newest one because it is known that the parsing ability of the newer ones is greatlly improved. Also CI job should be updated to assure the same execution, matching local development usage. Proposed command <CODE> This approach is also future proof as we could add new linters or swap exiting ones without changing the user interface, the job would still have the same name regardless what internal tools are used at a moment. ", "code": ["tox -e py27-lint,py36-lint,py37-lint,format-check\n", "tox -e lint\n"], "labels": ["enhancement"]}
{"project": "CachetHQ_Cachet", "title": "Component order changes when status is changed either from dashboard or edit component tab", "description": "We are using Cachet 2.3. We have observed component order changes when status is changed from either from edit tab or dashboard. Order also changes on dashboard.\nThis is also happening on cachet demo site(2.4 I believe). Below are the screenshots.\nQA1 a new component added and that's how it looks before change for status on demo site and dashboard: \n After QA1 status been changed to Major outage, it comes on the top.\n\n is this behaviour is expected?\nI have also noticed this happens after assigning groups to component. And set no order, it gets 0th order as default, but order changes when it's status changes and comes on top of group on dashboard. I am not sure why does the order changes on changing status? ", "code": [], "labels": ["Bug"]}
{"project": "yarnpkg_yarn", "title": "yarn create fails when specifying a package version", "description": "Do you want to request a feature or report a bug?\nbug What is the current behavior?\nRunning:\nyarn create react-app@next --help\nfails with an error: <CODE> What is the expected behavior?\nshould run /usr/local/bin/create-react-app and not /usr/local/bin/create-react-app@next Please mention your node.js, yarn and operating system version.\nyarn 1.10.1, mac os Mojave, node v8.11.3 Note that with npx you need to supply the version using additional flag: <CODE> ", "code": ["success Installed \"create-react-app@2.0.5-next.c662dfb0\" with binaries:\n      - create-react-app\n/bin/sh: /usr/local/bin/create-react-app@next: No such file or directory\n", "npx create-react-app test-app-typescript --typescript --scripts-version=@next\n"], "labels": ["triaged"]}
{"project": "status-im_status-react", "title": "Faucet request error shown even URL is up and running", "description": "Type: Bug Summary: can't request ETH, faucet request error shown user can call /faucet command  Ropsten: <URL> <URL> ", "code": [], "labels": ["bug", "high-priority"]}
{"project": "twbs_bootstrap", "title": "Content being duplicated when html: true and content: function(){...} were set.", "description": "Hi, Hope this doesn't take you guys too much time to look into it. See here for a runnable example: <URL> Try clicking the button 'Open a popover' multiple times, the content of popover becomes more and more. Just would like to know if this is an intended behavior. Thank you very much. ", "code": [], "labels": ["js"]}
{"project": "spring-projects_spring-security", "title": "SEC-1744: JaasAuthenticationProvider should not include the authorities in the provided authentication request object", "description": "Backported #1980 ", "code": [], "labels": ["Closed", "type: backport", "type: jira", "type: bug"]}
{"project": "renpy_renpy", "title": "from __future__ import unicode_strings", "description": "This should probably be the default in a near-future version of Ren'Py, to ease the py3 transition. ", "code": [], "labels": ["enhancement"]}
{"project": "dotnet_aspnetcore", "title": "@onclick No Longer Functions After Upgrade", "description": "A clear and concise description of what the bug is.\nThe method is never called when using the @onclick attribute. Steps to reproduce the behavior: I expect my method to be called when a button with @onclick=\"methodName\" is pressed. If applicable, add screenshots to help explain your problem. Add any other context about the problem here.\nInclude the output of dotnet --info I first realized this on my custom Blazor Page Component, then went back and tested this on the default template Counter page -- error persists. ", "code": [], "labels": ["area-blazor", "Needs: Author Feedback"]}
{"project": "elementor_elementor", "title": "Feature request: allow the user to design the toggle icon", "description": "Add few more controls to design the toggle icon: Currently the toggle icon positioned before the title, allow the user to move to the other side. change icon colors and select custom icons. Current:\n New:\n ", "code": [], "labels": ["request/enhancement", "ui/ux"]}
{"project": "aws_aws-cli", "title": "Problem Downloading files from S3 Bucket", "description": "I am downloading files from S3 bucket with hierarchy of folder structure.\nBucketName -> A -> B\nand then one of the folder has space and single quote So it is somewhat like\nBucket/A/B/DEF KLM  N'Q I tried to use CLI\naws s3 sync path .\nit fails how should I download the data from S3 ? -pR ", "code": [], "labels": ["guidance", "closing-soon-if-no-response"]}
{"project": "hypothesis_h", "title": "Add `reindex` command to `./bin/hypothesis` (or similar)", "description": "These lines of Python do the trick (re: conversation on #1407): Having those as part of ./bin/hypothesis would put them somewhere devs can find easily and use as needed. ", "code": [], "labels": ["Enhancement"]}
{"project": "Templarian_MaterialDesign", "title": "Icon - Important email", "description": "important + email as email-important (important on lower-right-hand side) ", "code": [], "labels": ["Icon Request"]}
{"project": "fuse-box_fuse-box", "title": "ResourceCSSPlugin -> handle hashtags in urls", "description": "I am trying to include the semantic-ui-css file using the ResourceCSSPlugin, but I am getting this error:\n(node:45936) UnhandledPromiseRejectionWarning: Unhandled promise rejection (rejection id: 2): Error: ENOENT: no such file or directory, open '/myprojectpath/node_modules/semantic-ui-css/themes/default/assets/fonts/icons.svg#icons' The problem is that fusebox is not handling that hashtag at the end (#icons). ", "code": [], "labels": ["bug"]}
{"project": "formatjs_react-intl", "title": "how to do ? eg:placeholder", "description": "placeholder can not use FormattedMessage, how to do this? ", "code": [], "labels": ["support"]}
{"project": "mattermost_mattermost-server", "title": "[Help Wanted] Channel name can be only one character long but channel URL must be at least two characters", "description": "If you're interested please comment here and come join our \"Contributors\" community channel on our daily build server, where you can discuss questions with community members and the Mattermost core team. For technical advice or questions, please  join our \"Developers\" community channel. New contributors please see our Developer's Guide, specifically for machine setup and for developer workflow. Notes: Jira ticket Repro: Observed: Expected:  ", "code": [], "labels": ["Difficulty/1:Easy", "Tech/ReactJS"]}
{"project": "microsoft_azuredatastudio", "title": "FETCH_HEAD duplicates with built-in SqlOpsStudio git client when repo on OneDrive", "description": "The Git client used by SQL Ops Studio results in failed updates to the FETCH_HEAD file of a git repo on OneDrive.  OneDrive will then copy the FETCH_HEAD file as a new file over and over and over again because it will fail to merge the desired changes into the original FETCH_HEAD file.  Other git clients, like one built into Visual Studio and Visual Studio Code, don't exhibit the same behavior under the same conditions. Other git files in the .git folder don't exhibit this behavior, just FETCH_HEAD.   Steps to Reproduce: ", "code": [], "labels": ["Bug"]}
{"project": "lodash_lodash", "title": "https://lodash.com/docs/3.10.1 is missing", "description": "The 3.10.1 docs are currently 404 (edit: except where the current docs are visited and then 3.10.1 is navigated via dropdown) <URL> ", "code": [], "labels": ["duplicate"]}
{"project": "rook_rook", "title": "OSD pods went into crashloopbackoff when pvc are deleted", "description": "Is this a bug report or feature request? Observed behavior:\ndeleted all pvc, and osd pods went in crashloopbackoff Expected behavior:\nPVC should not get deleted rook should prevent deletion How to reproduce it (minimal and precise): oc create -f common.yaml\noc create -f operator-openshift.yaml\noc create -f cluster-on-pvc.yaml oc delete pvc --all ", "code": [], "labels": ["bug"]}
{"project": "OpenTTD_OpenTTD", "title": "crash related to groups and old save games", "description": "fonsinchen opened the ticket and wrote: Attachments Reported version: trunk\nOperating system: All ", "code": [], "labels": ["Core", "flyspray"]}
{"project": "rust-lang_rustfmt", "title": "Bad formatting sometimes in `use` imports", "description": "gets turned into which exceeds the line length (102 vs 100). This is one of those cases where something that's fine gets changed by rustfmt into something that rustfmt doesn't like. I think this is because it's not taking into account the }; in the calculation of line length. Indeed: is correctly formatted to ", "code": [], "labels": ["poor-formatting", "bug"]}
{"project": "jupyterlab_jupyterlab", "title": "Weird mardown code style in alpha3", "description": "0.35:  1.0 latest alpha  ", "code": [], "labels": ["good first issue", "status:resolved-locked", "tag:Design and UX"]}
{"project": "microsoft_vscode", "title": "No longer hitting breakpoints VSCode / Chrome debugging 1.25", "description": "Hi, Type: BUG I was using 1.23.1 and upgraded to 1.25 and the issue still persists.\nI have the famous: Breakpoint set but not yet bound.\nSolutions I have found (or better saying tricks) online do not work. ", "code": [], "labels": ["needs more info", "debug"]}
{"project": "flutter_flutter", "title": "Performance: ListView disposes and recreates the State & RenderObject of all children (identified by ValueKey) when the item order changes", "description": "This report is the result of intensive performance tests of a list that can be filtered and sorted in different ways. I noticed that rebuilding the list was extremely slow (in profile mode) when the children changed:  As a test, I created a ListView with 5 children, identified by ValueKeys (A to E), and a button to reverse the sort order of the list items. What I expected was that that State and RenderObjects would be kept. But instead, all RenderObjects were recreated and all State was lost, which is quite a blow on performance if it happens frequently. It seems like the items are only recycled if they are still at the exact same index as before: The strange thing is that when I replace the ListView with a Column, all items are recycled and state is kept when I change the order (or remove items). Is this the intended behavior? ", "code": [], "labels": ["severe: performance", "f: scrolling", "framework"]}
{"project": "matomo-org_matomo", "title": "Visitor log: usability problem after clicking \"next\"", "description": "In Visitor log you can scroll down and click \"next\"-Button to see the visits before (within selected period)\nAfter having done this you scroll up again to have a look the first visits of the selected period again.\n=> Then you noticed you can't.\nSo you have to scroll down again and click \"before\" there. Because the visitor log website is relatively long,\nit would be better\na) to have a \"next\" button at the bottom\nand have a \"before\" button at the top (please see attachment.), or\nb) don't make the before visits not disappear and every time you click next the site only gets longer (to show older visits) What do you think?  ", "code": [], "labels": ["c: Usability", "Enhancement"]}
{"project": "QuantConnect_Lean", "title": "Security.ExecuteWithTimeLimit(): Algorithm took longer than 10 minutes on a single time loop.", "description": "Hi,\ni \"reopened\" issue #144 because think there is still a bug with: ExecuteWithTimeLimit.\nI tested it for the first time 2 days ago. My Algo is using 10 min bars (TradeBarConsolidator) only thats why i deleted OnData(TradeBars data) method. I ran it in debug mode with interactive brokers live account.\nlog.txt As you can see in the log:\n2016-10-19T11:45:00.0280069Z TRACE:: BrokerageTransactionHandler.PerformCashSync(): Sync cash balance\n2016-10-19T11:45:05.0005887Z TRACE:: InteractiveBrokersBrokerage.HandleError(): Order: -1 ErrorCode: 2119 - Market data farm is connecting:cashfarm 10 Minutes later:\n2016-10-19T11:55:00.8176609Z ERROR:: Engine.Run(): Breaking out of parent try catch: System.Exception: Algorithm took longer than 10 minutes on a single time loop. Maybe someone can help me.\nthx ", "code": [], "labels": ["bug"]}
{"project": "aspnet_AspNetCore.Docs", "title": "Fix the font sizes", "description": "The font sizes are too small, which makes the docs hard to read. The fonts for the API docs are even smaller. ", "code": [], "labels": ["P1", "3 - Done"]}
{"project": "golang_go", "title": "reflect.StructOf: Exported methods are generated for embedded fields", "description": "Please answer these questions before submitting your issue. Thanks! <CODE> <CODE> The documentation for reflect.StructOf states, So the expectation is that if I generate a struct using StructOf that embeds\n*bytes.Buffer, it does not implement io.Writer. <URL> demonstrates that this is not true: the\ngenerated struct claims to implement io.Writer, can be casted to it, and a\nWrite call on that io.Writer gets delegated to the right *bytes.Buffer. <CODE> <CODE> See also #20633 for inconsistent behavior when the method is unexported. ", "code": ["$ go version\ngo version go1.8.3 darwin/amd64\n", "$ go env\nGOARCH=\"amd64\"\nGOBIN=\"\"\nGOEXE=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"darwin\"\nGOOS=\"darwin\"\nGOPATH=\"/Users/abg/dev/go\"\nGORACE=\"\"\nGOROOT=\"/usr/local/Cellar/go/1.8.3/libexec\"\nGOTOOLDIR=\"/usr/local/Cellar/go/1.8.3/libexec/pkg/tool/darwin_amd64\"\nGCCGO=\"gccgo\"\nCC=\"clang\"\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/8z/qdzjsr3n5l72vdg67zr6xkjc0000gn/T/go-build554429180=/tmp/go-build -gno-record-gcc-switches -fno-common\"\nCXX=\"clang++\"\nCGO_ENABLED=\"1\"\nPKG_CONFIG=\"pkg-config\"\nCGO_CFLAGS=\"-g -O2\"\nCGO_CPPFLAGS=\"\"\nCGO_CXXFLAGS=\"-g -O2\"\nCGO_FFLAGS=\"-g -O2\"\nCGO_LDFLAGS=\"-g -O2\"\n", "Implements io.Writer: false\nCan cast to io.Writer: false\n", "Implements io.Writer: true\nCan cast to io.Writer: true\nWrote: hello\n"], "labels": ["FrozenDueToAge"]}
{"project": "Varying-Vagrant-Vagrants_VVV", "title": "VVV Base box", "description": "Today I have     default: Provisioning complete in 593 seconds\nAnd it make me sad. What do you think to make a vvv base box with preinstalled software and store in vagrant cloud?\nAt my work i have make multiple layers boxes to support different environments <CODE> base is just clean OS + shared provision scripts\ndepartment box contains engine dependencies\nengine box contains particular engine version This structure is flexible and supportable and more important - developers don't need to wait more time to setup dependencies. What do you think about it ? ", "code": ["base->department A->engine A\n    ->department B->engine B\n"], "labels": ["question"]}
{"project": "playframework_playframework", "title": "playGenerateSecret Shows No Output if logLevel := Level.Warn", "description": "The playGenerateSecret output should not be sent to a logger. Instead, playGenerateSecret should send output to the default output mechanisms for SBT tasks. ", "code": [], "labels": ["good first issue", "hacktoberfest"]}
{"project": "sublimehq_Packages", "title": "[C] Go to definition to enum value?", "description": "<CODE> It seems 'Go to definition' is not working in this case in *.c *.h files. Any help? ", "code": ["enum {\n   VALUE_1 = 0,\n   VALUE_2,\n   VALUE_3\n}\n"], "labels": ["enhancement"]}
{"project": "hexchat_hexchat", "title": "Find bar crashes Hexchat", "description": "I am using Hexchat 2.10.2 from the Ubuntu 15.10 repositories. I tried to find a relevant issue from someone with a more recent build and found nothing. The find bar closes. Hexchat continues being an IRC client. Hexchat crashes a couple of seconds after clicking the button. The UI may or may not freeze up beforehand\u2014I think this depends on the amount of text the window the find bar is opened in contains. ", "code": [], "labels": ["duplicate"]}
{"project": "pqrs-org_Karabiner-Elements", "title": "Korean Hangul-to-Hanja Input (as before in pre-Sierra Karabiner)?", "description": "Hello All, and especially Fumihiko: Many thanks for the great work!!! Very much appreciated! I have a question regarding where to find Sierra documentation about the new key codes. The INPUT METHOD for Korean \"Hanja\" (Chinese characters ... what's \"Kanji\" in the Japanese context) does not work for several major programs such as Microsoft Word 2011 and 2016. In other programs, e.g. Apple's Pages or even Microsoft's Excel, it does work fine. The \"old\" Karabiner offered a nice workaround for that. I see Fumihiko's list here on the Github page:\n<URL>\nAnd then this one at the Apple Developer site (WITHOUT explanations of what these codes do -- or am I missing something?):\n<URL>\nFurthermore, I see the SAMPLE file \"japanese_pc_keyboard.json\" that comes with the Karabiner-Elements beta. If I am not mistaken (?) the Hangul-to-Hanja input file should look somewhat similar. Anyone can help locating the codes that relate to KOREAN input? Thank you so much!\nFrank ", "code": [], "labels": ["stale"]}
{"project": "eslint_eslint", "title": "Confusing error messages in generator-star", "description": "I started out trying to fix #1680, but I wasn't able to figure out what the expected behavior should be since the messages produced by generator-star are confusing, and the implementation seems incomplete. For example: Will fail with \"Expected a space before _.\", even though there is a space before the _. More specifically, both of the following (theoretically invalid) test cases fail with zero errors: This one passes: But this one fails with the message \"Expected a space before *.\", even though a space is present: It's hard to understand what exactly each mode is attempting to enforce when start and end only check spacing on one side of the *. In fact, the only mode that checks spacing on both sides is middle, and it's undocumented. I'd like to revamp this rule to check spacing on both sides and to report exactly the change necessary to fix the error. Then maybe it will be easier to figure out what should happen with #1680. What about changing the error messages to the following: Thoughts? ", "code": [], "labels": ["accepted", "bug", "rule", "archived due to age"]}
{"project": "kubernetes_kubernetes", "title": "Migrate ServiceAccountAdmissionController to token projection", "description": "This issue is mostly to gather my notes. We need to complete a set of tasks to phase out the old service account token secrets. We'll have to complete these tasks over the course of a multiple release timeline in order to comply with our deprecation policy. Breaking changes: Tasks: /sig auth @liggitt @smarterclayton ", "code": [], "labels": ["kind/feature", "lifecycle/rotten", "sig/auth"]}
{"project": "tarantool_tarantool", "title": "Provide Lua bindings to internal logger (1.5)", "description": "For now there is a logging module, that use print for writing into logs.\nSo, even the critical message would not appear in logs, if log_level is lower, than required for print to work (info).\nI need a lua method for writing messages in logs ", "code": [], "labels": ["feature"]}
{"project": "spyder-ide_spyder", "title": "Shortcut to switch between screens in split-screen mode", "description": "I cannot find a keyboard shortcut that will allow me to switch between screens of code in split-screen mode. So if I am in split-screen horizontal mode and I see file1.py on the left and file2.py on the right, I would like to have a keyboard shortcut to switch focus between file1 to be able to edit file2 without using the mouse. Is this possible?? ", "code": [], "labels": ["type:Enhancement", "component:Editor"]}
{"project": "angular_angular", "title": "Error: No XHR implementation has been provided.", "description": "I'm submitting a ...  (check one with \"x\") <CODE> Current behaviour\nWhen the compiler receives a Module or component with templateUrl throws the next error:\nError: No XHR implementation has been provided. No error is thrown if we use template in the @Component decorator Expected/desired behaviuor\nThe compiler should be able to compile templateUrl properly. Reproduction of the problem\nYou can see this behaviour in this plunkr: <URL> What is the expected behaviour?\nThe compiler should be able to compile templateUrl properly. What is the motivation / use case for changing the behavior?\nTo load components dynamically in our apps Please tell us about your environment: node version: 4.1.1\ntypescript version: 1.8.10 ", "code": ["[x] bug report => search github for a similar issue or PR before submitting\n[ ] feature request\n[ ] support request => Please do not submit support request here, instead see https://github.com/angular/angular/blob/master/CONTRIBUTING.md#question\n"], "labels": ["comp: core"]}
{"project": "sitespeedio_sitespeed.io", "title": "Using sitespeed.io from Selenium Java tests????????", "description": "Hello, I have been talking with @soulgalore and he advised me to raise an issue here. We are running fully headed browsers using Java and Selenium 3.0.1. I presume we are interested in sending each page that loads to analysis (or a sample of which). PageXray converts a HAR file to a usable JSON structure that tells you more about your page. Is there a way form me to send the JSON files converted from HAR and other information to a DB/SiteSpeed.io from the browsers running the tests? Our load generators run currently on AWS and we can install any other server and networking required. The idea would be as our Selenium scripts run we send the perf data to other servers I presume Graphite for now and then be able to look at them using Garafana. So can you please help us get this going? And finally sitespeed.io is the main tool that uses all the previously mentioned tools and add supports for testing multiple pages as well as adds the ability to report the metrics to a TSDB (currently Graphite and soon also InfluxDB). Thank you,\nAli ", "code": [], "labels": ["question"]}
{"project": "qgis_QGIS", "title": "Nachinstallationsskriptfehler", "description": "Author Name: Sven Wehke (Sven Wehke)\nOriginal Redmine Issue: 19547\nAffected QGIS version: 3.2.1\nRedmine category:build/install Folgende Fehlermeldung nach dem Versuch, qgis 3.2.1 \u00fcber OSGeo4W zu installieren: Package: qgis\nqgis.bat exit code 255\nPackage: Unknown package\nqgis-common.bat exit code 255\nqgis-grass-plugin7.bat exit code 255 Related issue(s): #27378 (duplicates)\nRedmine related issue(s): 19551 ", "code": [], "labels": ["Build/Install", "Bug"]}
{"project": "facebook_hhvm", "title": "Issues compiling/installing on OS X 10.9 - 10/02/2014", "description": "Using the brew method: <CODE> Using the manual method: <CODE> ", "code": ["brew install hhvm --HEAD\nError: No available formula for ncurses \nSearching taps...\n", "/usr/local/Cellar/libarchive/3.1.2: 51 files, 3.0M, built in 57 seconds\n==> Installing libdwarf\n==> Downloading http://sourceforge.net/projects/elftoolchain/files/Sources/elftoolchain-0.6.1/elftoolchain-0.6.1.tgz\n\npatching file common/_elftc.h\npatching file ar/write.c\npatching file elfcopy/archive.c\npatching file libelf/_libelf_config.h\npatching file mk/elftoolchain.inc.mk\npatching file mk/elftoolchain.subdir.mk\npatching file mk/elftoolchain.prog.mk\npatching file mk/elftoolchain.lib.mk\n==> bsdmake libdwarf\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n*** Error code 1\n1 error\n*** Error code 2\n1 error\n"], "labels": ["build"]}
{"project": "ElemeFE_element", "title": "timerangepicker\u5947\u602a\u7684\u8868\u73b0", "description": "<URL> \u4efb\u610f\u65f6\u95f4\u8303\u56f4\u90a3\u91cc step 6\u548cstep2\uff0c4 \u7ed3\u679c\u4e00\u81f4 step6\u4e0e2\uff0c4\u4e0d\u4e00\u81f4 ", "code": [], "labels": ["type: bug"]}
{"project": "nopSolutions_nopCommerce", "title": "Add an opportunity to using custom attributes in nop tag helpers", "description": "For example in 3.x versions we can use\n@Html.TextBoxFor(model => model.ExpireMonth, new { style = \"Width: 30px;\", autocomplete = \"off\", maxlength = 2, required = \"required\", @type = \"number\", @pattern = \"\\\\d*\", min = 1, max = 12 }) Source: <URL> ", "code": [], "labels": ["functionality / feature"]}
{"project": "video-dev_hls.js", "title": "Green artifacts when using hls.js on latest Chrome Mac OS X", "description": "Go into sample page for hls.js <URL> with latest Chrome on latest Mac OS X. Load the above HLS feed.\nSee the green artifacts in the upper part of the video.\n It should not be green. VLC plays this HLS feed without issue. JW player also does play this HLS stream without issue on the same browser/OS (<URL> Green artifacts. I undertsand those are likely decoding artifacts provided by the OS or the browser. Actually this stream plays fine in Windows 10 latest Chrome or Canary. But I wonder why other player can play it without issue while hls.js fails. Is there a setting that can help fix this issue? Is there something to investiagte further? <CODE> ", "code": ["rmp.min.js:10 RMP: cssReady\nrmp.min.js:10 RMP: player DOM and CSS ready\nrmp.min.js:11 RMP: resize - new dimension: 640x360\nrmp.min.js:10 RMP: player ready in 64 ms\nrmp.min.js:8 RMP-cast: initializeCastApi\nrmp.min.js:8 RMP-cast: init success\nrmp.min.js:8 unavailable\nrmp.min.js:10 RMP: click event on container\nrmp.min.js:10 RMP: HTML5 playback requested\nrmp.min.js:12 RMP: HLSJS create hls.js instance\nrmp-hls.debug.js:8788[log] > attachMedia\nrmp.min.js:12 RMP: HLSJS loading source manifest now\nrmp-hls.debug.js:8788[log] > loadSource:https://playback.drntruhs.in:8443/vod/_definst_/mp4:NTR36271d/permanent/playback/2/dlink-20160908205503.mp4/playlist.m3u8\nrmp-hls.debug.js:8788[log] > trigger BUFFER_RESET\nrmp.min.js:10 RMP: HTML5 loadstart event\nrmp-hls.debug.js:8788[log] > media source opened\nrmp-hls.debug.js:8788 [log] > manifest loaded,1 level(s) found, first bitrate:2028411\nrmp-hls.debug.js:8788 [log] > startLoad\nrmp-hls.debug.js:8788 [log] > demuxing in webworker\nrmp-hls.debug.js:8788 [log] > switching to level 0\nrmp-hls.debug.js:8788 [log] > (re)loading playlist for level 0\nrmp.min.js:12 RMP: HLSJS manifest parsed\nrmp.min.js:12 RMP: abr hls.js ready\nrmp.min.js:10 RMP: HTML5 play event\nrmp.min.js:10 RMP: HTML5 waiting event\nrmp-hls.debug.js:8788 [log] > level 0 loaded [0,21],duration:216.176\nrmp-hls.debug.js:8788 [log] > Loading 0 of [0 ,21],level 0, currentTime:0,bufferEnd:0.000\nrmp.min.js:10 RMP: HTML5 stalled event\nrmp-hls.debug.js:8788 [log] > Loaded  0 of level 0\nrmp-hls.debug.js:8788 [log] > Demuxing 0 of [0 ,21],level 0, cc 0\nrmp-hls.debug.js:8788 [log] > creating sourceBuffer with mimeType:audio/mp4;codecs=mp4a.40.2\nrmp-hls.debug.js:8788 [log] > creating sourceBuffer with mimeType:video/mp4;codecs=avc1.42001f\nrmp-hls.debug.js:8788 [log] > track:audio,container:audio/mp4,codecs[level/parsed]=[mp4a.40.2/mp4a.40.5]\nrmp-hls.debug.js:8788 [log] > track:video,container:video/mp4,codecs[level/parsed]=[avc1.42001f/avc1.42c01f]\nrmp.min.js:10 RMP: HTML5 durationchange event - 216.175986\nrmp.min.js:10 RMP: HTML5 loadedmetadata event\nrmp-hls.debug.js:8788 [log] > parsed video,PTS:[0.000,9.999],DTS:[0.000/9.999],nb:305,dropped:0\nrmp-hls.debug.js:8788 [log] > parsed audio,PTS:[0.000,10.008],DTS:[0.000/10.008],nb:431,dropped:0\nrmp-hls.debug.js:8788 [log] > media buffered : [0,9.994754]\nrmp-hls.debug.js:8788 [log] > Loading 1 of [0 ,21],level 0, currentTime:10.007800453514703,bufferEnd:10.008\nrmp.min.js:10 RMP: HTML5 loadeddata event\nrmp.min.js:10 RMP: HTML5 canplay event\nrmp.min.js:10 RMP: HTML5 playing event\nrmp.min.js:10 RMP: HTML5 canplaythrough event\n8rmp.min.js:10 RMP: timeupdate\nrmp.min.js:10 RMP: HTML5 stalled event\n7rmp.min.js:10 RMP: timeupdate\nrmp-hls.debug.js:8788 [log] > Loaded  1 of level 0\nrmp-hls.debug.js:8788 [log] > Demuxing 1 of [0 ,21],level 0, cc 0\nrmp-hls.debug.js:8788 [log] > parsed video,PTS:[10.000,19.999],DTS:[9.999/19.999],nb:304,dropped:0\nrmp-hls.debug.js:8788 [log] > parsed audio,PTS:[10.008,20.016],DTS:[10.008/20.016],nb:431,dropped:0\nrmp-hls.debug.js:8788 [log] > media buffered : [0,19.994621]\nrmp-hls.debug.js:8788 [log] > Loading 2 of [0 ,21],level 0, currentTime:5.800772,bufferEnd:19.995\n7rmp.min.js:10 RMP: timeupdate\nrmp.min.js:10 RMP: HTML5 stalled event\n3rmp.min.js:10 RMP: timeupdate\nrmp-hls.debug.js:8788 [log] > Loaded  2 of level 0\nrmp-hls.debug.js:8788 [log] > Demuxing 2 of [0 ,21],level 0, cc 0\nrmp-hls.debug.js:8788 [log] > parsed video,PTS:[20.000,29.999],DTS:[19.999/29.999],nb:305,dropped:0\nrmp-hls.debug.js:8788 [log] > parsed audio,PTS:[20.016,30.023],DTS:[20.016/30.023],nb:431,dropped:0\nrmp-hls.debug.js:8788 [log] > media buffered : [0,29.994665]\nrmp-hls.debug.js:8788 [log] > Loading 3 of [0 ,21],level 0, currentTime:10.410702,bufferEnd:29.995\n7rmp.min.js:10 RMP: timeupdate\nrmp.min.js:10 RMP: HTML5 stalled event\n5rmp.min.js:10 RMP: timeupdate\nrmp-hls.debug.js:8788 [log] > Loaded  3 of level 0\nrmp-hls.debug.js:8788 [log] > Demuxing 3 of [0 ,21],level 0, cc 0\nrmp-hls.debug.js:8788 [log] > parsed video,PTS:[30.000,39.999],DTS:[29.999/39.999],nb:302,dropped:0\nrmp-hls.debug.js:8788 [log] > parsed audio,PTS:[30.023,40.008],DTS:[30.023/40.008],nb:430,dropped:0\nrmp-hls.debug.js:8788 [log] > media buffered : [0,39.994532]\nrmp-hls.debug.js:8788 [log] > Loading 4 of [0 ,21],level 0, currentTime:15.292343,bufferEnd:39.995\n8rmp.min.js:10 RMP: timeupdate\nrmp.min.js:10 RMP: HTML5 stalled event\n3rmp.min.js:10 RMP: timeupdate\nrmp.min.js:10 RMP: HTML5 playback requested\nrmp.min.js:10 RMP: timeupdate\nrmp.min.js:10 RMP: HTML5 pause event\n"], "labels": ["Bug"]}
{"project": "Icinga_icinga2", "title": "[dev.icinga.com #5255] Speed up config compiler", "description": "This issue has been migrated from Redmine: <URL> Created by gbeutner on 2013-12-03 08:45:01 +00:00 Assignee: gbeutner\nStatus: Resolved  (closed on 2013-12-03 10:22:03 +00:00)\nTarget Version: 0.0.6\nLast Update: 2013-12-03 10:22:03 +00:00 (in Redmine) Changesets 2013-12-03 08:59:21 +00:00 by gbeutner 6625346 <CODE> ", "code": ["Speed up config compiler.\n\nFixes #5255\n"], "labels": ["enhancement", "area/configuration"]}
{"project": "opensourcepos_opensourcepos", "title": "Taking Issue on live server and localhost", "description": "Hello daN4cat ,jekkos\ndear sir , i m facing issue in takkings , on local server takings working fine.. but on live server no date found\n. what the problem can you please tell me.. Localhost  LiveServer\n see video\nvideo ", "code": [], "labels": ["pending"]}
{"project": "goharbor_harbor", "title": "How to filter projects by owner name\uff1f", "description": "<CODE> owner=ma_k filter seems not effective  for this api. Am I wrong? By the way, I wonder if there is an api which can get projects or repos by a username. Thanks a lot. ", "code": ["api/projects?is_public=0&owner=ma_k&page=1&page_size=10\n"], "labels": ["area/API"]}
{"project": "angular_angular", "title": "routerCanReuse not implemented in 3.0 router ??", "description": "I don't see routerCanReuse in 3.0 router.\nRouter.renavigate is also gone in 3.0. It used to be <URL> I didn't find corresponding code in router 3.0.\nWhat's your plan about this  CanReuse ? ", "code": [], "labels": ["type: feature", "freq2: medium", "comp: router"]}
{"project": "joomla_joomla-cms", "title": "Please improve the user component to put some restriction on the registration form", "description": "Register a new user account through Joomla core registration form (com_users). You can not use special character (like: empty space) in \"username\" field;\nYou can not input a \"Name\" longer than 20 (or 30) characters;\nYou can not use email address under certain domains (like: @mail.ru );\n... You can use neary ANY character in \"username\" and \"Name\" field;\nYou can input a \"Name\" longer than 60 characters!\nYou can use ANY email address!\n... The Joomla website Admin can NOT put any restriction on the registration form! Joomla 3.6.5\nPHP 7.0.15 Could you please improve the com_users component to allow more options/restrictions on the user registration process? Thank you. ", "code": [], "labels": ["No Code Attached Yet", "J3 Issue"]}
{"project": "vector-im_riot-web", "title": "Pasting a bullet list from Google Doc loses the bulleting", "description": "I had a long list of bullet points in a Google Doc and pasted it in the editor: all the hierarchy and bullets were lost and items were displayed on several lines. ", "code": [], "labels": ["bug", "defect"]}
{"project": "wordpress-mobile_WordPress-Android", "title": "Reader 3.3 Punch List", "description": "These are the tentative Reader-related features & fixes I'm aiming to have in the 3.3 release. Checkmarked items have been submitted as pull requests, strikethrough denotes those that have been merged. ", "code": [], "labels": ["reader"]}
{"project": "confluentinc_ksql", "title": "UDFs do not get passed their config", "description": "GIven a UDF 'bob' that implements Configurable, it should get passed any config prefixed with ksql.functions.bob. or ksql.functions._global_..  However, this is no longer the case. ", "code": [], "labels": ["bug"]}
{"project": "dart-lang_sdk", "title": "Analyzer does not warn if overridding or implementing member parameter types are invalid", "description": "I don't see any static warnings if I override or implement a method and my parameter list is incompatible with the types of the base parameters. For example: class Base {\n\u00a0\u00a0foo(int arg) {}\n} class Derived implements Base {\n\u00a0\u00a0foo(String arg) {}\n} class Derived2 extends Base {\n\u00a0\u00a0foo(String arg) {}\n} I would expect to see warnings in both derived classes but currently (Dart Editor version 0.5.3_r22223) I get none. ", "code": [], "labels": ["area-analyzer", "Type-Defect"]}
{"project": "apache_incubator-echarts", "title": "\u5173\u4e8e\u5750\u6807\u8f74\u4e0a\u523b\u5ea6\u503c\u7684\u663e\u793a", "description": "\u6700\u8fd1\u9700\u8981\u505a\u4e00\u4e2a\u56db\u8c61\u9650\u7684\u529f\u80fd\uff0c\u6211\u7528\u5b98\u65b9\u7684\u6c14\u6ce1\u56fedemo\u505a\u5b9e\u9a8c\uff0c\u53d1\u73b0\u5f53\u6709\u8d1f\u6570\u7684\u70b9\u65f6\uff0c\u51fa\u73b0\u4e86\u5176\u4ed6\u8c61\u9650\uff0c\u4f46\u662f\u523b\u5ea6\u503c\u4e0d\u5728x\u8f74\u548cy\u8f74\u4e0a\uff0c\u4e0d\u77e5\u9053\u6709\u4ec0\u4e48\u53c2\u6570\u53ef\u4ee5\u8bbe\u7f6e\uff0c\u5c06\u523b\u5ea6\u503c\u6807\u5728x\u8f74\u548cy\u8f74\u4e0a\uff1f \u8bf7\u53c2\u8003\u9644\u4ef6 \n#### \u7248\u672c\u53ca\u73af\u5883 (Version & Environment)  ", "code": [], "labels": ["stale"]}
{"project": "RPCS3_rpcs3", "title": "Feature : CUDA , OpenCL Compute", "description": "Because emulator is emulate Cell Processor and Cell Processor is different and special architecture ( 1 PPE + 8 SPE ) , and i think modern CPU Intel or AMD ( Kaby Lake , Ryzen ) , does not powerful to emulate heavy game . I think you should to using GPGPU to help and improve speed emulate about that . CUDA and OpenCL is capable about to emulate Cell processor because is using parallel thread ", "code": [], "labels": ["Question"]}
{"project": "appium_appium", "title": "Can't find running on windows directions in english anymore", "description": "<URL> is a broken link now, which is the link I used from this page : <URL> I can still find the chinese version : <URL> But sadly I cannot read chinese\n:/ ", "code": [], "labels": ["P0", "Documentation", "Bug"]}
{"project": "ethereum_mist", "title": "Sync Stuck", "description": "Okay, I'm new to all of this so probably in way over my head.  Syncing Ethereum wallet for the first time and it gets 100 blocks away and stops.  Then \"downloading chain structure\" just seems to go on forever.  Is this normal? <CODE> ", "code": ["Version: `0.9.1`\nOS & Version: osx\nNode version: `geth 1.7.1` \nNumber of blocks synchronized: 4,354,530\n"], "labels": ["Status: Triage"]}
{"project": "spring-projects_spring-boot", "title": "Request Header filtering in WebRequestTraceFilter not case insensitive", "description": "Http header field names are case insensitive and this line does not take that into account:  ", "code": [], "labels": ["priority: normal", "type: bug"]}
{"project": "firefox-devtools_debugger", "title": "Can't switch to original source file", "description": "This is clone from issue #6685 STR: Honza ", "code": [], "labels": [" bug"]}
{"project": "Vincit_objection.js", "title": "Exception getIdProperty ?", "description": "I'm using objection & MSSQL.\nMy model (ClassA) is something like this: <CODE> And for the objection query I defined my where clause in a var objectClassA. <CODE> But this throws a exception: \"TypeError: model.constructor.getIdProperty is not a function.\" ", "code": ["import { Model } from 'objection';\n\nexport class ClassA extends Model {\n\n\tpublic constructor(init?: Partial<ClassA>) {\n\t\tsuper();\n\t\tObject.assign(this, init);\n\t}\n\n\tstatic get tableName() {\n\t\treturn 'ClassA';\n\t}\n\n\tpublic Name? : string = undefined;\n}\n", "let objectClassA: ClassA = new ClassA({\n\tName: \"name\"\n});\n\nreturn await ClassA.query().where(objectClassA).first();\n"], "labels": ["bug"]}
{"project": "matomo-org_matomo", "title": "SitesManager overrides current site type and breaks down MetaSites plugin", "description": "Goal of this issue is to fix following bug: I think that type of site should be passed somehow to updateSite API method, or at least not modified if not provided. Alternatively metasites should be excluded from default websites management, as it's a bit confusing and leads to error described above. Please let me know if you need any more info about this issue? ", "code": [], "labels": ["duplicate", "Bug"]}
{"project": "parcel-bundler_parcel", "title": "Cannot set property 'fileName' of undefined", "description": "Cannot set property 'fileName' of undefined\nConsole logs: <CODE> 1559749197535.zip ", "code": ["Server running at http://localhost:37557 - configured port 1234 could not be used.\n\u2819 Building landing.html...addDependencyTo is deprecated in favor of\nresult.messages.dependency; posthtml-loader >= v1.0.1 will\nautomatically add your imported files to webpack's file watcher.\naddDependencyTo is deprecated in favor of\nresult.messages.dependency; posthtml-loader >= v1.0.1 will\nautomatically add your imported files to webpack's file watcher.\n\ud83d\udea8  /src/pages/landing.html: Cannot set property 'fileName' of undefined\n    at Pipeline.process (/node_modules/parcel-bundler/src/Pipeline.js:30:22)\naddDependencyTo is deprecated in favor of\nresult.messages.dependency; posthtml-loader >= v1.0.1 will\nautomatically add your imported files to webpack's file watcher.\naddDependencyTo is deprecated in favor of\nresult.messages.dependency; posthtml-loader >= v1.0.1 will\nautomatically add your imported files to webpack's file watcher.\n"], "labels": [" Bug"]}
{"project": "qbittorrent_qBittorrent", "title": "[feature request] delete individual files from qbittorrent", "description": "A common problem is that when watching a series of movies contained in a single torrent, the hard drive doesn't actually have room for them all. To make room, the previously-watched movies can be deleted, but that process is complicated: ~~0. Uncheck the files to be deleted so that qbittorrent doesn't try to download them again. Not only is this cumbersome, it also requires a recheck that is ultimately unnecessary. A better solution would be to right click on the files in qbittorrent and hit 'delete'. That would be far simpler and wouldn't require the extra recheck. The bug purpose changed. See the new one here ", "code": [], "labels": ["Feature request"]}
{"project": "SortableJS_Sortable", "title": "newIndex is undefined in onEnd handler when an item's position doesn't change", "description": "First off, thanks for writing this library! It's been super helpful and works flawlessly most of the time. JSBin: <URL>,js,console,output Steps to reproduce: Expected: newIndex is >= 0 Probable cause: this line checks if newIndex is null or -1, but, the very first time onEnd is called, newIndex hasn't been initialized and is still undefined. GIF, using the above JSBin:\n ", "code": [], "labels": ["bug"]}
{"project": "Chocobozzz_PeerTube", "title": "Invitation link to create an account", "description": "On instances with closed registration, the admin or some users granted that right, might want to invite friends to create an account. It could be interesting to keep track of who invited a user. It could also be interesting to let the user create an account, but make it go through a vetting process by other admins, or even a vote by users. ", "code": [], "labels": ["Type: Enhancement "]}
{"project": "restic_restic", "title": "large prune fails", "description": "restic 0.3.3 (v0.3.3-4-g9f1f174)\ncompiled with go1.7.4 on linux/amd64 I ran backups followed by restic forget for several months before noticing that it was eating a ton of diskspace. They I tried running restic prune to reclaim the space, but it failed The repository is on another machine as accessed via NFS.  This failure is running the prune over NFS. If I run it directly on the server it runs out of memory very quickly. (very whimpy machine) <CODE> Rerunning has the same failure. ", "code": ["$ restic prune\ncounting files in repo\nbuilding new index for repo\n[28:47] 100.00%  332112 / 332112 packs\nrepository contains 332112 packs (5251506 blobs) with 1.499 TiB bytes\nprocessed 13790865 blobs: 8539359 duplicate blobs, 891.007 GiB duplicate\nload all snapshots\nfind data that is still in use for 32 snapshots\n[1:11:45] 100.00%  32 / 32 snapshots\nfound 2704802 of 13790865 data blobs still in use, removing 11086063 blobs\nwill delete 51619 packs and rewrite 271265 packs, this frees 284.798 GiB\nheader is larger than file\nrestic/pack.readHeader\n        /tmp/restic-build-068254688/src/restic/pack/pack.go:201\nrestic/pack.List\n        /tmp/restic-build-068254688/src/restic/pack/pack.go:223\nrestic/repository.Repack\n        /tmp/restic-build-068254688/src/restic/repository/repack.go:38\nmain.runPrune\n        /tmp/restic-build-068254688/src/cmds/restic/cmd_prune.go:211\nmain.glob..func11\n        /tmp/restic-build-068254688/src/cmds/restic/cmd_prune.go:26\ngithub.com/spf13/cobra.(*Command).execute\n        /tmp/restic-build-068254688/src/github.com/spf13/cobra/command.go:599\ngithub.com/spf13/cobra.(*Command).ExecuteC\n        /tmp/restic-build-068254688/src/github.com/spf13/cobra/command.go:689\ngithub.com/spf13/cobra.(*Command).Execute\n        /tmp/restic-build-068254688/src/github.com/spf13/cobra/command.go:648\nmain.main\n        /tmp/restic-build-068254688/src/cmds/restic/main.go:40\nruntime.main\n        /usr/local/go/src/runtime/proc.go:183\nruntime.goexit\n        /usr/local/go/src/runtime/asm_amd64.s:2086\n"], "labels": ["need feedback", "bug"]}
{"project": "openshift_origin", "title": "Jenkins extended run is returning inconsistent \"skip\" results", "description": "The skip numbers are swinging wildly from build to build - could be the failure of a worker (if one worker hangs it may not flush or complete its junit.xml report) or could be another test stomping on it. ", "code": [], "labels": ["area/tests", "priority/P2"]}
{"project": "nopSolutions_nopCommerce", "title": "Admin area. Disable autocomplete", "description": "We should disable autocomplete for admin area forms: Source: <URL> Check whether we can use use the 'autocomplete' attribute on your form element - <URL> Maybe we should make in configurable (and enabled by default) ", "code": [], "labels": ["on hold / maybe wont"]}
{"project": "angular_angular", "title": "Support @page css rule into component styles", "description": "I'm submitting a ...  (check one with \"x\") <CODE> Current behavior\nWhen I use the @page css rule in my component style, it gets encapsulated but it shouldn't. For example the following css: is transformed into It works fine with @media rules: is transformed into: which works just as expected. Expected behavior\nThe @page css rule should have the same behavior as @media and shouldn't be encapsulated. What is the motivation / use case for changing the behavior?\nThe @page css rule doesn't work in component styles right now Please tell us about your environment: ", "code": ["[x] bug report\n"], "labels": ["comp: core"]}
{"project": "dart-lang_sdk", "title": "co19: Un-optimizable test 'check' function", "description": "This issue was originally filed by zundel@google.com co19/LibTest/core/Queue/Queue.from/Queue/Queue.from/A01/t01\nco19/LibTest/core/Queue/Queue.from/Queue/Queue.from/A01/t02 file:/home/zundel/dart/tests/co19/src/LibTest/core/Queue/Queue.from/Queue_Queue.from_A01_t02.dart/Queue_Queue.from_A01_t02.dart:48: List<<dynamic>> has no method named \"removeFirst\"\n\u00a0\u00a0\u00a0\u00a047:   c.forEach(void compare(var element) {\n\u00a0\u00a0\u00a0\u00a048:     Expect.isTrue(l.removeFirst() == element); void check(List l, Collection c) {\n\u00a0\u00a0Expect.isTrue(l.length == c.length);\n\u00a0\u00a0c.forEach(void compare(var element) {\n\u00a0\u00a0\u00a0\u00a0Expect.isTrue(l.removeFirst() == element);\n\u00a0\u00a0});\n} removeFirst() is not a method on List or its superclasses, hence the type error.  When optimized, the removeFirst() method from the Queue object might be pruned because there are no references in the program to Queue.removeFirst().  I don't think the test needs to be written this way, maybe just change check() to take a Queue instance for the first parameter, or do something other than removeFirst() to test the first element. @peter, do you think we need a label below to categorize tests in general, maybe co19 tests in particular? ", "code": [], "labels": ["closed-not-planned", "Type-Defect"]}
{"project": "gogs_gogs", "title": "SSH Key import fails on CentOS/RHEL 5", "description": "SSHKeyGenParsePublicKey fails with OpenSSH_4.3, shipped with CentOS 5. This is because as per the Windows check in the method, OpenSSH 4..3 also does not output the key type, therefore there are only 3 fields returned and the check fails. Therefore adding any key fails, making SSH useless. <CODE> ", "code": ["[user@host ~]$ ssh -V\nOpenSSH_4.3p2, OpenSSL 0.9.8e-fips-rhel5 01 Jul 2008\n[user@host ~]$ ssh-keygen -l -f /home/user/id_rsa.pub \n4096 04:87:56:4a:55:c6:97:a3:b7:98:92:96:be:ae:00:43 /home/user/id_rsa.pub\n"], "labels": ["kind/bug"]}
{"project": "checkstyle_checkstyle", "title": "Problem to open archive web ages starting from 8.21", "description": "<URL> is last archive site that is accessible all further releases (for example <URL> )\nresult in: <CODE> ", "code": ["An error has been encountered in accessing this page.\n\n1. Server: checkstyle.sourceforge.io\n2. URL path: /version/8.21/\n3. Error notes: Server unable to read htaccess file, denying access to be safe\n4. Error type: 403\n5. Request method: GET\n6. Request query string: NONE\n7. Time: 2019-11-17 16:04:52 UTC (1574006692) \n"], "labels": ["miscellaneous", "approved"]}
{"project": "ariya_phantomjs", "title": "Element is not currently visible and may not be manipulated exception", "description": "Simple code in selenium works in both Firefox driver and HtmlUnit driver but it\nfails with PhantomJs as it returns element not visible exception. Steps. ", "code": [], "labels": ["stale"]}
{"project": "nopSolutions_nopCommerce", "title": "Add FollowUsLinks Token to all message templates", "description": "Adding a FollowUsLinks token to message templates will allow stores to connect more with customers and provide an easy mechanism for adding social links to messages Source: <URL> ", "code": [], "labels": ["on hold / maybe wont"]}
{"project": "ctripcorp_apollo", "title": "\u6743\u9650\u7ba1\u7406\u9009\u62e9\u6307\u5b9a\u591a\u4e2a\u73af\u5883", "description": "\u5f53\u6709\u5f88\u591a\u73af\u5883\u65f6\uff0c \u7ba1\u7406\u4eba\u5458\u5206\u914d\u6743\u9650\u65f6\u53ef\u4ee5\u4e00\u6b21\u9009\u62e9\u591a\u4e2a\u6307\u5b9a\u7684\u73af\u5883\uff0c\u5426\u5219\u4e00\u4e2a\u4e00\u4e2a\u73af\u5883\u6dfb\u52a0\u6743\u9650\u592a\u9ebb\u70e6\uff0c\u6dfb\u52a0\u6743\u9650\u5230\u6240\u6709\u73af\u5883\u53c8\u592a\u8fc7\u5bbd\u677e\uff0c\u56e0\u6b64\u5e0c\u671b\u6388\u6743\u65f6\u53ef\u4ee5\u52fe\u9009\u6307\u5b9a\u7684\u73af\u5883\u3002 ", "code": [], "labels": ["feature request"]}
{"project": "mui-org_material-ui", "title": "theme spacing not working as expected for line-height", "description": "When using theme.spacing(X) for lineHeight css property, you only get the number but not the px unit. You should get assigned the correct value and unit to the lineHeight property as it works with other css properties like padding or height. <URL> Steps: ", "code": [], "labels": ["duplicate"]}
{"project": "OrchardCMS_Orchard", "title": "Error\t5\tAssembly 'Orchard.Framework, Version=1.8.1.0, Culture=neutral, PublicKeyToken=null' uses 'System.Web.Mvc, Version=5.1.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35' which has a higher version than referenced assembly 'System.Web.Mvc, Vers", "description": "Yadagirij created:\n<URL> Error   5   Assembly 'Orchard.Framework, Version=1.8.1.0, Culture=neutral, PublicKeyToken=null' uses 'System.Web.Mvc, Version=5.1.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35' which has a higher version than referenced assembly 'System.Web.Mvc, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35'    d:\\Orchard(23112014)\\src\\Orchard\\bin\\Debug\\Orchard.Framework.dll    Orchard.Specs I am getting the above issue please provide the solution for it. Thanks\nYadagiri ", "code": [], "labels": ["resolved"]}
{"project": "primefaces_primeng", "title": "Flipfit collision detection for ContextMenu", "description": "If contextMenu has not enough space in viewport to open, first flip the position then apply offset to make sure it fits in. ", "code": [], "labels": ["enhancement"]}
{"project": "envoyproxy_envoy", "title": "Maximum direct response body size", "description": "Description\nHello, can someone please explain why is the direct response body limited explicitly to 4096B? See <URL> I would like to be at least able to change this value. Thank you. ", "code": [], "labels": ["stale", "question"]}
{"project": "libvips_libvips", "title": "Reduced grayscale png file size is larger than original png", "description": "I am testing libvips' resize API and found out it's really convenient. Great job. But I found out when png is grayscale, that exported png file with smaller dimension is acutally larger than the original. When it is colorful, the reduced png size is proportional. Why is it? Is there anyway to tune the code so png file with smalled dimensions is always smaller in term of file size? Below is the code I used to resize then crop: <CODE> And to export to png: <CODE> Original png, width: 1024  Resized, width: 900  Thanks ", "code": ["in = in.resize(scale).smartcrop(w, h, VImage::option()->\n                                            set( \"interesting\", VIPS_INTERESTING_ATTENTION));\n\n", "                in.pngsave( (char*) output.c_str(), VImage::option()\n                            ->set(\"compression\", 9)\n                            ->set(\"strip\", true)\n                    );\n\n"], "labels": ["question"]}
{"project": "ccxt_ccxt", "title": "Enable NodeSecurity", "description": "<URL> provides security scans for node packages in package.json, would be nice to enable this check. ", "code": [], "labels": ["enhancement"]}
{"project": "Beep6581_RawTherapee", "title": "Deactivate Retinex when editing non-raw image", "description": "#3704 deactivates tools which are unusable with the opened image type (non-raw, raw, or a specific type thereof), so in that fashion the Retinex tool should be deactivated for non-raw images. Specifically, the tool should be disabled (so that the icon is not in a misleading \"on\" state), collapsed (so that it doesn't take up vertical space), and set insensitive. ", "code": [], "labels": ["enhancement"]}
{"project": "RobotLocomotion_drake", "title": "Unable to open dreal/external/src/CAPD4/capdMake/INSTALL", "description": "Since #3221, several of Drake's demos and unit tests display a warning like this any time they run:\nUnable to open directory: /home/jwnimmer/jwnimmer-tri/drake-distro/build/externals/dreal/external/src/CAPD4/capdMake/INSTALL. It would be nice to suppress this.  (I assume it is unimportant?) ", "code": [], "labels": ["priority: low"]}
{"project": "rzwitserloot_lombok", "title": "@RequiredArgsConstructor expects super constructor fields", "description": "Migrated from Google Code (issue 515) ", "code": [], "labels": ["duplicate"]}
{"project": "bumptech_glide", "title": "I'm getting images to have a greenish background on all images for SVG images. Check below image for reference", "description": "Glide Version: 3.8.0 Integration libraries:  com.caverock:androidsvg:1.2.1 Device/Android Version: All versions Issue details / Repro steps / Use case background:  it's occurring with all icons Glide load line / GlideModule (if any) / list Adapter code (if any):  #3064 this is how i implemented SVG with v3.8.0 glide version ", "code": [], "labels": ["v3", "question"]}
{"project": "magnumripper_JohnTheRipper", "title": "AVX512BW detection is buggy", "description": "This works as expected: <CODE> But this fails: <CODE> <CODE> ", "code": ["./configure # OR ./configure CPPFLAGS='-mavx512bw'\n[...]\nTarget CPU ................................. x86_64 AVX512BW, 64-bit LE\nAES-NI support ............................. depends on OpenSSL\nTarget OS .................................. linux-gnu\nCross compiling ............................ no\nLegacy arch header ......................... x86-64.h\n", "./configure --disable-native-tests CPPFLAGS='-mavx512bw'\n[...]\nchecking for MMX... yes\nchecking for SSE2... yes\nchecking for SSSE3... yes\nchecking for SSE4.1... yes\nchecking for SSE4.2... yes\nchecking for AVX... yes\nchecking for XOP... no\nchecking for AVX2... yes\nchecking for AVX512F... yes\nchecking for AVX512BW... no\n[...]\nTarget CPU ................................. x86_64 AVX512F, 64-bit LE\nAES-NI support ............................. depends on OpenSSL\nTarget OS .................................. linux-gnu\nCross compiling ............................ no\nLegacy arch header ......................... x86-64.h\n", "configure:11595: checking for AVX512BW\nconfigure:11607: gcc -o conftest -m64 -g -O2 -I/usr/local/include   -O0 -mavx512bw -I/usr/local/include -m64  -L/usr/local/lib -L/usr/local/lib64 -L/usr/lib64 -L/lib64 conftest.c  >&5\nconftest.c: In function 'main':\nconftest.c:30:9: error: can't convert a vector of type '__m512i' {aka '__vector(8) long long int'} to type 'int' which has different size\n         int main(){__m512i t, t1;*((long long*)&t)=1;t1=t;t=_mm512_slli_epi16(t1,t);if((*(long long*)&t)==88)printf(\".\");exit(0);}\n         ^~~\nconfigure:11607: $? = 1\nconfigure: failed program was:\n"], "labels": ["bug"]}
{"project": "realm_realm-cocoa", "title": "RLMResult notification triggers even the object never exist in the result", "description": "Hey guys, I am using the results notification feature in my project but I found that even RLMResult is empty, changing other objects of the same class in the same realm will still trigger the notification block, like this :\nRLMResults * results = [CBMessage ObjectsWhere:@\"orderoptype = 123123123321321\"]; //this object will never exist in the RLMResults self.token = [results addNotificationBlock:^(RLMResults * _Nullable results, NSError * _Nullable error) {\nDLog(@\"It shouldn't happen but it does\");\n}]; Is it a bug? Or am I using it in the wrong way? ", "code": [], "labels": ["T-Help"]}
{"project": "SpongePowered_SpongeForge", "title": "Sponge Mixin to FML Launcher prevents mod_list.json mods to be loaded", "description": "While testing the new mod_list.json feature in forge, i've encountered the strange behavior, that no other mods have been loaded from a mod_list.json file in a sponge directory, except Sponge. It was even weirder as the first other mod I tried was IC2 which printed stuff to the console, but didn't show up in the mods list. Loading sponge from mod_list.json and other mods from the mods directory works just fine though. And loading all mods (including sponge) from the mods folder works as expected. Sponge mixes into the FML Loader in order to make the plugins directory configurable. here, it redirects a call to the ModDiscoverer to a custom function, recieving the discoverer, the mods directory and an optional array of additional mods, calls the original function, but does not pass on the additional mods array to the function call it replaces. I believe it is just a matter of replacing modDiscoverer.findModDirMods(modsDir); with modDiscoverer.findModDirMods(modsDir, additionalMods);. This way, the second argument is not ignored, and the information can pass through. I guess for the IC2 issue, tweakers/coremods do get loaded before, so the don't get blocked by this problem. I am currently running... What is the expected result?\nAll mods from mod_list.json appear in the Mods list What is the current result?\nThe mods from mod_list.json except Sponge don't appear ", "code": [], "labels": ["type: bug"]}
{"project": "zendframework_zendframework", "title": "Zend_Validate.php doesn't translate some classes", "description": "The classes Size and Extension from Zend\\Validator\\File, doesn't seem to be translated by the Zend_Validate class in pt_BR. In the class Extension for example we have: protected $messageTemplates = array(\nself::FALSE_EXTENSION => \"File has an incorrect extension\",\nself::NOT_FOUND       => \"File is not readable or does not exist\",\n); but in Zend_Validade (pt_BR) it's just like this: // Zend_Validator_File_ExcludeExtension\n\"File '%value%' has a false extension\" => \"O arquivo '%value%' possui uma extens\u00e3o incorreta\",\n\"File '%value%' is not readable or does not exist\" => \"O arquivo '%value%' n\u00e3o pode ser lido ou n\u00e3o existe\", It seems that the default template in the classes, like Size and Extension doens't have the \"%value%\". I might be wrong ", "code": [], "labels": ["bug", "Validator"]}
{"project": "redisson_redisson", "title": "Connection errors handling breaks redis watch/multi/exec semantics", "description": "Let's look into org.redisson.RedissonMap#replace(K, V, V)\nGood scenario:\nwatch -> ok\nhexists -> ok\nmulti -> ok\nhset -> queued\nexec -> ok Bad scenario:\nwatch -> ok\nhexists -> ok\nmulti -> ok\nhset -> operation timeout or other error handled by MasterSlaveConnectionManager#readAsync , retry on new connection, result ok\nexec -> \"exec without multi\" failure Impact: in bad scenario map content can be replaced with invalid value for key K ", "code": [], "labels": ["bug"]}
{"project": "aws-amplify_amplify-js", "title": "Password reset issue - chrome autofill", "description": "While trying to reset the password (for cases where the username and password have been saved), chrome autofills the Code and New Password fields with the username and password. It seems to be ignoring the autocomplete=\"off\" on the code input. Chrome : Version 75.0.3770.142 (Official Build) (64-bit) Pretty confusing to the end user. Planning to add a custom labels onto that for now. ", "code": [], "labels": ["Auth", "bug"]}
{"project": "monero-project_monero", "title": "monerod: crash while synchronizing with the network", "description": "Console output before crash: This happens both with official build (<URL> and native debug build of  \"release-v0.11.0.0\" branch (make debug).\nI tested official build on Tails (3.1) and Ubuntu (16.04.3 LTS) and native build on Ubuntu (gcc version 5.4.0).\nEverytime I start monerod I supply the same env (data.mdb, etc) and crash is always reproducible on first block received.\nI tried to specify \"--block-sync-size\" manually in range 1..20 but it doesn't have any impact. Trace: <CODE> (see below full trace) <CODE> So it seems like uninitialized std::vector m_blocks_txs_check Full trace:\ncrash.log Feel free to ask for missing details. ", "code": ["(gdb) bt\n#0  __memcmp_sse4_1 () at ../sysdeps/x86_64/multiarch/memcmp-sse4.S:1525\n#1  0x00007ffff7592533 in cryptonote::Blockchain::handle_block_to_main_chain\n      (this=this@entry=0x3460600, bl=..., id=..., bvc=...) \n      at src/cryptonote_core/blockchain.cpp:3334\n#2  0x00007ffff7598340 in cryptonote::Blockchain::add_new_block \n      (this=this@entry=0x3460600, bl_=..., bvc=...) \n      at src/cryptonote_core/blockchain.cpp:3481\n", "(gdb) frame 1\n#1  0x00007ffff7592533 in cryptonote::Blockchain::handle_block_to_main_chain\n      (this=this@entry=0x3460600, bl=...,  id=..., bvc=...) \n      at src/cryptonote_core/blockchain.cpp:3334\n3334          if (memcmp(&m_blocks_txs_check[tx_index++], &tx_id, sizeof(tx_id)) != 0)\n\n(gdb) p tx_index \n$1 = 1\n\n(gdb) p m_blocks_txs_check\n$8 = std::vector of length 0, capacity 0\n"], "labels": ["duplicate"]}
{"project": "TablePlus_TablePlus", "title": "SSH connection fails when more than one SSH-key been used", "description": "Hi, I found one very annoying error in Table Plus specifically relates to the connection via SSH-tunnel. My task:  I need to connect my TablePlus to my Postgres located on Vagrant host. If there are a few Private keys in .ssh/config and both are looks at the same IP but on the different ports, and one of these keys is not available for some reasons (was removed ), like: Example of bad .ssh/config: <CODE> then TablePlus tries this first key  and fails (!!!!!!without any DEBUG info!!!!!!! \ud83d\ude20)\n However, expecting behavior from TablePlus should keep trying to establish the connection by other keys as all other clients do. To fix this issue You just need to remove this bad key from .ssh/config.  Thank you. ", "code": ["Host            127.0.0.1\nPort            2200\nIdentityFile {path to wrong/not existed key}/.vagrant/virtualbox/private_key\nIdentitiesOnly  yes\n\nHost            127.0.0.1\nPort            2222\nIdentityFile  {path to correct key}/.vagrant/virtualbox/private_key\nIdentitiesOnly  yes\n"], "labels": ["investigating"]}
{"project": "kanboard_kanboard", "title": "Dependencies graph", "description": "Will be great to have a page where you can view visually as a tree the dependencies between tasks. ", "code": [], "labels": ["plugin"]}
{"project": "Automattic_jetpack", "title": "In case there's no backup data, API issues a notice.", "description": "In case VaultPress doesn't give anything back as a result of the API query, there is the following notice: <CODE> ", "code": ["PHP Notice:  Trying to get property of non-object in /var/www/wordpress/build/wp-content/plugins/jetpack/_inc/lib/core-api/class.jetpack-core-api-module-endpoints.php on line 1098\"\nPHP Stack trace:\"\nPHP   1. {main}() /var/www/wordpress/build/index.php:0\"\nPHP   2. require() /var/www/wordpress/build/index.php:17\"\nPHP   3. wp() /var/www/wordpress/build/wp-blog-header.php:16\"\nPHP   4. WP->main() /var/www/wordpress/build/wp-includes/functions.php:955\"\nPHP   5. WP->parse_request() /var/www/wordpress/build/wp-includes/class-wp.php:733\"\nPHP   6. do_action_ref_array() /var/www/wordpress/build/wp-includes/class-wp.php:386\"\nPHP   7. WP_Hook->do_action() /var/www/wordpress/build/wp-includes/plugin.php:515\"\nPHP   8. WP_Hook->apply_filters() /var/www/wordpress/build/wp-includes/class-wp-hook.php:323\"\nPHP   9. rest_api_loaded() /var/www/wordpress/build/wp-includes/class-wp-hook.php:298\"\nPHP  10. WP_REST_Server->serve_request() /var/www/wordpress/build/wp-includes/rest-api.php:259\"\nPHP  11. WP_REST_Server->dispatch() /var/www/wordpress/build/wp-includes/rest-api/class-wp-rest-server.php:323\"\nPHP  12. Jetpack_Core_API_Module_Data_Endpoint->process() /var/www/wordpress/build/wp-includes/rest-api/class-wp-rest-server.php:927\"\nPHP  13. Jetpack_Core_API_Module_Data_Endpoint->get_vaultpress_data() /var/www/wordpress/build/wp-content/plugins/jetpack/_inc/lib/core-api/class.jetpack-core-api-module-endpoints.php:833\"\n"], "labels": ["[Type] Bug", "Admin Page"]}
{"project": "tensorflow_tensorflow", "title": "how to take out the output of a layer", "description": "I am using the code from here:\n<URL>\nhow to take out the output of pool2_flat? ", "code": [], "labels": ["type:support"]}
{"project": "bwssytems_ha-bridge", "title": "[5.1.0] Harmony commands not being split into on/dim", "description": "First, Thanks for fixing pairing issue in 5.1.0. Working pretty well now! But with the following oddity: The \"On Items\" field is being completely ignored. Only \"dim items\" and \"off items\" are being used. So, for example, I have the \"on items\" field empty and the necessary JSON in the \"dim items\" field and when pressing the Harmony button, the scene turns on perfectly. Off works as well. However, my ideal functioning would be to have the Harmony button activate the \"on items\" field and then in the \"dim items\" field I could have a Hue passthru command so the brightness rocker on the Harmony Remote would function. Additional info: When entering the passthru command into \"dim items\" Harmony does turn on the light and the rocker works as well. But of course, can't set a scene this way. Hopefully this makes sense. If you want me to paste my exact config for all the fields, let me know! ", "code": [], "labels": ["enhancement", "question"]}
{"project": "James-Yu_LaTeX-Workshop", "title": "TOC Browser Enhancements", "description": "", "code": [], "labels": ["enhancement"]}
{"project": "hashicorp_nomad", "title": "[Feature] Allow the period to be specified when dispatching a parameterized periodic job", "description": "Hi, I was asking about this on the mailing list and figured it was worth capturing as feature request. I have a number of use cases where it would be useful to change/specify the cron pattern for a periodic parameterized job. It seems like a logical thing to be able to do for this kind of dispatch. Looking at the dispatch logic, it seems like it would be an easy thing to pass along updated PeriodicConfig in the JobDispatchRequest and add this the copy of the original job that's made for the dispatch. I could see the config in the base job containing rules to restrict changing the frequency, If this is feature that'd be considered I'd happily put a  pull request together for it. ", "code": [], "labels": ["waiting-reply"]}
{"project": "ansible_ansible", "title": "vmware_guest - Cluster option stopped working", "description": "modules/cloud/vmware/vmware_guest.py <CODE> DEFAULT_ROLES_PATH(env: ANSIBLE_ROLES_PATH) = [u'/home/xxxx/workspace/devops/platform-roles\nHOST_KEY_CHECKING(/home/xxxx/.ansible.cfg) = False\nRETRY_FILES_ENABLED(/home/xxxx/.ansible.cfg) = False Red Hat 7.4 Same issue as #30879. vmware_guest is not handling the \"cluster\" option correctly and fails that it can not find the data store. I have modified the vmware_guest.py to work properly and will do a pull request. Handle the Cluster option properly <CODE> ", "code": ["ansible 2.4.1.0\n  config file = /home/jzimmett/.ansible.cfg\n  configured module search path = [u'/home/jzimmett/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.5 (default, May  3 2017, 07:55:04) [GCC 4.8.5 20150623 (Red Hat 4.8.5-14)]\n\n", "Unable to access the virtual machine configuration: Unable to access file [Tintri-UAT-RPM]\n\n"], "labels": ["support:community", "vmware", "affects_2.4", "module", "bug", "cloud"]}
{"project": "AllenFang_react-bootstrap-table", "title": "Typo on the home page", "description": "The homepage reads: I guess it's built for React.js :) ", "code": [], "labels": ["in progress"]}
{"project": "vector-im_riot-android", "title": "Tapping on profile picture in sidebar should open settings page", "description": "I watched today as someone wanted to set a new profile picture in Riot. They repeatedly tapped on their profile picture in the sidebar and was confused why it didn't work. I think pointed them to the settings button. It would be a nice usability tweak if tapping your profile picture opened Settings instead of doing nothing. ", "code": [], "labels": ["good first issue", "P3"]}
{"project": "vector-im_riot-web", "title": "The loading wheel before displaying the login page and after submitting the login info is over the other options", "description": "Created by @ Amandine:matrix.org. Would be cleaner to have it over some white space ", "code": [], "labels": ["cosmetic", "bug", "p2"]}
{"project": "dbeaver_dbeaver", "title": "Table Indexes folder error", "description": "When I click on any table's Indexes folder I get the following error:  I'm using DBeaver 4.2.0 with postgres 9.6.2. ", "code": [], "labels": ["bug", "duplicate"]}
{"project": "qgis_QGIS", "title": "Crash while setting style on loading raster", "description": "Author Name: Nicholas Boyko (Nicholas Boyko)\nOriginal Redmine Issue: 19676\nAffected QGIS version: 3.0.3\nRedmine category:symbology QGIS crashes every time I load a style on a specific raster. The raster should be rectangular, running SW->NE, but appears as a large bounding rectangle, whereas similar files created the same way appear as the correct shape of rectangle, so I suspect that the raster itself is faulty, causing the crash, although a crappy raster should not bring down QGIS. Crash ID: 73aa49d2ddb692c383e6d1f2cd365390189da717 Stack Trace <CODE> QGIS Info\nQGIS Version: 3.0.3-Girona\nQGIS code revision: 8a899c8\nCompiled against Qt: 5.9.2\nRunning against Qt: 5.9.2\nCompiled against GDAL: 2.2.4\nRunning against GDAL: 2.2.4 System Info\nCPU Type: x86_64\nKernel Type: winnt\nKernel Version: 10.0.17134 ", "code": ["QgsColorRampShader::shade :\nQgsSingleBandPseudoColorRenderer::block :\nQgsBrightnessContrastFilter::block :\nQgsHueSaturationFilter::block :\nQgsRasterResampleFilter::block :\nQgsRasterProjector::block :\nQgsRasterIterator::readNextRasterPart :\nQgsRasterDrawer::draw :\nQgsRasterLayer::draw :\nQgsRasterLayer::previewAsImage :\nQgsRasterLayerProperties::sync :\nQgsRasterLayerProperties::syncToLayer :\nQgsRasterLayerProperties::loadStyle_clicked :\nQMetaObject::activate :\nQAction::activate :\nQMenu::actionGeometry :\nQMenu::actionGeometry :\nQMenu::mouseReleaseEvent :\nQWidget::event :\nQMenu::event :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsApplication::notify :\nQCoreApplication::notifyInternal2 :\nQApplicationPrivate::sendMouseEvent :\nQSizePolicy::QSizePolicy :\nQSizePolicy::QSizePolicy :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsApplication::notify :\nQCoreApplication::notifyInternal2 :\nQGuiApplicationPrivate::processMouseEvent :\nQWindowSystemInterface::sendWindowSystemEvents :\nQEventDispatcherWin32::processEvents :\nCallWindowProcW :\nDispatchMessageW :\nQEventDispatcherWin32::processEvents :\nqt_plugin_query_metadata :\nQEventLoop::exec :\nQMenu::exec :\nQDialogPrivate::operator= :\nQMetaObject::activate :\nQAbstractButton::clicked :\nQAbstractButton::mousePressEvent :\nQWidget::event :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsApplication::notify :\nQCoreApplication::notifyInternal2 :\nQApplicationPrivate::sendMouseEvent :\nQSizePolicy::QSizePolicy :\nQSizePolicy::QSizePolicy :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsApplication::notify :\nQCoreApplication::notifyInternal2 :\nQGuiApplicationPrivate::processMouseEvent :\nQWindowSystemInterface::sendWindowSystemEvents :\nQEventDispatcherWin32::processEvents :\nCallWindowProcW :\nDispatchMessageW :\nQEventDispatcherWin32::processEvents :\nqt_plugin_query_metadata :\nQEventLoop::exec :\nQCoreApplication::exec :\nmain :\nBaseThreadInitThunk :\nRtlUserThreadStart :\n\n"], "labels": ["Regression", "Bug", "Symbology", "High Priority", "Crash/Data Corruption"]}
{"project": "springfox_springfox", "title": "JAXB is required as explicit dependency for kotlin service/", "description": "I have created the most basic kotlin+springboot service with swagger and swagger-ui integrated in this repo. It should work fine with ./gradlew bootRun however if will fail with this stacktrace. <CODE> If you include JAXB directly (in that repo uncomment the last commit), it will work as expected. If this is a required dependency it should be indicated so in the published artifact so the build will pull it in transitively. ", "code": ["Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.\n2018-02-02 17:44:49.682 ERROR 90118 --- [           main] o.s.boot.SpringApplication               : Application startup failed\n                                      \norg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'xmlModelPlugin': Failed to introspect bean class [springfox.documentation.schema.XmlModelPlugin] for lookup method metadata: could not find class that it depends on; nested exception i\ns java.lang.NoClassDefFoundError: javax/xml/bind/annotation/XmlType\n        at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:269) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1118) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1091) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.10.RELEASE.jar:1.5.10.RELEASE]\n        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.10.RELEASE.jar:1.5.10.RELEASE]\n        at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.10.RELEASE.jar:1.5.10.RELEASE]\n        at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.10.RELEASE.jar:1.5.10.RELEASE]\n        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.10.RELEASE.jar:1.5.10.RELEASE]\n        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.10.RELEASE.jar:1.5.10.RELEASE]\n        at com.shoprunner.ApplicationKt.main(Application.kt:26) [main/:na]\nCaused by: java.lang.NoClassDefFoundError: javax/xml/bind/annotation/XmlType\n        at java.base/java.lang.Class.getDeclaredMethods0(Native Method) ~[na:na]\n        at java.base/java.lang.Class.privateGetDeclaredMethods(Class.java:3139) ~[na:na]\n        at java.base/java.lang.Class.getDeclaredMethods(Class.java:2266) ~[na:na]\n        at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:613) ~[spring-core-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:524) ~[spring-core-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:510) ~[spring-core-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:247) ~[spring-beans-4.3.14.RELEASE.jar:4.3.14.RELEASE]\n        ... 18 common frames omitted\nCaused by: java.lang.ClassNotFoundException: javax.xml.bind.annotation.XmlType\n        at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582) ~[na:na]\n        at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:185) ~[na:na]\n        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:496) ~[na:na]\n        ... 25 common frames omitted\n"], "labels": ["bug"]}
{"project": "SickChill_SickChill", "title": "Show 3% is not recognized by parser plus does not start to download.", "description": "Branch: master\nCommit: 17e9b81\nDatabase Version: 44.0 OS: QNAP\nWhat you did: Manually download the show\nWhat happened: Nothing\nWhat you expected: Parsed and sorted.\nLogs: Unable to match 3.Percent.S01E03.720p.WEBRip.X264-DEFLATE to a show in your database. Parser result: 3 Percent - S01E03 [GROUP: DEFLATE] [ABD: False] [ANIME: False] [whichReg: ['standard']] Seems sickrage does not adhere to scene standards to write the '%' sign in full instead of the symbol only. ", "code": [], "labels": ["Question"]}
{"project": "Rdatatable_data.table", "title": "Typo (?) in as.data.table example", "description": "The first example: <CODE> Presumably we're passing a named vector to runif in order to show the use of keep.rownames... but this is not what we get. runif strips the names of the output: <CODE> I guess we should just remove runif? The point is to show what as.data.table.numeric does, presumably, and as.data.table(c(a=0.1, b=0.2, c=0.3, d=0.4)) should suffice here. ", "code": ["nn = runif(c(a=0.1, b=0.2, c=0.3, d=0.4))\nas.data.table(nn)\nas.data.table(nn, keep.rownames=TRUE)\nas.data.table(nn, keep.rownames=\"rownames\")\n", "runif(c(a=0.1, b=0.2, c=0.3, d=0.4))\n# [1] 0.02227326 0.41916132 0.26085452 0.69217186\n"], "labels": ["documentation", "Enhancement"]}
{"project": "almende_vis", "title": "[Timeline] fitItem()", "description": "Would be cool to have a fitItem() method which will update the window to ensure an item is visible Bonus: I add bellow my onSelectItems callback where I do such things (as well as preventing multiselect that could be an option too) Thanks ", "code": [], "labels": ["Timeline"]}
{"project": "ansible_awx", "title": "Vault Issue on AWX 1.0.4.130  version", "description": "ISSUE TYPE I have created template and pointed one of my playbook which is vault encrypted , Created new credential with following details: Credential type : Vault\nVault Password  : password given at the time of creating vault file\nVault Identifier  : Vault file name Mapped this user to template. But playbook fails I have created template and pointed one of my playbook which is vault encrypted , Created new credential with following details: Credential type : Vault\nVault Password  : password given at the time of creating vault file\nVault Identifier  : Vault file name Mapped this user to template. Playbook should run successfully Found a vault_id (default) in the vault text, but we do not have a associated secret (--vault-id)\nTrying to use vault secret=(<ansible.parsing.vault.PromptVaultSecret object at 0x1c630d0>) id=db2_vault to decrypt None\nTrying secret <ansible.parsing.vault.PromptVaultSecret object at 0x1c630d0> for vault_id=db2_vault\nTried to use the vault secret (db2_vault) to decrypt (None) but it failed. Error: HMAC verification failed: Signature did not match digest. ", "code": [], "labels": ["type:bug", "state:needs_triage", "component:api"]}
{"project": "tensorflow_tensorflow", "title": "Docs load really slow", "description": "Please make sure that this is a documentation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template\nSystem information <CODE> It takes a really long time to load the docs. Navigating to another page can take 10+ seconds to load a new page. ", "code": ["chrome\nInternet speed 120+ Mbps\nTensorFlow version: all\nDoc Link: all pages\n"], "labels": ["type:docs"]}
{"project": "schwabe_ics-openvpn", "title": "Slashes in X509NAME are replaced with commas", "description": "<CODE> Original issue reported on code.google.com by david.ma...@gmail.com on 21 Aug 2012 at 3:23 ", "code": ["What steps will reproduce the problem?\nI'am trying to connect to my Astaro firewall using your app. In my ovpn I have \nconfigured something like this:\ntls-remote \"/C=c/L=l/O=o/CN=cn/emailAddress=a@b.com\"\n\nBut when connecting the slashes are converted into commas, which produces the \nfollowing error:\nP:VERIFY X509NAME ERROR: C=c, L=l, O=o, CN=cn, emailAddress=a@b.com, must be \n/C=c/L=l/O=o/CN=cn/emailAddress=a@b.com\n\nWhat is the expected output? What do you see instead?\nSlashes should not be replaced.\n\nWhat mobile phone are you using?\nAsus Transformer Pad Infinity\n\nWhich Android Version and stock ROM or aftermarket like cyanogenmod?\n4.0.3 Asus Stock Firmware\n\nPlease provide any additional information below.\n\n"], "labels": ["Priority-Medium", "Bug"]}
{"project": "dart-lang_sdk", "title": "Create a \"one click\" mechanism for reporting debug info from IntelliJ and Eclipse plugins if analysis server becomes unresponsive.", "description": "If the analysis server becomes unresponsive, the user should be able to click a single button which causes the following information to be captured in machine-readable format: This information should be reported in whatever way makes sense for the client (e.g. in IntelliJ it can be sent through IntelliJ's error reporting mechanism; in the Eclipse plug-ins it can be reported via the \"feedback\" mechanism). (Note: classifying the bug as \"Area-Editor\" since we don't have a component for the shared code used by both IntelliJ and the Eclipse plugins to communicate with the analysis server) ", "code": [], "labels": ["type-enhancement", "Type-Enhancement", "P2"]}
{"project": "pingcap_tidb", "title": "ErrInvalidFieldSize error code is not 3013 on branch release-3.0", "description": "Please answer these questions before submitting your issue. Thanks! According to pingcap/parser#534 , the error code should be 3013. <CODE> <CODE> ", "code": ["mysql> create table t (a bit(0));\nERROR 3013 (HY000): Invalid size for column 'a'.\n\nmysql> select tidb_version()\\G\n*************************** 1. row ***************************\ntidb_version(): Release Version: v4.0.0-alpha-984-gacfc7be79\nGit Commit Hash: acfc7be7941ed9f18d77009641ea77986de2ff1d\nGit Branch: master\nUTC Build Time: 2019-11-26 05:51:30\nGoVersion: go version go1.13.1 darwin/amd64\nRace Enabled: false\nTiKV Min Version: v3.0.0-60965b006877ca7234adaced7890d7b029ed1306\nCheck Table Before Drop: false\n1 row in set (0.00 sec)\n", "mysql> create table t (a bit(0));\nERROR 1105 (HY000): Invalid size for column 'a'.\n\nmysql> select tidb_version()\\G\n*************************** 1. row ***************************\ntidb_version(): Release Version: v3.0.5-87-gac4767a93\nGit Commit Hash: ac4767a933497db9053a6ae3e818959d2ef80d71\nGit Branch: release-3.0\nUTC Build Time: 2019-11-26 05:49:58\nGoVersion: go version go1.13.1 darwin/amd64\nRace Enabled: false\nTiKV Min Version: v3.0.0-60965b006877ca7234adaced7890d7b029ed1306\nCheck Table Before Drop: false\n1 row in set (0.00 sec)\n"], "labels": ["type/bug"]}
{"project": "sourcegraph_sourcegraph", "title": "Remove config-file.ConfigMap.yaml from deploy-sourcegraph, prod, dogfood, deploy-sourcegraph-docker", "description": "<CODE> ", "code": ["# TODO(slimsag): After 3.0 (NOT 3.0-preview), we can remove this. It is\n# left here now so that users upgrading to 3.0 will leave it here so\n# that the DB will be populated with their old site config file\n# (i.e. for migration). This means that for now we have two sources of\n# truth for the 'default' cluster configuration: The config-map in this\n# repository and the confdefaults.Cluster variable in our main repo.\n"], "labels": ["docs", "deployment"]}
{"project": "eslint_eslint", "title": "valid-jsdoc false positive for class documentation with class property arrow function", "description": "Tell us about your environment What parser (default, Babel-ESLint, etc.) are you using?\nbabel-eslint Please show your full configuration: What did you do? Please include the actual source code causing the issue. What did you expect to happen?\nNo lint errors. What actually happened? Please include the actual, raw output from ESLint.\nAt line number 1 the following errors are triggered: It looks like eslint thinks the comment above the class refers to the arrow function. If I replace the arrow function with a regular class method, the error vanishes. The error is also there when there's other methods above the class property function. ", "code": [], "labels": ["triage", "archived due to age"]}
{"project": "strapi_strapi", "title": "Infinite loader when clearing name field in role edition", "description": "Informations What is the current behavior? Infinite loading when clearing the name field of a role in the users-permissions plugin Steps to reproduce the problem What is the expected behavior? Suggested solutions Change these lines  By: <CODE> ", "code": ["  showLoaderForm = () => {\n    const { editPage: { modifiedData }, match: { params: { actionType } } } = this.props;\n\n    return actionType !== 'create' && isEmpty(modifiedData);\n  }\n"], "labels": ["priority: medium", "status: confirmed", "type: bug "]}
{"project": "Icinga_icinga2", "title": "[dev.icinga.com #10047] API action to schedule downtime for hosts and their respective child hosts", "description": "This issue has been migrated from Redmine: <URL> Created by schaefus on 2015-08-31 08:39:19 +00:00 Assignee: (none)\nStatus: New\nTarget Version: (none)\nLast Update: 2015-09-07 13:30:38 +00:00 (in Redmine) <CODE> There was a bug <<URL>> which was closed. The \"SCHEDULE_AND_PROPAGATE_TRIGGERED_HOST_DOWNTIME\" and \"SCHEDULE_AND_PROPAGATE_HOST_DOWNTIME\" external commands aren\u00b4t there any longer. It would be nice to have an API action in 2.4 to schedule downtime for hosts and their childs. ", "code": ["Backport?: Not yet backported\nInclude in Changelog: 1\n"], "labels": ["area/api", "enhancement"]}
{"project": "renovatebot_renovate", "title": "feat: Use official yarn install script for docker", "description": "What would you like Renovate to be able to do?\nCurrently the docker image is using npm to install yarn, which is not a supported way. Describe the solution you'd like\nWe should use the official yarn install script to install yarn in the docker image. We should change\n to @rarkins What do you think about this? ", "code": [], "labels": ["released"]}
{"project": "hazelcast_hazelcast", "title": "Change serialisation in classes using java.io.Serializable", "description": "HazelcastExpiryPolicy\nCacheClearResponse\nCacheEventListenerAdaptor\nCacheEntryListener\nCacheStatisticsMXBeanImpl\nEvictionConfig\nMaxSizeConfig\nNearCacheConfig\nWanReplicationRef\nSimulateLoadTask\nLazyMapEntry (?)\nMulticastMemberInfo ", "code": [], "labels": ["Team: Core"]}
{"project": "webtorrent_webtorrent", "title": "Support iOS 11 (blob redirect issue)", "description": "What version of WebTorrent?\nLast\nWhat operating system and Node.js version?\niOS 11\nWhat browser and version? (if using WebTorrent in the browser)\nSafari\nWhat did you expect to happen?\nStart Streaming\nWhat actually happened?\nGet error with redirected to blob file.\nSame issue on all webtorrents-based sites (instant.io)/ related DiegoRBaquero/BTorrent#48 ", "code": [], "labels": ["question"]}
{"project": "cuberite_cuberite", "title": "Redstone simulator can crash on setting block powered in Neighbour.", "description": "Picked up by coverity CID 70468. Its a rather complicated way that the redstone simulator can crash if it sets a block to be powered in a neighbouring chunk whilst a neighbour is unloaded. Needs a null check in SetBlockPowered on Neighbour. I'd do it myself but I'm not sure what it should do if it is null. ", "code": [], "labels": ["bug"]}
{"project": "oracle_graal", "title": "Mongonaut does not work on macOS", "description": "The native-image from <URL> builds fine but at execution there is an exception during socket creation: <CODE> This is caused by the move to JNI. ", "code": ["$ ./mongonaut\n13:24:01.429 [main] DEBUG io.jaegertracing.Configuration - Found a Metrics Factory service: class io.jaegertracing.micrometer.MicrometerMetricsFactory\n13:24:01.430 [main] DEBUG i.j.t.i.senders.ThriftSenderFactory - Using the UDP Sender to send spans to the agent.\n13:24:01.432 [main] DEBUG i.j.internal.senders.SenderResolver - Using sender UdpSender()\n13:24:01.459 [main] INFO  io.micronaut.runtime.Micronaut - Startup completed in 80ms. Server Running: http://localhost:8080\n13:24:11.424 [nioEventLoopGroup-2-2] INFO  org.mongodb.driver.cluster - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}\n13:24:11.433 [cluster-ClusterId{value='5df2316bb02edf0fa0184e76', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:27017\ncom.mongodb.MongoSocketOpenException: Exception opening socket\n\tat com.mongodb.internal.connection.AsynchronousSocketChannelStream$OpenCompletionHandler.failed(AsynchronousSocketChannelStream.java:117)\n\tat sun.nio.ch.Invoker.invokeUnchecked(Invoker.java:128)\n\tat sun.nio.ch.Invoker$2.run(Invoker.java:218)\n\tat sun.nio.ch.AsynchronousChannelGroupImpl$1.run(AsynchronousChannelGroupImpl.java:112)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\tat com.oracle.svm.core.thread.JavaThreads.threadStartRoutine(JavaThreads.java:527)\n\tat com.oracle.svm.core.posix.thread.PosixJavaThreads.pthreadStartRoutine(PosixJavaThreads.java:193)\nCaused by: java.net.ConnectException: Connection refused\n\tat com.oracle.svm.jni.JNIJavaCallWrappers.jniInvoke_VA_LIST:Ljava_net_ConnectException_2_0002e_0003cinit_0003e_00028Ljava_lang_String_2_00029V(JNIJavaCallWrappers.java:0)\n\tat sun.nio.ch.UnixAsynchronousSocketChannelImpl.checkConnect(UnixAsynchronousSocketChannelImpl.java)\n\tat sun.nio.ch.UnixAsynchronousSocketChannelImpl.finishConnect(UnixAsynchronousSocketChannelImpl.java:252)\n\tat sun.nio.ch.UnixAsynchronousSocketChannelImpl.finish(UnixAsynchronousSocketChannelImpl.java:198)\n\tat sun.nio.ch.UnixAsynchronousSocketChannelImpl.onEvent(UnixAsynchronousSocketChannelImpl.java:213)\n\tat sun.nio.ch.KQueuePort$EventHandlerTask.run(KQueuePort.java:301)\n\t... 3 common frames omitted\n"], "labels": ["native-image"]}
{"project": "foundation_foundation-sites", "title": "[Orbit] slide and container height on resize", "description": "Slide and container height doesn't get refreshed on resize ", "code": [], "labels": ["javascript", "bug"]}
{"project": "gatsbyjs_gatsby", "title": "Incorrect picture when sharing Gatsby's site", "description": "This issue might be specific to Facebook Messenger, but might be a larger issues: if you share Gatsby's website in Facebook Messenger, you see what I believe is @calcsam's face! \ud83d\ude06 Just share this link in Facebook Messenger. What should happen? Should have seen Gatsby's logo, or something other than @calcsam (no offence, Sam! \ud83d\ude05)  I'm running Chrome 69.0.3497.100, if that helps! ", "code": [], "labels": ["type: bug"]}
{"project": "doctrine_orm", "title": "DDC-2569: Unable to reverse engineer non \"dbo\" schema table", "description": "Jira issue originally created by user manseuk: I am unable to reverse engineer a table with a non \"dbo\" schema from Microsoft SQL Server 2008. The \"getListTablesSQL\" SQL returns a list of tables without the schema name. An alternative would be to use the SQL : SELECT '['SCHEMA_NAME(schema_id)'].['name']' AS name FROM sys.tables instead - this returns the list of table with the schema name. ", "code": [], "labels": ["Invalid", "Bug"]}
{"project": "qgis_QGIS", "title": "WMS-C troubles with BBOX", "description": "Author Name: Luca Casagrande (Luca Casagrande)\nOriginal Redmine Issue: 3585 Redmine category:web_services_clients/wms\nAssignee: Marco Hugentobler The tiled layer from this service doesn't work:\n<URL> Debugging the request I can get this information\nGET /proxy/service?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&BBOX=-89.910000,5.038871,0.090000,95.038871&SRS=EPSG:4326&WIDTH=256&HEIGHT=256&LAYERS=osm&STYLES=&FORMAT=image/png&TILED=true Changing BBOX by hand works fine: <URL>,0.000,0.000000,90.00&SRS=EPSG:4326&WIDTH=256&HEIGHT=256&LAYERS=osm&STYLES=&FORMAT=image/png&TILED=true It seems that QGis calculate a wrong BBOX and [[MapProxy]] doesn't accept it.\nIt'a all fine using [[GeoWebCache]], but it allows a big tollerance. ", "code": [], "labels": ["Bug", "Data Provider"]}
{"project": "travis-ci_travis-ci", "title": "APT whitelist request for libcollectdclient1 libcollectdclient-dev", "description": "Needed for radsniff utility in the FreeRADIUS project ", "code": [], "labels": ["apt-whitelist"]}
{"project": "status-im_status-react", "title": "Nothing happens when /request is sent without providing the amount", "description": "Type: Bug Summary: In a chat, nothing happens after sending /request \"Anna\" without providing the requested amount. It maybe not obvious why there was no action after clicking the send button.  Instead, user should see an info that she needs to provide the amount. User understands that she can't request tokens without providing the amount. User may be confused why nothing happens after clicking the send button for /request \"Anna\" command. ", "code": [], "labels": ["chat", "bug", "stale"]}
{"project": "dotnet_efcore", "title": "Many To Many self reference relationship with non-tree structure", "description": "Hello!\nI need to create non-tree structure with my Users. Each user can grant access for his profile to another users. This is my User class: I don't understand, how can I do it with fluent API. I stopped by \"WithOne\". ", "code": [], "labels": ["closed-duplicate"]}
{"project": "fritzing_fritzing-app", "title": "mask layer rotation bug in gerber export", "description": "From irasc...@gmail.com on March 10, 2013 11:51:05 <URL> Original issue: <URL> ", "code": [], "labels": ["bug"]}
{"project": "tootsuite_mastodon", "title": "audit log breaks with deleted statuses", "description": "going to <URL> currently returns a 500 error logs: <CODE> this happens after taking action on statuses that are later deleted, I assume ", "code": [" ActionView::Template::Error (No route matches {:account_username=>nil, :action=>\"show\", :controller=>\"statuses\", :id=>#<Status id: nil, uri: nil, text: \"\", created_at: nil, updated_at: nil, in_reply_to_id: nil, reblog_of_id: nil, url: nil, sensitive: true, visibility: \"public\", spoiler_text: \"\", reply: false, favourites_count: 0, reblogs_count: 0, language: nil, conversation_id: nil, local: false, account_id: nil, application_id: nil, in_reply_to_account_id: nil>}, possible unmatched constraints: [:account_username, :id]):\n     4:       = image_tag action_log.account.avatar.url(:original), alt: '', width: 40, height: 40, class: 'avatar'\n     5:     .log-entry__content\n     6:       .log-entry__title\n     7:         = t(\"admin.action_logs.actions.#{action_log.action}_#{action_log.target_type.underscore}\", name: content_tag(:span, action_log.account.username, class: 'username'), target: content_tag(:span, log_target(action_log), class: 'target')).html_safe\n     8:       .log-entry__timestamp\n     9:         %time= l action_log.created_at\n    10:     .spacer\napp/lib/tag_manager.rb:44:in `url_for'\napp/helpers/admin/action_logs_helper.rb:37:in `log_target_from_history'\napp/helpers/admin/action_logs_helper.rb:8:in `log_target'\napp/views/admin/action_logs/_action_log.html.haml:7:in `_app_views_admin_action_logs__action_log_html_haml__247563165727585356_70074423886980'\napp/views/admin/action_logs/index.html.haml:5:in `_app_views_admin_action_logs_index_html_haml__4526750395608647622_70074485034700'\n"], "labels": ["bug"]}
{"project": "quasarframework_quasar", "title": "no-hover not working if q-table element is in slot", "description": "Describe the bug\nWhen <q-tr> or <q-td> with no-hover attribute is in q-table's slot (eg. bottom-row) class responsible for no-hover effect is not rendered on elements. However, we can manually add q-td--no-hover class. Codepen/jsFiddle/Codesandbox (required)\n<URL> To Reproduce\nSteps to reproduce the behavior: Expected behavior\nHover effect should be removed (q-td--no-hover class should be rendered on element) if no-hover attribute is present on <q-tr> or <q-td> elements in slots. Platform (please complete the following information):\nOS: Windows_NT(10.0.17763) - win32/x64\nNode: 12.13.1\nNPM: 6.12.1\nYarn: 1.19.2\nBrowsers: Chrome 79.0.3945.117\nQuasar: 1.6.1 ", "code": [], "labels": ["bug"]}
{"project": "CocoaPods_CocoaPods", "title": "Cannot archive when using target inheritance", "description": "Run pod install The resulting workspace to Build and Archive In Xcode, building only works if I change the scheme to the library target and build, then switch it back to the application target and build.  However, when attempting to Product > Archive, the process always fails with the error No such module 'library' <CODE> <CODE> <CODE> <URL> ", "code": ["   CocoaPods : 1.0.1\n        Ruby : ruby 2.0.0p648 (2015-12-16 revision 53162) [universal.x86_64-darwin15]\n    RubyGems : 2.6.6\n        Host : Mac OS X 10.11.4 (15E65)\n       Xcode : 7.3 (7D175)\n         Git : git version 2.6.4 (Apple Git-63)\nRuby lib dir : /System/Library/Frameworks/Ruby.framework/Versions/2.0/usr/lib\nRepositories : master - https://github.com/CocoaPods/Specs.git @ 8a55c671d76a2f2a464a059c699c3767f0cf3c9c\n", "Executable Path: /usr/local/bin/pod\n", "cocoapods-deintegrate : 1.0.0\ncocoapods-plugins     : 1.0.0\ncocoapods-search      : 1.0.0\ncocoapods-stats       : 1.0.0\ncocoapods-trunk       : 1.0.0\ncocoapods-try         : 1.1.0\n"], "labels": ["s1:awaiting input"]}
{"project": "microsoft_MixedRealityToolkit-Unity", "title": "HandGuidance.cs: error CS0619", "description": "Hey, guys!\nI just download the master branch and use the package in my unity project. Before i build my project into VS solution, 8 errors are pushed out as the following picture:\n\nit recommends to use the functions with a prefix of 'Interaction' in UnityEngine.XR.WSA.Input.InteractionManager.xxxx()\nCan anybody help me out on this problem? Thanks!\nEdison ", "code": [], "labels": ["Question"]}
{"project": "BVLC_caffe", "title": "Scale Invariant CNN (SICNN)", "description": "The Spatial Pyramid Pooling net of #548 improves the speed of Regions with Convolutional Neural Network Features by extracting features for each image only once while R-CNN does so for each region of interest in an image. The most important insight of SPP-net is that only the classifiers or the fully-connected layers require fixed-length vector. The convolution layers do not have to constrain the sizes of the images. The experiments show that full image is better than cropped ones and larger scales lead to higher accuracy. The SPP-net simulate the multiple scales with fixed-size networks. The \"scale-mismatch\" problem is not solved. In #308, multi-scale feature extraction is achieved by packing the multiple scales of a image in a single large image. They can only process pre-defined discrete scales. The authentic scale invariant CNN means that the extracted features can be scaled up or down to get the features of the images undergoing the same scaling. The feature of an image only has to be extracted once by the network. Any ideas about the existing works in this direction? ", "code": [], "labels": ["question"]}
{"project": "dotnet_efcore", "title": "An exception occurred in the database while iterating the results of a query.", "description": "I have a table MyData with 3 columns of interest...\nName (string, not required) Description (string, not required) ID (long, required) When running the following code: <CODE> EF generates the following SQL: <CODE> and then blows up on res.Count() with <CODE> The Description column does have some null values in it in the database. If I remove the condition p.ID.ToString().Contains(test) from the Where clause then no exception is thrown because EF does the filtering on the SQL server by generating the following SQL: <CODE> It seems like the filtering should be done on the server in either case, by doing something like\nWHERE CONVERT(varchar(max), ID) LIKE '%@TesVar%'\ninstead of pulling ALL records to the web server and then iterating over them locally... no? Either way, I'm not sure what's up with the NullRef exception - that seems like an issue no matter what. EF Core version: 1.0.0\nOperating system:  W10\nVisual Studio version: 2015 ", "code": ["           string test = \"26\";\n            var res = _context.MyData.Where(\n                    p => p.Name.Contains(test) ||\n                    p.Description.Contains(test) ||\n                    p.ID.ToString().Contains(test)\n                    );\n           int count = res.Count();\n", "Opening connection to database 'blah' on server\nSELECT [p].[ID], [p].[Description], [p].[Name] FROM [MyData] AS [p]\nClosing connection to database 'blah' on server\n", "System.NullReferenceException: Object reference not set to an instance of an object.\n   at lambda_method(Closure , MyData)\n   at System.Linq.Enumerable.WhereEnumerableIterator`1.MoveNext()\n   at System.Linq.Enumerable.Count[TSource](IEnumerable`1 source)\n   at lambda_method(Closure , QueryContext )\n   at Microsoft.EntityFrameworkCore.Query.Internal.QueryCompiler.<>c__DisplayClass19_1`1.<CompileQuery>b__1(QueryContext qc)\nException thrown: 'System.NullReferenceException' in Microsoft.EntityFrameworkCore.dll\n\n", "[Parameters=[@__test_0='?' (Size = 4000), @__test_1='?' (Size = 4000)], CommandType='Text', CommandTimeout='30']\n\nSELECT COUNT(*)\nFROM [MyData] AS [p]\nWHERE [p].[Name] LIKE (N'%' + @__test_0) + N'%' OR [p].[Description] LIKE (N'%' + @__test_1) + N'%'\n"], "labels": ["closed-duplicate"]}
{"project": "nodejs_node", "title": "Module._load: returning module from cache without file-check?:", "description": "I am trying to feed require.cache with modules from memory, unfortunately Module._resolveFilename does a file-check and aborts. Any chance to overcome this without creating files?\nthanks! ", "code": [], "labels": ["module", "question"]}
{"project": "electron-userland_electron-builder", "title": "How to use ignore files when packaging", "description": "electron-builder: 3.16.0 I have a project setup using the two package.json structure. Everything works fine now, but I need to dynamically ignore files from the package. To do this, I am switching from the CLI to the API. My current build command is: I have changed it to the following script: However, the ignore field is not being read; all files are packaged and all the filenames are not being printed. Any idea on why this is? ", "code": [], "labels": ["question"]}
{"project": "flutter_flutter", "title": "Semantics tree print is hard to read", "description": "We are adding more and more attributes to the semantics tree so the \"one line per node\" format gets harder and harder to read. We should switch to a representation that sues multiple lines per node (similar to the widget and render tree). ", "code": [], "labels": ["a: accessibility"]}
{"project": "matomo-org_matomo", "title": "Allowed Memory Size Executed /core/DataTable.php on line 935", "description": "Hello, Wen I try to call a month or year statistics do I get the error, the availabilities of the space is insufficient and at 256MB, Temporary I increased the memory to 512MB. The only question when it is not enough anymore. Allowed Memory Size Executed /core/DataTable.php on line 935 MfG ", "code": [], "labels": ["T: Bug"]}
{"project": "sublimehq_Packages", "title": "Some definitions are not shown", "description": "Issue based on this. Steps to reproduce the bug: As you can see, neither wglMakeCurrent nor wglCreateContext are showing up the existing definitions from wingdi.h file. @wbond comment : I looked at the .h file, and it appears the preprocessor directives at lines 4754-4761 are the issue ", "code": [], "labels": ["bug"]}
{"project": "linuxmint_cinnamon", "title": "Steam slows down shutdown", "description": "If the steam window is open at shutdown, shutting down takes very long. (By shutdown I mean the time until cinnamon closes; once it logged off, everything is pretty fast).\nMaybe cinnamon tries to store some information to startup steam again after the next boot (which btw does not work - for other programs it works though). ", "code": [], "labels": ["BUG"]}
{"project": "Homebrew_brew", "title": "Trying to install shellcheck initiated a build from source rather than using the bottle", "description": "@sitsofe commented on Jul 11, 2018, 11:27 AM UTC: Please note we will close your issue without comment if you delete, do not read or do not fill out the issue checklist below and provide ALL the requested information. If you repeatedly fail to use the issue template, we will block you from ever submitting issues to Homebrew again. To help us debug your issue please explain: Trying to install shellcheck Rather than using the bottle shellcheck tried to build itself (and ghc) from source... Pre-built bottle to be used. <CODE> This issue happened on two separate macOS 10.12 installs. However in both cases after stopping the source build and doing: <CODE> The bottle for ghc was found. Once this was installed doing <CODE> quickly found and installed the bottle. Attaching log:\nhomebrew-log.txt This issue was moved by ilovezfs from Homebrew/homebrew-core#29973. ", "code": ["brew install shellcheck\n\n", "brew install ghc\n\n", "brew install shellcheck\n\n"], "labels": ["outdated"]}
{"project": "linkerd_linkerd2", "title": "Add integration tests for single-namespace mode", "description": "Right now we don't have any integration tests for linkerd installed with the --single-namespace flag. We should modify the bin/test-run script to re-run the install test with the --single-namespace flag set, in much the same way that it already re-runs the install test with the --tls optional flag set. That will help us catch issues like #2119 as soon as they hit master. ", "code": [], "labels": ["area/test"]}
{"project": "NativeScript_NativeScript", "title": "iOS - project doesn't build", "description": "If you create a project with space in the name and try to build ios , you will see exception iOS <CODE> ", "code": ["2018-07-04 13:56:33.530 xcodebuild[38841:990585] Error Domain=NSCocoaErrorDomain Code=3840 \"Unexpected character / at line 1\" UserInfo={NSDebugDescription=Unexpected character / at line 1, kCFPropertyListOldStyleParsingError=Error Domain=NSCocoaErrorDomain Code=3840 \"Expected terminating ')' for array at line 375\" UserInfo={NSDebugDescription=Expected terminating ')' for array at line 375}}\nxcodebuild: error: Unable to read project 'TestApp.xcodeproj'.\n\tReason: Project /Users/nsbuilduser/workspace/CLI-stable-tests-build-ios-common-osx/Test App/platforms/ios/TestApp.xcodeproj cannot be opened because the project file cannot be parsed.\n\n\n?[31;1mCommand xcodebuild failed with exit code 74?\n"], "labels": ["os: ios"]}
{"project": "dotnet_efcore", "title": "Where can I learn how to use advanced APIs like SqlFragmentExpression or IMethodCallTranslator?", "description": "I'd like to know more about these advanced APIs (and others) and how I can customize EF-Core by implementing my own IMethodCallTranslator and generate some custom SQL with the SqlFragmentExpression. I'd also like to know which services are replacable and to what extent they can be customized. Could you share some links to articles about such more advanced techniques? ", "code": [], "labels": ["customer-reported", "closed-question"]}
{"project": "terraform-providers_terraform-provider-aws", "title": "Per error message request, submitting issue for diff's didn't match issue", "description": "This issue was originally opened by @phwelo as hashicorp/terraform#21841. It was migrated here as a result of the provider split. The original body of the issue is below. 1 error(s) occurred: Please include the following information in your report: <CODE> Also include as much context as you can about your config, state, and the steps you performed to trigger this error. Terraform does not automatically rollback in the face of errors.\nInstead, your Terraform state file has been partially updated with\nany resources that successfully completed. Please address the error\nabove and apply again to incrementally change your infrastructure. ", "code": ["Terraform Version: 0.11.13\nResource ID: aws_ecs_task_definition.ecs-task\nMismatch reason: diff RequiresNew; old: false, new: true\nDiff One (usually from plan): *terraform.InstanceDiff{mu:sync.Mutex{state:0, sema:0x0}, Attributes:map[string]*terraform.ResourceAttrDiff{\"container_definitions\":*terraform.ResourceAttrDiff{Old:\"[{\\\"cpu\\\":256,\\\"environment\\\":[],\\\"essential\\\":true,\\\"image\\\":\\\"groundspeedorg/file-router-dev:latest\\\",\\\"logConfiguration\\\":{\\\"logDriver\\\":\\\"awslogs\\\",\\\"options\\\":{\\\"awslogs-group\\\":\\\"dev-ecs-services\\\",\\\"awslogs-region\\\":\\\"us-east-1\\\",\\\"awslogs-stream-prefix\\\":\\\"file-router-dev\\\"}},\\\"memory\\\":512,\\\"mountPoints\\\":[],\\\"name\\\":\\\"file-router-dev\\\",\\\"portMappings\\\":[],\\\"volumesFrom\\\":[]}]\", New:\"[{\\\"cpu\\\":256,\\\"essential\\\":true,\\\"image\\\":\\\"groundspeedorg/file-router-dev:latest\\\",\\\"logConfiguration\\\":{\\\"logDriver\\\":\\\"awslogs\\\",\\\"options\\\":{\\\"awslogs-group\\\":\\\"dev-ecs-services\\\",\\\"awslogs-region\\\":\\\"us-east-1\\\",\\\"awslogs-stream-prefix\\\":\\\"file-router-dev\\\"}},\\\"memory\\\":512,\\\"name\\\":\\\"file-router-dev\\\"}]\", NewComputed:false, NewRemoved:false, NewExtra:\"[\\n    {\\n      \\\"cpu\\\": 256,\\n      \\\"essential\\\": true,\\n      \\\"image\\\": \\\"groundspeedorg/file-router-dev:latest\\\",\\n      \\\"memory\\\": 512,\\n      \\\"name\\\": \\\"file-router-dev\\\",\\n      \\\"logConfiguration\\\": {\\n          \\\"logDriver\\\": \\\"awslogs\\\",\\n          \\\"options\\\": {\\n              \\\"awslogs-group\\\": \\\"dev-ecs-services\\\",\\n              \\\"awslogs-region\\\": \\\"us-east-1\\\",\\n              \\\"awslogs-stream-prefix\\\": \\\"file-router-dev\\\"\\n          }\\n      }\\n    }\\n  ]\", RequiresNew:false, Sensitive:false, Type:0x0}}, Destroy:false, DestroyDeposed:false, DestroyTainted:false, Meta:map[string]interface {}(nil)}\nDiff Two (usually from apply): *terraform.InstanceDiff{mu:sync.Mutex{state:0, sema:0x0}, Attributes:map[string]*terraform.ResourceAttrDiff{\"execution_role_arn\":*terraform.ResourceAttrDiff{Old:\"arn:aws:iam::330914985129:role/ecsTaskExecutionRole\", New:\"arn:aws:iam::330914985129:role/ecsTaskExecutionRole\", NewComputed:false, NewRemoved:false, NewExtra:interface {}(nil), RequiresNew:false, Sensitive:false, Type:0x0}, \"family\":*terraform.ResourceAttrDiff{Old:\"file-router-dev\", New:\"file-router-dev\", NewComputed:false, NewRemoved:false, NewExtra:interface {}(nil), RequiresNew:false, Sensitive:false, Type:0x0}, \"revision\":*terraform.ResourceAttrDiff{Old:\"2\", New:\"\", NewComputed:true, NewRemoved:false, NewExtra:interface {}(nil), RequiresNew:false, Sensitive:false, Type:0x0}, \"task_role_arn\":*terraform.ResourceAttrDiff{Old:\"arn:aws:iam::330914985129:role/file-router-task-dev\", New:\"arn:aws:iam::330914985129:role/file-router-dev\", NewComputed:false, NewRemoved:false, NewExtra:interface {}(nil), RequiresNew:true, Sensitive:false, Type:0x0}, \"network_mode\":*terraform.ResourceAttrDiff{Old:\"\", New:\"\", NewComputed:true, NewRemoved:false, NewExtra:interface {}(nil), RequiresNew:false, Sensitive:false, Type:0x0}, \"container_definitions\":*terraform.ResourceAttrDiff{Old:\"[{\\\"cpu\\\":256,\\\"environment\\\":[],\\\"essential\\\":true,\\\"image\\\":\\\"groundspeedorg/file-router-dev:latest\\\",\\\"logConfiguration\\\":{\\\"logDriver\\\":\\\"awslogs\\\",\\\"options\\\":{\\\"awslogs-group\\\":\\\"dev-ecs-services\\\",\\\"awslogs-region\\\":\\\"us-east-1\\\",\\\"awslogs-stream-prefix\\\":\\\"file-router-dev\\\"}},\\\"memory\\\":512,\\\"mountPoints\\\":[],\\\"name\\\":\\\"file-router-dev\\\",\\\"portMappings\\\":[],\\\"volumesFrom\\\":[]}]\", New:\"[{\\\"cpu\\\":256,\\\"essential\\\":true,\\\"image\\\":\\\"groundspeedorg/file-router-dev:latest\\\",\\\"logConfiguration\\\":{\\\"logDriver\\\":\\\"awslogs\\\",\\\"options\\\":{\\\"awslogs-group\\\":\\\"dev-ecs-services\\\",\\\"awslogs-region\\\":\\\"us-east-1\\\",\\\"awslogs-stream-prefix\\\":\\\"file-router-dev\\\"}},\\\"memory\\\":512,\\\"name\\\":\\\"file-router-dev\\\"}]\", NewComputed:false, NewRemoved:false, NewExtra:\"[\\n    {\\n      \\\"cpu\\\": 256,\\n      \\\"essential\\\": true,\\n      \\\"image\\\": \\\"groundspeedorg/file-router-dev:latest\\\",\\n      \\\"memory\\\": 512,\\n      \\\"name\\\": \\\"file-router-dev\\\",\\n      \\\"logConfiguration\\\": {\\n          \\\"logDriver\\\": \\\"awslogs\\\",\\n          \\\"options\\\": {\\n              \\\"awslogs-group\\\": \\\"dev-ecs-services\\\",\\n              \\\"awslogs-region\\\": \\\"us-east-1\\\",\\n              \\\"awslogs-stream-prefix\\\": \\\"file-router-dev\\\"\\n          }\\n      }\\n    }\\n  ]\", RequiresNew:false, Sensitive:false, Type:0x0}, \"arn\":*terraform.ResourceAttrDiff{Old:\"arn:aws:ecs:us-east-1:330914985129:task-definition/file-router-dev:2\", New:\"\", NewComputed:true, NewRemoved:false, NewExtra:interface {}(nil), RequiresNew:false, Sensitive:false, Type:0x0}}, Destroy:true, DestroyDeposed:false, DestroyTainted:false, Meta:map[string]interface {}(nil)}\n"], "labels": ["needs-triage"]}
{"project": "kubernetes_kubernetes", "title": "Density test can fail on cleanup", "description": "If the cleanup of the replication controller takes too long after a successful test run, then the clean up performed in the AfterEach can actually cause the test to fail.  Should only perform the clean up if the rc exists and its replica count is non-zero. ", "code": [], "labels": ["priority/awaiting-more-evidence", "area/test", "sig/node"]}
{"project": "NuGet_Home", "title": "Auto-complete on Uninstall-Package cmdlet lists the installed packages from the solution and not just the default project name", "description": "<CODE> ", "code": ["    a. Repro steps\n        i. Create 2 or more projects in a solution\n        ii. Install 2 or more packages to 2 or more projects in this solution\n        iii. On PMC, hit TAB after typing Uninstall-Package\n        iv. Expected: Packages on the current project alone are displayed\n"], "labels": ["Type:Bug", "Priority:2", "Area:VS.Client"]}
{"project": "vapor_vapor", "title": "Client has no way to send POST|PUT|PATCH data", "description": "the necessary overloads described in the comment above are missing ", "code": [], "labels": ["bug"]}
{"project": "elastic_elasticsearch", "title": "The edit field format absent", "description": "Elasticsearch version:\nES 2.3 Description of the problem including expected versus actual behavior:\nPlease see <URL> The edit field format is absent. ", "code": [], "labels": [">docs", ">bug"]}
{"project": "owncloud_core", "title": "Do not log auth error in publicwebdav for initial auth call", "description": "No error in log Log is full with: <CODE> When debugging I noticed that when doing a single Sabre Client call, curl (the one used by Sabre) would first do a non-authenticated call to \"publicwebdav.php\" which triggers the message and returns 401. After that, curl would send a second request with the auth info. According to @LukasReschke this is the expected protocol. So if this is expected, we need to find a way to prevent that error to be logged during the first \"handshake\" request to avoid polluting the logs and making people believe that something is wrong. ", "code": ["ic authentication headers were found\\\",\\\"Code\\\":0,\\\"Trace\\\":\\\"#0 \\\\\\/srv\\\\\\/www\\\\\\/htdocs\\\\\\/owncloud\\\\\\/3rdparty\\\\\\/sabre\\\\\\/dav\\\\\\/lib\\\\\\/Sabre\\\\\\/DAV\\\\\\/Auth\\\\\\/Plugin.php(108): Sabre\\\\\\\\DAV\\\\\\\\Auth\\\\\\\\Backend\\\\\\\\AbstractBasic->authenticate(Object(OC_Connector_Sabre_Server), 'ownCloud')\\\\n#1 [internal function]: Sabre\\\\\\\\DAV\\\\\\\\Auth\\\\\\\\Plugin->beforeMethod('PROPFIND', '')\\\\n#2 \\\\\\/srv\\\\\\/www\\\\\\/htdocs\\\\\\/owncloud\\\\\\/3rdparty\\\\\\/sabre\\\\\\/dav\\\\\\/lib\\\\\\/Sabre\\\\\\/DAV\\\\\\/Server.php(433): call_user_func_array(Array, Array)\\\\n#3 \\\\\\/srv\\\\\\/www\\\\\\/htdocs\\\\\\/owncloud\\\\\\/3rdparty\\\\\\/sabre\\\\\\/dav\\\\\\/lib\\\\\\/Sabre\\\\\\/DAV\\\\\\/Server.php(455): Sabre\\\\\\\\DAV\\\\\\\\Server->broadcastEvent('beforeMethod', Array)\\\\n#4 \\\\\\/srv\\\\\\/www\\\\\\/htdocs\\\\\\/owncloud\\\\\\/3rdparty\\\\\\/sabre\\\\\\/dav\\\\\\/lib\\\\\\/Sabre\\\\\\/DAV\\\\\\/Server.php(214): Sabre\\\\\\\\DAV\\\\\\\\Server->invokeMethod('PROPFIND', '')\\\\n#5 \\\\\\/srv\\\\\\/www\\\\\\/htdocs\\\\\\/owncloud\\\\\\/apps\\\\\\/files_sharing\\\\\\/publicwebdav.php(78): Sabre\\\\\\\\DAV\\\\\\\\Server->exec()\\\\n#6 \\\\\\/srv\\\\\\/www\\\\\\/htdocs\\\\\\/owncloud\\\\\\/public.php(48): require_once('\\\\\\/srv\\\\\\/www\\\\\\/htdocs...')\\\\n#7 {main}\\\",\\\"File\\\":\\\"\\\\\\/srv\\\\\\/www\\\\\\/htdocs\\\\\\/owncloud\\\\\\/3rdparty\\\\\\/sabre\\\\\\/dav\\\\\\/lib\\\\\\/Sabre\\\\\\/DAV\\\\\\/Auth\\\\\\/Backend\\\\\\/AbstractBasic.php\\\",\\\"Line\\\":73}\",\"level\":0,\"time\":\"2015-01-21T12:16:08+00:00\",\"method\":\"PROPFIND\",\"url\":\"\\/owncloud\\/public.php\\/webdav\\/\"}\n"], "labels": ["bug", "sev4-low", "feature:sharing"]}
{"project": "microsoft_TypeScript", "title": "No intellisense when extend prototype", "description": "From @PixelT on February 28, 2018 22:12 I created myMethod in Number prototype, but after create variable Number type, the myMethod isn't exist in suggestion list:  VSC 1.21.0-insider / 2018-02-28T06:03:54.355Z Copied from original issue: microsoft/vscode#44773 ", "code": [], "labels": ["Bug", "VS Code Tracked"]}
{"project": "tmrowco_electricitymap-contrib", "title": "Italy is missing from ENTSOE", "description": "As per the title there has been no data for Italy on ENTSOE for at least 2-3 weeks. @Dalius-ENTSO-E any news on this? ", "code": [], "labels": ["bug ", "parser"]}
{"project": "NativeScript_nativescript-angular", "title": "tns preview crashed on shared code", "description": "Environment\nProvide version numbers for the following components (information can be retrieved by running tns info in your project folder or by inspecting the package.json of the project): Describe the bug\ntns preview command crash in an empty angular shared code project To Reproduce\ntns preview <CODE> ", "code": ["Executing before-shouldPrepare hook from \nmyapp/hooks/before-shouldPrepare/nativescript-dev-webpack.js\nSkipping prepare.\nSuccessfully synced changes for platform android.\nLOG from device ASUS_X00ID: An uncaught Exception occurred on \"main\" thread.\njava.lang.RuntimeException: Unable to start activity ComponentInfo{org.nativescript.preview/com.tns.NativeScriptActivity}: com.tns.NativeScriptException: \nCalling js method onCreate failed\n\nTypeError: Cannot read property 'create' of undefined\nFile: \"file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/builder/builder.js, line: 75, column: 14\n\nStackTrace: \n\tFrame: function:'', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/builder/builder.js', line: 75, column: 15\n\tFrame: function:'FrameBase.navigate', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/frame-common.js', line: 118, column: 30\n\tFrame: function:'ActivityCallbacksImplementation.setActivityContent', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/frame.js', line: 832, column: 30\n\tFrame: function:'ActivityCallbacksImplementation.onCreate', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/frame.js', line: 691, column: 14\n\tFrame: function:'NativeScriptActivity.onCreate', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/activity.js', line: 20, column: 25\n\n\n\tat android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2665)\n\tat android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2726)\n\tat android.app.ActivityThread.-wrap12(ActivityThread.java)\n\tat android.app.ActivityThread$H.handleMessage(ActivityThread.java:1477)\n\tat android.os.Handler.dispatchMessage(Handler.java:102)\n\tat android.os.Looper.loop(Looper.java:159)\n\tat android.app.ActivityThread.main(ActivityThread.java:6139)\n\tat java.lang.reflect.Method.invoke(Native Method)\n\tat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:886)\n\tat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:776)\nCaused by: com.tns.NativeScriptException: \nCalling js method onCreate failed\n\nTypeError: Cannot read property 'create' of undefined\nFile: \"file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/builder/builder.js, line: 75, column: 14\n\nStackTrace: \n\tFrame: function:'', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/builder/builder.js', line: 75, column: 15\n\tFrame: function:'FrameBase.navigate', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/frame-common.js', line: 118, column: 30\n\tFrame: function:'ActivityCallbacksImplementation.setActivityContent', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/frame.js', line: 832, column: 30\n\tFrame: function:'ActivityCallbacksImplementation.onCreate', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/frame.js', line: 691, column: 14\n\tFrame: function:'NativeScriptActivity.onCreate', file:'file:///data/data/org.nativescript.preview/files/app/tns_modules/tns-core-modules/ui/frame/activity.js', line: 20, column: 25\n\n\n\tat com.tns.Runtime.callJSMethodNative(Native Method)\n\tat com.tns.Runtime.dispatchCallJSMethodNative(Runtime.java:1116)\n\tat com.tns.Runtime.callJSMethodImpl(Runtime.java:996)\n\tat com.tns.Runtime.callJSMethod(Runtime.java:983)\n\tat com.tns.Runtime.callJSMethod(Runtime.java:967)\n\tat com.tns.Runtime.callJSMethod(Runtime.java:959)\n\tat com.tns.NativeScriptActivity.onCreate(NativeScriptActivity.java:18)\n\tat android.app.Activity.performCreate(Activity.java:6759)\n\tat android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1119)\n\tat android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2618)\n\t... 9 more\n\n\n"], "labels": ["needs more info"]}
{"project": "polybar_polybar", "title": "Tray transparency", "description": "Not sure if its implemented but does the tray have transparency / match the background of the bar; If not then mine has a solid black background ", "code": [], "labels": ["bug", "confirmed"]}
{"project": "strongloop_loopback", "title": "hateoas support", "description": "Strong need to add jsonapi support, maybe pluggable support to other paradigms like hal. slc loopback:jsonapi\nslc loopback:hal ", "code": [], "labels": ["feature", "stale"]}
{"project": "golang_go", "title": "encoding/json: include field name in unmarshal error messages when extracting time.Time", "description": "allocated from #6716 . go1.9.2 linux/amd64 yes GOARCH=\"amd64\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"linux\"\nGOOS=\"linux\" run <URL> If possible, provide a recipe for reproducing the error.\nA complete runnable program is good.\nA link on play.golang.org is best. Field name with error message Error without field name ", "code": [], "labels": ["NeedsInvestigation"]}
{"project": "microsoft_vscode", "title": "Test Runner Viewlet with an Extension API to plug into [Enhancement Request]", "description": "In response to Erich Gamma's tweet @Krzysztof-Cieslak A test runner viewlet/sidebar with a pluggable API would be a great addition to vscode. The viewlet should include visual indications of  The test runner should be able to provide a set of sorting categories and repopulate the viewlet based on the users selection  A query box with the ability to filter the tests based on the names shown in the runner's list at a minimum, with the ability for the underlying runner to populate a set of query filters.  Instead of the VS style of collapsing categories  I think the vscode style used in the debugger viewlet is much nicer \ud83d\ude04  A button could be used to select which test runner you want to use out of the test runner extensions that have been installed  But a dropdown menu would work too  A side button to open a menu could enable the active test runner to populate it with any additional commands specific to its functionality  Some other functionality points - ", "code": [], "labels": ["feature-request"]}
{"project": "vector-im_riot-web", "title": "first class UI for bridge status and feedback", "description": "for ages we've wanted to replace the admin rooms as the main mechanism for interaction with bridges with a GUI widget that lists the health of your bridges and gives you some basic commands (and linking to the Admin window if needed). This solves the 'why is the bridge PMing me?!' questions, and could just give nice little 'you are currently bridged to IRC!' badges or LEDs etc. I don't think we have a bug for this though. It's sad to see people have to write huge guides to how to use Admin rooms when we can just shove a UI on it. This might also tie into @rxl881's current experiments... ", "code": [], "labels": ["feature", "p2"]}
{"project": "Vincit_objection.js", "title": "leverage ajv cache and serialize function", "description": "Currently objection manages the compiled schema cache itself.\nHowever ajv has a cache too.\nTo avoid that redundancy, i suggest objection could use directly the ajv cache.\nTo keep the optimization of costly serialization of the schema to build the cache key, objection could track changes in jsonSchema setter, to increment a schema non-enumerable property, used by serialize to return a cache key. ", "code": [], "labels": ["enhancement"]}
{"project": "grafana_grafana", "title": "Available dashboard list varies when opening and closing list version 1.9.0", "description": "Hi All,\nWe recently imported some dashboards created in the lab on the same 1.9.0 configuration and also deleted some of the previously created dashboards and now the dashboard list is not displaying correctly.  On the dashboard list below we imported the lower case dashboard names and removed some of the upper case dashboard names.  If we close the dashboard list by clicking on the folder icon in top right corner and then open again by clicking on the folder icon in the top right corner a different list will be populated.  Please see the differences below between screenshot 1 and screenshot 2. \n\n\n\n Is there a back-end way to just blow away the available dashboards from the list and re-import? ", "code": [], "labels": ["type/question"]}
{"project": "python_mypy", "title": "Add Python 2 support for __metaclass__", "description": "Now that we have metaclasses, we should support them for Python 2 as well. While in Python 3 the metaclass is specified as a metaclass=M keyword arg in the class heading, for Python 2 the metaclass is given by a __metaclass__ = M assignment in the body of the class. ", "code": [], "labels": ["feature"]}
{"project": "protocolbuffers_protobuf", "title": "Make php c extension portable on windows", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement", "php"]}
{"project": "helm_helm", "title": "Feat: Configuration option for tiller probeAddr IP/port.", "description": "Currently the probeAddr listens on *:44135 and it is not configurable. Together with the host networking option for tiller, installation gives unexpected external visibility for this listening point for any potential user.\nThis might have a configuration option, similarly to the grpcAddr, or in this case, I would even expect that is can be disabled entirely if not needed. ", "code": [], "labels": ["help wanted", "feature"]}
{"project": "realm_realm-cocoa", "title": "Chained queries are overwriting previous query", "description": "From google groups, I tested this as well and got the same result I was trying to test the 'Chaining queries' and I found out that it doesn't chain my queries but it overwrites the WHERE-clause. <CODE> This is the result I get: [0] Hobby {name = Michael; year = 20;}, [1] Hobby {name = Michael; year = 20;}, [2] Hobby {name = Michael; year = 20;}, [3] Hobby { name = Joske; year = 20;}) ", "code": ["RLMArray *hobbiesWithOArray = [Hobby objectsWhere:@\"name CONTAINS 'o'\"];\n\nRLMArray *hobbies = [hobbiesWithOArray objectsWhere:@\"year == 20\"];\n\nNSLog(@\"hobbies: %@\", hobbies);\n"], "labels": ["T-Bug"]}
{"project": "yannickcr_eslint-plugin-react", "title": "`boolean-prop-naming` triggers \"Cannot read property 'type' of undefined\"", "description": "Hello, When I add this rule to my .eslintrc file Visual Studio Code triggers a popup error Cannot read property 'type' of undefined. This is my rule:\n\"react/boolean-prop-naming\": [1, { \"rule\": \"(^(is|has)[A-Z]([A-Za-z0-9]?)+)|(^[a-z]+(ed|able)$)\" }], I think this is related somehow to the spread operator as the errors trigger when I type ...test ", "code": [], "labels": ["help wanted", "bug"]}
{"project": "autowarefoundation_autoware", "title": "[feature] load multiple rosbags in Simulation tab", "description": "Only one rosbag can be loaded and played in Simulation tab. It would be helpful if consecutive rosbags can be loaded at the same time. ", "code": [], "labels": ["enhancement"]}
{"project": "flutter_flutter", "title": "GridView / CustomScrollView randomly fails assert depending on childAspectRatio value and screen resolution", "description": "Since tickets with similar issues are already months (or over a year) old and still open, I'll post it as separate issue: When using GridView or CustomScrollView, any childAspectRatio (besides 1.0) has a chance to trigger this problem, due to a double precision issue: <CODE> To be more specific:\nI/flutter ( 5004): The maxPaintExtent is 208.75000000000003, but the paintExtent is 208.75000000000006. Maybe you have <CODE> Another example: <CODE> This problem seems to depend on screen size, as it only appears on certain emulated devices and not on others. Since the issue comes from sliver.dart, I can't do much from the outside: <CODE> There are a number similar issues still open, that seem to have the same cause:\n#11079\n#16086\n#16126\n#16125 If it's too difficult or time consuming to fix this issue properly right now, could the assert at least be turned into a warning instead? Right now the only \"solution\" for me is to guess the right number for childAspectRatio every time I test on a different device, as I can't seem to be able to predict the Sliver's behavior :) <CODE> ", "code": ["I/flutter ( 5004): \u2550\u2550\u2561 EXCEPTION CAUGHT BY RENDERING LIBRARY \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nI/flutter ( 5004): The following assertion was thrown during performLayout():\nI/flutter ( 5004): SliverGeometry is not valid: The \"maxPaintExtent\" is less than the \"paintExtent\".\nI/flutter ( 5004): The maxPaintExtent is 208.75000000000003, but the paintExtent is 208.75000000000006. Maybe you have\nI/flutter ( 5004): fallen prey to floating point rounding errors, and should explicitly apply the min() or max()\nI/flutter ( 5004): functions, or the clamp() method, to the paintExtent? By definition, a sliver can't paint more than\nI/flutter ( 5004): the maximum that it can paint!\nI/flutter ( 5004): The RenderSliver that returned the offending geometry was:\nI/flutter ( 5004):   RenderSliverGrid#3a956 relayoutBoundary=up11 NEEDS-LAYOUT NEEDS-PAINT\nI/flutter ( 5004):   creator: SliverGrid \u2190 SliverPadding \u2190 ShrinkWrappingViewport \u2190 _ScrollableScope \u2190\nI/flutter ( 5004):   IgnorePointer-[GlobalKey#78fe7] \u2190 Semantics \u2190 Listener \u2190 _GestureSemantics \u2190\nI/flutter ( 5004):   RawGestureDetector-[LabeledGlobalKey<RawGestureDetectorState>#ffd86] \u2190\nI/flutter ( 5004):   _ScrollSemantics-[GlobalKey#59efa] \u2190 RepaintBoundary \u2190 CustomPaint \u2190 \u22ef\nI/flutter ( 5004):   parentData: paintOffset=Offset(20.0, 20.0) (can use size)\nI/flutter ( 5004):   constraints: SliverConstraints(AxisDirection.down, GrowthDirection.forward, ScrollDirection.idle,\nI/flutter ( 5004):   scrollOffset: 0.0, remainingPaintExtent: 492.0, crossAxisExtent: 344.0, crossAxisDirection:\nI/flutter ( 5004):   AxisDirection.right, viewportMainAxisExtent: 512.0, remainingCacheExtent: 742.0 cacheOrigin: 0.0 )\nI/flutter ( 5004):   geometry: SliverGeometry(scrollExtent: 208.8, paintExtent: 208.8, maxPaintExtent: 208.8,\nI/flutter ( 5004):   hasVisualOverflow: true, cacheExtent: 208.8)\nI/flutter ( 5004):   currently live children: 0 to 11\n", "return new CustomScrollView(\n\tslivers: <Widget>[\n\t\tnew SliverPadding(\n\t\t\tpadding: const EdgeInsets.all( 20.0 ),\n\t\t\tsliver: SliverGrid.count(\n\t\t\t\tcrossAxisCount:   2,\n\t\t\t\tcrossAxisSpacing: 10.0,\n\t\t\t\tchildAspectRatio: 4.8,\n\t\t\t\tchildren:         items,\n\t\t\t),\n\t\t),\n\t],\n);\n", "\t\treturn new GridView.count(\n\t\t\tcrossAxisSpacing: 10.0,\n\t\t\tchildAspectRatio: 4.8,\n\t\t\tcrossAxisCount:   2,\n\t\t\tchildren:         items,\n\t\t);\n", "if (maxPaintExtent < paintExtent) {\n        verify(false,\n          'The \"maxPaintExtent\" is less than the \"paintExtent\".\\n' +\n          _debugCompareFloats('maxPaintExtent', maxPaintExtent, 'paintExtent', paintExtent) +\n          'By definition, a sliver can\\'t paint more than the maximum that it can paint!'\n        );\n      }\n", "[\u2713] Flutter (Channel beta, v0.9.4, on Linux, locale en_US.UTF-8)\n    \u2022 Flutter version 0.9.4 at /home/dev1/flutter\n    \u2022 Framework revision f37c235c32 (5 weeks ago), 2018-09-25 17:45:40 -0400\n    \u2022 Engine revision 74625aed32\n    \u2022 Dart version 2.1.0-dev.5.0.flutter-a2eb050044\n\n[\u2713] Android toolchain - develop for Android devices (Android SDK 28.0.3)\n    \u2022 Android SDK at /home/dev1/Android/Sdk\n    \u2022 Android NDK location not configured (optional; useful for native profiling support)\n    \u2022 Platform android-28, build-tools 28.0.3\n    \u2022 Java binary at: /home/dev1/android-studio/jre/bin/java\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1136-b06)\n    \u2022 All Android licenses accepted.\n\n[\u2713] Android Studio (version 3.2)\n    \u2022 Android Studio at /home/dev1/android-studio\n    \u2022 Flutter plugin version 29.1.1\n    \u2022 Dart plugin version 181.5656\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1136-b06)\n\n[\u2713] Connected devices (1 available)\n    \u2022 Android SDK built for x86 \u2022 emulator-5554 \u2022 android-x86 \u2022 Android 9 (API 28) (emulator)\n\n\u2022 No issues found!\n"], "labels": ["framework", "severe: crash"]}
{"project": "CleverRaven_Cataclysm-DDA", "title": "Distribute food does not display days.", "description": "Describe the bug\nText for: Total faction food stock: X kcal or X days cuts off after Xkcal if numbers are too large. To Reproduce\nSteps to reproduce the behavior: Expected behavior\nTo see total kcal and days of food stocks. It helps to plan out raids and food usage by companions. Screenshots\nIf applicable, add screenshots to help explain your problem.\n Versions and configuration(please complete the following information): ", "code": [], "labels": ["Info / User Interface", "<Suggestion / Discussion>"]}
{"project": "mrdoob_three.js", "title": "Room lights and shadows", "description": "Hello, I try to create a room full of furniture loaded from obj files. I add textures to the object. I dinamically create the walls and floor, I add lights (the extra lines in the images are from the DirectLight Helper).\nBut there are these problems: <CODE> ", "code": ["this.dirLight = new THREE.DirectionalLight( 0xffffff, 1);\nthis.dirLight.position.set( 2000,3000,2000);\nthis.dirLight.castShadow=true;\nthis.dirLight.shadowMapWidth = 2048;\nthis.dirLight.shadowMapHeight =2048;\nvar d = 1300;\nthis.dirLight.shadowCameraLeft = -d;\nthis.dirLight.shadowCameraRight = d;\nthis.dirLight.shadowCameraTop = d;\nthis.dirLight.shadowCameraBottom = -d;\nthis.dirLight.shadowCameraFar = d*10;\nthis.dirLight.shadowBias =  0.0003;\nthis.dirLight.shadowDarkness = 0.2;\n"], "labels": ["Help (please use the forum)"]}
{"project": "lucas-clemente_quic-go", "title": "Calling stream.Write with 1MB slice gives PacketPacker BUG: packet too large", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug"]}
{"project": "tootsuite_mastodon", "title": "Support using read replicas", "description": "Send writes to master, send reads to replicas when configured. Octopus seems unmaintained and incompatible with Rails 5, Makara seems promising. ", "code": [], "labels": ["performance"]}
{"project": "cockpit-project_cockpit", "title": "Start docker pull, click on other image, no more status", "description": "When you start a docker pull from Cockpit, you can see some status in the 'Images' section. However if you click on another image, and then return to the images list, you can no longer see that status. You should be able to see the status/progress messages when you return. ", "code": [], "labels": ["bug"]}
{"project": "qgis_QGIS", "title": "WFS not working at all", "description": "Author Name: Willem Buitendyk (@swaxolez)\nOriginal Redmine Issue: 19801\nAffected QGIS version: 3.2.2\nRedmine category:web_services_clients/wfs Upgraded to 3.2.2 on Mac.  WFS is completely non-responsive using WFS 1.1 or WFS 2.0.  Error coming back is: Server generated an exception in GetFeature response: org.opengis.referencing.NoSuchAuthorityCodeException: No authority was defined for code \"\". Did you forget \"AUTHORITY:NUMBER\"? In addition I'm also seeing that upon initially loading the canvas is truncated.  Opening python console or messages console, resizing and then closing allows the canvas to snap to entire screen. Related issue(s): #29258 (relates)\nRedmine related issue(s): 21441 ", "code": [], "labels": ["High Priority", "Regression", "Bug", "Data Provider"]}
{"project": "akka_akka-http", "title": "[Discuss] Prevent construction of impossible routes with types", "description": "This issue falls more into the wishlist area, and I think it makes more sense to consider it if (when) wanting to apply a lifting to the current DSL.\nThere are some directives that makes no sense to nest inside each other. For example: The current DSL doesn't prevent nor help the developer to catch such errors, and in some cases, it might lead to some wasted time debugging why a route is not called when it should.\nIt would be good if all those impossible scenarios were caught by the compiler. Another alternative would be to convince some IDE maintainers to include such checks as warnings. ", "code": [], "labels": ["discuss"]}
{"project": "opentoonz_opentoonz", "title": "\"Adjust Current Level to This Palette\" dialog strings not translated.", "description": "As the title says:  the Adjust Current Level to This Palette dialog strings do not show translated, even though the strings are translated in the toonzqt.ts file. ", "code": [], "labels": ["translation"]}
{"project": "nwjs_nw.js", "title": "The webview tag is not sized properly", "description": "Even if an explicit size has been declared, the webview tag is not sized properly when the application starts up. However, if the application's window is manually resized, then the webview immediately gets resized properly. Here is an example page that triggers the problem: When the application is launched the webview occupies roughly the height of a single line of text. The problem happens on Mac OS X Yosemite and Windows 8.1. This is in NW.js 0.13beta2 Want to back this issue? Post a bounty on it! We accept bounties via Bountysource.\n ", "code": [], "labels": ["bug", "triaged", "P2"]}
{"project": "brave_browser-laptop", "title": "64 bit Installer is not cleared on 32 bit Windows", "description": "Installer is not cleared and causes an error. STR: <CODE> cc: @bsclifton ", "code": ["2016-08-11 16:24:33> Program: Starting Squirrel Updater: --install . --rerunningWithoutUAC \n2016-08-11 16:24:34> Program: Starting install, writing to C:\\Users\\HP\\AppData\\Local\\SquirrelTemp \n2016-08-11 16:24:34> Program: About to install to: C:\\Users\\HP\\AppData\\Local\\brave \n2016-08-11 16:24:34> Program: Install path C:\\Users\\HP\\AppData\\Local\\brave already exists, burning it to the ground \n2016-08-11 16:24:41> IEnableLogger: Failed to remove existing directory on full install, is the app still running???: System.IO.IOException: The process cannot access the file 'C:\\Users\\HP\\AppData\\Local\\brave\\packages\\brave-0.11.4-full.nupkg' because it is being used by another process. \n"], "labels": ["OS/Windows", "installation", "needs-info", "bug", "stale"]}
{"project": "angular_protractor", "title": "Protractor waitforAngular() waits indefinitely and timesout", "description": "Even though the application is angular, when using the protractor function waitForAngular() it waits indefintely. First i am getting the error \"A Jasmine spec timed out. Resetting the WebDriver Control Flow.\" and then It waits for allScriptsTimeout and then stops. I could see that the element is available in the page, but it is just idle does not do anything. What is the reason, how to fix this? below is the code: <CODE> ", "code": ["    element(by.css('[ng-click=\"gencn(tokForm)\"]')).click();\n    browser.waitForAngular();\n\n    var paymentuipageelement = element(by.id('method-title'));\n    expect(paymentuipageelement.getText()).toEqual('Payment Methods');\n"], "labels": ["status: needs more info"]}
{"project": "nopSolutions_nopCommerce", "title": "Localize hard-coded resources", "description": "Nop.Services\\Catalog\\ProductAttributeFormatter.cs: \" - qty {0}\" ", "code": [], "labels": ["functionality / feature"]}
{"project": "phpDocumentor_phpDocumentor", "title": "Nothing parsed - still says everything is ok", "description": "When I run phpdoc from the phar with a custom config xml* or source & target, it runs through (very quickly) but it doesn\u2019t create any doc files except the index.html and the doc template resources. * custom config is named \"codedocu.xml\" and it's xml structure is positively validated It also doesn\u2019t create nor write anything to the given log path. It does however say that it found the source folder... so I assume it\u2019s not simply because a wrong path is given. Any clues where and how I can debug this?\nI already tried setting logging level to \"debug\" and to run it using --verbose\u2026 <CODE> When I look at the generated documentation folder, there is no \"structure.xml\" in there \u2013 which I read, should contain all the information (not sure). ", "code": ["Collecting files .. OK\nInitializing parser .. OK\nParsing files\nStoring cache in \"/output/build\" .. OK\nLoad cache                                                         ..    0.000s\nPreparing template \"clean\"                                         ..    0.006s\nPreparing 17 transformations                                       ..    0.000s\nBuild \"elements\" index                                             ..    0.000s\nReplace textual FQCNs with object aliases                          ..    0.000s\nResolve @link and @see tags in descriptions                        ..    0.000s\nEnriches inline example tags with their sources                    ..    0.000s\nBuild \"packages\" index                                             ..    0.000s\nAdding Parents to child interfaces                                 ..    0.000s\nCollect all markers embedded in tags                               ..    0.000s\nBuild \"namespaces\" index and add namespaces to \"elements\"          ..    0.000s\nAdding Parents to child classes                                    ..    0.000s\nTransform analyzed project into artifacts                          .. \nApplying 17 transformations\n  Initialize writer \"phpDocumentor\\Plugin\\Core\\Transformer\\Writer\\FileIo\"\n  Initialize writer \"phpDocumentor\\Plugin\\Twig\\Writer\\Twig\"\n  Initialize writer \"phpDocumentor\\Plugin\\Graphs\\Writer\\Graph\"\n  Execute transformation using writer \"FileIo\"\n  Execute transformation using writer \"FileIo\"\n  Execute transformation using writer \"FileIo\"\n  Execute transformation using writer \"FileIo\"\n  Execute transformation using writer \"FileIo\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"twig\"\n  Execute transformation using writer \"Graph\"\n   0.094s\nAnalyze results and write report to log                            ..    0.000s\n\n"], "labels": ["bug"]}
{"project": "OpenTTD_OpenTTD", "title": "[OSX] x86_64 binary graphics issues", "description": "planetmaker opened the ticket and wrote: Attachments Reported version: trunk\nOperating system: Mac OS X ", "code": [], "labels": ["bug", "flyspray", "Interface"]}
{"project": "wix_react-native-navigation", "title": "[V2][Ios] Custom component > setting buttons is changing the navBar padding making the component to \"dance\"", "description": "setting buttons is changing the navBar padding making the component to \"dance\" Video link: <URL>\ncode example: <URL> ", "code": [], "labels": [" stale"]}
{"project": "npm_npm", "title": "support for \"NONE\" or \"NOASSERTION\" licenses", "description": "SPDX provides for both \"NONE\" and \"NOASSERTION\" as valid license fields, but npm init accepts neither. See <URL> section Section 3.12-3.14 Is is related to #8542 and #8291 ", "code": [], "labels": ["feature-request"]}
{"project": "grpc_grpc", "title": "unit._metadata_code_details_test.MetadataCodeDetailsTest.testCustomCodeExceptionStreamUnary", "description": "Timeout in unit._metadata_code_details_test.MetadataCodeDetailsTest.testCustomCodeExceptionStreamUnary. <URL> ", "code": [], "labels": ["infra/BUILDPONY", "lang/Python"]}
{"project": "ankidroid_Anki-Android", "title": "Link to source code is missing", "description": "Originally reported on Google Code with ID 1819 <CODE> Reported by jdoe000000000 on 2013-08-06 15:56:25 ", "code": ["The \"Source\" link on the project pages goes to this URL: \"https://code.google.com/p/ankidroid/wiki/Contribution#Source_code\",\nwhich references the old Github repo. However, the source code is no longer hosted\non Github and I'm unable to find it anywhere in this repo either.\n"], "labels": ["done", "Bug"]}
{"project": "c3js_c3", "title": "Performance issue after upgrade", "description": "After upgrading from 0.3.0 to 0.4.2 I noticed a drastic drop in performance when generating many charts on a single page. I created a crude test that generates 100 charts inside a loop: Version 0.4.2: takes ~5 seconds\n<URL> Version 0.3.0: takes ~3 seconds\n<URL> Is this something that might get fixed in a future release? Any suggestions on how to optimize the rendering? Thanks. Update:\nVersion 0.4.4: ~4 seconds\n<URL> ", "code": [], "labels": ["C-performance", "C-feature-request"]}
{"project": "ckeditor_ckeditor5", "title": "Image resizer test race condition", "description": "\ud83d\udc77\u200d Task CKEditor v5 @ 12.4.0 One of tests in srcset integration test suite is causing a random fails, this can be seen especially on CI (not reproducible locally for me). The issue is probably with with the fact that test fires before the image is loaded, as the dimension (width/height) is given as NaN rather than a number. <CODE> ", "code": ["FAILED TESTS:\nImageResize\n    srcset integration\n      \u00d7 retains width after removing srcset\n\t  Chrome 77.0.3865 (Windows 10.0.0)\n\tAssertionError: DOM width check: expected NaN to be close to 80 +/- 2\n"], "labels": ["status:confirmed", "type:task"]}
{"project": "riot_riot", "title": "New riot.mount() doesn't ensure the element isn't already mounted", "description": "riot.mount() in 2.0.10 used to ensure that every element selected was a raw, unmounted DOM element (by way of elem.riot = 1, I believe).  The new riot.mount() in 2.0.11 doesn't perform this check, so depending on application logic it is possible to double mount elements, which should be an error. Even if the intent is to allow remounting of tags, there appears to be a bug in this logic -- duplication of tag content based on a single entry shouldn't be possible. Possibly related to this issue, some of my auto-mounted nested tags are being duplicated at run time. Inside one of my application tags, I reference another: <CODE> reactor-side-bar looks like this: <CODE> When I load this on the page however, this is the result: <CODE> This doesn't happen with all my nested tags though -- only this one.  I'm still trying to track down the cause. ", "code": ["<reactor-side-bar></reactor-side-bar>\n", "<reactor-side-bar>\n  <div class=\"sidebar\">\n    <div class=\"icons\"> ... </div>\n    <div class=\"panels\"> ... </div>\n  </div>\n</reactor-side-bar>\n", "<reactor-side-bar>\n  <div class=\"sidebar\">\n    <div class=\"icons\"> ... </div>\n    <div class=\"panels\"> ... </div>\n  </div>\n  <div class=\"sidebar\">\n    <div class=\"icons\"> ... </div>\n    <div class=\"panels\"> ... </div>\n  </div>\n</reactor-side-bar>\n"], "labels": ["fixed"]}
{"project": "AntennaPod_AntennaPod", "title": "Technical - reduce repetition in styles.xml", "description": "In updating themes in styles.xml, developers often have to repeat the same thing twice, once in the base theme, and once in the .NoTitle variant. It is a bit error-prone. Change .NoTitle variant so that it extends from the base so that the attributes do not need to be repeated. The tradeoff: .NoTitle variant will need to repeat AppCompat's .NoActionBar variant customization. AppCompat's .NoActionBar customization list is small (2) and static (tied to support library version), apparently with no extra complication (such as API level-specific settings), so the maintenance cost is low. ", "code": [], "labels": ["enhancement"]}
{"project": "golang_go", "title": "strings.TrimRight works not the same", "description": "Please answer these questions before submitting your issue. Thanks! go version go1.8.5 windows/amd64 no set GOARCH=amd64\nset GOBIN=\nset GOEXE=.exe\nset GOHOSTARCH=amd64\nset GOHOSTOS=windows\nset GOOS=windows\nset GOPATH=D:\\backstage\\newest\\hmi-server\\code\\gopath;D:\\golib\nset GORACE=\nset GOROOT=C:\\Go\nset GOTOOLDIR=C:\\Go\\pkg\\tool\\windows_amd64\nset GCCGO=gccgo\nset CC=gcc\nset GOGCCFLAGS=-m64 -mthreads -fmessage-length=0 -fdebug-prefix-map=C:\\Users\\yuyang\\AppData\\Local\\Temp\\go-build583116219=/tmp/go-build -gno-record-gcc-switches\nset CXX=g++\nset CGO_ENABLED=1\nset PKG_CONFIG=pkg-config\nset CGO_CFLAGS=-g -O2\nset CGO_CPPFLAGS=\nset CGO_CXXFLAGS=-g -O2\nset CGO_FFLAGS=-g -O2\nset CGO_LDFLAGS=-g -O2 <CODE> opc.tcp://188.0.0.181\nopc.tcp://188.0.0.182\nopc.tcp://188.0.0.183\nopc.tcp://188.0.0.184\nopc.tcp://188.0.0.185\nopc.tcp://188.0.0.186 opc.tcp://188.0.0.181\nopc.tcp://188.0.0.182\nopc.tcp://188.0.0.183\nopc.tcp://188.0.0.1\nopc.tcp://188.0.0.185\nopc.tcp://188.0.0.186 ", "code": ["package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\nfunc main() {\n\tfmt.Println(strings.TrimRight(\"opc.tcp://188.0.0.181:4840\", \":4840\"))\n\tfmt.Println(strings.TrimRight(\"opc.tcp://188.0.0.182:4840\", \":4840\"))\n\tfmt.Println(strings.TrimRight(\"opc.tcp://188.0.0.183:4840\", \":4840\"))\n\tfmt.Println(strings.TrimRight(\"opc.tcp://188.0.0.184:4840\", \":4840\"))\n\tfmt.Println(strings.TrimRight(\"opc.tcp://188.0.0.185:4840\", \":4840\"))\n\tfmt.Println(strings.TrimRight(\"opc.tcp://188.0.0.186:4840\", \":4840\"))\n}\n"], "labels": ["FrozenDueToAge"]}
{"project": "ansible_ansible", "title": "win_reboot hangs when reboot is too quick", "description": "win_reboot <CODE> default any If you run win_reboot and the host comes back within a very short period of time, the win_reboot action plugin will hang while waiting for the port to go offline before checking it is online. This has happened a few times with a brand new Windows install on vagrant with VirtualBox. A bit hard to reproduce, I can do it on my end with my current image but install Windows with the latest ISO and the reboot time should be too quick for win_reboot to handle win reboot to finish and continue along win_reboot eventually times out and the playbook is stopped. ", "code": ["2.4\n"], "labels": ["support:core", "affects_2.4", "module", "windows", "bug"]}
{"project": "monero-project_monero", "title": "PR #3303 breaks build for non x86_64 architectures", "description": "crypto/chacha.h calls cn_slow_hash_pre() from crypto/slow_hash.c but this method is only compiled for and so, builds for arm & x86 fail with error: undefined reference to 'cn_slow_hash_pre' ", "code": [], "labels": ["resolved"]}
{"project": "mailcow_mailcow-dockerized", "title": "rspamd subject privacy", "description": "Hi, I want to hide the subject in the rspamd logs.\nAfter a little googling I found a PR in the rspamd repo.\n#2093 This feature can enabled by settings.\nI edited the /data/conf/rspamd/local.d/history_redis.conf and added subject_privacy = true; Now it works fine but isn't persistent during updates.\nIs it possible to add a history_redis_local.conf or something like that? ", "code": [], "labels": ["dunno"]}
{"project": "mui-org_material-ui", "title": "isRtl method issue with RaisedButtons", "description": "When I add isRtl: true the Button ripples show on the wrong place; for example if i click on the right side ripple will be shown on the left side. As I saw changing isRtl method, converts some lefts css properties to some rights.\nThe ripple's position is absolute and based on the left css property in isRtl: false mode but after\nchanging isRtl to true, the left css property replaces with right css property but the value for the property is the same as before. So it fades In in the wrong direction. <URL> at line 14 and 15 ", "code": [], "labels": ["bug"]}
{"project": "servo_servo", "title": "Constellation: there should be one focused pipeline by top level browsing context id", "description": "At the moment, there is one global focused pipeline. The actual focused pipeline being the focused pipeline under the last top level browsing context sent to the compositor. ", "code": [], "labels": ["C-assigned"]}
{"project": "symless_synergy-core", "title": "Synergy server + winamp + trying to open mp3 = crash", "description": "Imported issue: Steps to reproduce: Expected: synergy should not inhibit my ability to play mp3s with winamp Actual: it does. Versions and operating systems: Temporary workarounds: Additional comments: ", "code": [], "labels": ["obsolete"]}
{"project": "ngx-formly_ngx-formly", "title": "[V3][FormlyAttributes] remove `formControl` input", "description": "I'm submitting a ...  (check one with \"x\") <CODE> passing the formControl is useless as it can be retrieved from form.formControl too. ", "code": ["[ ] bug report => search github for a similar issue or PR before submitting\n[x] feature request\n[ ] support request\n"], "labels": ["enhancement"]}
{"project": "saltstack_salt", "title": "EventPublisher consumes 100% CPU", "description": "EventPublisher process starts to consume 100% CPU, minions become mostly unavailable and any state is applied very slowly and unreliably.\nUsually EventPublisher is idling, never saw it consuming more then 1-2% CPU.\nI do not know what triggers this issue, but it's a floating bug, usually happens on the 7-15th day of uptime. hw: 8 cores, 32g ram, LA ~ 0.50\ntcp transport enabled\n~500 minions\nRunning strace against the stuck proccess shows: <CODE> Run salt-master for 7-15 days <CODE> ", "code": ["sendto(289, \"\\202\\244body\\332\\0\\313salt/job/20160815162022\"..., 218, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(394, \"\\202\\244body\\332\\0\\313salt/job/20160816103806\"..., 218, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(109, \"\\202\\244body\\332\\0\\303salt/job/20160813080233\"..., 210, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(130, \"\\202\\244body\\332\\0\\303salt/job/20160813081334\"..., 210, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(212, \"\\202\\244body\\332\\2\\24salt/auth\\n\\n\\205\\242id\\246hss485\\246\"..., 547, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(321, \"\\202\\244body\\332\\2/salt/auth\\n\\n\\205\\242id\\332\\0!devop\"..., 574, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(128, \"\\202\\244body\\332\\0\\313salt/job/20160813080843\"..., 218, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(389, \"\\202\\244body\\332\\2\\26salt/auth\\n\\n\\205\\242id\\247hss1062\"..., 549, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(344, \"\\202\\244body\\332\\0\\306salt/job/20160816013507\"..., 213, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(217, \"\\202\\244body\\332\\0\\303salt/job/20160814192519\"..., 210, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(364, \"\\202\\244body\\332\\0\\303salt/job/20160816040259\"..., 210, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(140, \"\\202\\244body\\332\\0\\303salt/job/20160813134021\"..., 210, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\nsendto(314, \"\\202\\244body\\332$\\227salt/job/20160815210650\"..., 9382, 0, NULL, 0) = -1 EAGAIN (Resource temporarily unavailable)\n", "# salt-call --versions-report\nSalt Version:\n           Salt: 2016.3.2\n\nDependency Versions:\n           cffi: 1.5.2\n       cherrypy: 2.3.0\n       dateutil: 2.4.2\n          gitdb: 0.6.4\n      gitpython: 2.0.6\n          ioflo: Not Installed\n         Jinja2: 2.8\n        libgit2: Not Installed\n        libnacl: Not Installed\n       M2Crypto: Not Installed\n           Mako: 1.0.3\n   msgpack-pure: Not Installed\n msgpack-python: 0.4.6\n   mysql-python: Not Installed\n      pycparser: 2.14\n       pycrypto: 2.6.1\n         pygit2: Not Installed\n         Python: 2.7.12 (default, Jul  1 2016, 15:12:24)\n   python-gnupg: Not Installed\n         PyYAML: 3.11\n          PyZMQ: 15.2.0\n           RAET: Not Installed\n          smmap: 0.9.0\n        timelib: 0.2.4\n        Tornado: 4.2.1\n            ZMQ: 4.1.4\n\nSystem Versions:\n           dist: Ubuntu 16.04 xenial\n        machine: x86_64\n        release: 4.4.0-31-generic\n         system: Linux\n        version: Ubuntu 16.04 xenial\n\n# pip freeze\napache-libcloud==0.20.0\nazure==1.0.3\nazure-common==1.1.4\nazure-mgmt==0.20.2\nazure-mgmt-common==0.20.0\nazure-mgmt-compute==0.20.1\nazure-mgmt-network==0.20.1\nazure-mgmt-nspkg==1.0.0\nazure-mgmt-resource==0.20.1\nazure-mgmt-storage==0.20.0\nazure-nspkg==1.0.0\nazure-servicebus==0.20.1\nazure-servicemanagement-legacy==0.20.2\nazure-storage==0.20.3\ncffi==1.5.2\nchardet==2.3.0\nCherryPy==2.3.0\ncroniter==0.3.8\ncryptography==1.2.3\nenum34==1.1.2\nfutures==3.0.5\ngitdb==0.6.4\nGitPython==2.0.6\nidna==2.0\ninotify==0.2.6\nipaddress==1.0.16\nJinja2==2.8\nlockfile==0.12.2\nMako==1.0.3\nMarkupSafe==0.23\nmsgpack-python==0.4.6\nndg-httpsclient==0.4.0\nnetaddr==0.7.18\nply==3.7\npyasn1==0.1.9\npycparser==2.14\npycrypto==2.6.1\npycurl==7.43.0\nPyMySQL==0.7.2\npyOpenSSL==0.15.1\npython-apt==1.1.0b1\npython-dateutil==2.4.2\npython-systemd==231\npytz==2014.10\nPyYAML==3.11\npyzmq==15.2.0\nrequests==2.9.1\nsalt==2016.3.2\nsetproctitle==1.1.10\nsimplejson==3.8.1\nsix==1.10.0\nsmmap==0.9.0\ntimelib==0.2.4\ntornado==4.2.1\nujson==1.35\nurllib3==1.13.1\n"], "labels": ["Core", "Critical", "Bug", "Fixed Pending Verification", "P4"]}
{"project": "signalapp_Signal-Android", "title": "Intolerance against crashed services", "description": "TextSecure is not robust if its services are crashed/quitted. This may cause all kinds of bugs. For example, follow the following steps to reproduce two problems. I've also pulled a debug log: <URL> (taken by Bob after step 5) Finally - this reliably reproduces delayed as well as bad encrypted messages. Really hope it helps! ", "code": [], "labels": ["bug"]}
{"project": "coq_coq", "title": "Warning: Invalid character '-' in identifier \"_UNBOUND_REL_-1\".", "description": "Note: the issue was created automatically with bugzilla2github tool Original bug ID: BZ#2956\nFrom: @JasonGross\nReported version: 8.4\nCC:   @herbelin, @JasonGross, @letouzey ", "code": [], "labels": ["platform: Windows"]}
{"project": "woocommerce_woocommerce", "title": "Skip shipping calculation on add to cart action", "description": "Is your feature request related to a problem? Please describe.\nI have several shipping methods that require external requests. One to calculate the cost and one for delivery time. So I've got 7 methods which result in 14 requests each time when a user with a filled address adds item in a cart. So adding product to cart takes around 10 seconds (depending on speed connection).  I have tried to skip calculation but in this case, all rates already stored in a session and recalculate it without modifying cart is impossible Describe the solution you'd like\nCan you add method which forces recalculating rates on a cart and checkout page or simply do not store session rates on add to cart action Thank you for your time ", "code": [], "labels": ["enhancement"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Theme per server", "description": "<CODE> It should change the theme based on server. It uses the default theme instead Operating system: Ubuntu Web server: Nginx Database: AWS RDS PHP version: 7.0 phpMyAdmin version: 4.7.1 Browser: Opera/Chrome Operating system: OS sierra ", "code": ["$i++;\n$cfg['Servers'][$i]['verbose'] = 'server1';\n$cfg['Servers'][$i]['auth_type'] = 'cookie';\n$_COOKIE['pma_theme-' . $i] = 'custom1';\n\n$i++;\n$cfg['Servers'][$i]['verbose'] = 'server2';\n$cfg['Servers'][$i]['auth_type'] = 'cookie';\n$_COOKIE['pma_theme-' . $i] = 'custom2';\n"], "labels": ["bug"]}
{"project": "mozilla-mobile_fenix", "title": "[Bug] Tab Header in RTL language overlaps menu icons", "description": " ", "code": [], "labels": [" bug"]}
{"project": "bumptech_glide", "title": "Registry$NoModelLoaderAvailableException", "description": "com.bumptech.glide.Registry$NoModelLoaderAvailableException: Failed to find any ModelLoaders for model: com.jiulong.yizhitong.entity.medicalMeeting.MeetingDetails$AreaImages@f0c1ae6\nat com.bumptech.glide.Registry.getModelLoaders(Registry.java:584)\nat com.bumptech.glide.load.engine.DecodeHelper.getLoadData(DecodeHelper.java:205)\nat com.bumptech.glide.load.engine.DecodeHelper.getCacheKeys(DecodeHelper.java:223)\nat com.bumptech.glide.load.engine.ResourceCacheGenerator.startNext(ResourceCacheGenerator.java:44)\nat com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:302)\nat com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:269)\nat com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:233)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1112)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:587)\nat java.lang.Thread.run(Thread.java:818)\nat com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:446) \u96c6\u6210\u7684\u6700\u65b0\u7248\u672c   \u52a0\u8f7d\u56fe\u7247\u62a5\u8fd9\u4e2a\u9519 ", "code": [], "labels": ["stale", "question"]}
{"project": "arendst_Tasmota", "title": "Different Displays on direct access and over webserver", "description": "IMPORTANT NOTICE\nIf you do not complete the template below it is likely that your issue will not be addressed. When providing information about your issue please be as extensive as possible so that it can be solved by as little as possible responses. Make sure these boxes are checked [x] before submitting your issue - Thank you! <CODE> ", "code": ["STATUS 0 OUTPUT HERE\n{\"Status\":{\"Module\":1,\"FriendlyName\":[\"Sonoff1\"],\"Topic\":\"sonoff\",\"ButtonTopic\":\"0\",\"Power\":0,\"PowerOnState\":3,\"LedState\":1,\"SaveData\":1,\"SaveState\":1,\"SwitchTopic\":\"0\",\"SwitchMode\":[0,0,0,0,0,0,0,0],\"ButtonRetain\":0,\"SwitchRetain\":0,\"SensorRetain\":0,\"PowerRetain\":0},\"StatusPRM\":{\"Baudrate\":115200,\"GroupTopic\":\"sonoffs\",\"OtaUrl\":\"http://sonoff.maddox.co.uk/tasmota/sonoff.bin\",\"RestartReason\":\"Software/System restart\",\"Uptime\":\"0T00:53:21\",\"StartupUTC\":\"\",\"Sleep\":0,\"BootCount\":446,\"SaveCount\":863,\"SaveAddress\":\"F9000\"},\"StatusFWR\":{\"Version\":\"6.3.0\",\"BuildDateTime\":\"2018.10.30 17:39:28\",\"Boot\":31,\"Core\":\"2_3_0\",\"SDK\":\"1.5.3(aec24ac9)\"},\"StatusLOG\":{\"SerialLog\":2,\"WebLog\":2,\"SysLog\":0,\"LogHost\":\"\",\"LogPort\":514,\"SSId\":[\"7050\",\"7050-box\"],\"TelePeriod\":300,\"SetOption\":[\"00008001\",\"55818000\",\"00000001\"]},\"StatusMEM\":{\"ProgramSize\":490,\"Free\":512,\"Heap\":12,\"ProgramFlashSize\":1024,\"FlashSize\":1024,\"FlashMode\":3,\"Features\":[\"00000407\",\"0FDAE794\",\"000183A0\",\"23B617CE\",\"00003BC0\"]},\"StatusNET\":{\"Hostname\":\"sonoff-7328\",\"IPAddress\":\"192.168.1.27\",\"Gateway\":\"192.168.1.27\",\"Subnetmask\":\"255.255.255.0\",\"DNSServer\":\"192.168.2.27\",\"Mac\":\"60:01:94:5D:FC:A0\",\"Webserver\":2,\"WifiConfig\":3},\"StatusTIM\":{\"UTC\":\"Thu Jan 01 00:53:24 1970\",\"Local\":\"Thu Jan 01 00:53:24 1970\",\"StartDST\":\"Thu Jan 01 00:00:00 1970\",\"EndDST\":\"Thu Jan 01 00:00:00 1970\",\"Timezone\":1,\"Sunrise\":\"07:43\",\"Sunset\":\"16:03\"},\"StatusSNS\":{\"Time\":\"1970-01-01T00:53:24\"},\"StatusSTS\":{\"Time\":\"1970-01-01T00:53:24\",\"Uptime\":\"0T00:53:21\",\"Vcc\":3.142,\"POWER\":\"OFF\",\"Wifi\":{\"AP\":1,\"SSId\":\"7050\",\"BSSId\":\"C4:6E:1F:3A:87:82\",\"Channel\":6,\"RSSI\":60}}}\n\nDisplay Information-Panel:\n\nTasmota Version | 6.3.0\n-- | --\n2018.10.30 17:39:28\n2_3_0/1.5.3(aec24ac9)\n0T00:57:18\n863 at F9000\n446\nSoftware/System restart\nSonoff1\n\u00a0\n7050 (60%)\nsonoff-7328.local\n192.168.1.27\n192.168.1.27\n255.255.255.0\n192.168.2.27\n60:01:94:5D:FC:A0\n\u00a0\ndeaktiviert\n\u00a0\nkeine\naktiviert\nWeb-Server\n\u00a0\n6159520\n1327198\n1024kB\n1024kB\n490kB\n512kB\n13kB\n\n![direct-access](https://user-images.githubusercontent.com/14790813/47741844-9abd8580-dc7b-11e8-831a-d259223b481a.png)\n![over-webserver](https://user-images.githubusercontent.com/14790813/47741855-a27d2a00-dc7b-11e8-9a44-c61269286239.png)\n\n\n\nThe Problem is that on the Display over my Webserver nginx the message ON or OFF disappears and switching is not possible. \nI have addressed the SONOFF over a proxy statement in nginx, it is possible that this configuration causes the problem.\nConfiguration Statements in nginx:\nlocation /huhnschalter1 {\nproxy_intercept_errors on;\n            proxy_bind $server_addr;\n            proxy_pass              http://192.168.1.30:80/;\n           proxy_set_header Authorization \"Basic coded password\";\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header Host $http_host;\n            proxy_set_header X-NginX-Proxy true;\n            proxy_read_timeout      90;\n        } \n\n**(Please, remember to close the issue when the problem has been addressed)**\n"], "labels": ["question"]}
{"project": "trufflesuite_truffle", "title": "[BETA] truffle debug - ReferenceError: callback is not defined", "description": "When I run truffle debug without a transaction hash I get this stack trace: <CODE> callback is not defined in this context, so error handling needs to be different here. I don't know the code, but looks to me like it should probably be Run truffle debug I expected Truffle to provide a helpful error message. Truffle provides a confusing error message. ", "code": ["$ truffle debug\nReferenceError: callback is not defined\n    at /[my project folder]/node_modules/truffle-core/lib/commands/debug.js:39:9\n    at web3.eth.getAccounts.then.accounts (/[my project folder]/node_modules/truffle-core/lib/environment.js:72:9)\n    at process._tickCallback (internal/process/next_tick.js:68:7)\n"], "labels": ["Debugger"]}
{"project": "react-native-elements_react-native-elements", "title": "Icon won't display in button. Posted solutions not working. (Is there an old version of the docs available?)", "description": "So this app I'm working on has been in development since last year, and it's so heavily reliant on RNE, that changing the version would be more trouble than it's worth... However, the docs only provide support for the most recent version. Also please include the version of react-native-elements that you are using.\n0.17.0 Button Code <CODE> Button styles <CODE> Can you suggest a possible fix that would address this issue?\nReleasing an older version of the docs for those of us who can't upgrade versions due to the amount of restyling work it would require. The other solutions posted for this problem have not helped me ", "code": ["<Button \n    buttonStyle={ styles.backButton }\n    icon={{ name:'navigate-before', color:'white', size:20 }}\n    onPress={() => {\n        navigate('Login');\n    }}\n/>\n", "backButton: {\n    width: 40,\n    height: 40,\n    backgroundColor: 'forestgreen',\n    borderColor: 'white',\n    borderWidth: 2,\n    borderRadius: 25\n},\n"], "labels": [" Help Wanted"]}
{"project": "duplicati_duplicati", "title": "VSS on Windows 8.1, Duplicati 2.0.0.73", "description": "First, I've read similar reports, but they all indicate that the problem is resolved in the latest Duplicati, but for me it isn't. Here is the error: Failed to create a snapshot: Alphaleonis.Win32.Vss.VssUnexpectedProviderErrorException: The provider returned an unexpected error code.\nat Alphaleonis.Win32.Vss.VssBackupComponents.IsVolumeSupported(String volumeName)\nat Duplicati.Library.Snapshots.WindowsSnapshot..ctor(String[] sourcepaths, Dictionary'2 options)\nat Duplicati.Library.Main.Operation.BackupHandler.GetSnapshot(String[] sources, Options options, ILogWriter log) => Alphaleonis.Win32.Vss.VssUnexpectedProviderErrorException: The provider returned an unexpected error code.\nat Alphaleonis.Win32.Vss.VssBackupComponents.IsVolumeSupported(String volumeName)\nat Duplicati.Library.Snapshots.WindowsSnapshot..ctor(String[] sourcepaths, Dictionary'2 options)\nat Duplicati.Library.Main.Operation.BackupHandler.GetSnapshot(String[] sources, Options options, ILogWriter log)]\nErrors: [] I have the following Microsoft Visual C++ Redistributables installed (both x86 and x64 versions)\n8.0.61001\n8.0.59193\n8.0.59192\n8.0.61000\n9.0.30729.4148\n9.0.30729.6161\n10.0.40219\n11.0.61030.0 I'm running Duplicati through the Task Scheduler with elevated privileges. Want to back this issue? Post a bounty on it! We accept bounties via Bountysource.\n ", "code": [], "labels": ["bug"]}
{"project": "openlayers_openlayers", "title": "ol.source.TileWMS does not respect maxZoom option", "description": "It seems that ol.source.TileWMS does not pass maxZoom on to it's parent's constructor: <URL> Adding it is of course a simple fix, but I'm curious about if there are other options lost with different subclasses. What is the reason for explicitly declaring every option member to pass on to the parent construction instead of passing all options except those that the subclass determines should be changed/removed? ", "code": [], "labels": ["stale"]}
{"project": "solus-project_budgie-desktop", "title": "Scale for menu and title bars", "description": "This feature will be great for the users that have a low resolution. I did test in in ubuntu unity  and it's by far the best way to increase the productivity by having a cleaner and smaller desktop. On the other side can help the users that have a hi rez screen by make all things bigger.\nFirst screenshot is with the normal scale of the os\n\n\n ", "code": [], "labels": ["enhancement"]}
{"project": "saltstack_salt", "title": "file.replace doesn't replace `pattern` when `repl` exists", "description": "file.replace was modified in v2014.7.1 so that it doesn't make changes if it finds the repl string. However, it's not making changes even if pattern does exist in the file. It seems that the correct behavior would be for file.replace to replace pattern even if repl exists. Here's the test case: <CODE> At the end of that, I'd expect that 'abc' would have been replaced by 'baz'. As recently as v2014.7.0, it worked as expected: <CODE> ", "code": ["# echo \"baz\" > ~/foo\n# echo \"abc\" >> ~/foo\n# cat ~/foo\nbaz\nabc\n# salt-call --local file.replace ~/foo abc baz\nlocal:\n\n# cat ~/foo\nbaz\nabc\n", "# salt-call --local file.replace ~/foo abc baz\nlocal:\n    ---\n    +++\n    @@ -1,2 +1,2 @@\n     baz\n    -abc\n    +baz\n# cat ~/foo\nbaz\nbaz\n"], "labels": ["Medium Severity", "Regression", "Bug"]}
{"project": "firasdib_Regex101", "title": "Non-raw string checking in python regex interface", "description": "Short version: It would be nice to have the option to turn off the expectation that the input string will be a raw string. In particular this arises in the context of you working with regular expressions that have been created by someone else in a programmatic fashion (i.e., are never encoded as raw literal strings). This service is awesome for exploring the meaning & interpretation of regular expressions, but in cases where you are debugging an extant regular expression that already exists in memory my_exp.pattern will successfully give you a string, but there is no straightforward way to transform that string into what would be its raw literal equivalent. Fixing these weird escaping edge cases can be really slow and tiresome. Rather than requiring this effort, it'd be much nicer if there were a way to simply create a string literal instead of a raw string literal! Long version (with example): I have been trying to debug some issues that have arisen around <URL> & <URL> Mistune programmatically creates many regular expressions After a while, I figured out how to get the pattern that was causing an issue. As a string obtained via rule.pattern it was: The problem is that if you were to express this in terms of it's raw literal value, which copying and pasting that into the current regex101.com interface, this would be interpreted as Which is wrong, it's actually treating the \\\\ as unescaped \\'s therefore expecting all cases that should be \\ (for example in defining shorthand character classes like \\s) to be \\\\. One way to get at this would be to attempt to print it, but then that introduced the issue of unescaping punctuation marks (e.g.,  \\' becoming ') which meant that regex was no longer a valid python string if delimited by either ' or \": To fix this required manually editing the printed output to re\u00ebscape the punctuation (specifically ' and \") or noticing that there were no doubled single-quotes (''\u2026'') or doubled double-quotes (\"\"\u2026\"\") and changing the delimiter to match that. Rather than requiring this effort, it'd be much nicer if there were a way to simply create a string literal instead of a raw string literal, since I could have then just directly copied and pasted the existing string literal representation. It took a lot of time looking up how to \"recreate\" what would have been the raw string literal content and I'd like no one else to have to do that if it can be avoided. ", "code": [], "labels": ["won't fix", "feature request", "enhancement"]}
{"project": "vector-im_riot-web", "title": "clicking on user IDs in the timeline has regressed", "description": "clicking on @matthew:matrix.org explodes in MemberInfo.js:861 Uncaught TypeError: Cannot read property 'getContent' of null ", "code": [], "labels": ["p1", "cannot-reproduce", "major", "bug", "question"]}
{"project": "microsoft_TypeScript", "title": "Should leading ampersands (&) be allowed in intersection types?", "description": "TypeScript Version:  2.4.2 / playground (2.3.?) Code Expected behavior:\nEmits error, since language spec said, in the subsection 3.8.7 Actual behavior:\nDoesn't emit error and uses it as number & string. ", "code": [], "labels": ["Working as Intended"]}
{"project": "serverless_serverless", "title": "Feature Request: Set Concurrency Limits on Individual AWS Lambda", "description": "Following AWS announcement of the ability to set the concurrency limit per each Lambda function (<URL>, it would be nice to get this ability through the serverless framework. For bug reports: For feature proposals: <CODE> Similar or dependent issues: ", "code": ["functions:\n  hello:\n    handler: handler.hello # required, handler set in AWS Lambda\n    name: ${self:provider.stage}-lambdaName # optional, Deployed Lambda name\n    description: Description of what the lambda function does \n    concurrency: 5\n"], "labels": ["good first issue", "help wanted", "feature"]}
{"project": "fishtown-analytics_dbt", "title": "Cross-db utils defined in adapter macros", "description": "Currently, there is no way to add adapter versions to crucial utility macros, such as the ones defined in dbt-utils, without opening PRs against each macro package. Specific use case: We want to implement date_spine on Spark. The only required changes are special implementations of dateadd and datediff, as on this branch. (The rest of the date spine works exactly the same.) In the long run, we should not house an implementation of these core functions, for every single adapter, in the dbt-utils package. Ideally, we'd be able to create extension packages, e.g. dbt-utils-spark-ext, that include just the custom implementations for a few critical macros. But this doesn't work with the way that package macros are currently scoped. We need some system of dependency resolution. My best current proposal: Implement the cross_db_utils in the  dbt/include/adapters.sql of each adapter plugin. Packages like dbt_utils call these adapter macros instead of calling macros name-spaced to specific packages. Anyone running dbt with an adapter outside of the Core Four. At present, that list includes Presto and Spark. ", "code": [], "labels": ["enhancement"]}
{"project": "microsoft_TypeScript", "title": "Incomplete function return type", "description": "TypeScript Version:  2.9.2 Search Terms:  Union Code Expected behavior:\nReturn type of noUnion function should be { key: boolean; } | { key: boolean; data: string; } Actual behavior:\nnoUnion return type is { key: boolean; } Playground Link: \n<URL> Related Issues: \n#25321 ", "code": [], "labels": ["Working as Intended"]}
{"project": "aws_aws-sdk-go", "title": "Textract", "description": "when is it gonna be included in the SDK? 1.16 go 1.11 Textract is not supported ", "code": [], "labels": ["service-api"]}
{"project": "grpc_grpc-go", "title": "adding a new rpc to a proto is a breaking api change", "description": "While I can understand that sun-setting a field (read: reserved field) in a proto would lead to a breaking change in generated Go code, it confuses me why adding a new rpc would also cause a breaking API change. (Reproducer available upon request.) ", "code": [], "labels": ["Status: Duplicate"]}
{"project": "rspamd_rspamd", "title": "[BUG] ContOS 7 / CentOS8 rspamd_symcache_load_items: cannot open file /var/lib/rspamd/symbols.cache", "description": "Describe the bug Rspamd cannot open file /var/lib/rspamd/symbols.cache 2019-10-15 11:10:54 #561(main) ; symcache; rspamd_symcache_load_items: cannot open file /var/lib/rspamd/symbols.cache, error 2, No such file or directory\n2019-10-15 11:14:48 #564(normal) <48cdd1>; lua; common.lua:223: got error checking cache: timeout while connecting the server For testing I created the empty file and chmod _rspamd:_rspamd, which resulted in: 2019-10-15 11:57:16 #648(main) ; symcache; rspamd_symcache_load_items: cannot use file /var/lib/rspamd/symbols.cache, error 22, Invalid argument Expected behavior No error. Rspamd daemon version 2.0 OS: CentOS 8 running in the latest Proxmox (cpu: Sandy Bridge)\nLinux 4.18.0-80.el8.x86_64 Same problem exists when running Rspamd 2.0 in a CentOS 7 Linux Container: OS: CentOS 7 running in the latest Proxmox (cpu: Sandy Bridge)\nKernel 5.0.21-2-pve on an x86_64 ", "code": [], "labels": ["bug", "wontfix"]}
{"project": "appium_appium", "title": "Appium :: org.openqa.selenium.SessionNotCreatedException: Unable to create a new remote session", "description": "Below is the exception on the appium server NOTE : Before the update it was working properly. Below are the logs that I Get on eclipse console :: <CODE> <CODE> [XCUITest] Continuing without capturing device logs: Connection was refused to port 57483\n[XCUITest] Setting up real device\n[XCUITest] Error: Connection was refused to port 57486\n[XCUITest]     at Usbmux.connect (/Applications/Appium.app/Contents/Resources/app/node_modules/appium-ios-device/lib/usbmux/index.js:183:13)\n[DevCon Factory] Releasing connections for f29645da08dedad0760f2efa2e451949ea4124d2 device on any port number\n[DevCon Factory] No cached connections have been found\n[BaseDriver] Event 'newSessionStarted' logged at 1576053574827 (14:09:34 GMT+0530 (IST))\n[W3C] Encountered internal error running command: Error: Connection was refused to port 57486\n[W3C]     at Usbmux.connect (/Applications/Appium.app/Contents/Resources/app/node_modules/appium-ios-device/lib/usbmux/index.js:183:13)\n[HTTP] <-- POST /wd/hub/session 500 80492 ms - 702 ", "code": ["FAILED CONFIGURATION: @BeforeTest beforeTest\norg.openqa.selenium.SessionNotCreatedException: Unable to create a new remote session. Please check the server log for more details. Original error: An unknown server-side error occurred while processing the command. Original error: Connection was refused to port 53359\nBuild info: version: '3.141.59', revision: 'e82be7d358', time: '2018-11-14T08:17:03'\nSystem info: host: 'M16IMACHDMGG7J.local', ip: '127.0.0.1', os.name: 'Mac OS X', os.arch: 'x86_64', os.version: '10.15.1', java.version: '12.0.1'\nDriver info: driver.version: IOSDriver\nremote stacktrace: UnknownError: An unknown server-side error occurred while processing the command. Original error: Connection was refused to port 53359\n    at getResponseForW3CError (/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-base-driver/lib/protocol/errors.js:804:9)\n    at asyncHandler (/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-base-driver/lib/protocol/protocol.js:388:37)\n    at process._tickCallback (internal/process/next_tick.js:68:7)\nBuild info: version: '3.141.59', revision: 'e82be7d358', time: '2018-11-14T08:17:03'\nSystem info: host: 'M16IMACHDMGG7J.local', ip: '127.0.0.1', os.name: 'Mac OS X', os.arch: 'x86_64', os.version: '10.15.1', java.version: '12.0.1'\nDriver info: driver.version: IOSDriver\n\tat io.appium.java_client.remote.AppiumCommandExecutor$1.createSession(AppiumCommandExecutor.java:208)\n\tat io.appium.java_client.remote.AppiumCommandExecutor.createSession(AppiumCommandExecutor.java:217)\n\tat io.appium.java_client.remote.AppiumCommandExecutor.execute(AppiumCommandExecutor.java:239)\n\tat org.openqa.selenium.remote.RemoteWebDriver.execute(RemoteWebDriver.java:552)\n\tat io.appium.java_client.DefaultGenericMobileDriver.execute(DefaultGenericMobileDriver.java:41)\n\tat io.appium.java_client.AppiumDriver.execute(AppiumDriver.java:1)\n\tat io.appium.java_client.ios.IOSDriver.execute(IOSDriver.java:1)\n\tat org.openqa.selenium.remote.RemoteWebDriver.startSession(RemoteWebDriver.java:213)\n\tat io.appium.java_client.AppiumDriver.startSession(AppiumDriver.java:323)\n\tat org.openqa.selenium.remote.RemoteWebDriver.<init>(RemoteWebDriver.java:131)\n\tat io.appium.java_client.DefaultGenericMobileDriver.<init>(DefaultGenericMobileDriver.java:37)\n\tat io.appium.java_client.AppiumDriver.<init>(AppiumDriver.java:86)\n\tat io.appium.java_client.AppiumDriver.<init>(AppiumDriver.java:96)\n\tat io.appium.java_client.ios.IOSDriver.<init>(IOSDriver.java:92)\n\tat utils.Capability.capability_phone(Capability.java:53)\n\tat testcases.search.beforeTest(search.java:74)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:124)\n\tat org.testng.internal.MethodInvocationHelper.invokeMethodConsideringTimeout(MethodInvocationHelper.java:59)\n\tat org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:458)\n\tat org.testng.internal.Invoker.invokeConfigurations(Invoker.java:222)\n\tat org.testng.internal.Invoker.invokeConfigurations(Invoker.java:142)\n\tat org.testng.TestRunner.beforeRun(TestRunner.java:529)\n\tat org.testng.TestRunner.run(TestRunner.java:497)\n\tat org.testng.SuiteRunner.runTest(SuiteRunner.java:455)\n\tat org.testng.SuiteRunner.runSequentially(SuiteRunner.java:450)\n\tat org.testng.SuiteRunner.privateRun(SuiteRunner.java:415)\n\tat org.testng.SuiteRunner.run(SuiteRunner.java:364)\n\tat org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)\n\tat org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:84)\n\tat org.testng.TestNG.runSuitesSequentially(TestNG.java:1208)\n\tat org.testng.TestNG.runSuitesLocally(TestNG.java:1137)\n\tat org.testng.TestNG.runSuites(TestNG.java:1049)\n\tat org.testng.TestNG.run(TestNG.java:1017)\n\tat org.testng.remote.AbstractRemoteTestNG.run(AbstractRemoteTestNG.java:115)\n\tat org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:251)\n\tat org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:77)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat io.appium.java_client.remote.AppiumCommandExecutor$1.createSession(AppiumCommandExecutor.java:186)\n\t... 39 more\nCaused by: org.openqa.selenium.WebDriverException: An unknown server-side error occurred while processing the command. Original error: Connection was refused to port 53359\nBuild info: version: '3.141.59', revision: 'e82be7d358', time: '2018-11-14T08:17:03'\nSystem info: host: 'M16IMACHDMGG7J.local', ip: '127.0.0.1', os.name: 'Mac OS X', os.arch: 'x86_64', os.version: '10.15.1', java.version: '12.0.1'\nDriver info: driver.version: IOSDriver\nremote stacktrace: UnknownError: An unknown server-side error occurred while processing the command. Original error: Connection was refused to port 53359\n    at getResponseForW3CError (/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-base-driver/lib/protocol/errors.js:804:9)\n    at asyncHandler (/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-base-driver/lib/protocol/protocol.js:388:37)\n    at process._tickCallback (internal/process/next_tick.js:68:7)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)\n\tat org.openqa.selenium.remote.W3CHandshakeResponse.lambda$errorHandler$0(W3CHandshakeResponse.java:62)\n\tat org.openqa.selenium.remote.HandshakeResponse.lambda$getResponseFunction$0(HandshakeResponse.java:30)\n\tat org.openqa.selenium.remote.ProtocolHandshake.lambda$createSession$0(ProtocolHandshake.java:126)\n\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)\n\tat java.base/java.util.Spliterators$ArraySpliterator.tryAdvance(Spliterators.java:958)\n\tat java.base/java.util.stream.ReferencePipeline.forEachWithCancel(ReferencePipeline.java:127)\n\tat java.base/java.util.stream.AbstractPipeline.copyIntoWithCancel(AbstractPipeline.java:502)\n\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:488)\n\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)\n\tat java.base/java.util.stream.FindOps$FindOp.evaluateSequential(FindOps.java:150)\n\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.base/java.util.stream.ReferencePipeline.findFirst(ReferencePipeline.java:543)\n\tat org.openqa.selenium.remote.ProtocolHandshake.createSession(ProtocolHandshake.java:128)\n\t... 44 more\n", "Capability which I am using are as follows :\n\n public static IOSDriver capability_phone() throws MalformedURLException {\n final String URL_STRING = \"http://0.0.0.0:4723/wd/hub\";\n url = new URL(URL_STRING);\nDesiredCapabilities cap = new DesiredCapabilities();\ncap.setCapability(\"deviceName\",\"iPhone7_Hml\");\ncap.setCapability(\"udid\",\"89c4364185f2f1dba22992faaae1179e32a4eb41\");\ncap.setCapability(\"platformVersion\",\"13.2\");\ncap.setCapability(\"platformName\",\"IOS\");\ncap.setCapability(\"automationName\", \"XCUITest\");\ncap.setCapability(\"bundleId\",\"com.hungama.myplay\");\ncap.setCapability(\"noReset\",true);\ncap.setCapability(\"xcodeSigningId\", \"iPhone Developer\");\n cap.setCapability(\"xcodeOrgId\", \"XXXXXXXXXXXXXXXXXXXX\");\n cap.setCapability(\"newCommandTimeout\", 160);\n we = new IOSDriver(url, cap);\n we.manage().timeouts().implicitlyWait(2, TimeUnit.SECONDS);\nSystem.out.println(\" ~~~ !!! Setting the capabilities !!! ~~~ \");\n return we;\n    \t}\n"], "labels": ["XCUITest"]}
{"project": "google_ExoPlayer", "title": "Unable to resolve dependency for exoplayer-library-core", "description": "I have created a new project in latest android studio and when I am adding exoplayer locally as shown on github then I am getting unable to resolve dependency for exoplayer-library-core and same for HLS, UI, DASH ", "code": [], "labels": ["question"]}
{"project": "googleapis_google-cloud-go", "title": "bigquery: integration test that asserts x-goog-api-client (and related headers) is being sent", "description": "go/cloud-api-headers-2019 ", "code": [], "labels": ["type: feature request", "api: bigquery"]}
{"project": "eslint_eslint", "title": "Improve `padding-line-between-statements` for `delete` operator", "description": "What rule do you want to change? padding-line-between-statements Does this change cause the rule to produce more or fewer warnings? more How will the change be implemented? (New option, new default behavior, etc.)? Add delete to STATEMENT_TYPE. I understand that this is not entirely true because it is a unary expression with delete operator, but maybe it will be easy to understand other developers. Please provide some example code that this change will affect: What does the rule currently do for this code? No errors/warnings for code above What will the rule do after it's changed? Require newline before/after delete (depends on how the developer setup the rule) Are you willing to submit a pull request to implement this change? Yes ", "code": [], "labels": ["rule", "evaluating", "auto closed", "enhancement"]}
{"project": "microsoft_vscode", "title": "Cannot read property 'type' of undefined when restart a debug session with DebugAdapterTracker hookup", "description": "This only happen when liveshare is installed and we register our 'generic' adapter tracker to 'spy' messages. It will happen during restart only, normal debugging works fine. i found the offending code and it seems to be on 'extHostDebugService.ts'.\nBTW, the marketplace liveshare extension is broken against the latest debug API, we a private VSIX with those fixes if necessary to repro the issue, i suspect it will happen for other extension that use the new tracking API's public $startDASession(debugAdapterHandle: number, sessionDto: IDebugSessionDto): Thenable {\nconst mythis = this; <CODE> ", "code": ["const session = this.getSession(sessionDto); <=== this return 'undefined'\nreturn this.getAdapterDescriptor(this.getAdapterProviderByType(session.type), session).then(x => {\n"], "labels": ["bug", "debug", "verified"]}
{"project": "unbit_uwsgi", "title": "lazy-apps and start issue", "description": "Hi, I got \"lazy-apps = True; worker = 4\", and an error in the application, so that it can start ... ...\nThu Oct  1 12:37:34 2015 - DAMN ! worker 3 (pid: 27566) died :( trying respawn ...\nThu Oct  1 12:37:34 2015 - worker respawning too fast !!! i have to sleep a bit (2 seconds)...\nThu Oct  1 12:37:36 2015 - Respawned uWSGI worker 3 (new pid: 27600)\nThu Oct  1 12:37:36 2015 - DAMN ! worker 4 (pid: 27567) died :( trying respawn ...\nThu Oct  1 12:37:36 2015 - Respawned uWSGI worker 4 (new pid: 27601)\nThu Oct  1 12:37:36 2015 - DAMN ! worker 2 (pid: 27569) died :( trying respawn ...\nThu Oct  1 12:37:36 2015 - Respawned uWSGI worker 2 (new pid: 27602)\nThu Oct  1 12:37:36 2015 - DAMN ! worker 1 (pid: 27590) died, killed by signal 6 :( trying respawn ...\nThu Oct  1 12:37:36 2015 - Respawned uWSGI worker 1 (new pid: 27603) Thu Oct  1 12:37:37 2015 - DAMN ! worker 3 (pid: 27600) died :( trying respawn ...\nThu Oct  1 12:37:37 2015 - Respawned uWSGI worker 3 (new pid: 27625)\nThu Oct  1 12:37:37 2015 - DAMN ! worker 2 (pid: 27602) died :( trying respawn ...\nThu Oct  1 12:37:37 2015 - worker respawning too fast !!! i have to sleep a bit (2 seconds)... Thu Oct  1 12:37:39 2015 - Respawned uWSGI worker 2 (new pid: 27632)\nThu Oct  1 12:37:39 2015 - DAMN ! worker 4 (pid: 27601) died :( trying respawn ...\nThu Oct  1 12:37:39 2015 - Respawned uWSGI worker 4 (new pid: 27633)\nThu Oct  1 12:37:39 2015 - DAMN ! worker 1 (pid: 27603) died :( trying respawn ...\nThu Oct  1 12:37:39 2015 - Respawned uWSGI worker 1 (new pid: 27634)\nThu Oct  1 12:37:39 2015 - DAMN ! worker 3 (pid: 27625) died :( trying respawn ...\nThu Oct  1 12:37:39 2015 - Respawned uWSGI worker 3 (new pid: 27635) Thu Oct  1 12:37:40 2015 - DAMN ! worker 1 (pid: 27634) died :( trying respawn ...\nThu Oct  1 12:37:40 2015 - Respawned uWSGI worker 1 (new pid: 27656) Thu Oct  1 12:37:41 2015 - DAMN ! worker 2 (pid: 27632) died :( trying respawn ...\nThu Oct  1 12:37:41 2015 - worker respawning too fast !!! i have to sleep a bit (2 seconds)...\nThu Oct  1 12:37:43 2015 - Respawned uWSGI worker 2 (new pid: 27662)\nThu Oct  1 12:37:43 2015 - DAMN ! worker 4 (pid: 27633) died :( trying respawn ...\nThu Oct  1 12:37:43 2015 - Respawned uWSGI worker 4 (new pid: 27663)\nThu Oct  1 12:37:43 2015 - DAMN ! worker 3 (pid: 27635) died :( trying respawn ...\nThu Oct  1 12:37:43 2015 - Respawned uWSGI worker 3 (new pid: 27664)\nThu Oct  1 12:37:43 2015 - DAMN ! worker 1 (pid: 27656) died :( trying respawn ...\nThu Oct  1 12:37:43 2015 - Respawned uWSGI worker 1 (new pid: 27665) Thu Oct  1 12:37:44 2015 - DAMN ! worker 2 (pid: 27662) died :( trying respawn ...\nThu Oct  1 12:37:44 2015 - Respawned uWSGI worker 2 (new pid: 27686) Thu Oct  1 12:37:45 2015 - DAMN ! worker 4 (pid: 27663) died :( trying respawn ...\nThu Oct  1 12:37:45 2015 - worker respawning too fast !!! i have to sleep a bit (2 seconds)...\nThu Oct  1 12:37:47 2015 - Respawned uWSGI worker 4 (new pid: 27696)\nThu Oct  1 12:37:47 2015 - DAMN ! worker 3 (pid: 27664) died :( trying respawn ...\nThu Oct  1 12:37:47 2015 - Respawned uWSGI worker 3 (new pid: 27697)\nThu Oct  1 12:37:47 2015 - DAMN ! worker 1 (pid: 27665) died :( trying respawn ...\nThu Oct  1 12:37:47 2015 - Respawned uWSGI worker 1 (new pid: 27698)\nThu Oct  1 12:37:47 2015 - DAMN ! worker 2 (pid: 27686) died :( trying respawn ...\nThu Oct  1 12:37:47 2015 - Respawned uWSGI worker 2 (new pid: 27699)\n... The application can't start and this process never ends.\nIs there any option that I can add to limit the loop?\neg. max-worker-respawning-count = 2 If the application can not run, it makes no sense to try to infinity. ", "code": [], "labels": ["feature request"]}
{"project": "dotnet_roslyn", "title": "remove custom non-fatal watson we copied from debugger and use new VS non-fatal watson service from VSTelemetry", "description": "VS telemetry team added non-fatal watson API. we should use the official one now. here are information.\n...\nSlide deck with usage and screen shots of results from Watson back end:\n<URL> Spec with sample code is here.\n<URL>\n.. this is new code, so might not in our branch yet. here is sample code. <CODE> ", "code": ["            TelemetrySession.GetDefaultTelemetrySession().PostFaultEvent( \n                eventName: \"VS/Core/PackageLoadFailure\", \n                description: packageName, \n                exceptionObject: ex); \n"], "labels": ["Area-Analyzers", "Bug"]}
{"project": "abpframework_abp", "title": "Template project can not download", "description": "This page isn\u2019t working after I click 'Create Now' button.\nurl: <URL>  ", "code": [], "labels": ["problem"]}
{"project": "flutter_flutter", "title": "Displaying large images on low-performance phones fails with no error message", "description": "Displaying large images on low-performance phones fails with no error message. device: xiaomi m4\nimage url: <URL> set filterQuality: FilterQuality.none  before running\nImage.network('<URL>', filterQuality: FilterQuality.none, ), ", "code": [], "labels": ["severe: performance"]}
{"project": "fish-shell_fish-shell", "title": "fish_color_valid_path only works for last entered token", "description": "If I type, say, ls Pictures then Pictures is underlined but as soon as I type another argument the underlining is gone.  If the next argument is also a valid path then that one is also underlined, and also reset once I type a third argument, et cetera.  Same problem if I type multiple commands, either with semicolon or Alt-Enter.  If I move the cursor within the commandline and type in a valid file path, that one is underlined and any other underlining is reset.  Only the last entered token in one command line is ever affected by fish_color_valid_path. ", "code": [], "labels": ["duplicate"]}
{"project": "aws_aws-sdk-ruby", "title": "DynamoDB :retry_limit and ProvisionedThroughputExceededExceptions", "description": "I have code where DynamoDB throttling errors are self implemented by catching Aws::DynamoDB::Errors::ProvisionedThroughputExceededException and retrying (with exponential backoff). I didn't realize that there was a :retry_limit config option on the DynamoDB client. Based on the docs, it seems that it is on by default, and I'm assuming that it doesn't matter that I have one configuration set on the client (simple_attributes) -- i.e. configuring one attribute doesn't override defaults for other config attributes. Is that correct? So, assuming that retries are on by default in the SDK, when would my code see a Aws::DynamoDB::Errors::ProvisionedThroughputExceededException? After 10 retries have been taken care of by the SDK? Also, I am testing my current retry code by stubbing DynamoDB responses in rspec: Aws.config[:dynamodb][:stub_responses] = {get_item: 'ProvisionedThroughputExceededException'}. Is there a way to test out the SDK retry code or see it in action (aside from in production)? Thanks! ", "code": [], "labels": ["guidance", "v2"]}
{"project": "microsoft_react-native-code-push", "title": "react-native link continually prompts for crash report configuration", "description": "Thanks so much for filing an issue or feature request! Please fill out the following (wherever relevant): It prompts twice (ios & android). Not to prompt for this again (only on the first time of setup). What actually happens?  ", "code": [], "labels": ["question"]}
{"project": "microsoft_vcpkg", "title": "[spdlog v1.4.2] build failure", "description": "Host Environment To Reproduce\nSteps to reproduce the behavior:\n./vcpkg install spdlog Failure logs\nD:\\git\\vcpkg\\installed\\x86-windows\\include\\fmt/format.h(2780): error C2220: \u8b66\u544a\u88ab\u89c6\u4e3a\u9519\u8bef - \u6ca1\u6709\u751f\u6210\u201cobject\u201d\u6587\u4ef6\nD:\\git\\vcpkg\\installed\\x86-windows\\include\\fmt/format.h(2780): warning C4189: \u201coptions\u201d: \u5c40\u90e8\u53d8\u91cf\u5df2\u521d\u59cb\u5316\u4f46\u4e0d\u5f15\u7528 Additional context ", "code": [], "labels": ["port bug"]}
{"project": "flutter_flutter", "title": "No way to set the initial value of an Input if you use formField", "description": "From #5505: You can't do this: <CODE> Because you can't use both value and formField. We need a way to set the initial value. ", "code": ["body: new Form(\n  child: new Block(\n    children: <Widget>[\n      new Input(\n        value: new InputValue(text: initialValue),\n        formField: new FormField<String>(\n          setter:  (String val) {\n            this._username = val;\n          }\n        )\n      ),\n    ]\n  )\n)\n"], "labels": ["framework"]}
{"project": "facebook_react-native", "title": "[Documentation] Style prop of View lost link to flexbox/transform docs", "description": "As the title states, the links to the Flexbox and Transform documentation seems to be gone with the new doc updates. ", "code": [], "labels": ["Resolution: Locked"]}
{"project": "sqlmapproject_sqlmap", "title": "Unhandled exception (#b72e9bad)", "description": "<CODE> <CODE> ", "code": ["sqlmap version: 1.0-dev-nongit-20150912\nPython version: 2.7.9\nOperating system: posix\nCommand line: /usr/bin/sqlmap -u **************************************** --dbs\nTechnique: None\nBack-end DBMS: None (identified)\n", "Traceback (most recent call last):\n  File \"sqlmap\", line 100, in main\n    start()\n  File \"share/sqlmap/lib/controller/controller.py\", line 377, in start\n    if not checkConnection(suppressOutput=conf.forms) or not checkString() or not checkRegexp():\n  File \"share/sqlmap/lib/controller/checks.py\", line 1310, in checkConnection\n    page, _ = Request.queryPage(content=True, noteResponseTime=False)\n  File \"share/sqlmap/lib/request/connect.py\", line 1054, in queryPage\n    page, headers, code = Connect.getPage(url=uri, get=get, post=post, method=method, cookie=cookie, ua=ua, referer=referer, host=host, silent=silent, auxHeaders=auxHeaders, response=response, raise404=raise404, ignoreTimeout=timeBasedCompare)\n  File \"share/sqlmap/lib/request/connect.py\", line 460, in getPage\n    page = decodePage(page, responseHeaders.get(HTTP_HEADER.CONTENT_ENCODING), responseHeaders.get(HTTP_HEADER.CONTENT_TYPE))\n  File \"share/sqlmap/lib/request/basic.py\", line 292, in decodePage\n    kb.pageEncoding = kb.pageEncoding or checkCharEncoding(getHeuristicCharEncoding(page))\n  File \"share/sqlmap/lib/request/basic.py\", line 215, in getHeuristicCharEncoding\n    retVal = detect(page)[\"encoding\"]\n  File \"share/sqlmap/thirdparty/chardet/__init__.py\", line 21, in detect\n    import universaldetector\n  File \"share/sqlmap/thirdparty/chardet/universaldetector.py\", line 31, in <module>\n    from mbcsgroupprober import MBCSGroupProber # multi-byte character sets\n  File \"share/sqlmap/thirdparty/chardet/mbcsgroupprober.py\", line 32, in <module>\n    from sjisprober import SJISProber\n  File \"share/sqlmap/thirdparty/chardet/sjisprober.py\", line 30, in <module>\n    from chardistribution import SJISDistributionAnalysis\n  File \"share/sqlmap/thirdparty/chardet/chardistribution.py\", line 29, in <module>\n    from euctwfreq import EUCTWCharToFreqOrder, EUCTW_TABLE_SIZE, EUCTW_TYPICAL_DISTRIBUTION_RATIO\nImportError: cannot import name EUCTWCharToFreqOrder\n"], "labels": ["duplicate"]}
{"project": "zammad_zammad", "title": "Not used SQL index with postgresql in certain cases on very large setups.", "description": "<CODE> <CODE> The id DESC was only used because mysql/mariadb was not supporting milliseconds in timestamps in earlier version. References: <URL> ", "code": ["zammad=# explain analyze select updated_at from tickets order by updated_at desc limit 1;\n                                                                            QUERY PLAN                                                                            \n------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=0.00..0.06 rows=1 width=8) (actual time=0.017..0.018 rows=1 loops=1)\n   ->  Index Only Scan Backward using index_tickets_on_updated_at on tickets  (cost=0.00..43802.61 rows=777781 width=8) (actual time=0.017..0.017 rows=1 loops=1)\n         Heap Fetches: 1\n Total runtime: 0.032 ms\n", "zammad=# explain analyze select updated_at from tickets order by updated_at desc, id DESC limit 1;\n                                                          QUERY PLAN                                                          \n------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=44808.71..44808.72 rows=1 width=12) (actual time=416.030..416.030 rows=1 loops=1)\n   ->  Sort  (cost=44808.71..46753.17 rows=777781 width=12) (actual time=416.030..416.030 rows=1 loops=1)\n         Sort Key: updated_at, id\n         Sort Method: top-N heapsort  Memory: 25kB\n         ->  Seq Scan on tickets  (cost=0.00..40919.81 rows=777781 width=12) (actual time=0.011..310.465 rows=777554 loops=1)\n Total runtime: 416.057 ms\n"], "labels": ["enhancement", "verified"]}
{"project": "aws-amplify_amplify-js", "title": "Are there any security considerations for using the API component, which does not have a way to clean data before putting it into the database?", "description": "** Which Category is your question related to? **\nAPI (or Storage) ** What AWS Services are you utilizing? **\nAPI, Storage, Analytics, Lambda, AppSync, ** Provide additional details e.g. code snippets **\nAs we prepare to go live in production, are there any security considerations that we might have overlooked? One particular area of uncertainty is the API package, which does not provide a way to clean data before persisting it. In traditional rest services, I would perform tasks like limitSize(input), removeHTML(input), etc. If Attacker were to persist <script>window.alert('ATTACK')</script> or <DIV STYLE=\"background-image: url(javascript:alert('Injected'))\"> as the name of a Book object, and my react code looks something like: <CODE> Will that attack succeed? Additionally, because I'm using SSR, does that increase the risk of malicious code executing in the browser because all of the HTML is printed on the server? ", "code": ["const { getBook } = await API.getBook(id);\n\nreturn (<div>{getBook.data.name}</div>);\n"], "labels": ["pending-close-response-required"]}
{"project": "arrayfire_arrayfire", "title": "Delay the normalization of the input when performing fft", "description": "This example shows the behavior in python but similar results can be seen in C++ as well.\n<URL> fft and ifft should be normalized after the transform (not before) for better accuracy. ", "code": [], "labels": ["bug"]}
{"project": "microsoft_vscode", "title": "Debug toolbar buttons disabled", "description": "VSCode:  Version 1.27.1 (1.27.1) 5944e81\nPlatform: macOS/ubuntu When the user is stepping over his program, the CALL STACK view shows the program is PAUSED ON STEP, but the debug toolbar buttons are disabled. See the following screenshot.\n This issue is stably reproduced on macOS/ubuntu. Also there is some user reporting it occurs in Windows 10 sometimes, and downgrade to 1.26.0, the issue disappear. ", "code": [], "labels": ["bug", "debug", "verified"]}
{"project": "beakerbrowser_beaker", "title": "Add a configurable cap on Dat bandwidth use", "description": "Operation System: MacOS Sierra\nBeaker Version: v0.7.7 Using Beaker (in MacOS guest VM under MacOS VMWare Fusion host) on home wifi network with asymmetric, small-upload-bandwidth internet connection (ADSL). When Beaker is running with a few dat: tabs open, internet usability collapses in guest VM where Beaker is running, in host VM, and other devices sharing same internet uplink. (That is: lots of loading-slowly, failed-to-connect, etc. Google Wifi app even has problems connecting reliably to Google OnHub.) I strongly suspect uplink-saturation (perhaps exacerbated by UDP/multicast?) is sabotaging other connections \u2013 an effect really common in P2P file-sharing apps that don't self-limit (via a manual cap or adaptive backoff) their uplink saturation. Do any parts of the Beaker Browser stack have a hidden option to limit uplink bandwidth? Can it be added? Is the DAT-P2P-Swarm background traffic all on a few stable ports suitable for the external application of OS/appliance shaping/QoS rules? ", "code": [], "labels": ["enhancement"]}
{"project": "RobotLocomotion_drake", "title": "Move fork of bot_core_lcmtypes to RobotLocomotion organization", "description": "Fork: <URL> ", "code": [], "labels": ["priority: low", "team: kitware", "type: cleanup"]}
{"project": "froala_wysiwyg-editor", "title": "Insert video button not working", "description": "When clicking insert video button, popup should show up with insert video options No video options pop up shows up when clicking the insert video button Initialize Froala editor with videoInsertButtons setting set to  ['videoByURL']\nThen click Insert Video button\nSee <URL> When you set videoInsertButtons setting to default as mentioned here it works MacOS Mojave 10.14.2 Chrome 71.0.3578.98 See jsfiddle <URL> ", "code": [], "labels": ["bug"]}
{"project": "ember-cli_ember-cli", "title": "Customizations and the new \"Brocfile.js\" structure", "description": "This comes from my need to just concatenate a couple of CSS files without even using any of the pre-processors and optionally minify the CSS when generating a production build - please let me know if there are better ways to achieve this because I think this is a fairly common scenario. I used to do something like this in Brocfile.js: But with the new structure and this section out of reach on a project level, I don't think we can do anything like this. Any suggestions on how do we address this or any similar custom needs? ", "code": [], "labels": ["docs"]}
{"project": "netblue30_firejail", "title": "thunderbird use \"wrong\" pdf viewer", "description": "after running thunderbird started by firejail version 0.9.40 I can't view attached pdf files by double click or \"open\", because thunderbird is not using my preferred pdf viewer anymore. It's starting the ubuntu default pdf viewer evince with the first part of pdf file name (white space in original name like \"my test.pdf\" Found in syslog\nAug 16 01:16:24 ubuntu kernel: [228493.464107] audit: type=1400 audit(1471302984.440:780): apparmor=\"DENIED\" operation=\"open\" profile=\"/usr/bin/evince\" name=\"/etc/ld.so.preload\" pid=1512 comm=\"evince\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=0\nAug 16 01:16:24 ubuntu kernel: [228493.638309] audit: type=1400 audit(1471302984.616:781): apparmor=\"DENIED\" operation=\"open\" profile=\"/usr/bin/evince\" name=\"/etc/xfce4/defaults.list\" pid=1512 comm=\"evince\" requested_mask=\"r\" denied_mask=\"r\" fsuid=1000 ouid=0 anything to do with my problem? not sure, /etc/xfce4/default.list is empty If I start thunderbird without firejail everything works fine. any hints and tips are welcome how to config firejail, that thunderbird is using my preferred applications for attached files. ", "code": [], "labels": ["information"]}
{"project": "mautic_mautic", "title": "Twitter generic error on tweet send", "description": "Fresh install of 2.9.2\nEnable the twitter integration / authorized my twitter app\nCreated a tweet message names \"tweet1\" body \"this is a sample tweet message\"\nCreated a dummy public segment - no filters\nCreated a campaign based on segment - used segment 1\nadded an action \"tweet contact\" and selected \"tweet1\"\npublished the campaign\nCreated a contact with twitter nickhandle\nManually trigger the campaign thanks to campaign popup on the contact\nRun the cronjob to launch the triggers (no errors/warning)\nGot the tweet in activity line BUT in error (Generic error) and of course no tweet really sent  No error in log files ", "code": [], "labels": ["Bug"]}
{"project": "brave_browser-laptop", "title": "About dialog reports incorrect Brave version on dev channel", "description": "Did you search for similar issues before submitting this one?\nYes Describe the issue you encountered:\nI downloaded and installed 0.11.6dev-beta6, but the About dialog still says \"0.11.5\" Expected behavior:\nAbout dialog should always report the correct version  ", "code": [], "labels": ["invalid"]}
{"project": "reactor_reactor-core", "title": "Uncaught exceptions are silently ignored", "description": "In 3.0.2.RELEASE an uncaught exception thrown by a subscriber without an error consumer would be logged via the thread's UncaughtExceptionHandler.  In 3.0.3.RELEASE the uncaught exception is silently thrown away.  I would consider this a bug since otherwise I believe I would have to add an error consumer to every subscriber to be sure no subscriber threw an exception. The following code reproduces the issue. In 3.0.2.RELEASE the code would display the exception.  In 3.0.3.RELEASE nothing is shown. <CODE> ", "code": ["import reactor.core.publisher.Flux;\n\nimport static reactor.core.scheduler.Schedulers.parallel;\n\npublic class UncaughtExceptionHandler {\n    public static void main(String[] args) throws InterruptedException {\n        Flux.intervalMillis(100)\n                .take(1)\n                .publishOn(parallel())\n                .subscribe(i -> throwEx());\n        Thread.sleep(3000);\n    }\n\n    private static void throwEx() {\n        System.out.println(\"About to throw...\");\n        throw new IllegalStateException();\n    }\n}\n"], "labels": ["type/bug"]}
{"project": "statsmodels_statsmodels", "title": "Add seasonal unit root tests", "description": "For arrays we'll have to take a period argument. There is some code to deal with pandas freqs -> period already. Used in seasonal_decomp and more in the exponential smoothing PR. Rarely used now: Dickey-Hasza-Fuller (DHF) Seems to be the most popular: Hylleberg-Granger-Engle-Yoo (HEGY) ", "code": [], "labels": ["wishlist"]}
{"project": "yajra_laravel-datatables", "title": "fractal transformer and action buttons", "description": "If i user this - action buttons do not display. How to include them with the transformer ? ", "code": [], "labels": ["documentation", "question"]}
{"project": "ansible_ansible", "title": "kubevirt_template module is not passing merge_type", "description": "kubevirt_template module is not passing the merge_type to the parent class, which makes it fail kubevirt_template <CODE> <CODE> <CODE> ", "code": ["devel\n", "\n", "Traceback\nThe full traceback is:\nTraceback (most recent call last):\n  File \"/home/vparekh/.ansible/tmp/ansible-tmp-1553237982.1-20313872141039/AnsiballZ_kubevirt_template.py\", line 114, in <module>\n    _ansiballz_main()\n  File \"/home/vparekh/.ansible/tmp/ansible-tmp-1553237982.1-20313872141039/AnsiballZ_kubevirt_template.py\", line 106, in _ansiballz_main\n    invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)\n  File \"/home/vparekh/.ansible/tmp/ansible-tmp-1553237982.1-20313872141039/AnsiballZ_kubevirt_template.py\", line 49, in invoke_module\n    imp.load_module('__main__', mod, module, MOD_DESC)\n  File \"/tmp/ansible_kubevirt_template_payload_M6iyQQ/__main__.py\", line 359, in <module>\n  File \"/tmp/ansible_kubevirt_template_payload_M6iyQQ/__main__.py\", line 351, in main\n  File \"/tmp/ansible_kubevirt_template_payload_M6iyQQ/ansible_kubevirt_template_payload.zip/ansible/module_utils/kubevirt.py\", line 128, in __init__\n  File \"/tmp/ansible_kubevirt_template_payload_M6iyQQ/ansible_kubevirt_template_payload.zip/ansible/module_utils/k8s/raw.py\", line 115, in __init__\nKeyError: 'merge_type'\n\n"], "labels": ["support:community", "traceback", "affects_2.8", "module", "bug", "cloud"]}
{"project": "microsoft_WSL", "title": "gperftools doesn't work", "description": "gperftools (aka Google Profiler) produces no useful output. E.g., this code: <CODE> produces the following output on a real Ubuntu machine: <CODE> but this output on WSL: <CODE> Trying to dump prof.out indeed shows it is empty: <CODE> I tried running with various levels of PERFTOOLS_VERBOSE, but was not able to obtain any leads on where the problem might be. ", "code": ["#include \"gperftools/profiler.h\"\n#include <iostream>\n#include <math.h>\nusing namespace std;\nvoid bar()\n{\n  int a,b,c,d,j,k;\n  a=0;\n  int z=0;\n  b = 1000;\n  while(z < b)\n    {\n      while (a < b)\n        {\n          d = sin(a);\n          c = cos(a);\n          j = tan(a);\n          k = tan(a);\n          k = d * c + j *k;\n          a++;\n        }\n      a = 0;\n      z++;\n    }\n}\n\nint main()\n{\n  ProfilerStart(\"prof.out\");\n\n  bar();\n  ProfilerFlush();\n  ProfilerStop();\n}\n", "$ CPUPROFILE=prof.out ./test\nPROFILE: interrupts/evictions/bytes = 26/2/1848\n", "$ CPUPROFILE=prof.out ./test\nPROFILE: interrupts/evictions/bytes = 0/0/64\n", "$ google-pprof ./test --svg prof.out\nUsing local file ./test.\nUsing local file prof.out.\nNo nodes to print\n"], "labels": ["feature"]}
{"project": "jekyll_jekyll", "title": "jekyl install error", "description": "After executing: gem install jekyll Fetching: liquid-2.6.1.gem (100%)\nERROR:  While executing gem ... (Errno::EACCES)\nPermission denied - /Library/Ruby/Gems/2.0.0/cache/liquid-2.6.1.gem Help me out what might fix this. I'm running Mac Os X Mavericks and executing this in a virtualenv. ", "code": [], "labels": ["frozen-due-to-age"]}
{"project": "flutter_flutter", "title": "Installing build failing", "description": "I took a 1 month break from this project and I am back at it but when I try running flutter run, this is what happens: <CODE> Here is flutter doctor: <CODE> ", "code": ["Built build\\app\\outputs\\apk\\debug\\app-debug.apk.\nInstalling build\\app\\outputs\\apk\\app.apk...\n\nOops; flutter has exited unexpectedly: \"Exit code -1 from: C:\\Users\\A296791\\AppData\\Local\\Android\\sdk\\platform-tools\\adb -s emulator-5554 shell am start -a android.intent.action.RUN -f 0x20000000 --ez enable-background-compilation true --ez enable-dart-profiling true --ez enable-checked-mode true com.example.lnotes/com.apptreesoftware.mapview.MapActivity:\nStarting: Intent { act=android.intent.action.RUN flg=0x20000000 cmp=com.example.lnotes/com.apptreesoftware.mapview.MapActivity (has extras) }\n\nSecurity exception: Permission Denial: starting Intent { act=android.intent.action.RUN flg=0x30000000 cmp=com.example.lnotes/com.apptreesoftware.mapview.MapActivity (has extras) } from null (pid=14660, uid=2000) not exported from uid 10085\n\njava.lang.SecurityException: Permission Denial: starting Intent { act=android.intent.action.RUN flg=0x30000000 cmp=com.example.lnotes/com.apptreesoftware.mapview.MapActivity (has extras) } from null (pid=14660, uid=2000) not exported from uid 10085\n        at com.android.server.am.ActivityStackSupervisor.checkStartAnyActivityPermission(ActivityStackSupervisor.java:1788)\n        at com.android.server.am.ActivityStarter.startActivity(ActivityStarter.java:717)\n        at com.android.server.am.ActivityStarter.startActivity(ActivityStarter.java:544)\n        at com.android.server.am.ActivityStarter.startActivityMayWait(ActivityStarter.java:1099)\n        at com.android.server.am.ActivityStarter.execute(ActivityStarter.java:486)\n        at com.android.server.am.ActivityManagerService.startActivityAsUser(ActivityManagerService.java:5120)\n        at com.android.server.am.ActivityManagerService.startActivityAsUser(ActivityManagerService.java:5094)        at com.android.server.am.ActivityManagerShellCommand.runStartActivity(ActivityManagerShellCommand.java:479)        at com.android.server.am.ActivityManagerShellCommand.onCommand(ActivityManagerShellCommand.java:161)        at android.os.ShellCommand.exec(ShellCommand.java:103)\n        at com.android.server.am.ActivityManagerService.onShellCommand(ActivityManagerService.java:16005)        at android.os.Binder.shellCommand(Binder.java:634)\n        at android.os.Binder.onTransact(Binder.java:532)\n        at android.app.IActivityManager$Stub.onTransact(IActivityManager.java:3592)\n        at com.android.server.am.ActivityManagerService.onTransact(ActivityManagerService.java:3291)        at android.os.Binder.execTransact(Binder.java:731)\".\n", "Doctor summary (to see all details, run flutter doctor -v):\n[\u221a] Flutter (Channel beta, v0.6.0, on Microsoft Windows [Version 6.1.7601], locale sv-SE)\n[\u221a] Android toolchain - develop for Android devices (Android SDK 28.0.2)\n[\u221a] Android Studio (version 3.1)\n    X Flutter plugin not installed; this adds Flutter specific functionality.\n    X Dart plugin not installed; this adds Dart specific functionality.\n[\u221a] IntelliJ IDEA Community Edition (version 2018.2)\n[\u221a] Connected devices (1 available)\n\n\u2022 No issues found!\n"], "labels": ["tool", "severe: regression", "severe: crash"]}
{"project": "gravitational_teleport", "title": "Default selinux config breaks teleport when PAM is enabled", "description": "Have a question? Please use Our Forum What happened:\nTeleport cannot spawn a shell on nodes running SELinux in Enforcing mode when PAM is enabled What you expected to happen: Shell opens normally. How to reproduce it (as minimally and precisely as possible): Environment: Browser environment Relevant Debug Logs If Applicable audit.log: <CODE> sealert output: <CODE> ", "code": ["type=AVC msg=audit(1577935071.749:574): avc:  denied  { transition } for  pid=549056 comm=\"teleport\" path=\"/usr/bin/bash\" dev=\"dm-1\" ino=2363051 scontext=system_u:system_r:unconfined_service_t:s0 tcontext=unconfined_u:unconfined_r:unconfined_t:s0 tclass=process permissive=0\n", "SELinux is preventing teleport from using the transition access on a process.\n\n*****  Plugin catchall (100. confidence) suggests   **************************\n\nIf you believe that teleport should be allowed transition access on processes labeled unconfined_t by default.\nThen you should report this as a bug.\nYou can generate a local policy module to allow this access.\nDo\nallow this access for now by executing:\n# ausearch -c 'teleport' --raw | audit2allow -M my-teleport\n# semodule -X 300 -i my-teleport.pp\n\n\nAdditional Information:\nSource Context                system_u:system_r:unconfined_service_t:s0\nTarget Context                unconfined_u:unconfined_r:unconfined_t:s0\nTarget Objects                /usr/bin/bash [ process ]\nSource                        teleport\nSource Path                   teleport\nPort                          <Unknown>\nHost                          eschatologist\nSource RPM Packages\nTarget RPM Packages           bash-5.0.11-1.fc31.x86_64\nPolicy RPM                    selinux-policy-3.14.4-43.fc31.noarch\nSelinux Enabled               True\nPolicy Type                   targeted\nEnforcing Mode                Permissive\nHost Name                     eschatologist\nPlatform                      Linux eschatologist 5.3.16-300.fc31.x86_64 #1 SMP\n                              Fri Dec 13 17:59:04 UTC 2019 x86_64 x86_64\nAlert Count                   4\nFirst Seen                    2019-12-25 22:36:16 EST\nLast Seen                     2020-01-01 22:18:05 EST\nLocal ID                      67c013ad-2e4d-4303-8f30-10ea6e58a253\n\nRaw Audit Messages\ntype=AVC msg=audit(1577935085.716:582): avc:  denied  { transition } for  pid=549592 comm=\"teleport\" path=\"/usr/bin/bash\" dev=\"dm-1\" ino=2363051 scontext=system_u:system_r:unconfined_service_t:s0 tcontext=unconfined_u:unconfined_r:unconfined_t:s0 tclass=process permissive=1\n\n\nHash: teleport,unconfined_service_t,unconfined_t,process,transition\n"], "labels": ["bug"]}
{"project": "saltstack_salt", "title": "Include minion IP in auth event data", "description": "It would be useful to have the minion IP address included with auth events. A use case for this is EC2 autoscaling. A reactor would call a runner, which would do a boto lookup on the IP, the name and the autoscaling group to ensure the key in question matches the node that should be generating it. Without the IP it's basically impossible to securely sign a key without SSHing into the node. ", "code": [], "labels": ["stale", "Feature"]}
{"project": "npm_npm", "title": "I use the \"npm start\" executed \"GitHub-Pages\" project, an error occurred ,please help", "description": "HI,I was troubled for a long time this issue, root@a-virtual-machine:/data/proj/GitLab-Pages# npm start module.js:327\nthrow err;\n^ Error: Cannot find module '../build/Debug/nodegit.node'\nat Function.Module._resolveFilename (module.js:325:15)\nat Function.Module._load (module.js:276:25)\nat Module.require (module.js:353:17)\nat require (internal/module.js:12:17)\nat Object. (/data/proj/GitLab-Pages/node_modules/nodegit/lib/nodegit.js:16:12)\nat Module._compile (module.js:409:26)\nat Object.Module._extensions..js (module.js:416:10)\nat Module.load (module.js:343:32)\nat Function.Module._load (module.js:300:12)\nat Module.require (module.js:353:17)\nat require (internal/module.js:12:17) npm ERR! Linux 3.19.0-25-generic\nnpm ERR! argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"start\"\nnpm ERR! node v4.3.2\nnpm ERR! npm  v3.8.0\nnpm ERR! code ELIFECYCLE\nnpm ERR! GitLab-Pages@0.1.0 start: node ./bin/www\nnpm ERR! Exit status 1\nnpm ERR!\nnpm ERR! Failed at the GitLab-Pages@0.1.0 start script 'node ./bin/www'.\nnpm ERR! Make sure you have the latest version of node.js and npm installed.\nnpm ERR! If you do, this is most likely a problem with the GitLab-Pages package,\nnpm ERR! not with npm itself.\nnpm ERR! Tell the author that this fails on your system:\nnpm ERR!     node ./bin/www\nnpm ERR! You can get information on how to open an issue for this project with:\nnpm ERR!     npm bugs GitLab-Pages\nnpm ERR! Or if that isn't available, you can get their info via:\nnpm ERR!     npm owner ls GitLab-Pages\nnpm ERR! There is likely additional logging output above. npm ERR! Please include the following file with any support request:\nnpm ERR!     /data/proj/GitLab-Pages/npm-debug.log But I can not find \"Debug\" directory!!!!!    nodejs version is the problem? or npm version? ", "code": [], "labels": ["support"]}
{"project": "CartoDB_cartodb", "title": "Time-Series Widget does not work if dataset doesn't have geometry", "description": "Hi @alonsogarciapablo  I see you were working on this - maybe related? cc @zingbot @saleiva Not sure if this is a bug or something we're going to add in the future - what if a client wants to use widgets to filter non-geospatial data? If we want to support that, right now the Time Series widget isn't loading for datasets with null the_geom. For example, what if we have a dataset without geometry and we want to use Formula widget to calculate the sum of a numeric column, but only for values filtered by Time-Series widget? <URL> time_series_null_geom map (on 2016-08-24 at 19.25.30).zip Filterable time-series widget will appear at bottom of the map.  error: 'the tiler does not support non-torque layers just yet\u2026' also 400/Bad Request error:  ", "code": [], "labels": ["question"]}
{"project": "facebook_flow", "title": "Is there a way to type a pick(source, fieldMap) with $ObjMap in Flow?", "description": "We have a pick() util function that uses es6 class fields to specify the target fields: <CODE> I'm wondering if there's a way to provide a type signature for pick() so its return value properly reflects the field types from the source object. ", "code": ["const source = {\n  id: 12,\n  name: 'source',\n  // ... other fields\n};\n\n// use es6 class properties to specify the field names instead of an array of strings\nconst pickedObject = pick(source, class {\n  id;\n  name;\n});\n\nconsole.log(pickedObject);\n/*\n{\n  id: 12,\n  name: 'source'\n}\n*/\n"], "labels": ["question"]}
{"project": "Templarian_MaterialDesign", "title": "Poor rendering on Microsoft Edge/IE11", "description": "Take a look at this comparative SVG rendering:  Using md-icon on Material Angular\n<URL> ", "code": [], "labels": ["Bug"]}
{"project": "dcloudio_uni-app", "title": "uni-app tree-shaking\u65e0\u6548\uff0c\u8bf7\u95ee\u600e\u4e48\u89e3\u51b3", "description": "\u95ee\u9898\u63cf\u8ff0\n\u4f7f\u7528uni-app\u521d\u59cb\u5316\u7684\u9879\u76ee\uff0c\u53d1\u73b0\u65e0\u6cd5tree shaking \u590d\u73b0\u6b65\u9aa4\n\u9879\u76ee\u521d\u59cb\u5316\u6d41\u7a0b <CODE> demo: <CODE> \u671f\u671b\u7684\u7ed3\u679c\u662f shake \u6389 src/src1.ts \u7684\u4ee3\u7801,\u56e0\u4e3a\u6211\u5e76\u6ca1\u6709\u7528\u5230\u5176\u4e2d\u7684\u4ee3\u7801\u3002\u4f46\u4e0d\u884c\u3002\u7ed3\u679c\u5982\u4e0b\uff1a <CODE> \u5b9a\u4f4d\u4e86\u4e00\u4e0b\u53d1\u73b0\u4fee\u6539 babel.config presets \u5373\u53ef <CODE> \u672c\u4ee5\u4e3a\u95ee\u9898\u89e3\u51b3\uff0c\u7ed3\u679c\u4e50\u6781\u751f\u60b2\u3002\u5f53\u4f9d\u8d56 components \u65f6\u7f16\u8bd1\u53c8\u6709\u95ee\u9898\u3002\u4ee3\u7801\u5982\u4e0b <CODE> \u62a5\u9519\u4fe1\u606f\u5982\u4e0b\uff1a <CODE> \u53ef\u4ee5\u770b\u51fa\u4fee\u6539 presets \u540e\uff0cwebpck-uni-mp-loader \u5728\u6267\u884c\u65f6\u4f1a\u51fa\u9519 \u8bf7\u95ee\u8be5\u5982\u4f55\u5b9e\u73b0 tree shaking \u5462\uff1f [\u6216\u8005\u53ef\u4ee5\u76f4\u63a5\u8d34\u6e90\u4ee3\u7801] \u9884\u671f\u7ed3\u679c\n\u80fd\u591fshake\u6389\u65e0\u7528\u4ee3\u7801 \u7cfb\u7edf\u4fe1\u606f: uni-app v2.3.7\nuni-app cli v2.0.0-23720191024001 Environment Info: System:\nOS: macOS 10.14.6\nCPU: (8) x64 Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz\nBinaries:\nNode: 10.15.0 - ~/.nvm/versions/node/v10.15.0/bin/node\nYarn: 1.17.3 - /usr/local/bin/yarn\nnpm: 6.4.1 - ~/.nvm/versions/node/v10.15.0/bin/npm\nnpmPackages:\n@dcloudio/types: * => 0.4.1\n@dcloudio/uni-app-plus: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-app-plus-nvue:  0.0.1\n@dcloudio/uni-app-plus-nvue-v8:  0.0.1\n@dcloudio/uni-cli-shared: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-h5: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-helper-json: * => 1.0.3\n@dcloudio/uni-mp-alipay: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-mp-baidu: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-mp-qq: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-mp-toutiao: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-mp-weixin: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-stat: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/uni-template-compiler: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/vue-cli-plugin-hbuilderx: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/vue-cli-plugin-uni: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/vue-cli-plugin-uni-optimize: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/webpack-uni-mp-loader: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@dcloudio/webpack-uni-nvue-loader:  0.0.1\n@dcloudio/webpack-uni-pages-loader: ^2.0.0-23720191024001 => 2.0.0-23720191024001\n@vue/babel-helper-vue-jsx-merge-props:  1.0.0\n@vue/babel-plugin-transform-vue-jsx:  1.0.0\n@vue/babel-preset-app:  3.12.1\n@vue/babel-preset-jsx:  1.1.1\n@vue/babel-sugar-functional-vue:  1.0.0\n@vue/babel-sugar-inject-h:  1.0.0\n@vue/babel-sugar-v-model:  1.1.1\n@vue/babel-sugar-v-on:  1.1.0\n@vue/cli-overlay:  4.0.5\n@vue/cli-plugin-babel: 3.5.1 => 3.5.1\n@vue/cli-plugin-router:  4.0.5\n@vue/cli-plugin-typescript: ^3.5.1 => 3.12.1\n@vue/cli-plugin-vuex:  4.0.5\n@vue/cli-service: ^4.0.0 => 4.0.5\n@vue/cli-shared-utils:  3.12.1\n@vue/component-compiler-utils:  3.0.0\n@vue/preload-webpack-plugin:  1.1.1\n@vue/web-component-wrapper:  1.2.0\nmpvue-page-factory:  1.0.1\nmpvue-template-compiler:  1.0.13\nuni-h5-vue:  2.6.10\nuni-mp-vue:  2.6.10\nvue: ^2.6.10 => 2.6.10\nvue-class-component: ^6.3.2 => 6.3.2 (7.1.0)\nvue-hot-reload-api:  2.3.4\nvue-loader:  15.7.1\nvue-property-decorator: ^8.0.0 => 8.3.0\nvue-router:  3.0.1\nvue-style-loader:  4.1.2\nvue-template-compiler: ^2.6.10 => 2.6.10\nvue-template-es2015-compiler:  1.9.1\nvuex: ^3.0.1 => 3.1.1\nnpmGlobalPackages:\n@vue/cli: 3.9.3 \u8865\u5145\u4fe1\u606f\n\u53ef\u4ee5\u770b\u51fa\u4fee\u6539 presets \u540e\uff0cwebpck-uni-mp-loader \u5728\u6267\u884c\u65f6\u4f1a\u51fa\u9519 ", "code": ["vue create -p dcloudio/uni-preset-vue my-project\n// \u4e4b\u540e\u9009\u62e9\u9ed8\u8ba4\u6a21\u677f(typescript)\n", "// src/src.ts\nexport const a = \"12345\";\nexport const b = \"b12345\";\nexport const c = 3;\n\n// src/src1.ts\nexport const aa = \"a111111\";\nexport const bb = 22222;\nexport const cc = 333333;\n\n// src/demo.ts\nimport { a, b, c } from \"@/src\";\nimport { aa, bb, cc } from \"@/src1\";\n\nexport { a, b, c, aa, bb, cc };\n\n// src/App.vue\n    import { a } from \"./demo\";\n\n    console.log(\"TCL: a\", a);\n\n", "// \u8fd0\u884c\u547d\u4ee4\uff1ayarn build:mp-weixin\n// dist/build/mp-weixin/common/vendor.js\nvar r=\"a111111\";e.aa=r;var o=22222;e.bb=o;var i=333333;e.cc=i\n", "//babel.config.js\nmodule.exports = {\n  presets: [\n    [\n      \"@vue/app\",  // \"@vue/cli-plugin-babel/preset\"\u4e5f\u884c\u7684\n      {\n        modules: false, // modules: 'commonjs' => false\n        useBuiltIns: process.env.UNI_PLATFORM === \"h5\" ? \"usage\" : \"entry\"\n      }\n    ]\n  ],\n  plugins\n};\n", "// src/compDemo.vue\n<template>\n    <div class=\"hello\">\n        <h1>{{ msg }}</h1>\n        <p>\n            For a guide and recipes on how to configure / customize this project,\n            <br>check out the\n            <a href=\"https://cli.vuejs.org\" target=\"_blank\" rel=\"noopener\">vue-cli documentation</a>.\n        </p>\n    </div>\n</template>\n\n<script>\n    export default {\n        name: \"HelloWorld\",\n        props: {\n            msg: String\n        }\n    };\n</script>\n\n\n// src/page/index/index.vue\n<template>\n\t<view class=\"content\">\n        <image class=\"logo\" src=\"../../static/logo.png\"></image>\n\t\t<view>\n            <text class=\"title\">{{title}}</text>\n        </view>\n\t\t<comp-demo></comp-demo>\n\t</view>\n</template>\n\n<script lang=\"ts\">\n\timport Vue from 'vue';\n\timport compDemo from \"../../compDemo.vue\";\n\texport default Vue.extend({\n\t\tcomponents: {\n            compDemo\n        },\n\t\tdata() {\n\t\t\treturn {\n\t\t\t\ttitle: 'Hello'\n\t\t\t}\n\t\t},\n\t\tonLoad() {\n\n\t\t},\n\t\tmethods: {\n\n\t\t}\n\t});\n</script>\n\n", "TypeError: Cannot read property 'id' of undefined\n    at Object.keys.forEach.name (/Users/xxxx/my-project/node_modules/@dcloudio/webpack-uni-mp-loader/lib/plugin/generate-component.js:57:15)\n    at Array.forEach (<anonymous>)\n    at generateComponent (/Users/xxxx/my-project/node_modules/@dcloudio/webpack-uni-mp-loader/lib/plugin/generate-component.js:24:25)\n    at Promise (/Users/xxxx/my-project/node_modules/@dcloudio/webpack-uni-mp-loader/lib/plugin/index-new.js:84:11)\n    at new Promise (<anonymous>)\n    at compiler.hooks.emit.tapPromise.compilation (/Users/xxxx/my-project/node_modules/@dcloudio/webpack-uni-mp-loader/lib/plugin/index-new.js:72:16)\n    at _next2 (eval at create (/Users/xxxx/my-project/node_modules/tapable/lib/HookCodeFactory.js:33:10), <anonymous>:9:17)\n    at _err2 (eval at create (/Users/xxxx/my-project/node_modules/tapable/lib/HookCodeFactory.js:33:10), <anonymous>:26:1)\n    at callback (/Users/xxxx/my-project/node_modules/copy-webpack-plugin/dist/index.js:77:17)\n    at /Users/xxxx/my-project/node_modules/copy-webpack-plugin/dist/index.js:118:24\nerror Command failed with exit code 1.\n"], "labels": ["bug"]}
{"project": "GeekyAnts_NativeBase", "title": "CardItem layout issues only on iPhone plus devices.", "description": "The layout which i designed using card layout works correctly on iPhone 5, iPhone 6, iPhone 7, iPhone 7 and iPhone 6S. But the design is completely messed up on iPhone Plus Devices. #612 issues is closed with out any solutions? please reopen it. ", "code": [], "labels": ["duplicate"]}
{"project": "saltstack_salt", "title": "npm.installed mistakenly throws error for packages which are \"installed via remote\"", "description": "The npm.installed state throws an error when installing certain packages. I was able to track this down to packages where \"is installed via remote\" is printed to stdout. (Whatever that means, it's not really Google-able.) Examples for such packages are \"sqlite3\" or \"bcrypt\", and the exact line looks like this: However, the packages acutally are successfully installed, so a subsequent highstate will succeed. The cause for this appears to be that the npm.install module cannot parse the output of npm install --silent --json because of that line. It therefore returns a string, which the npm.installed state counts as failure. Since #35075, there already is the special _extract_json() function in place, which tries to isolate the JSON from the other output like this: <CODE> Unfortunately, the line from above starts with a '[', although it's not part of the JSON. NPM appears to always output a JSON object (not a list), so the checks could probably be limited to startswith('{'). But what do I know, I can't even find documentation for NPM's JSON output. Create a target directory like \"/tmp/npm-test\" on the minion and try to install a NPM package like \"sqlite3\" or \"bcrypt\" using npm.installed like this: <CODE> It will fail with the error \"Could not install package(s) 'sqlite3'\", but the package will still be installed. ", "code": ["while lines and not lines[0].startswith('{') and not lines[0].startswith('['):\n    lines = lines[1:]\nwhile lines and not lines[-1].startswith('}') and not lines[-1].startswith(']'):\n    lines = lines[:-1]\n", "sqlite3:\n  npm.installed:\n    - dir: /tmp/npm-test\n"], "labels": ["RIoT", "State Module", "Bug", "Fixed Pending Verification", "Medium Severity", "P4"]}
{"project": "pocoproject_poco", "title": "Use of Inherently Dangerous Function", "description": "Ran a Veracode (<URL> static scan of our application windows 32-bit binaries that are using poco library.\nUsed the following compiler/linker flags, see \"Compilation Instructions for C/C++ on Windows\" here:\n<URL>\nIt found 2 very high security issue in poco library:\nUse of Inherently Dangerous Function in: foundation/src/process_win32u.cpp line: 299\nUse of Inherently Dangerous Function in: foundation/src/process_win32u.cpp line: 313 poco version: 1.7.8-all (2017-02-22) Operating system: Windows 10 Pro Expected: No very high security issues. ", "code": [], "labels": ["wontfix"]}
{"project": "VsVim_VsVim", "title": ":vsplit <FILENAME> \"Trailing characters\"", "description": "If you specify a file name after :vsplit, vsvim complains of trailing characters.\nI believe in Vim in directly opens the file in the new split. Thanks ", "code": [], "labels": ["bug"]}
{"project": "ionic-team_ionic", "title": "bug(infinite-scroll): throws uncatchable error if scrollToTop is called before it is resolved", "description": "Ionic version:  (check one with \"x\")\n[ ] 1.x (For Ionic 1.x issues, please use <URL>\n[ ] 2.x\n[x] 3.x I'm submitting a ...  (check one with \"x\")\n[x] bug report\n[ ] feature request\n[ ] support request => Please do not submit support requests here, use one of these channels: <URL> or <URL> Current behavior:\nHaving infinite scroll, calling content.scrollToTop() before last content.scrollToTop() resolves, throws an un-catchable error, and breaks the app. Expected behavior:\nEither be able to catch the error, or better yet don't error. Steps to reproduce:\nPlunker: <URL>\nSteps: You can do it only once though (per refresh), because it kills the thread. Ionic info: (run ionic info from a terminal/cmd prompt and paste output below): <CODE> ", "code": ["global packages:\n\n    @ionic/cli-utils : 1.4.0\n    Ionic CLI        : 3.4.0\n\nlocal packages:\n\n    @ionic/app-scripts              : 2.0.0\n    @ionic/cli-plugin-ionic-angular : 1.3.1\n    Ionic Framework                 : ionic-angular 3.5.0\n\nSystem:\n\n    Node       : v8.1.2\n    OS         : Windows 10\n    Xcode      : not installed\n    ios-deploy : not installed\n    ios-sim    : not installed\n    npm        : 5.0.3 \n"], "labels": ["v3", "ionitron: v3"]}
{"project": "dart-lang_sdk", "title": "Hang in test framework on dartc crash", "description": "This issue was originally filed by zundel@google.com I had a crash in dartc that caused the test framework to hang. I think our recent changes to drain stderr have a flaw in the crash case.  I patched up a problem in the Java side, but there is still a problem.  I was able to debug it to the _exitHandler firing before one of stdout or stderr was properly drained. reproduce with ./tools/build.py $ ./tools/test.py --progress line --component dartc  language/TopLevelFuncTest\n_stdoutDrained: language/TopLevelFuncTest\n*** POTENTIAL DEADLOCK on process restart\n_stdoutDrained: language/TopLevelFuncTest ", "code": [], "labels": ["Type-Defect", "area-test"]}
{"project": "spring-projects_spring-boot", "title": "Reactive Resource Server Auto Configuration", "description": "Complementary to #14150 for Servlet-based apps is the equivalent for WebFlux-based apps. The property is the same (spring.security.oauth2.resource-server.jwt.oidc-issuer-location). As is the needed configuration: And when WebFlux is present, as well as ReactiveJwtAuthenticationManager, then it is appropriate to use this property to publish a ReactiveJwtDecoder bean, e.g.: At that point, the Spring Security WebFlux configurer will pick up the bean and compose its security components accordingly. ", "code": [], "labels": ["status: superseded"]}
{"project": "olifolkerd_tabulator", "title": "Multiple selected value", "description": "hey,\ncan we select multiple values at a time from dropdown filter in column header and then search for those values...need assistance... ", "code": [], "labels": ["Question - Ask On Stack Overflow"]}
{"project": "apache_incubator-superset", "title": "Normal_distribution over bar chart", "description": "Hi, is it possible, to draw normal_distribution over barchart  by sperset ? ", "code": [], "labels": ["inactive"]}
{"project": "24pullrequests_24pullrequests", "title": "Upgrade mail to version 2.6.4", "description": "Libraries.io has found that there is a newer version of mail that this project depends on. More info: <URL> ", "code": [], "labels": ["help wanted", "enhancement"]}
{"project": "JosefNemec_Playnite", "title": "AoE2: African Kingdoms DLC imported as a game", "description": "Please don't make scan ## Age of Empires 2 HD: The African Kingdoms, since it isn't a standalone expansion and morelike a DLC. ", "code": [], "labels": ["bug"]}
{"project": "idris-lang_Idris-dev", "title": "Add basic tactics for failure with an error message and no-op", "description": "These are needed for user-friendly custom tactics with decent error-reporting. Example: in <CODE> which simplifies goals, recursively rewriting instances of plus n (S m) to S (plus n m), the final case should really be a \"no-op\" tactic. It should also be able to examine the goal and report if it is inapplicable. The error reporting feature should use the same types as error reflection, at least for tactics written using reflection, to give access to things like the pretty printer inside the error messages. ", "code": ["normPlus : List (TTName, Binder TT) -> TT -> Tactic\nnormPlus ctxt `((=) {Nat} {Nat} ~x ~y) = normPlus ctxt x `Seq` normPlus ctxt y\nnormPlus ctxt `(S ~n) = normPlus ctxt n\nnormPlus ctxt `(plus ~n (S ~m)) = Rewrite `(plusSuccRightSucc ~n ~m) `Seq`\n                                  normPlus ctxt m\nnormPlus _ _ = Refine \"id\"\n"], "labels": ["Feature request"]}
{"project": "dotnet_docs", "title": "Missing hyperlink", "description": "In the last sentence of the second-to-last paragraph in the section titled, \"Recognize CPU-Bound and I/O-Bound Work,\" the reference to the Task Parallel Library should probably be hyperlinked to the TPL documentation (<URL> \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["doc-enhancement", "P2", "up-for-grabs", " Area - C# Guide", "good-first-issue", "resolved"]}
{"project": "mapsplugin_cordova-plugin-googlemaps", "title": "Ground Overlay not overlapping the satellite view", "description": "I'm submitting a ...  (check one with \"x\") OS:  (check one with \"x\") cordova information:  (run $> cordova plugin list) <CODE> Current behavior:\nThe Ground Overlay DOESNOT exactly overlap the satellite view. Expected behavior:\nWhen accurate bounds are specified, the Ground Overlay should exactly overlap the satellite view. We want to add a GroundOverlay of an illustration of the ThemePark on the actual satellite view as shown in the attached \"appScreenshot.png\"  The set of bounds (Lat,Long of the 4 Corners of Overlay Image) passed to the map.addGroundOverlay() method is as below: <CODE> But the problem we are facing is - No matter in what order we specify the lat long of the corners, the overlay image DOES NOT EXACTLY overlap the satellite view. Please see attached image. In what order should the lat long of the bounds be specified? Can you please specify how we can exactly overlap the ground overlay on the satellite view? Also what is the maximum size of the image we can use for GroundOverlay? ", "code": ["com.ionic.keyboard 1.0.4 \"Keyboard\"\ncordova-plugin-console 1.0.2 \"Console\"\ncordova-plugin-device 1.1.1 \"Device\"\ncordova-plugin-googlemaps 2.3.8 \"cordova-plugin-googlemaps\"\ncordova-plugin-whitelist 1.2.2 \"Whitelist\"\n", "//LatLong of 4 corners of the overlay image\nvar bounds = [\n            {\"lat\": 23.180857, \"lng\": 72.564129},//Rw\n            {\"lat\": 23.182776, \"lng\": 72.576878},//Garden\n            {\"lat\": 23.187722, \"lng\": 72.569211},//Rail\n            {\"lat\": 23.176023, \"lng\": 72.571833},//Parking\n        ];\n"], "labels": ["question"]}
{"project": "dotnet_efcore", "title": "Query: projections pushed to database", "description": "\nNo description provided.\n ", "code": [], "labels": ["3 - Done"]}
{"project": "dotnet_roslyn", "title": "ArgumentOutOfRangeException during extract method", "description": "Crash dump: <CODE> Stack trace <CODE> ", "code": ["%internal_share%\\public\\tomat\\Bugs\\4635\n", "\"Specified argument was out of the range of valid values.\\r\\nParameter name: index\"\n\n   at Microsoft.VisualStudio.Text.Utilities.FrugalList`1.get_Item(Int32 index) in f:\\dd\\src\\Platform\\Text\\Util\\TextDataUtil\\FrugalList.cs:line 254\n   at Microsoft.VisualStudio.Text.Projection.Implementation.ProjectionSnapshot.MapToSourceSnapshot(Int32 position) in f:\\dd\\src\\Platform\\Text\\Impl\\TextModel\\Projection\\ProjectionSnapshot.cs:line 483\n   at Microsoft.VisualStudio.Text.Projection.Implementation.BufferGraph.MapDownToInsertionPoint(SnapshotPoint position, PointTrackingMode trackingMode, Predicate`1 match) in f:\\dd\\src\\Platform\\Text\\Impl\\TextModel\\Projection\\BufferGraph.cs:line 168\n   at Microsoft.CodeAnalysis.Editor.Shared.Extensions.IBufferGraphExtensions.MapUpOrDownToBuffer(IBufferGraph bufferGraph, SnapshotPoint point, ITextBuffer targetBuffer) in F:\\Builds\\5433\\DevDiv\\Roslyn-Master-Signed-Release\\src\\Open\\src\\EditorFeatures\\Core\\Shared\\Extensions\\IBufferGraphExtensions.cs:line 66\n   at Microsoft.CodeAnalysis.Editor.Shared.Extensions.ITextViewExtensions.GetCaretPoint(ITextView textView, ITextBuffer subjectBuffer) in F:\\Builds\\5433\\DevDiv\\Roslyn-Master-Signed-Release\\src\\Open\\src\\EditorFeatures\\Core\\Shared\\Extensions\\ITextViewExtensions.cs:line 34\n   at Microsoft.CodeAnalysis.Editor.Tagging.AbstractAsynchronousTaggerProvider`1.GetCaretPoint(ITextView textViewOpt, ITextBuffer subjectBuffer) in F:\\Builds\\5433\\DevDiv\\Roslyn-Master-Signed-Release\\src\\Open\\src\\EditorFeatures\\Core\\Tagging\\AbstractAsynchronousTaggerProvider.cs:line 153\n   at Microsoft.CodeAnalysis.Editor.Tagging.AbstractAsynchronousTaggerProvider`1.TagSource.RecomputeTagsForeground() in F:\\Builds\\5433\\DevDiv\\Roslyn-Master-Signed-Release\\src\\Open\\src\\EditorFeatures\\Core\\Tagging\\AbstractAsynchronousTaggerProvider.TagSource_ProduceTags.cs:line 288\n   at Microsoft.CodeAnalysis.Editor.Implementation.ForegroundNotification.ForegroundNotificationService.NotifyOnForegroundWorker() in F:\\Builds\\5433\\DevDiv\\Roslyn-Master-Signed-Release\\src\\Open\\src\\EditorFeatures\\Core\\Implementation\\ForegroundNotification\\ForegroundNotificationService.cs:line 116\n   at Microsoft.CodeAnalysis.Editor.Implementation.ForegroundNotification.ForegroundNotificationService.NotifyOnForeground() in F:\\Builds\\5433\\DevDiv\\Roslyn-Master-Signed-Release\\src\\Open\\src\\EditorFeatures\\Core\\Implementation\\ForegroundNotification\\ForegroundNotificationService.cs:line 90\n   at Roslyn.Utilities.TaskFactoryExtensions.<>c__DisplayClass1_0.<SafeStartNew>b__0() in F:\\Builds\\5433\\DevDiv\\Roslyn-Master-Signed-Release\\src\\Open\\src\\Workspaces\\Core\\Portable\\Utilities\\TaskFactoryExtensions.cs:line 30\n"], "labels": ["Area-IDE", "Bug", "Resolution-Duplicate"]}
{"project": "dotnet_docs", "title": "TDD misunderstood", "description": "Hi there, It seems that you've misunderstood TDD in terms of fail first.  Yes, a test must fail the first time, but it is not because it is written wrong, it's because the business logic should not yet have been implemented. Once the test fails you then fix your business logic or method and once you've done that properly your test will pass. My recommendation: = TDD Writing a wrong test that fails and then correcting the test to pass is not TDD - I'm pretty sure it doesn't have a name or purpose. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": [" Area - .NET Core Guide"]}
{"project": "dc-js_dc.js", "title": "heatmap labels", "description": "As shown in #1301 Risk Matrix, it can be useful to have labels inside the heatmap rects. This fork of @oingelsson's fiddle shows a possible implementation:\n<URL> ", "code": [], "labels": ["enhancement"]}
{"project": "armory3d_armory", "title": "Sound Broken on Krom Linux", "description": "(drag & drop zipped .blend file here)\nI have been trying to add sound to my game by opening the sound, giving it a fake user, and then selecting it in the play sound node. However, the sound does not at all play when on my Mac. I have also tried the sound example and that does not work. When I tried to play sound on Windows, it played the very first bit of the sound and then stopped without playing all the way through. This was both for my own sound as well as the example sound blend. This is a major stopping point at the moment. ", "code": [], "labels": ["bug"]}
{"project": "microsoft_vscode-python", "title": "'python.pythonPath' does not resolve '${workspaceFolder:Sibling}'", "description": "When I work in a multi-root workspace and define \"python.pythonPath\": \"${workspaceFolder:Sibling}/.venv/bin/python3\" in my workspace configuration (.code-workspace-file), I expect ${workspaceFolder:Sibling} to be resolved. I want this so that the value for python.pythonPath points to an absolute path and all root folders in my workspace will be able to work with the venv that has its configuration stored in the .venv directory in the Sibling root folder of my workspace. The ${workspaceFolder:Sibling} variable is not resolved at all. If ${workspaceFolder:Sibling} is changed to ${workspaceFolder} it is resolved, but the functionality that I am looking for is not possible anymore (see above, under 'Expected behaviour'). Output for Python in the Output panel (View\u2192Output, change the drop-down the upper-right of the Output panel to Python) <CODE> Output from Console under the Developer Tools panel (toggle Developer Tools on under Help; turn on source maps to make any tracebacks be useful by running Enable source map support for extension debugging) **Note: I don't know how to 'turn on source maps', sorry (Google didn't help me either). ** <CODE> ", "code": ["Starting Jedi Python language engine.\nDiagnostic Code: InvalidPythonInterpreterDiagnostic, Message: No Python interpreter is selected. You need to select a Python interpreter to enable features such as IntelliSense, linting, and debugging.\n\nLinter 'pylint' is not installed. Please install it or select another linter\".\nError: spawn /Users/usp-boy/docs/external/$workspaceFolder:Shared}/.venv/bin/python3 ENOENT\n\nLinter 'pylint' is not installed. Please install it or select another linter\".\nError: spawn /Users/usp-boy/docs/external/$workspaceFolder:Shared}/.venv/bin/python3 ENOENT\n", "extensionHost.ts:311 [Extension Host] debugger listening on port 49542\nconsole.ts:134 [Extension Host] (node:55977) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.\nt.log @ console.ts:134\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Create file systemwatcher with pattern */python\nconsole.ts:134 [Extension Host] Python Extension: Create file systemwatcher with pattern */*/python\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Register Intepreter Watcher, Class name = p, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Build the workspace interpreter watcher, Class name = h, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: <Return value cannot be serialized for logging>\nconsole.ts:134 [Extension Host] Python Extension: Detection of Python Interpreter for Command python2 and args  failed\nconsole.ts:134 [Extension Host] Python Extension: Detection of Python Interpreter for Command /Users/usp_boy/docs/external/$workspaceFolder:Shared}/.venv/bin/python3 and args  failed\nconsole.ts:134 [Extension Host] Python Extension: Rule = settings, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from settings\nconsole.ts:134 [Extension Host] Python Extension: Rule = settings, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from settings\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, <No Resource>\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Create file systemwatcher with pattern */python\nconsole.ts:134 [Extension Host] Python Extension: Create file systemwatcher with pattern */*/python\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Register Intepreter Watcher, Class name = p, Arg 1: <Uri:/Users/usp_boy/docs/>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Build the workspace interpreter watcher, Class name = h, Arg 1: <Uri:/Users/usp_boy/docs/>, Return Value: <Return value cannot be serialized for logging>\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by CondaEnvFileService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by PipEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by CondaEnvService are of count 0\n3console.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by VirtualEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by WorkspaceVirtualEnvService are of count 0\n2console.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by KnownPathsService are of count 12\n2console.ts:134 [Extension Host] Python Extension: Interpreters returned by PipEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by WorkspaceVirtualEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from workspaceEnvs, Nothing Selected\nconsole.ts:134 [Extension Host] Python Extension: Rule = workspaceEnvs, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from workspaceEnvs\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule system is {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule currentPath is {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule windowsRegistry is nothing\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from cachedInterpreters, {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by WorkspaceVirtualEnvService are of count 2\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}, Arg 2: <argument cannot be serialized for logging>, Return Value: true\nconsole.ts:134 [Extension Host] Python Extension: Rule = cachedInterpreters, result = exit\n3console.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Arg 2: <argument cannot be serialized for logging>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Rule = windowsRegistry, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from windowsRegistry\nconsole.ts:134 [Extension Host] Python Extension: Rule = settings, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from settings\nconsole.ts:134 [Extension Host] Python Extension: Build the workspace interpreter watcher, Class name = h, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: <Return value cannot be serialized for logging>\n2console.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, /Users/usp_boy/docs/external/conf.py\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule system is {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule currentPath is {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule windowsRegistry is nothing\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from cachedInterpreters, {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from currentPath, {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Diagnostic Code: InvalidPythonInterpreterDiagnostic, Message: No Python interpreter is selected. You need to select a Python interpreter to enable features such as IntelliSense, linting, and debugging.\nt.log @ console.ts:134\nnotificationsAlerts.ts:40 No Python interpreter is selected. You need to select a Python interpreter to enable features such as IntelliSense, linting, and debugging.\nonDidNotificationChange @ notificationsAlerts.ts:40\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from system, {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true,\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, <No Resource>\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, /Users/usp_boy/docs/external\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, <No Resource>\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = cachedInterpreters, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from cachedInterpreters\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: undefined\n2console.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, /Users/usp_boy/docs/external/conf.py\nconsole.ts:134 [Extension Host] Python Extension: Linter 'pylint' is not installed. Please install it or select another linter\". Error: spawn /Users/usp_boy/docs/external/$workspaceFolder:Shared}/.venv/bin/python3 ENOENT\n\tat Process.ChildProcess._handle.onexit (internal/child_process.js:229:19)\n\tat onErrorNT (internal/child_process.js:406:16)\n\tat process._tickCallback (internal/process/next_tick.js:63:19)\nt.log @ console.ts:134\n2console.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, /Users/usp_boy/docs/external/conf.py\nconsole.ts:134 [Extension Host] Python Extension: Linter 'pylint' is not installed. Please install it or select another linter\". Error: spawn /Users/usp_boy/docs/external/$workspaceFolder:Shared}/.venv/bin/python3 ENOENT\n\tat Process.ChildProcess._handle.onexit (internal/child_process.js:229:19)\n\tat onErrorNT (internal/child_process.js:406:16)\n\tat process._tickCallback (internal/process/next_tick.js:63:19)\nt.log @ console.ts:134\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = currentPath, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from currentPath\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true,\"displayName\":\"Python 3.7.2 64-bit\"}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = system, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from system\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by PipEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by WorkspaceVirtualEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from workspaceEnvs, Nothing Selected\nconsole.ts:134 [Extension Host] Python Extension: Rule = workspaceEnvs, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from workspaceEnvs\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/external/conf.py>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by CurrentPathService are of count 4\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: true\nconsole.ts:134 [Extension Host] Python Extension: Hide locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: All locators have completed locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from workspaceEnvs, {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"envName\":\".venv\",\"type\":\"Venv\"}\nconsole.ts:134 [Extension Host] Python Extension: Rule = workspaceEnvs, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from workspaceEnvs\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule system is {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true,\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule currentPath is {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule windowsRegistry is nothing\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from cachedInterpreters, {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true}, Arg 2: <argument cannot be serialized for logging>, Return Value: true\nconsole.ts:134 [Extension Host] Python Extension: Rule = cachedInterpreters, result = exit\n3console.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/>, Arg 2: <argument cannot be serialized for logging>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Rule = windowsRegistry, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from windowsRegistry\nconsole.ts:134 [Extension Host] Python Extension: Rule = settings, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from settings\n2console.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from currentPath, {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule system is {\"architecture\":3,\"path\":\"/Users/usp_boy/docs/.venv/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/Users/usp_boy/docs/.venv\",\"fileHash\":\"3851f15b31ea732e5e795b65a5b6ea004ff8b7f9133f16a537b6daf79150eb2fdae1b1e7f98a09fdc272916bab47af34a6af24a45a0974a4b43e73aa9c4aec82\",\"type\":\"Unknown\",\"cachedEntry\":true,\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule currentPath is {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule windowsRegistry is nothing\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from cachedInterpreters, {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: Rule = workspaceEnvs, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from workspaceEnvs\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, /Users/usp_boy/docs/\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from system, {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = currentPath, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from currentPath\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = cachedInterpreters, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from cachedInterpreters\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = system, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from system\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:/Users/usp_boy/docs/>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Rule = settings, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from settings\nconsole.ts:134 [Extension Host] Python Extension: Rule = workspaceEnvs, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from workspaceEnvs\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule system is {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule currentPath is {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule windowsRegistry is nothing\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from cachedInterpreters, {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}, Arg 2: <argument cannot be serialized for logging>, Return Value: true\nconsole.ts:134 [Extension Host] Python Extension: Rule = cachedInterpreters, result = exit\n3console.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:extension-output-#6>, Arg 2: <argument cannot be serialized for logging>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, extension-output-#6\nconsole.ts:134 [Extension Host] Python Extension: Rule = windowsRegistry, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from windowsRegistry\nconsole.ts:134 [Extension Host] Python Extension: Rule = settings, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from settings\n2console.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:extension-output-#6>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from currentPath, {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Create file systemwatcher with pattern */python\nconsole.ts:134 [Extension Host] Python Extension: Create file systemwatcher with pattern */*/python\nconsole.ts:134 [Extension Host] Python Extension: Display locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Notify locators are locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Detected refreshing of Interpreters, Class name = p, Arg 1: {}, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Register Intepreter Watcher, Class name = p, Arg 1: <Uri:extension-output-#6>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Build the workspace interpreter watcher, Class name = h, Arg 1: <Uri:extension-output-#6>, Return Value: <Return value cannot be serialized for logging>\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule system is {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule currentPath is {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: Current value for rule windowsRegistry is nothing\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from cachedInterpreters, {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}\nconsole.ts:134 [Extension Host] Python Extension: Rule = workspaceEnvs, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from workspaceEnvs\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:extension-output-#6>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Selected Interpreter from system, {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by WorkspaceVirtualEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = currentPath, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from currentPath\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:extension-output-#6>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Interpreters returned by PipEnvService are of count 0\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\"}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = cachedInterpreters, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from cachedInterpreters\nconsole.ts:134 [Extension Host] Python Extension: Checking whether locactors have completed locating, Class name = p, , Return Value: true\nconsole.ts:134 [Extension Host] Python Extension: Hide locator refreshing progress, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: All locators have completed locating, Class name = p, , Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:extension-output-#6>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: setGlobalInterpreter, Class name = f, Arg 1: {\"architecture\":3,\"path\":\"/usr/local/bin/python3\",\"version\":{\"raw\":\"3.7.2-final\",\"major\":3,\"minor\":7,\"patch\":2,\"prerelease\":[\"final\"],\"build\":[],\"version\":\"3.7.2-final\"},\"sysPrefix\":\"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7\",\"fileHash\":\"2e485b16896e665052c6420f846a58cf2a37ac01a6e649a3a12057caff765f178981d6518a1a148ec6c22beab0d9793ffca4428b55771d94766576729be7e960\",\"type\":\"Unknown\",\"displayName\":\"Python 3.7.2 64-bit\"}, Arg 2: undefined, Return Value: false\nconsole.ts:134 [Extension Host] Python Extension: Rule = system, result = runNextRule\nconsole.ts:134 [Extension Host] Python Extension: Executing next rule from system\nconsole.ts:134 [Extension Host] Python Extension: autoSelectInterpreter, Class name = f, Arg 1: <Uri:extension-output-#6>, Return Value: undefined\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, /Users/usp_boy/docs/external\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, extension-output-#5\nconsole.ts:134 [Extension Host] Python Extension: Cached data exists getEnvironmentVariables, Untitled-1\n"], "labels": ["feature-*", "needs PR", "type-enhancement", "good first issue"]}
{"project": "tensorflow_tensorflow", "title": "Keras load weights fails to load model from directory containing [[", "description": "System information Describe the current behavior\nWhen model checkpoint is stored in a directory containing [[ in its name, the model fails to load, looks like the model files are missing, throwing NotFoundError model.load_weights(osp.join(model_dir, 'model')) throws exception when for example, the model_dir='/home/projects/my_ml/data/sims/bs=2048_dataset=[[2019_9_13],[2019_9_12,2019_9_11,2019_9_10,2019_9_9]]' Describe the expected behavior model.load_weights(osp.join(model_dir, 'model')) should load the data without problems Code to reproduce the issue\nHere is google colab code with mnist example. Other info / logs\nThe error is NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bs=2048_dataset=[[2019_9_13],[2019_9_12,2019_9_11,2019_9_10,2019_9_9]]/model ", "code": [], "labels": ["type:bug", "comp:keras", "TF 1.14"]}
{"project": "hazelcast_hazelcast", "title": "3.2.2 transient test failure: IMap.get(k) returning null", "description": "I have a simple unit test which occasionally fails with hazelcast 3.2.2. This is the sequence of events, all happening in the same thread: I have debug logs for a particular failure. All nodes run on localhost in the same JVM, and in this example A used port 47941, B used port 43858, and C also used port 43858 because NetworkConfig.isReuseAddress() is true (the test is running on linux). One oddity in the logs which I hope doesn't cause confusion, you'll see hazelcast claiming to be version 2.5 and you'll see the package being reported as com.hazelcast32.*. This is because we have both 2.5 and 3.2 on the classpath. The 3.2 files are all shaded (terminology taken from maven shade plugin) and the test is written against the 3.2 API. We do this to allow a smoother transition/upgrade period for users. ", "code": [], "labels": ["Team: Core"]}
{"project": "google_shaka-player", "title": "MP3 HLS in Firefox \"No decoders for requested formats\" MP3 to MP4 remux required", "description": "Using information from #1210 Have you read the FAQ and checked for duplicate open issues?: What version of Shaka Player are you using?:\n2.3.2 Can you reproduce the issue with our latest release version?:\nyes Can you reproduce the issue with the latest code from master?:\nyes Are you using the demo app or your own custom app?:\nDemo app If custom app, can you reproduce the issue using our demo app?: What browser and OS are you using?:\nFirefox 59.0 & Mac High Sierra What are the manifest and license server URIs?:\n<URL> What did you do?\n<URL>;lang=es;build=uncompiled What did you expect to happen?\nmp3 to play What actually happened? **Player error\ncategory: 4\ncode: 9009\ndata: Array []\nhandled: false\nmessage: \"Shaka Error MANIFEST.CONTENT_UNSUPPORTED_BY_BROWSER ()\"\nseverity: 2 Warning: Cannot play media. No decoders for requested formats: audio/mpeg Firefox is able to play the mp3 if you paste an mp3 directly in the url Update 1: Firefox returns false for MediaSource.isTypeSupported(\"audio/mpeg\") Update 2:  Looking further it appears firefox requires mp3 to be remuxed as mp4, is mux.js able to be used for this?\n<URL> ", "code": [], "labels": ["enhancement"]}
{"project": "github_VisualStudio", "title": "Security tenet: Fuzz testing", "description": "We need to perform fuzz testing around the following areas: - All applicable file parsers must be fuzz tested and issues fixed: <URL> Onboard to Microsoft Security Risk Detection (aka Project Springfield), fuzz test your application, and triage resulting bugs according to the SDL bug bar. All failures must be tracked as bugs, triaged according to the SDL Bug Bar and all critical, important, or moderate security bugs must be fixed.   (Note: here's a related URL:  <URL> Note: - Native network protocol parsers must be fuzz tested and issues fixed: <URL> A network interface (i.e. network protocol parser) must be fuzz tested if it receives network traffic from an untrusted or less privileged source, or where the traffic may have been tampered with en route. (this includes traffic originating from an authenticated source) Verify all network parsers are able to withstand 100,000 malformed packets. Note: - RPC/IPC Listeners, URI Protocol Handlers and other types of interfaces must be fuzz tested and issues fixed: <URL> There are a number of ways for programs to pass data between themselves, including traditional RPC/IPC and URI protocol handlers. All \"listeners\" implemented in applicable programming languages are in-scope and must be fuzzed accordingly.  For RPC interfaces where data crosses a trust boundary or could originate from a less trusted source, you must complete 24 hours of fuzzing and triage and fix bugs according to the SDL Bug Bar. Note: ", "code": [], "labels": ["task"]}
{"project": "dotnet_roslyn", "title": "Crash on arm/arm64 with mono due to missing memory barriers", "description": "Version Used: 2.6.0. Doesn't matter Steps to Reproduce: I've seen random roslyn crashes / compilation errors with mono ever since switching to it for building the BCL (on arm/arm64 linuxes)\nFor reproduction you just need to build mono, but the bug is extremely evasive. I have reliably reproduced it on a scaleway.com arm64 vm and also on a compulab utilite2. I can provide access to a machine where it should be easy to reproduce. Expected Behavior: Don't crash Issue: As far as I've investigated the crashes and my small understanding of object pools, it looks like missing memory barriers here <URL> The thread that owns the object and puts it back for reuse doesn't use any synchronisation primitives, so the thread that will reuse this freed object is not guaranteed to see the correct state of the freed object. ", "code": [], "labels": ["Bug", "Area-Compilers"]}
{"project": "mozilla-mobile_focus-android", "title": "Easier way to add custom search engines", "description": "Why What Acceptance Criteria (how do I know when I\u2019m done?) This issue is focused specifically on the context menu item that allows you to add a search engine This menu item is called \u201cAdd Search Engine\u201d. It appears when you tap and hold a search text field that uses the OpenSearch description format.  The UX for this work is finished. ", "code": [], "labels": ["UX", "feature", "P4"]}
{"project": "microsoft_azuredatastudio", "title": "Error uploading files to HDFS", "description": "Issue Type: Bug This is a regression which needs to be fixed. There is an error on uploading the files in HDFS File explorer.  Azure Data Studio version: Azure Data Studio 1.3.4-insider (59b2e70, 2018-11-28T03:10:34.447Z)\nOS version: Darwin x64 17.7.0 ", "code": [], "labels": ["Area - Notebooks", "duplicate"]}
{"project": "endless-sky_endless-sky", "title": "\"On visit\" doesn't work for stopovers", "description": "I'm writing a mission where you escort a ship to a stopover and then go somewhere else. The \"on visit\" tag (to display the \"oops, wait for your escort to show up\" text) only works when I land on the final destination without the escort. It doesn't fire when I land on the stopover planet without the escort. ", "code": [], "labels": ["question"]}
{"project": "angular_angular", "title": "Can you add a link to a new resource?", "description": "In Russia, now the popularization of the framework is the Angular-RU and AngularMoscow community:\n<URL>  <URL> I translate and our team spends different examples with Angular in Russian. It would be great if you added a link (<URL> to our community. Thank you. ", "code": [], "labels": ["comp: docs"]}
{"project": "akiran_react-slick", "title": "Swipe option to falsedisables all clicks within contained elements", "description": "Passing the swipe option as false disables all click events in the containing elements! For example, stopping the carousel and having an element with clickable buttons inside no longer works! How can i fix this? ", "code": [], "labels": ["stale"]}
{"project": "openlayers_openlayers", "title": "Support offsetting/translating features through Style", "description": "Currently, only a few style classes implement an offset option: The general use case of offsetting a shape in pixel space is currently covered by providing a geometry function on the style which will compute a new geometry in world space by applying a delta to the coordinates. This is quite straightforward although not very intuitive. Let's call this first use case \"translating\" instead of \"offsetting\". A bit more complex use case is implementing a logic similar to the line-offset option of the mapbox style spec, or  turfjs. Example with mapbox: <URL> Both use cases could be implemented in the rendering code of OpenLayers, e.g. with the following API: Related issues I found:\n#5057\n#6597\n#7573 -> having a translate option would allow shadows (although not as nice as with shadowColor and shadowColor canvas properties) ", "code": [], "labels": ["stale"]}
{"project": "jeremylong_DependencyCheck", "title": "FileNameAnalyzer.IGNORED_FILES should probably be extended", "description": "The FileNameAnalyzer uses IGNORED_FILES to tell whether it should populate vendor and product evidence. I suspect this blacklist should be extended to exclude files which are pulled in by other analyzers but knowingly do never denote either vendor or product. The following is a concrete suggestion for additions based on other analyzers: As is, the following evidence is reported for e.g. a Gemfile.lock which seems inappropriate/misleading: <CODE>  ", "code": ["\"vendorEvidence\": {\n  \"evidence\": [\n    {\n      \"name\": \"name\",\n      \"source\": \"file\",\n      \"value\": \"Gemfile\",\n      \"used\": true,\n      \"confidence\": \"HIGH\"\n    }\n  ]\n},\n\"productEvidence\": {\n  \"evidence\": [\n    {\n      \"name\": \"name\",\n      \"source\": \"file\",\n      \"value\": \"Gemfile\",\n      \"used\": true,\n      \"confidence\": \"HIGH\"\n    }\n  ]\n},\n"], "labels": ["enhancement"]}
{"project": "primefaces_primeng", "title": "New TreeTable", "description": "Reimplement TreeTable based on the architecture of new p-table (successor of p-dataTable). Initial feature set would be; ", "code": [], "labels": ["enhancement"]}
{"project": "formatjs_react-intl", "title": "Support instant locale switching by making context consumers subscribe to IntlProvider", "description": "As far as I can tell there's currently no simple and convenient way with React-Intl of supporting instant locale switching in a large app that uses pure components (such as your standard usage of react-redux). I think the only good solution to this problem is the observer pattern, which would entail something along the lines of the following: I believe the result would be a clean abstraction (no extra configuration or usage gotchas necessary for users), that should solve the problem seamlessly with minimal performance implications. However if there were any concerns about enabling this by default it could be enabled via a prop on IntlProvider, after-all not everyone uses pure components and needs instant locale switching. I'd be happy to put together a pull request if you think this is a good idea and likely to be merged. ", "code": [], "labels": ["wontfix"]}
{"project": "cdnjs_cdnjs", "title": "[Request] Add regularjs", "description": "Library name: regularjs\nGit repository url: <URL>\nnpm package name or url (if there is one): <URL>\nLicense (List them all if it's multiple): MIT\nOfficial homepage: <URL>\nWanna say something? Leave message here: regularjs is a mvvm framework like vuejs ===================== Notes from cdnjs maintainer:\nPlease read the README.md and CONTRIBUTING.md document first. We encourage you to add a library via sending pull request,\nit'll be faster than just opening a request issue,\nsince there are tons of issues, please wait with patience,\nand please don't forget to read the guidelines for contributing, thanks!! Want to back this issue? Post a bounty on it! We accept bounties via Bountysource.\n ", "code": [], "labels": [" Library Request"]}
{"project": "elastic_elasticsearch", "title": "Repository verification exceptions should be logged", "description": "Currently repository verification exceptions are returned to the user, but not logged on the node where the exception occurred. This behavior makes debugging of some repository registration issues difficult. See elastic/elasticsearch-cloud-aws#217 for example. ", "code": [], "labels": [":Distributed/Snapshot/Restore", ">bug"]}
{"project": "IdentityServer_IdentityServer4", "title": "Exception when posting wrong Content-Type header to introspection", "description": "Greetings! There is an unhandled exception when the wrong Content-Type header is specified while POSTing to the introspection endpoint. Steps to reproduce\nClone the <URL> repo\nModify the GetApiResources method to the following: <CODE> POST the following payload <CODE> You should receive a 500 response back and corresponding stacktrace. <CODE> Thank you! ", "code": ["public static IEnumerable<ApiResource> GetApiResources()\n        {\n            return new List<ApiResource>\n            {\n                new ApiResource\n                {\n                           Name = \"api1\",\n                           DisplayName = \"api1\",\n                           Description = \"test\",\n                           ApiSecrets = new List<Secret> {new Secret(\"secret\".Sha256()) },\n                           Scopes =\n                           {\n                               new Scope(\"test\", \"Test\")\n                               {\n                                   Description = \"test2\",\n                                   ShowInDiscoveryDocument = false\n                               }\n                    }\n                }\n            };\n        }\n", "POST http://localhost:5000/connect/introspect HTTP/1.1\ncache-control: no-cache\nPostman-Token: a9b9362f-47ee-4658-957b-c385c889ea48\nContent-Type: application/json\nAuthorization: Basic YXBpMTpzZWNyZXQ=\nUser-Agent: PostmanRuntime/6.1.6\nAccept: */*\nHost: localhost:5000\naccept-encoding: gzip, deflate\ncontent-length: 0\nConnection: keep-alive\n", "info: IdentityServer4.Startup[0]\n      You are using the in-memory version of the persisted grant store. This will store consent decisions, authorization codes, refresh and reference tokens in memory only. If you are using any of those features in production, you want to switch to a different store implementation.\ndbug: IdentityServer4.Hosting.CookieMiddlewareExtensions[0]\n      Using built-in CookieAuthentication middleware with scheme: idsrv\ndbug: IdentityServer4.Hosting.CookieMiddlewareExtensions[0]\n      Adding CookieAuthentication middleware for external authentication with scheme: idsrv.external\ninfo: Microsoft.Extensions.DependencyInjection.DataProtectionServices[0]\n      User profile is available. Using 'C:\\Users\\john.holmes\\AppData\\Local\\ASP.NET\\DataProtection-Keys' as key repository and Windows DPAPI to encrypt keys at rest.\ndbug: Microsoft.AspNetCore.Hosting.Internal.WebHost[3]\n      Hosting starting\ndbug: Microsoft.AspNetCore.Hosting.Internal.WebHost[4]\n      Hosting started\nHosting environment: Development\nContent root path: C:\\code\\IdentityServer4.Samples\\Quickstarts\\1_ClientCredentials\\src\\QuickstartIdentityServer\nNow listening on: http://localhost:5000\nApplication started. Press Ctrl+C to shut down.\ndbug: Microsoft.AspNetCore.Server.Kestrel[1]\n      Connection id \"0HL6NNDF8T63S\" started.\ndbug: Microsoft.AspNetCore.Server.Kestrel[1]\n      Connection id \"0HL6NNDF8T63T\" started.\ndbug: Microsoft.AspNetCore.Server.Kestrel[6]\n      Connection id \"0HL6NNDF8T63T\" received FIN.\ndbug: Microsoft.AspNetCore.Server.Kestrel[10]\n      Connection id \"0HL6NNDF8T63T\" disconnecting.\ndbug: Microsoft.AspNetCore.Server.Kestrel[7]\n      Connection id \"0HL6NNDF8T63T\" sending FIN.\ndbug: Microsoft.AspNetCore.Server.Kestrel[8]\n      Connection id \"0HL6NNDF8T63T\" sent FIN with status \"0\".\ndbug: Microsoft.AspNetCore.Server.Kestrel[2]\n      Connection id \"0HL6NNDF8T63T\" stopped.\ninfo: Microsoft.AspNetCore.Hosting.Internal.WebHost[1]\n      Request starting HTTP/1.1 POST http://localhost:5000/connect/introspect application/json 0\ndbug: Microsoft.AspNetCore.Authentication.Cookies.CookieAuthenticationMiddleware[9]\n      AuthenticationScheme: idsrv was not authenticated.\ndbug: IdentityServer4.Hosting.EndpointRouter[0]\n      Request path /connect/introspect matched to endpoint type Introspection\ndbug: IdentityServer4.Hosting.EndpointRouter[0]\n      Mapping found for endpoint: Introspection, creating handler: IdentityServer4.Endpoints.IntrospectionEndpoint\ninfo: IdentityServer4.Hosting.IdentityServerMiddleware[0]\n      Invoking IdentityServer endpoint: IdentityServer4.Endpoints.IntrospectionEndpoint for /connect/introspect\ntrce: IdentityServer4.Endpoints.IntrospectionEndpoint[0]\n      Processing introspection request.\ndbug: IdentityServer4.Endpoints.IntrospectionEndpoint[0]\n      Starting introspection request.\ntrce: IdentityServer4.Validation.ApiSecretValidator[0]\n      Start API validation\ndbug: IdentityServer4.Validation.BasicAuthenticationSecretParser[0]\n      Start parsing Basic Authentication secret\ndbug: IdentityServer4.Validation.SecretParser[0]\n      Parser found secret: BasicAuthenticationSecretParser\ndbug: IdentityServer4.Validation.SecretParser[0]\n      Secret id found: api1\ndbug: IdentityServer4.Validation.SecretValidator[0]\n      Secret validator success: HashedSharedSecretValidator\ndbug: IdentityServer4.Validation.ApiSecretValidator[0]\n      API resource validation success\ncrit: IdentityServer4.Hosting.IdentityServerMiddleware[0]\n      Unhandled exception: System.InvalidOperationException: Incorrect Content-Type: application/json\n         at Microsoft.AspNetCore.Http.Features.FormFeature.<InnerReadFormAsync>d__18.MoveNext()\n      --- End of stack trace from previous location where exception was thrown ---\n         at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n         at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n         at IdentityServer4.Endpoints.IntrospectionEndpoint.<ProcessIntrospectionRequestAsync>d__7.MoveNext()\n      --- End of stack trace from previous location where exception was thrown ---\n         at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n         at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n         at IdentityServer4.Endpoints.IntrospectionEndpoint.<ProcessAsync>d__6.MoveNext()\n      --- End of stack trace from previous location where exception was thrown ---\n         at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n         at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n         at IdentityServer4.Hosting.IdentityServerMiddleware.<Invoke>d__3.MoveNext()\nfail: Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware[0]\n      An unhandled exception has occurred while executing the request\nSystem.InvalidOperationException: Incorrect Content-Type: application/json\n   at Microsoft.AspNetCore.Http.Features.FormFeature.<InnerReadFormAsync>d__18.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at IdentityServer4.Endpoints.IntrospectionEndpoint.<ProcessIntrospectionRequestAsync>d__7.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at IdentityServer4.Endpoints.IntrospectionEndpoint.<ProcessAsync>d__6.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at IdentityServer4.Hosting.IdentityServerMiddleware.<Invoke>d__3.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at IdentityServer4.Hosting.FederatedSignOutMiddleware.<Invoke>d__6.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at IdentityServer4.Hosting.AuthenticationMiddleware.<Invoke>d__2.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware`1.<Invoke>d__18.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware`1.<Invoke>d__18.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware`1.<Invoke>d__18.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware`1.<Invoke>d__18.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Microsoft.AspNetCore.Cors.Infrastructure.CorsMiddleware.<Invoke>d__7.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at IdentityServer4.Hosting.BaseUrlMiddleware.<Invoke>d__2.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.<Invoke>d__7.MoveNext()\ndbug: Microsoft.AspNetCore.Server.Kestrel[9]\n      Connection id \"0HL6NNDF8T63S\" completed keep alive response.\ninfo: Microsoft.AspNetCore.Hosting.Internal.WebHost[2]\n      Request finished in 704.4651ms 500 text/html; charset=utf-8\n\n"], "labels": ["bug"]}
{"project": "Automattic_mongoose", "title": "Need an option to disable auto-conversion of strings to dates", "description": "Forgive me if there is already a way to do this, I can't find an answer on SO. I have a query: In my schema, value is a string, but when this query is run, it seems that Mongoose is converting my date strings to Date objects. Here's the query parameters from mongoose debug: I need the date strings to stay as date strings, or else this query fails. How do I do this? Or is this a feature request? I'm using mongoose 5.1.2 ", "code": [], "labels": ["can't reproduce"]}
{"project": "dart-lang_sdk", "title": "JS-interop example produces > 2.5 mb .js file", "description": "This issue was originally filed by Roman.Korneyev@gmail.com What steps will reproduce the problem? import 'dart:html';\nimport 'package:js/js.dart' as js; // js not usssed! but output is about 2.5mb! void main() {\n\u00a0// do something\n} Using import 'package:js/js.dart'; in a simple dart-app causes the output file is huge (about 2.5 mb) I Using import 'package:js/js.dart'; in a simple dart-app causes the output file is huge (about 2.5 mb). I guess that this problem may be in any package imports dart:mirrors without specifieng @\u00adMirrorsUsed ", "code": [], "labels": ["closed-as-intended", "Type-Defect", "web-dart2js"]}
{"project": "flutter_flutter", "title": "How to create a horizontal  SliverList\uff1f", "description": "<CODE> ", "code": ["  return CustomScrollView(\n    slivers: <Widget>[\n      headerView('\u6211\u7684\u5e94\u7528'),\n      new SliverFixedExtentList(\n        itemExtent: 44.0,\n        delegate: new SliverChildBuilderDelegate((context,index) {\n          return new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('data'),\n            ),\n          );\n        },\n        childCount: 5,\n        ),\n      ),\n      new SliverGrid.extent(\n        maxCrossAxisExtent: 100,\n        children: <Widget>[\n          new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('\u56fa\u5b9a\u5bbd\u5ea6'),\n            ),\n          ),\n          new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('\u56fa\u5b9a\u5bbd\u5ea6'),\n            ),\n          ),\n          new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('\u56fa\u5b9a\u5bbd\u5ea6'),\n            ),\n          ),\n          new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('\u56fa\u5b9a\u5bbd\u5ea6'),\n            ),\n          ),\n          new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('\u56fa\u5b9a\u5bbd\u5ea6'),\n            ),\n          ),\n          new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('\u56fa\u5b9a\u5bbd\u5ea6'),\n            ),\n          ),\n          new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('\u56fa\u5b9a\u5bbd\u5ea6'),\n            ),\n          ),\n        ],\n      ),\n      new SliverGrid(\n        gridDelegate: SliverGridDelegateWithFixedCrossAxisCount(\n          crossAxisCount: 5,\n        ),\n        delegate: new SliverChildBuilderDelegate((context,index) {\n          return new Card(\n            child: FlatButton(\n              onPressed: () {\n                print('\u70b9\u51fb\u6587\u4ef6\u5939');\n              },\n              child: Text('data'),\n            ),\n          );\n        },\n        childCount: items.length,\n        ),\n      ),\n    ],\n  );\n}\n"], "labels": ["d: stackoverflow", "f: scrolling", "framework"]}
{"project": "aio-libs_aiohttp", "title": "Requests with long responses hang when await is used instead of async with", "description": "Requests seem to hang when the response is long. Try this code: This snippet returns the BTC-USD orderbook from the exchange Coinbase Pro. The level parameter controls the amount of data. The calls work for level values 1 and 2, but not 3. If you do the same request via a browser (or any synchronous library like requests), you'll see that it returns a similar type of data (but a much larger amount). OS: Mac OS X High Sierra\nPython version: 3.7.4\naiohttp version: 3.5.4 ", "code": [], "labels": ["invalid"]}
{"project": "magento_magento2", "title": "Mass action dropdowns in new UI grids (Sales, Products, etc.) don't support scrolling", "description": "Version: 1.0.0-beta We need to add a lot actions to the Sales > Orders actions dropdown. However, it doesn't limit the number of actions shown at the same time, but the dropdown just gets longer and longer. I would highly suggest to add scrolling support - as many developers will add mass actions there. Example:  ", "code": [], "labels": ["Progress: needs update", "improvement", "CS", "Issue: Ready for Work"]}
{"project": "parse-community_parse-server", "title": "ACL to enable public or role read / write on specific fields of a class", "description": "If a class has 3 fields namely: A, B, C; is it possible to enable field specific individual role permission? Ex:\nField A could have public read.\nField B could have role read only.\nField C could have public read and role write only.\nSo on and so forth... ", "code": [], "labels": ["wontfix"]}
{"project": "magnumripper_JohnTheRipper", "title": "RAR3 multi-volume archive", "description": "hashcat/hashcat#1420 (comment) I think we need to fix rar2john as well as the JtR formats. While at it, we should make rar2john output \"hash only\" when argv[0] is rar2hashcat. That is, skip the login/gecos fields. My rationale is to avoid forks that divert too much. ", "code": [], "labels": ["enhancement"]}
{"project": "Wox-launcher_Wox", "title": "\u80fd\u5426\u52a0\u5165\u8c03\u6574\u641c\u7d22\u6846\u5927\u5c0f\u7684\u529f\u80fd\uff1f", "description": "\u5c0f\u5c4f\u5e55\u7684\u7b14\u8bb0\u672c\u4e0a\u7528\u7740\u5b9e\u5728\u592a\u5927\u4e86 ", "code": [], "labels": ["ui"]}
{"project": "24pullrequests_24pullrequests", "title": "Upgrade term-ansicolor to version 1.4.0", "description": "Libraries.io has found that there is a newer version of term-ansicolor that this project depends on. More info: <URL> ", "code": [], "labels": ["help wanted", "enhancement"]}
{"project": "kubernetes_kops", "title": "rolling-update wants to replace spot instances created by Autospotting", "description": "Thanks for submitting an issue! Please fill in as much of the template below as\nyou can. ------------- BUG REPORT TEMPLATE -------------------- Version 1.9.0 <CODE> AWS <CODE> 'kops rolling-update' wants to replace spot instances, allthough they have the same tags and config as specified in the launchconfig. 'kops rolling-update' should show NEEDUPDATE column with value '0'. <CODE> <CODE> I use <URL> to automatically replace on-demand instances with spot instances. The spot instances have the same configuration as the on-demand instances and they are attached to the same ASG (bastion & nodes).\nWhenever a new on-demand instance comes up (for example by cluster autoscaling), Autospotting will replace it with a spot-instance. ", "code": ["Client Version: version.Info{Major:\"1\", Minor:\"10\", GitVersion:\"v1.10.2\", GitCommit:\"81753b10df112992bf51bbc2c2f85208aad78335\", GitTreeState:\"clean\", BuildDate:\"2018-05-12T04:12:12Z\", GoVersion:\"go1.9.6\", Compiler:\"gc\", Platform:\"darwin/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"9\", GitVersion:\"v1.9.8\", GitCommit:\"c138b85178156011dc934c2c9f4837476876fb07\", GitTreeState:\"clean\", BuildDate:\"2018-05-21T18:53:18Z\", GoVersion:\"go1.9.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n", "# kops rolling-update cluster --name CLUSTERNAME --state s3://S3_BUCKET\nNAME\t\t\tSTATUS\t\tNEEDUPDATE\tREADY\tMIN\tMAX\tNODES\nbastions\t\tNeedsUpdate\t1\t\t0\t1\t1\t0\nmaster-eu-west-1a\tReady\t\t0\t\t1\t1\t1\t1\nmaster-eu-west-1b\tReady\t\t0\t\t1\t1\t1\t1\nmaster-eu-west-1c\tReady\t\t0\t\t1\t1\t1\t1\nnodes\t\t\tNeedsUpdate\t3\t\t0\t3\t6\t3\n\nMust specify --yes to rolling-update.\n", "kops get --name CLUSTERNAME --state s3://S3_BUCKET -o yaml\napiVersion: kops/v1alpha2\nkind: Cluster\nmetadata:\n  creationTimestamp: 2018-06-19T11:22:54Z\n  name: CLUSTERNAME\nspec:\n  additionalPolicies:\n    bastion: |\n      [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:*\", \"ec2:Describe*\", \"cloudwatch:*\"],\n          \"Resource\": [\"*\"]\n        }\n      ]\n    master: |\n      [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:*\", \"ec2:Describe*\", \"cloudwatch:*\"],\n          \"Resource\": [\"*\"]\n        }\n      ]\n    node: |\n      [\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\"s3:*\", \"ec2:Describe*\", \"cloudwatch:*\", \"sts:AssumeRole\"],\n          \"Resource\": [\"*\"]\n        }\n      ]\n  api:\n    loadBalancer:\n      type: Public\n  authorization:\n    rbac: {}\n  channel: stable\n  cloudLabels:\n    foo: bar\n  cloudProvider: aws\n  configBase: s3://S3_BUCKET/CLUSTERNAME\n  dnsZone: ABCDEFGH\n  docker:\n    bridge: \"\"\n    ipMasq: false\n    ipTables: false\n    logDriver: json-file\n    logLevel: warn\n    logOpt:\n    - max-size=10m\n    - max-file=5\n    storage: overlay2\n    version: 17.03.2\n  etcdClusters:\n  - enableEtcdTLS: true\n    etcdMembers:\n    - encryptedVolume: true\n      instanceGroup: master-eu-west-1a\n      name: a\n    - encryptedVolume: true\n      instanceGroup: master-eu-west-1b\n      name: b\n    - encryptedVolume: true\n      instanceGroup: master-eu-west-1c\n      name: c\n    name: main\n    version: 3.1.12\n  - enableEtcdTLS: true\n    etcdMembers:\n    - encryptedVolume: true\n      instanceGroup: master-eu-west-1a\n      name: a\n    - encryptedVolume: true\n      instanceGroup: master-eu-west-1b\n      name: b\n    - encryptedVolume: true\n      instanceGroup: master-eu-west-1c\n      name: c\n    name: events\n    version: 3.1.12\n  iam:\n    allowContainerRegistry: true\n    legacy: false\n  kubeAPIServer:\n    runtimeConfig:\n      autoscaling/v2beta1: \"true\"\n  kubeControllerManager:\n    horizontalPodAutoscalerUseRestClients: true\n  kubelet:\n    enableCustomMetrics: true\n  kubernetesApiAccess:\n  - xxx.xxx.xxx.xxx/yyy\n  kubernetesVersion: 1.9.3\n  masterInternalName: api.internal.CLUSTERNAME\n  masterPublicName: api.CLUSTERNAME\n  networkCIDR: 172.20.0.0/16\n  networking:\n    calico: {}\n  nonMasqueradeCIDR: 100.64.0.0/10\n  sshAccess:\n  - xxx.xxx.xxx.xxx/yyy\n  subnets:\n  - cidr: 172.20.64.0/18\n    name: eu-west-1a\n    type: Private\n    zone: eu-west-1a\n  - cidr: 172.20.128.0/18\n    name: eu-west-1b\n    type: Private\n    zone: eu-west-1b\n  - cidr: 172.20.192.0/18\n    name: eu-west-1c\n    type: Private\n    zone: eu-west-1c\n  - cidr: 172.20.0.0/24\n    name: utility-eu-west-1a\n    type: Utility\n    zone: eu-west-1a\n  - cidr: 172.20.1.0/24\n    name: utility-eu-west-1b\n    type: Utility\n    zone: eu-west-1b\n  - cidr: 172.20.2.0/24\n    name: utility-eu-west-1c\n    type: Utility\n    zone: eu-west-1c\n  topology:\n    bastion:\n      bastionPublicName: bastion.CLUSTERNAME\n    dns:\n      type: Private\n    masters: private\n    nodes: private\n\n---\n\napiVersion: kops/v1alpha2\nkind: InstanceGroup\nmetadata:\n  creationTimestamp: 2018-06-19T11:22:54Z\n  labels:\n    kops.k8s.io/cluster: CLUSTERNAME\n  name: bastions\nspec:\n  cloudLabels:\n    spot-enabled: \"true\"\n  image: ami-baa19ac3\n  machineType: t2.micro\n  maxSize: 1\n  minSize: 1\n  nodeLabels:\n    kops.k8s.io/instancegroup: bastions\n  role: Bastion\n  rootVolumeSize: 30\n  subnets:\n  - utility-eu-west-1a\n  - utility-eu-west-1b\n  - utility-eu-west-1c\n\n---\n\napiVersion: kops/v1alpha2\nkind: InstanceGroup\nmetadata:\n  creationTimestamp: 2018-06-19T11:22:54Z\n  labels:\n    kops.k8s.io/cluster: CLUSTERNAME\n  name: master-eu-west-1a\nspec:\n  cloudLabels:\n    spot-enabled: \"false\"\n  image: ami-003838ea\n  machineType: m5.large\n  maxSize: 1\n  minSize: 1\n  nodeLabels:\n    kops.k8s.io/instancegroup: master-eu-west-1a\n  role: Master\n  rootVolumeSize: 60\n  subnets:\n  - eu-west-1a\n\n---\n\napiVersion: kops/v1alpha2\nkind: InstanceGroup\nmetadata:\n  creationTimestamp: 2018-06-19T11:22:54Z\n  labels:\n    kops.k8s.io/cluster: CLUSTERNAME\n  name: master-eu-west-1b\nspec:\n  cloudLabels:\n    spot-enabled: \"false\"\n  image: ami-003838ea\n  machineType: m5.large\n  maxSize: 1\n  minSize: 1\n  nodeLabels:\n    kops.k8s.io/instancegroup: master-eu-west-1b\n  role: Master\n  rootVolumeSize: 60\n  subnets:\n  - eu-west-1b\n\n---\n\napiVersion: kops/v1alpha2\nkind: InstanceGroup\nmetadata:\n  creationTimestamp: 2018-06-19T11:22:54Z\n  labels:\n    kops.k8s.io/cluster: CLUSTERNAME\n  name: master-eu-west-1c\nspec:\n  cloudLabels:\n    spot-enabled: \"false\"\n  image: ami-003838ea\n  machineType: m5.large\n  maxSize: 1\n  minSize: 1\n  nodeLabels:\n    kops.k8s.io/instancegroup: master-eu-west-1c\n  role: Master\n  rootVolumeSize: 60\n  subnets:\n  - eu-west-1c\n\n---\n\napiVersion: kops/v1alpha2\nkind: InstanceGroup\nmetadata:\n  creationTimestamp: 2018-06-19T11:22:54Z\n  labels:\n    kops.k8s.io/cluster: CLUSTERNAME\n  name: nodes\nspec:\n  cloudLabels:\n    autospotting_allowed_instance_types: current\n    spot-enabled: \"true\"\n  image: ami-003838ea\n  machineType: m5.large\n  maxSize: 6\n  minSize: 3\n  nodeLabels:\n    kops.k8s.io/instancegroup: nodes\n  role: Node\n  rootVolumeSize: 60\n  subnets:\n  - eu-west-1a\n  - eu-west-1b\n  - eu-west-1c\n", "...\nI0619 14:49:45.009897   82893 aws_utils.go:39] Querying EC2 for all valid regions\nI0619 14:49:45.643529   82893 aws_cloud.go:981] Querying EC2 for all valid zones in region \"eu-west-1\"\nI0619 14:49:45.643686   82893 request_logger.go:45] AWS request: ec2/DescribeAvailabilityZones\nI0619 14:49:45.958178   82893 aws_cloud.go:423] Listing all Autoscaling groups matching cluster tags\nI0619 14:49:45.960381   82893 request_logger.go:45] AWS request: autoscaling/DescribeTags\nI0619 14:49:46.266176   82893 request_logger.go:45] AWS request: autoscaling/DescribeAutoScalingGroups\nNAME\t\t\tSTATUS\t\tNEEDUPDATE\tREADY\tMIN\tMAX\tNODES\nbastions\t\tNeedsUpdate\t1\t\t0\t1\t1\t0\nmaster-eu-west-1a\tReady\t\t0\t\t1\t1\t1\t1\nmaster-eu-west-1b\tReady\t\t0\t\t1\t1\t1\t1\nmaster-eu-west-1c\tReady\t\t0\t\t1\t1\t1\t1\nnodes\t\t\tNeedsUpdate\t3\t\t0\t3\t6\t3\n\nMust specify --yes to rolling-update.\n"], "labels": ["lifecycle/rotten"]}
{"project": "gatsbyjs_gatsby", "title": "Custom postcss.config.js isn't loaded by gatsby-plugin-postcss or gatsby-plugin-sass", "description": "I'm trying to use postcss.config.js file to configure postcss but the config isn't loaded at all. <CODE> The config file should be used. <CODE> <CODE> ", "code": ["\"gatsby\": \"^2.13.67\"\n\"gatsby-plugin-sass\": \"^2.1.8\"\n\"gatsby-plugin-postcss\": \"^2.1.3\"\n", "\"gatsby\": \"^2.13.67\"\n\"gatsby-plugin-sass\": \"^2.1.8\"\n\"gatsby-plugin-postcss\": \"^2.1.3\"\n", "  System:\n    OS: Linux 5.0 Ubuntu 18.04.3 LTS (Bionic Beaver)\n    CPU: (12) x64 AMD Ryzen 5 2600X Six-Core Processor\n    Shell: 4.4.20 - /bin/bash\n  Binaries:\n    Node: 11.14.0 - /tmp/yarn--1566058060211-0.37519524786455727/node\n    Yarn: 1.17.3 - /tmp/yarn--1566058060211-0.37519524786455727/yarn\n    npm: 6.7.0 - ~/n/bin/npm\n  Languages:\n    Python: 3.7.2 - /home/starptech/.pyenv/shims/python\n  Browsers:\n    Chrome: 76.0.3809.100\n"], "labels": ["status: needs more info", "type: bug"]}
{"project": "nodejs_node", "title": "Undefined hostname defaults to 127.0.0.1", "description": "I'm not sure what's the idea behind defaulting to 127.0.0.1 in http.request when hostname is undefined, but it's not a good one. Please throw an error when hostname is anything but string, telling the user she's an idiot, rather than defaulting to some arbitrary IP address causing potentially dangerous and destructive side-effects (what if Trump's nukes are on the same port on 127.0.0.1?) It's all cool that it's in the docs, but that doesn't mean it makes any sense or any good. Common pitfall: undefined slips into the variable used to fill hostname, and all the user gets is this: <CODE> Not even a hint of what is going on, or where. ", "code": ["Error: connect ECONNREFUSED 127.0.0.1:80\n    at Object.exports._errnoException (util.js:1028:11)\n    at exports._exceptionWithHostPort (util.js:1051:20)\n    at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1090:14)\n"], "labels": ["http"]}
{"project": "spring-projects_spring-security", "title": "XML configuration with multiple security:http register multiple requestDataValueProcessor", "description": "Backport of gh-6423 ", "code": [], "labels": ["type: backport", "type: bug"]}
{"project": "OpenTTD_OpenTTD", "title": "Lodaing too many grf's breaks sound (bugger overflow?)", "description": "Leviath.NL opened the ticket and wrote: Attachments Reported version: trunk\nOperating system: Linux ", "code": [], "labels": ["Core", "flyspray"]}
{"project": "translate_pootle", "title": "Drop old password change UI", "description": "We have an obsolete <URL> UI that has been replaced with the new sign in UI. Let's drop it. Optionally, If we want to have a quick access to password reset feature, we can keep the <URL> URL which should render a welcome page template with 'Reset Your Password' popup being displayed automatically (similar to what we do with <URL> ", "code": [], "labels": ["enhancement", "cleanup", "ui"]}
{"project": "envoyproxy_envoy", "title": "Backtrace support in debug builds", "description": "Add something like <URL> to the build (at least for debug builds) and enable dumping a stack trace on crash with a std::terminate_handler. ", "code": [], "labels": ["area/build"]}
{"project": "microsoft_vscode", "title": "react fragment breaks code formatting", "description": "Version: 1.34.0 (user setup)\nDate: 2019-05-15T21:59:37.030Z\nElectron: 3.1.8\nChrome: 66.0.3359.181\nNode.js: 10.2.0\nV8: 6.6.346.32\nOS: Windows_NT x64 10.0.17134 Steps to Reproduce: Does this issue occur when all extensions are disabled?: Yes/No\nNo ", "code": [], "labels": ["needs more info"]}
{"project": "twbs_bootstrap", "title": "Custom control border color missing on focus and checked", "description": "Focus border color is missing when a custom checkbox is checked. It's because of the following line of code: <CODE> It should be without\n:not(:checked) Resulting in: <CODE> ", "code": ["&:focus:not(:checked) ~ .custom-control-label::before {\n  border-color: $custom-control-indicator-focus-border-color;\n}\n", "&:focus ~ .custom-control-label::before {\n  border-color: $custom-control-indicator-focus-border-color;\n}\n"], "labels": ["v4"]}
{"project": "rest-assured_rest-assured", "title": "Upgrade Groovy from 1.8.4 to 1.8.9", "description": "From Juergen....@HS-Karlsruhe.de on April 01, 2013 18:14:22 The release date of Groovy 1.8.4 is Nov 2011, and 1.8.9 was released in Feb. 2013. Original issue: <URL> ", "code": [], "labels": ["wontfix", "Priority-Medium", "imported", "bug"]}
{"project": "pwn20wndstuff_Undecimus", "title": "Random reboots on iOS 11.3.1 iPhone 6s", "description": "On the latest version of uncOver\nThe phone would randomly get hotter than normal and freeze up like Electra would. Then reboot into non jailbroken state.\nIt. It once resprong randomly with tweaks partially on but another respring fixed that one. But the random freezes don\u2019t last as long as Electra\u2019s does. Device just overly gets hot and reboots.\nI could add my tweak list or a crash log if that would help. As it maybe could be a tweak causing it but it\u2019s worth getting to you just in case it\u2019s Unc0vers problem for the freezes. Only happend twice so far. But the over heating has happened when I first tried out your jailbreak with no tweaks installed\nUpdate - added a drobox folder you can taks a look at. It contains all the potential priblems that could of caused the freeze of the phone to reboot. I think its just the kernal panicking to often. But since i switched over to the unc0ver jailbreak which is noticably better. It causes device to over heat excessivly when a kenal panic happens which never happened with electea when the kernal panic happned <URL> ", "code": [], "labels": ["need more info"]}
{"project": "ngx-formly_ngx-formly", "title": "Showcase Nativescript support", "description": "\ud83c\udf89\ud83c\udf89 I think we need to document this in Readme file <URL> ", "code": [], "labels": ["question"]}
{"project": "pymedusa_Medusa", "title": "Config patch ignored {u'clients': {u'torrents': {u'rpcUrl': u'transmission'}}}", "description": "Describe the bug\nShows error when  I try to setup Transmission. Does not save \"RPC URL\" field. 2019-01-02 23:03:23 WARNING  APIv2-Thread_6 :: [918cfe7] Config patch ignored {u'clients': {u'torrents': {u'rpcUrl': u'transmission'}}} To Reproduce Expected behavior\nShould save settings and work Logs:\n2019-01-02 23:03:23 WARNING  APIv2-Thread_6 :: [918cfe7] Config patch ignored {u'clients': {u'torrents': {u'rpcUrl': u'transmission'}}} Additional context\nAdd any other context about the problem here. ", "code": [], "labels": ["triage"]}
{"project": "logaretm_vee-validate", "title": "Confirmed validation rule doesn't work with lazy models", "description": "If field A's model is lazy and field B has a confirmed validation rule pointing to field A, typing into field A does not work. When the first character is entered, it immediately triggers failed validation on Field B. Very bizarre issue. The below markup should reproduce the issue: It starts working again when lazy is removed from the password model. However, I don't want that because then validation becomes too aggressive and annoying. I did not test this on other field types, or without the required validation rule. ", "code": [], "labels": [" enhancement"]}
{"project": "angular_components", "title": "mat-select should close when escape is pressed, also stop propagation", "description": "bug? when mat-select is open and escape is pressed it should close the select select doesn't close and the element upstream gets the escape. In my case the mat-drawer catches this Escape which results in weird behavior: drawer closes, and the opened select is floating outside of it (because it's part of the cdk-portal). <URL> Open drawer\nClick the selector\nPress ESC ", "code": [], "labels": ["P3"]}
{"project": "alacritty_alacritty", "title": "Writting in last column inserts a newline (unlike xterm/rxvt)", "description": "To reproduce it, execute this in bash (bash --norc if custom prompt is obstructing): <CODE> This should make the word \"TEST\" appear in the bottom right, exactly in the corner border.\nHowever, in alacritty it will also insert a newline, which does not happen in xterm or rxvt. I'm using something like this as a pre-prompt hook in my bashrc to add prompt information to the right side, but this change of behavior in alacritty adds additional spaces to the prompt, and I guess it could potentially also mess up ncurses interfaces if they write characters in that space too. ", "code": ["echo -ne \"\\e[s\\e[$LINES;$((COLUMNS-3))fTEST\\e[u\"\n"], "labels": ["B - bug"]}
{"project": "rails_rails", "title": "group trashes select values", "description": "When I do a query with both select and group, the group trashes the values I specified with select, eg: <CODE> ... will not include a sum_b column in the result. This appears to be caused by activerecord/lib/active_record/relation/calculation.rb, line ~299 (in both 4.1.4 and master): <CODE> Essentially the last line trashes the previously set relation.select_values. One possible fix appears to be to change the last line to: <CODE> ... but I am not particularly certain that this is correct in all cases, and anyway I'm not sure if the select_values should really be added to if they have already been specified. ", "code": ["User.select('a', 'sum(b) as sum_b').group('a')\n", "  select_values = [\n    operation_over_aggregate_column(\n      aggregate_column(column_name),\n      operation,\n      distinct).as(aggregate_alias)\n  ]\n  select_values += select_values unless having_values.empty?\n\n  select_values.concat group_fields.zip(group_aliases).map { |field,aliaz|\n    if field.respond_to?(:as)\n      field.as(aliaz)\n    else\n      \"#{field} AS #{aliaz}\"\n    end\n  }\n\n  relation = except(:group)\n  relation.group_values  = group\n  relation.select_values = select_values\n", "  relation.select_values = select_values\n"], "labels": ["stale", "activerecord"]}
{"project": "jekyll_jekyll", "title": "Please update the macOS install documentation", "description": "Hi Guys, Firstly, thank you for taking the time to make such an epic service and for providing support to folks like myself. I am attempting to install Jekyll on a new machine and I quickly remembered a previous painful attempt earlier this year #6894 Thanks to @DirtyF for some great support during that harsh time \ud83e\udd23 I am about to give it another go on a new machine and the docs here are lacking a few details. I really like the style and consideration that has gone into those docs. So it seems a bit sad that they are lacking a step or two. I think it's a serious issue because another dude is also having similar problems #6690 by the looks of it. I think it all boils down to ruby and unix. I realise there is a thin line between providing support for Jekyll and support for everything else, but I think web developers might have a stronger understanding of these workflows. As an iOS developer, I don't usually spend a lot of time with bash shell's. This is merely a request to update the docs found here with some more guidance. Maybe written in such a way so that a 7 year old could understand. ", "code": [], "labels": ["documentation", "frozen-due-to-age"]}
{"project": "gwtproject_gwt", "title": "RichTextArea should allow use of StyleInjector", "description": "Originally reported on Google Code with ID 3060 <CODE> Reported by mmastrac on 2008-10-30 16:02:03 ", "code": ["Found in GWT Release:\n\n1.5\n\nDetailed description:\n\nRichTextArea's default font is Serif (at least in Safari and FF), which\nisn't the prettiest.  GWT needs a way to inject stylesheets into a\nRichTextArea at the appropriate time.  Because of timing issues, this is a\nbit tricky to get right (you need to use timers to make sure you are doing\nit at the right time).\n\nIdeally, we could use StyleInjector to inject CSS into the IFRAME, the same\nway we inject CSS into the main module.  If not StyleInjector, at least a\nmethod on IFRAME that takes stylesheet text and caches and/or injects it\n(depending on the state of the IFRAME - see the setHTML() method).\n\n\nWorkaround if you have one:\n\nDo it with JSNI after the appropriate delay.\n\n\nLinks to the relevant GWT Developer Forum posts:\n\nn/a\n"], "labels": ["Category-UI", "Type-Feature"]}
{"project": "tensorflow_tensorflow", "title": "scatter_add for non variable tensors", "description": "Hi, I am interested in using scatter_add when the tensor being update is not a variable. Is this possible? I am looking to do something like this: X1_ph = tf.placeholder(tf.float32, shape=(None, 3))\nind_ph = tf.placeholder(tf.int32, shape=(None)) #Z = tf.Variable(tf.zeros([10, 3]))\nZ = tf.zeros([10, N_feat]) X1 = np.array([[1,0.00,1],\n[2,0.00,1],\n[3,0.00,1],\n[5,0.00,1.1],\n[6,1.0,1.8]]) ind = [0, 1, 1, 0, 0] Z = tf.scatter_add(Z, ind_ph, X1) If I declare Z as a tf.Variable, I can do this, but I need to call this operation hundreds of thousands of times, and do not want to store any copies of Z once I am done with them. If I were to declare Z as a Variable, would there be any way to destroy Z once I am done with it (maybe with a garbage collector or something similar)? Thank you so much for your help! ", "code": [], "labels": ["stat:contributions welcome"]}
{"project": "gogs_gogs", "title": "Init repository with LICENSE", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement"]}
{"project": "dotnet_coreclr", "title": "CoreCLR Windows PortableBuild failed with \"File not found: 'E:\\A\\_work\\803\\s\\bin\\Product\\Windows_NT.x64.Release\\SOS.NETCore.dll'\"", "description": "Opened on behalf of @jcagme Warnings: 1\nStatus Message: failed Build : Master - 20180103.06 (Product Build)\nFailing configurations: ", "code": [], "labels": ["area-Infrastructure-coreclr", "bug"]}
{"project": "composer_composer", "title": "Composer not notifying installs to Packagist", "description": "My composer.json: Tried in a real project and had the same behavior. So I reproduced this issue in a blank folder without a composer.json for the sake of minimizing other factors. Output of composer diagnose: <CODE> When I run this command: <CODE> I get the following output: <CODE> Then immediately ran this next command below: <CODE> And I expected this to happen: Number of installs at <URL> to increase. Additionally, I have also tried a manual POST request to <URL> with the following data: The number increased +1 as expected when manually making POST request to <URL>, but not when cache is cleared and installing the package via composer from the same machine. Also, this package has been installed a few times by me on my work machine, home machine, work network, home network, other team mates' machines, as well as a few AWS EC2 instances. None increased the number of installs. I wish I could also try other people's projects but I'm afraid I have no control on who installs when to track the number of installs effectively. Here is my composer --version: <CODE> ", "code": ["$ composer diagnose\nChecking platform settings: OK\nChecking git settings: OK\nChecking http connectivity to packagist: OK\nChecking https connectivity to packagist: OK\nChecking github.com oauth access: OK\nChecking disk free space: OK\nChecking pubkeys:\nTags Public Key Fingerprint: 57815BA2 7E54DC31 7ECC7CC5 573090D0  87719BA6 8F3BB723 4E5D42D0 84A14642\nDev Public Key Fingerprint: 4AC45767 E5EC2265 2F0C1167 CBBB8A2B  0C708369 153E328C AD90147D AFE50952\nOK\nChecking composer version: OK\n$\n", "composer clear-cache\ncomposer require maqe/laravel-sqs-fifo\n", "$ composer clear cache\nClearing cache (cache-dir): /Users/unnawut/.composer/cache\nClearing cache (cache-files-dir): /Users/unnawut/.composer/cache/files\nClearing cache (cache-repo-dir): /Users/unnawut/.composer/cache/repo\nClearing cache (cache-vcs-dir): /Users/unnawut/.composer/cache/vcs\nAll caches cleared.\n$ \n", "$ composer require maqe/laravel-sqs-fifo\nUsing version ^0.1.0 for maqe/laravel-sqs-fifo\n./composer.json has been created\nLoading composer repositories with package information\nUpdating dependencies (including require-dev)\n  - Installing mtdowling/jmespath.php (2.4.0)\n    Downloading: 100%\n\n  - Installing psr/http-message (1.0.1)\n    Downloading: 100%\n\n  - Installing guzzlehttp/psr7 (1.3.1)\n    Downloading: 100%\n\n  - Installing guzzlehttp/promises (1.3.0)\n    Downloading: 100%\n\n  - Installing guzzlehttp/guzzle (6.2.2)\n    Downloading: 100%\n\n  - Installing aws/aws-sdk-php (3.20.7)\n    Downloading: 100%\n\n  - Installing paragonie/random_compat (v2.0.4)\n    Downloading: 100%\n\n  - Installing illuminate/contracts (v5.3.23)\n    Downloading: 100%\n\n  - Installing doctrine/inflector (v1.1.0)\n    Downloading: 100%\n\n  - Installing illuminate/support (v5.3.23)\n    Downloading: 100%\n\n  - Installing symfony/process (v3.1.8)\n    Downloading: 100%\n\n  - Installing psr/log (1.0.2)\n    Downloading: 100%\n\n  - Installing symfony/debug (v3.1.8)\n    Downloading: 100%\n\n  - Installing symfony/polyfill-mbstring (v1.3.0)\n    Downloading: 100%\n\n  - Installing symfony/translation (v3.2.1)\n    Downloading: 100%\n\n  - Installing nesbot/carbon (1.21.0)\n    Downloading: 100%\n\n  - Installing illuminate/container (v5.3.23)\n    Downloading: 100%\n\n  - Installing symfony/console (v3.1.8)\n    Downloading: 100%\n\n  - Installing illuminate/console (v5.3.23)\n    Downloading: 100%\n\n  - Installing illuminate/queue (v5.3.23)\n    Downloading: 100%\n\n  - Installing maqe/laravel-sqs-fifo (v0.1.0)\n    Downloading: 100%\n\naws/aws-sdk-php suggests installing aws/aws-php-sns-message-validator (To validate incoming SNS notifications)\naws/aws-sdk-php suggests installing doctrine/cache (To use the DoctrineCacheAdapter)\nparagonie/random_compat suggests installing ext-libsodium (Provides a modern crypto API that can be used to generate random bytes.)\nilluminate/support suggests installing illuminate/filesystem (Required to use the composer class (5.2.*).)\nilluminate/support suggests installing symfony/var-dumper (Required to use the dd function (3.1.*).)\nsymfony/translation suggests installing symfony/config ()\nsymfony/translation suggests installing symfony/yaml ()\nsymfony/console suggests installing symfony/event-dispatcher ()\nilluminate/console suggests installing mtdowling/cron-expression (Required to use scheduling component (~1.0).)\nilluminate/queue suggests installing illuminate/redis (Required to use the Redis queue driver (5.3.*).)\nilluminate/queue suggests installing pda/pheanstalk (Required to use the Beanstalk queue driver (~3.0).)\nWriting lock file\nGenerating autoload files\n$ \n", "$ composer --version\nComposer version 1.2.4 2016-12-06 22:00:51\n"], "labels": ["Support"]}
{"project": "OpenTTD_OpenTTD", "title": "On Screen Keyboard, fully configurable", "description": "Dominik opened the ticket and wrote: Attachments Reported version: trunk\nOperating system: All ", "code": [], "labels": ["patch from FlySpray", "flyspray", "Interface"]}
{"project": "dotnet_corefx", "title": "System.Net.Http not working for .NET core project targeting net45", "description": "I have a project which is written both in .NET framework and .NET core.\nThe core project targets netstandard2.0, net45 and net461 I have a Package reference to System.Net.Http as follows, in both the projects <ItemGroup> <PackageReference Include=\"Newtonsoft.Json\" Version=\"10.0.1\" /> <PackageReference Include=\"System.Net.Http\" Version=\"4.3.0\" /> </ItemGroup> net45 target expects the System.Net.Http version to be 4.0.0 , and I have used binding redirect to achieve the same in the .NET Framework project <dependentAssembly> <assemblyIdentity name=\"System.Net.Http\" publicKeyToken=\"b03f5f7f11d50a3a\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-4.2.0.0\" newVersion=\"4.0.0.0\" /> </dependentAssembly>   The referenced dll in case of the .NET framework project is version 4.0.0 as expected. But the same is not achievable in .NET core project. Somehow it refers to 4.2.0.0 and hence the application targeting net45 breaks. Please advice how to use System.Net.Http version 4.0.0 in .NET Core application targeting ns2, net45 and net461 ", "code": [], "labels": ["question", "area-System.Net.Http"]}
{"project": "rust-lang_rustup", "title": "builds fail due to missing components on non tier 1 platforms using the default profile", "description": "Problem\nOn platforms that don't have rustfmt and/or clippy, packages that use a rust-toolchain file that contains a toolchain that isn't already present on the host machine will fail because cargo does not call rustup with the --force option. e.g. <CODE> This is problematic for 2 reasons. 1, it probably shouldn't happen at all unless the package actually depends on one of those tools, and 2, nothing in the above message says anything about --force being a thing, so it's not obvious how I can fix it. I had to ask on discord to figure that out. <CODE> ", "code": ["$ rustup toolchain install nightly-2019-10-02-powerpc64le-unknown-linux-gnu         \ninfo: syncing channel updates for 'nightly-2019-10-02-powerpc64le-unknown-linux-gnu'\ninfo: latest update on 2019-10-02, rust version 1.40.0-nightly (702b45e40 2019-10-01)\nerror: some components unavailable for download for channel nightly-2019-10-02: 'clippy', 'rustfmt'\nIf you require these components, please install and use the latest successful build version,\nwhich you can find at <https://rust-lang.github.io/rustup-components-history>.\n\nAfter determining the correct date, install it with a command such as:\n\n    rustup toolchain install nightly-2018-12-27\n\nThen you can use the toolchain with commands such as:\n\n    cargo +nightly-2018-12-27 build\n", "$ rustup --version\nrustup 1.20.2 (13979c968 2019-10-16)\n"], "labels": ["E-easy", "E-mentor", "bug", "help wanted"]}
{"project": "bumptech_glide", "title": "Bitmaps may be encoded as PNGs unecessarily", "description": "This was reported on Glide 3.4. It's possible it's been fixed since then, but we should look in to it. ", "code": [], "labels": ["bug"]}
{"project": "MicrosoftDocs_azure-docs", "title": "Typo", "description": "It should be persistent instead of persistant. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["triaged", "in-progress", "container-service/svc", "doc-bug", "cxp"]}
{"project": "dropwizard_dropwizard", "title": "Provide a way to customize the request logging", "description": "\nNo description provided.\n ", "code": [], "labels": ["feature"]}
{"project": "dotnet_roslyn", "title": "Apply insert_final_newline consistently to our code base", "description": "Currently the .editorconfig files used by this project do not specify a value for insert_final_newline. In combination with various settings on individual developer machines, this is causing a fair amount of unnecessary code churn in pull requests. I propose adding this value to .editorconfig in a manner consistent with the existing configurations of dotnet/corefx and dotnet/coreclr. Currently the value is not enforced by Roslyn or the IDE, but both the commonly-used EditorConfig and certain other source editors do recognize it already. Tighter integration between Roslyn and EditorConfig is planned, but it doesn't seem necessary to wait for that to make this change. ", "code": [], "labels": ["Area-Infrastructure", "Resolution-Fixed"]}
{"project": "pandas-dev_pandas", "title": "DOC: Generating docs doesn't work if path has whitespaces", "description": "Related to #20862 If there are spaces in the path where pandas is installed (e.g. /home/my user/my code/pandas), when building the documentation (i.e. ./doc/make.py html) seems to generate a long list of usage errors like those: <CODE> ", "code": ["UsageError: %bookmark: too many arguments\nUsageError: %bookmark -d: Can't delete bookmark 'ipy_savedir'\n"], "labels": ["Docs", "good first issue"]}
{"project": "Semantic-Org_Semantic-UI", "title": "[Sticky] Stale cache for context.bottom", "description": "<CODE> Regarding this piece of code in sticky. If an element is being stuck to the top of the page it all behaves nicely until the height of the context is changed (an accordion opened, perhaps). This causes the context.bottom to be stale and the condition to be reached prematurely. The result is that the element suddenly jumps to the bottom. As a quick workaround, I implemented something like that: <CODE> .. do you see any alternatives? ", "code": ["            else if( (element.height + scroll.top - elementScroll) >= context.bottom ) {\n              module.debug('Fixed element reached bottom of container');\n              module.bindBottom();\n            }\n", "    onScroll: _.debounce(function() {       \n        $context = $('main.container');\n        $(this).data('moduleSticky').cache.context.bottom = $context.offset().top + $context.outerHeight();         \n    }, 100),\n"], "labels": ["Usage Question"]}
{"project": "highcharts_highcharts", "title": "Gauge (highcharts) - IE10 - Dialers not coming up", "description": "Hi Team, We am facing an IE 10 specific issue with the gauge chart (highcharts). The scaling is not coming up on the chart. The chart pointer is working fine.\nPlease let me know if this is a known issue or a solution is available.  ", "code": [], "labels": ["Status: Stale"]}
{"project": "lerna_lerna", "title": "Lerna does not hoist dependent packages", "description": "In general, lerna bootstrap should organise monorepo, as like all packages had been installed from npm. Any packages should be placed in that directories, in which they will be placed, if regular npm install process had been occured. Of course, coping can be avoided by using symlinks. Something like --hoist flag can be appropriate - <URL> . But installation should be performed not in global scope, but it dependent package's scope. Now dependent packages of two and deeper levels do not hoist to upper node_modules directory, even in symlink form. Current behaviour also reflected in hoist-flag documentation: Issue can be solved, if perform creating symlinks for nested packages in node_modules directory. In other words, folder structure in each module should repeat tree, which will be built, it read npm install occured. Imagine that you have monorepo with two global folders: for packages and for examples on them. Some package P in packages folder has requirements from npm - let it be D package. Then some example E from example folder try to use bootstrapped package P from current monorepo, but process fall with error - because node.js require tries to find dependencies only in root node_modules, and since there is not D package there - it can't be resolved. ", "code": [], "labels": ["stale"]}
{"project": "dotnet_roslyn", "title": "[Proposal] Stringly typed macros", "description": "Hi, I was thinking about the proposed generators. Can this not be expanded to macros? In the sense of LISP/Scala/Rust macros. I was thinking of a syntax similar to Rust (note the '!'): <CODE> The macro is defined in another, already compiled dll, similar to analyzers. We could even reuse the same infrastructure. Eg: NB: I typed this from my phone, I am not sure of exact Node names but you get the point. ", "code": ["class Example\n{\n    NotifyPropertyChanged!(public int Id {get; set;})\n}\n"], "labels": ["Area-Language Design"]}
{"project": "vector-im_riot-android", "title": "Check the layout of the hamburger handle for moving rooms around", "description": "Created by @ matthew:matrix.org. This is a note for me ", "code": [], "labels": ["enhancement", "P3"]}
{"project": "shadowsocks_shadowsocks-libev", "title": "wishlist request: the supported cipher list by run-time result", "description": "2.5.6+ds-1 of Debian Stretch I'm just wondering whether there's a way to get to know the supported ciphers on the system. Like #851, it's better to show the supported cipher list by run-time result, instead of (or in addition to) in manpage. Because document may be not accurate.\nThanks! ", "code": [], "labels": ["wontfix"]}
{"project": "bblanchon_ArduinoJson", "title": "Support for escape sequence \\u", "description": "Hello,\nI try to decode json with binary data in a string: <CODE> This code prints \"117 48 48 48 49\" (u 0 0 0 1) but I expect \"1\" ", "code": ["  char json[] = \"{\\\"data\\\":\\\"\\\\u0001\\\"}\";\n  StaticJsonBuffer<50> jsonBuffer;\n  JsonObject& root = jsonBuffer.parseObject(json);\n  String str(root[\"data\"].as<String>());\n  for ( int i = 0; i < str.length(); ++i )\n    Serial.println((byte)str.charAt(i));\n"], "labels": ["enhancement"]}
{"project": "cake-build_cake", "title": "Zip compression improvements", "description": "Add ZIP compression options which include: Example: you add directory C:\\Test\\Sub123 from C:\\ as root. Then the ZIP file contains that in Test\\Sub123 but maybe you want to place that data into another folder in the ZIP archive. Currently you can do this only by creating the desired folder structure beforehand with copying files around which costs performance. As far as I have seen in the source it is possible to provide a new path when adding items to the archive. ", "code": [], "labels": ["Improvement"]}
{"project": "ChrisRM_material-theme-jetbrains", "title": "Status Bar Indicator doesn't work for Custom Themes", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug"]}
{"project": "angular_components", "title": "Getting started guide unclear about dependency on @angular/animations", "description": "Bug <URL>\nGetting started says that So, I expect to don't install @angular/animations when I import this module Actually, @angular/platform-browser/animations uses the @angular/animations internally and it's not possible to compile a project without it. Hence, the question what's the real difference between this to options? At the moment it's not possible to use Material without animations module\nHere's the stackblitz that illustrate the problem <URL> Angular Material 6.4.1 ", "code": [], "labels": ["help wanted", "docs", "P2"]}
{"project": "photonstorm_phaser", "title": "firefox 33 this.glContextId = gl.id = PIXI.WebGLRenderer.glContextId ++;", "description": "hi\nwin7 32bit\nfirefox 33.0\nphaser 2.1.1\nTypeError: gl is null\nfirefox 33 Since FIREFOX automatically updated to 33 versions of the game after the phaser not run up. Error Messages\nError: This browser does not support webGL Try using the canvas renderer [object Object].\n... new Error ('This browser does not support webGL. Try using the canvas renderer' + ...\nthis.glContextId = gl.id = PIXI.WebGLRenderer.glContextId ++; Attempt to modify\nPhaser.AUTO\nChanged\nPhaser.CANVAS\nThe results just a black screen ", "code": [], "labels": ["invalid"]}
{"project": "ansible_ansible", "title": "[1.6.1] Value getting lost when a variable name is HOME", "description": "\u201cBug Report\u201d ansible 1.6.1 Debian / local connection I am creating a variable named HOME and setting it to user's home directory by looking up environment. In ansible 1.6.1, the value of this variable is becoming empty string during the playbook execution. Run the following playbook and checkout the result of second debug task. ansible-playbook homedir.yml <CODE> <CODE> <CODE> ", "code": ["\n---\n- hosts: all\n  gather_facts: False\n  vars:\n    HOME: \"{{lookup('env','HOME')}}\"\n  tasks:\n    - debug: var=HOME\n    - debug: var=HOME\n", "PLAY [all] ******************************************************************** \n\nTASK: [debug var=HOME] ******************************************************** \nok: [localhost] => {\n    \"HOME\": \"/home/jay\"\n}\n\nTASK: [debug var=HOME] ******************************************************** \nok: [localhost] => {\n    \"HOME\": \"/home/jay\"\n}\n\nPLAY RECAP ******************************************************************** \nlocalhost                  : ok=2    changed=0    unreachable=0    failed=0   \n", "PLAY [all] ******************************************************************** \n\nTASK: [debug var=HOME] ******************************************************** \nok: [localhost] => {\n    \"HOME\": \"/home/jay\"\n}\n\nTASK: [debug var=HOME] ******************************************************** \nok: [localhost] => {\n    \"HOME\": \"\"\n}\n\nPLAY RECAP ******************************************************************** \nlocalhost                  : ok=2    changed=0    unreachable=0    failed=0   \n"], "labels": ["bug"]}
{"project": "xamarin_xamarin-macios", "title": "[XI] System test failure on iOS 11.0.3 device", "description": "Update System to XI, xamarin.ios-11.8.0.9.pkg\nCheckout 0059e3e\nBuild and execute system test on an iOS 11.0.3 device Tests should pass Observed that SocketTest.TestSelect1 :   #2 and  TcpListenerTest.TcpListener :   Expected: True failed on device .  WebClientTest.DownloadTwice : System.Net.WebException : Error getting response stream (ReadDone1): ReceiveFailure\nThis is also observed on a single device. <CODE> Test Log: <URL>, <URL>\nBuild Log: <URL> ", "code": ["Tested with xamarin.ios-11.8.0.9.pkg\n"], "labels": ["iOS", "bug"]}
{"project": "joomla_joomla-cms", "title": "Exceptions when sorting feeds 'oldest first' in stead of 'newest first'", "description": "Create new newsfeed with the url: <CODE> On the 'Display' tab, set the 'Feed Display Order to' 'Oldest first'\nLoad the feed using an menu-item or some others means. No errors! The following errors are displayed (along the the content) <CODE> Using Joomla 3.4.3 To remove the error, modify line 69 $items = $categoryModel->getItems(); in the following $item->items = $categoryModel->getItems(); The error will no longer be shown, however it seems the sorting functionality does not work art all :(.\nMaybe a result of the complete rewrite of the newsfeed code starting with Joomla 3.0 ", "code": ["http://www.volleybal.nl/application/handlers/export.php?format=rss&type=vereniging&programma=8151&iRegionId=7000\n", "Notice: Undefined property: stdClass::$items in D:\\Xampp\\htdocs\\hwvvbenevia\\components\\com_newsfeeds\\views\\newsfeed\\view.html.php on line 191\n\nWarning: array_reverse() expects parameter 1 to be array, null given in D:\\Xampp\\htdocs\\hwvvbenevia\\components\\com_newsfeeds\\views\\newsfeed\\view.html.php on line 191\n"], "labels": ["No Code Attached Yet"]}
{"project": "microsoft_BotFramework-Emulator", "title": "Add UI to clear saved bot urls", "description": "It would be helpful to have UI for clearing out saved bot urls in the autocomplete list. Clear all and / or remove specific url ", "code": [], "labels": ["Design", "P2", "Enhancement"]}
{"project": "Rdatatable_data.table", "title": "FR: make unique = TRUE default for CJ", "description": "The unique-parameter of CJ was initially set to FALSE when introduced. The relevant item in the newsfile when 1.9.6 was released said: As CJ is probably mostly used used with unique = TRUE (see also the original issue), maybe the time has come to set this parameter to unique = TRUE ? ", "code": [], "labels": ["breaking-change"]}
{"project": "owncloud_core", "title": "more (useful) feedback when contents/settings are saved", "description": "normally there are almost none notifications in the UI when you enter something on the settings page as admin and it is saved ", "code": [], "labels": ["Bug"]}
{"project": "microsoft_vscode", "title": "Read only files are not properly marked in the editor", "description": "Issue Type: Bug I've got a file set to Read only but am not seeing this properly marked in the editor like #53022. Did this change?   VS Code version: Code - Insiders 1.32.0-insider (003521e, 2019-02-15T06:14:19.935Z)\nOS version: Darwin x64 18.0.0 ", "code": [], "labels": ["*duplicate", "file-explorer", "bug"]}
{"project": "home-assistant_home-assistant", "title": "Inconsistent bus behavior / formatting for light service_call", "description": "I noticed that my automations designed to trigger on a light state change, or a light service call, behave inconsistently depending on how I interact with a light in the HA web interface. If click the light switch from on to off, both the homeassistant and light domain experience a service call: <CODE> If click the light switch from off to \"full\" on, I see the same behavior (both domains): <CODE> But, if I open the dimmer panel in the HA web interface and click the input slider when the light is off to turn it on to an intermediate brightness, only the light domain experiences a service call: <CODE> The behavior is the same if I If click slider to adjust from one intermediate brightness to another brightness: <CODE> I think that because of the different formatting of the latter two service calls in the light domain (with service_data=entity_id=light.game_room_hall_1_by_door instead of service_data=entity_id=['light.game_room_hall_1_by_door']), my automations won't trigger on those behaviors. Here's an automation that triggers on service calls (works for switch toggling, not slider adjusting): <CODE> (I say it works, but I can't actually figure out how to format the data_template for taking brightness from one device and passing it to another when the trigger is a call_service event -- happy to take suggestions on that part of it) Here's an automation that triggers on state changes (works for switch toggling, not slider adjusting): <CODE> ", "code": ["2017-06-30 06:28:21 INFO (MainThread) [homeassistant.core] Bus:Handling <Event call_service[L]: domain=homeassistant, service=turn_off, service_data=entity_id=light.game_room_hall_1_by_door, service_call_id=140286323438200-69>\n2017-06-30 06:28:21 INFO (MainThread) [homeassistant.core] Bus:Handling <Event call_service[L]: domain=light, service=turn_off, service_data=entity_id=['light.game_room_hall_1_by_door'], service_call_id=140286323438200-70>\n", "2017-06-30 06:27:42 INFO (MainThread) [homeassistant.core] Bus:Handling <Event call_service[L]: domain=homeassistant, service=turn_on, service_data=entity_id=light.game_room_hall_1_by_door, service_call_id=140286323438200-66>\n2017-06-30 06:27:42 INFO (MainThread) [homeassistant.core] Bus:Handling <Event call_service[L]: domain=light, service=turn_on, service_data=entity_id=['light.game_room_hall_1_by_door'], service_call_id=140286323438200-67>\n", "2017-06-30 06:27:07 INFO (MainThread) [homeassistant.core] Bus:Handling <Event call_service[L]: domain=light, service=turn_on, service_data=entity_id=light.game_room_hall_1_by_door, brightness=121, service_call_id=140286323438200-61>\n", "2017-06-30 06:28:40 INFO (MainThread) [homeassistant.core] Bus:Handling <Event call_service[L]: domain=light, service=turn_on, service_data=entity_id=light.game_room_hall_1_by_door, brightness=164, service_call_id=140286323438200-74>\n", "  - alias: 'Dimmer Fix Garage Stairs On'\n    trigger:\n      platform: event\n      event_type: call_service\n      event_data:\n        service_data: \n          entity_id: light.garage_stairs_1_top\n        domain: light\n        service: turn_on\n    action: \n      service: light.turn_on\n      entity_id:\n        - light.garage_stairs_2_bottom\n      data_template:\n        brightness: '{{ trigger.event.service_data.data.brightness|int() }}'\n", "  - alias: 'Dimmer Fix Hallway Cans On'\n    trigger:\n      platform: state\n      entity_id: light.hall_cans_1_by_master\n      to: 'on'\n    action: \n      service: light.turn_on\n      entity_id:\n        - light.hall_cans_2_by_thermostat\n      data_template:\n        brightness: '{{ trigger.to_state.attributes.brightness }}'\n"], "labels": ["auto-closed", "waiting-for-reply"]}
{"project": "qgis_QGIS", "title": "QGIS Server crash with OTF active and layer without features", "description": "Author Name: Horst D\u00fcster (@hdus)\nOriginal Redmine Issue: 14059\nAffected QGIS version: 2.8.5\nRedmine category:qgis_server With OTF EPSG:4326 QGIS Server works fine! This error affects all QGIS Server releases from 2.8 - 2.12 ", "code": [], "labels": ["High Priority", "Server", "Bug", "Crash/Data Corruption"]}
{"project": "snowplow_snowplow", "title": "Scala Hadoop Enrich: update to use new EtlPipeline", "description": "See #1841 ", "code": [], "labels": ["enhancement", "3. ETL"]}
{"project": "ag-grid_ag-grid", "title": "[filters] Add 'Cancel' and 'Close' to filters", "description": "<URL> ", "code": [], "labels": ["enhancement"]}
{"project": "rancher_rancher", "title": "Backport: Default Install URL - Docker 18.09", "description": "#21858 ", "code": [], "labels": ["kind/task", "[zube]: Done", "team/ca"]}
{"project": "godotengine_godot", "title": "NavigationPolygonInstance crash with Sprite parent (Godot 3)", "description": "Operating system or device, Godot version, GPU Model and driver (if graphics related):\nmacOS Sierra 10.12.6\nGodot v3.0.alpha.custom_build.ae94758 Issue description:\nAdding NavigationPolygonInstance node without a parent Navigation2D under Sprite freezes Godot (only force quit works). I've only seen this behaviour if its under Sprite node, maybe other nodes crash it too. Steps to reproduce:\nCreate blank Godot 3 project. Add following nodes: Non-working: <CODE> Working: <CODE> Link to minimal example project:\nTEST.zip ", "code": ["Sprite\n - NavigationPolygonInstance (crashes)\n", "Sprite\n- Navigation2D\n- - NavigationPolygonInstance\n"], "labels": ["topic:core", "junior job", "bug"]}
{"project": "yarnpkg_yarn", "title": "Custom CLI-based Warnings for Sub-Registries", "description": "I don't know that I would call this a substantial feature request, but it would certainly depend on the status of this issue: npm/npm#19249 I would like to implement something similar for Yarn to what is described in that issue/feature request for npm: Since Yarn works based on the npm registry, this would depend on the presence of the added \"packageWarnings\" or \"genericWarnings\" keys in the registry itself, unless someone was to use Yarn with a sub-registry, which is my intent. I've looked at the source and I cannot find anything other than the engine-based warnings and some other CLI-internals. Question is: is this something that already exists? If it does not, is it a suitably small feature request? I do not mind implementing this myself. ", "code": [], "labels": ["triaged"]}
{"project": "keras-team_keras", "title": "`ctc_label_dense_to_sparse` broken under TensorFlow 0.10.0", "description": "Steps to reproduce: The problem appears that dense_mask has shape=None, which seems to be not (anymore?) supported by tf.boolean_mask. Unfortunately, I do not know enough about what ctc_label_dense_to_sparse does to fix it myself. Here's the relevant part of the trace: <CODE> ", "code": ["  File \"/Users/matze/Labs/Handwriting/venv/lib/python2.7/site-packages/Keras-1.0.8-py2.7.egg/keras/backend/tensorflow_backend.py\", line 1798, in ctc_batch_cost\n    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n  File \"/Users/matze/Labs/Handwriting/venv/lib/python2.7/site-packages/Keras-1.0.8-py2.7.egg/keras/backend/tensorflow_backend.py\", line 1767, in ctc_label_dense_to_sparse\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n  File \"/Users/matze/Labs/Handwriting/venv/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 819, in boolean_mask\n    \"mask dimensions must be specified, even if some dimensions are None\"\nValueError: mask dimensions must be specified, even if some dimensions are None.  E.g. shape=[None] is ok, but shape=None is not.\n"], "labels": ["stale"]}
{"project": "saltstack_salt", "title": "unit.utils.test_vmware.RenameDatastoreTestCase.test_rename_datastore_raise_vim_fault", "description": "name 'vim' is not defined <CODE> ", "code": ["\nTraceback (most recent call last):\n  File \"/tmp/kitchen/testing/salt/utils/vmware.py\", line 2131, in rename_datastore\n    datastore_ref.RenameDatastore(new_datastore_name)\n  File \"/usr/local/lib/python3.7/site-packages/mock/mock.py\", line 1091, in __call__\n    return _mock_self._mock_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/mock/mock.py\", line 1142, in _mock_call\n    raise effect\npyVmomi.VmomiSupport.vim.fault.VimFault: (vim.fault.VimFault) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'vim_fault',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/kitchen/testing/tests/unit/utils/test_vmware.py\", line 4304, in test_rename_datastore_raise_vim_fault\n    'fake_new_name')\n  File \"/tmp/kitchen/testing/salt/utils/vmware.py\", line 2132, in rename_datastore\n    except vim.fault.NoPermission as exc:\nNameError: name 'vim' is not defined\n\t\t\n"], "labels": ["Test Failure"]}
{"project": "preactjs_preact", "title": "[10.0.0-rc.1] Component with conditional render result forces remount of siblings", "description": "Codepen: <URL> Certain wrapping component causes preact to remount all subsequent siblings without calling any lifecycle methods. However, when I inline the same logic ({this.props.open && <Modal {...this.props} />}), it works correctly. From the codepen you can see that the button before the wrapper component preserves focus, but the button after does not. This happens because after unmounting Wrapper and returning focus, preact temporarily removes second button from DOM. The issue was introduced between 10.0.0-beta.0 and 10.0.0-beta.1. ", "code": [], "labels": ["bug"]}
{"project": "iron-meteor_iron-router", "title": "0.6.0: Call to 'setData()' in action method leads to infinite loop", "description": "I think, that this happens because of infinite invalidation of reactive computation, that wraps controller's run method.\nI inspected run method, but I didn't understand, why when setDataHook calls setData() method, then context is not invalidated, but when I call it from action method, then it is? ", "code": [], "labels": ["bug"]}
{"project": "npm_npm", "title": "npm ERR! Error: EPERM: operation not permitted, open", "description": "Trying to install Ionic using npm. This is similar to many others, but I haven't seen this error with OPEN. Windows 7 x64.  I've tried node v0.8, v0.10.38, v6.2.2.  All have the exact same error.\nI've tried different versions of ionic.\nI've uninstall everything.  I've done cache cleans.  I've moved directories.  I've used Admin consoles. Any ideas would be greatly appreciated! `C:\\N>npm install -g ionic@beta\nnpm ERR! tar.unpack untar error C:\\Users\\Scott\\AppData\\Roaming\\npm-cache\\ionic\\2\n.0.0-beta.32\\package.tgz\nnpm ERR! Windows_NT 6.1.7601\nnpm ERR! argv \"C:\\N\\node.exe\" \"C:\\N\\node_modules\\npm\\bin\\npm-cli.js\" \"ins\ntall\" \"-g\" \"ionic@beta\"\nnpm ERR! node v6.2.2\nnpm ERR! npm  v3.9.5\nnpm ERR! path c:\\npm\\temp\\npm-5168-46f40d44\\unpack-079d2c3a\\node_modules\\ionic-a\npp-lib\\node_modules\\cordova-lib\\node_modules\\cordova-js\\node_modules\\browserify\nnode_modules\\browser-pack\\node_modules\\combine-source-map\\node_modules\\source-ma\np\\build\\prefix-source-map.jsm\nnpm ERR! code EPERM\nnpm ERR! errno -4048\nnpm ERR! syscall open npm ERR! Error: EPERM: operation not permitted, open 'c:\\npm\\temp\\npm-5168-46f40\nd44\\unpack-079d2c3a\\node_modules\\ionic-app-lib\\node_modules\\cordova-lib\\node_mod\nules\\cordova-js\\node_modules\\browserify\\node_modules\\browser-pack\\node_modules\\c\nombine-source-map\\node_modules\\source-map\\build\\prefix-source-map.jsm'\nnpm ERR!     at Error (native)\nnpm ERR!  { Error: EPERM: operation not permitted, open 'c:\\npm\\temp\\npm-5168-46\nf40d44\\unpack-079d2c3a\\node_modules\\ionic-app-lib\\node_modules\\cordova-lib\\node_\nmodules\\cordova-js\\node_modules\\browserify\\node_modules\\browser-pack\\node_module\ns\\combine-source-map\\node_modules\\source-map\\build\\prefix-source-map.jsm'\nnpm ERR!     at Error (native)\nnpm ERR!   errno: -4048,\nnpm ERR!   code: 'EPERM',\nnpm ERR!   syscall: 'open',\nnpm ERR!   path: 'c:\\npm\\temp\\npm-5168-46f40d44\\unpack-079d2c3a\\node_module\ns\\ionic-app-lib\\node_modules\\cordova-lib\\node_modules\\cordova-js\\node_modu\nles\\browserify\\node_modules\\browser-pack\\node_modules\\combine-source-map\\n\node_modules\\source-map\\build\\prefix-source-map.jsm' }\nnpm ERR!\nnpm ERR! Please try running this command again as root/Administrator. npm ERR! Please include the following file with any support request:\nnpm ERR!     C:\\N\\npm-debug.log` ", "code": [], "labels": ["windows", "bot-closed", "support"]}
{"project": "SAP_openui5", "title": "sap.ui.table.Table with large max rows, page scroll mousewheel does not work", "description": "OpenUI5 version: 1.38.4 Browser/version (+device/version): Chrome Version 51.0.2704.106 (64-bit) Any other tested browsers/devices(OK/FAIL): Safari (latest): Fail URL (minimal example if possible): Will make one later Steps to reproduce the problem: sap.ui.table.Table has a built-in scroll bar, which works fine as per the documentation. If, however, you intend to display the entire table, there is (obviously) no scroll bar on the table, instead it is in the page. The mouse wheel no longer works when positioned over the table. It will not scroll the page. Perhaps this has something to do with the disappearance of navigationMode What is the expected result? The mouse wheel to scroll the page, displaying the rest of the table. What happens instead? Scroll is not happening. Manually dragging the page scroll bar up and down still works. I'll attach some more information / jsbin later. For now, just wanted to make you aware. ", "code": [], "labels": ["bug", "in progress"]}
{"project": "aws_aws-sdk-go", "title": "[Question] AssumeRole to get session for subsequent API calls unclear", "description": "Please fill out the sections below to help us address your issue. 1.8.11 1.7 This is for cross account role assume.\nI ahve configured and allow assume roles access on the both the assumer and the account granting roles to be assumed.\nI tested with AWS CLI to make sure the configuration works. There are two use cases: So far it is just failing with:\nInvalidClientTokenId: The security token included in the request is invalid.\nstatus code: 403, request id: 2201986a-765f-11e7-a6c9-1dbe398d3d41\nWhere is this security token coming from? I did not ask for one. Do I have to save this to ENV variables to make it work? Any convenient method that just do that automatically without so many calls? It is not at all clear what to do with the examples, api. There are: What is wrong and can examples be updated for more real world examples. List CRUD is not helpful for access control where expiry/invalid access etc is important Admin\nExample settings files\ncredentials: <CODE> config <CODE> Value of role_arn is not in file, but is fetched form some other store\nrole_arn = arn:aws:iam:::role/adminrole If you have have an runnable example, please include it.\nWhat I intend to use: <CODE> <CODE> ", "code": ["[admin]\naws_access_key_id = 1234\naws_secret_access_key = abcd\n\n[testprovider]\naws_access_key_id = 1234\naws_secret_access_key = abcd\n", "[profile admin]\nregion = us-west-1\nsource_profile = admin\n\n[profile testprovider]\nregion = us-west-1\nrole_arn = arn:aws:iam::<account number>:role/testprovider\nsource_profile = testprovider\n\n", "sess := getSessionByProfile(&validAwsRegion, \"admin\", true) <-- this is admin profile\n\nsvc := s3.New(sess) ....\nsvc.SomeS3Method  <--- shall let it through\n\nsvc2 := ec2.New(sess) ..\nsvc2.SomeEc2Method  <--- shall says not authorized\n\nsessA := getSessionByProfile(&validAwsRegion, \"testprovider\", true) <-- this is testprovider profile\nsvc9 := s3.New(sessA) ....\nsvc9.SomeS3Method  <--- shall let it through\nsvc10 := ec2.New(sessA) ..\nsvc10.SomeEc2Method  <--- shall says not authorized\n\n\n\n\nrole_arn :=  \"arn:aws:iam::<some accoutn bymer>:role/adminrole\"\nsess2:=GetSessionByRole(\"us-west-1\", \"admin\", roleArn, true)  <--- this is admin profile\n\nsv3 := s3.New(sess2) ....\nsvc3.SomeS3Method   <--- shall let it through\n\nsvc4 := ec2.New(sess2) .. \nsvc4.SomeEc2Method   <--- shall says not authorized\n\n\nsessB := getSessionByProfile(&validAwsRegion, \"testprovider\", true) <-- this is testprovider profile\nsvc11 := s3.New(sessB) ....\nsvc11.SomeS3Method  <--- shall let it through\nsvc12 := ec2.New(sessB) ..\nsvc12.SomeEc2Method  <--- shall says not authorized\n\n// Following lines also errored out about invalid security token\ncredVal, err = (*s.Config).Credentials.Get()  <-- FAIL \nassert.NoError(t, err)\n// I want to verify the access key and and access Id is from the correct profile . but cannot do this\nassert.EqualValues(t, testDefaultAccessKeyId, credVal.AccessKeyID, \"access key id should be same \nassert.EqualValues(t, testDefaultAccessSecret, credVal.SecretAccessKey, \"access key should be same\")\n\n\n", "func getSessionByProfile(region *string, iamProfile string, debug bool) *session.Session {\n\tlogLevel := aws.LogOff\n\tif debug {\n\t\tlogLevel = aws.LogDebugWithHTTPBody\n\t}\n\n\tcfg := aws.NewConfig().\n\t\tWithCredentialsChainVerboseErrors(debug).\n\t\tWithRegion(*region).\n\t\tWithLogger(aws.LoggerFunc(func(args ...interface{}) {\n\t\t\tlog.WithFields(log.Fields{\"provider\": \"aws\"}).Debug(args...)\n\t\t})).\n\t\tWithLogLevel(logLevel)\n\n\treturn session.Must(session.NewSessionWithOptions(session.Options{\n\t\tConfig:            *cfg,\n\t\tSharedConfigState: session.SharedConfigEnable,\n\t\tProfile:           iamProfile,\n\t}))\n}\n\n\nfunc GetSessionByRole(region *string, iamProfile string, roleArn string, debug bool) (*session.Session, error) {\n\tlogLevel := aws.LogOff\n\tif debug {\n\t\tlogLevel = aws.LogDebugWithHTTPBody\n\t}\n\n\t// Initial credentials loaded from SDK's default credential chain, such as\n\t// the environment, shared credentials (~/.aws/credentials), or EC2 Instance\n\t// Role. These credentials are used to make the AWS STS Assume Role API.\n\tsess := getSessionByProfile(region, iamProfile, debug)\n\n\t// Create the credentials from AssumeRoleProvider to assume the role\n\t// referenced by the role ARN. Prompt for MFA token from stdin.\n\tnewCreds := stscreds.NewCredentials(sess, roleArn, func(p *stscreds.AssumeRoleProvider) {})\n\n\tcfg := aws.NewConfig().\n\t\tWithCredentialsChainVerboseErrors(debug).\n\t\tWithCredentials(newCreds).\n\t\tWithRegion(*region).\n\t\tWithLogger(aws.LoggerFunc(func(args ...interface{}) {\n\t\t\tlog.WithFields(log.Fields{\"provider\": \"aws\"}).Debug(args...)\n\t\t})).\n\t\tWithLogLevel(logLevel)\n\n\tsess = session.Must(session.NewSessionWithOptions(session.Options{\n\t\tConfig: *cfg,\n\t})\n\n\treturn sess, nil\n}\n\n"], "labels": ["guidance"]}
{"project": "keystonejs_keystone-classic", "title": "Heroku Error R10 (Boot timeout) w/ Long Running Application Updates", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug"]}
{"project": "microsoft_vscode-go", "title": "Output panel always popping when coverOnSave=true", "description": "Wouldn't it be nice to add an option so that the output panel would not pop every time something is failing?  getCoverage() in goCover.ts is being called with true every time. Can we somehow make this optional? Does that make sense? ", "code": [], "labels": ["duplicate"]}
{"project": "elastic_elasticsearch", "title": "Add a maximum size for stored fields (truncate)", "description": "For a stored field, add a max size at which they are truncated.  Of couse this can be done on the client, but it allows central enforcement of things to protect the index and search engine's health. ", "code": [], "labels": ["feedback_needed"]}
{"project": "DotNetAnalyzers_StyleCopAnalyzers", "title": "SA1119 Works incorrectly with C# 7.0 pattern matching", "description": "This code will trigger SA1119 (Statement must not use unnecessary parenthesis) while those parenthesis are necessary to make the expression negative. On the other hand, if we use only type check without pattern matching, the error will not pop up: ", "code": [], "labels": ["duplicate"]}
{"project": "Koenkk_zigbee2mqtt", "title": "CC2530 + CC2592 = Very long range solution", "description": " The guys from our community tried to use TI cc2530 modules from EBYTE with a new cc2592 amplifier with a power of 100mW E18-MS1PA1-PCB. For this module, we had to build a special Z-Stack ZNP firmware, since there was no firmware for such an amplifier. And the results exceeded expectations! The tests with the \u201cround button\u201d from Xiaomi showed that the coordinator get the signals even at a distance of 400m of direct visibility. In the house, the button works through 2 reinforced concrete walls. Those the amplifier greatly increases the range and sensitivity. Another indicative criterion is the parameters of the link_quality signals from devices (they can be seen, for example, on the network map in iobroker.zigbee or zigbee2mqtt). For this module, link_quality shows 36\u201340 and good work, where the coordinator cc2531 showed 2\u20135 and there were interruptions in communication (3 foam-block walls, one thin wooden wall). There is a version of this module with an external antenna connection. And there is also a 500mW E18-2G4Z27SI module, but we didn\u2019t feel any significant difference in comparison with the 100mW module (or we couldn\u2019t correct start it in the firmware yet), the current consumption of the 500mW module coincided with the 100mW module. On the basis of these modules, the craftsmen made themselves coordinators and routers to cover with the network not only a residential building, but also the area around it. \n The user Jager share his stick PCB in his blog.   ps. sorry for my English :) ", "code": [], "labels": ["stale"]}
{"project": "golang_go", "title": "runtime/race: freebsd race builder is broken", "description": "<URL> broke the FreeBSD race builder. ", "code": [], "labels": ["release-blocker", "FrozenDueToAge", "NeedsFix"]}
{"project": "neovim_neovim", "title": "Default colorscheme using bright colours", "description": "<CODE> (also occurs with the arch build of 0.3.2) nvim -u NORC Neovim default colorscheme uses brighter colours like in the right of the picture. Neovim default colorscheme uses darker colours like in the left, like it always has for me before.\n ", "code": ["NVIM v0.4.0-70-g292b1790c\nBuild type: RelWithDebInfo\nLuaJIT 2.0.5\nCompilation: /usr/lib/ccache/bin/clang -march=native -O2 -pipe -fstack-protector-strong -fno-plt -fcolor-diagnostics -Qunused-arguments -stdlib=libc++ -rtlib=compiler-rt -Wshadow -Wconversion -O2 -g -DMIN_LOG_LEVEL=3 -Wall -Wextra -pedantic -Wno-unused-parameter -Wstrict-prototypes -std=gnu99 -Wimplicit-fallthrough -Wvla -fstack-protector-strong -fdiagnostics-color=auto -DINCLUDE_GENERATED_DECLARATIONS -D_GNU_SOURCE -DNVIM_MSGPACK_HAS_FLOAT32 -DNVIM_UNIBI_HAS_VAR_FROM -I/home/e5ten/sdfm/AUR/neovim-git/src/neovim-git/build/config -I/home/e5ten/sdfm/AUR/neovim-git/src/neovim-git/src -I/usr/include -I/home/e5ten/sdfm/AUR/neovim-git/src/neovim-git/build/src/nvim/auto -I/home/e5ten/sdfm/AUR/neovim-git/src/neovim-git/build/include\nCompiled by e5ten@clevo\n\nFeatures: +acl +iconv -jemalloc +tui\n"], "labels": ["question"]}
{"project": "Polymer_polymer", "title": "Cannot I disable eventDataCache?", "description": "It's very difficult to debug leak memory using Polymer. Chrome debug show a lot of memory stored in eventDataCache. Cannot I disable it to better debug? the row :\nuseCache: Polymer.Settings.eventDataCache || !Polymer.Settings.isIE suppose that in chrome useCache is always true if I not  set also Polymer.Settings.isIE to true . is it correct? ", "code": [], "labels": ["pending-response", "1.x"]}
{"project": "microsoft_vscode", "title": "Crashes on regex find and replace", "description": "On using the below regex (without quotations) in find and replace box, vscode just freezes and and gives a prompt to reopen or close a few seconds after VSCode version - 1.36.1\nOS - Windows 10 1803 x64 ", "code": [], "labels": ["*duplicate"]}
{"project": "iview_iview", "title": "vue.esm.js?efeb:578 [Vue warn]: Do not use built-in or reserved HTML elements as component id: Circle", "description": "\nNo description provided.\n ", "code": [], "labels": ["invalid"]}
{"project": "saltstack_salt", "title": "Windows saltutil.kill_job", "description": "When running a salt '*' saltutil.kill_job Windows hosts fail with the following: <CODE> Windows hosts should fail gracefully, not with an exception.  Although this job was not active on the hosts, this brings up the question whether kill_job is even supported or functional on Windows hosts...\nSee internal issue 197. ", "code": ["dc2.redacted:\n    The minion function caused an exception: Traceback (most recent call last):\n      File \"salt/minion.py\", line 1022, in _thread_return\n      File \"salt/modules/saltutil.py\", line 581, in kill_job\n    AttributeError: 'module' object has no attribute 'SIGKILL'\n"], "labels": ["High Severity", "Duplicate", "Bug", "Fixed Pending Verification", "Platform", "Windows"]}
{"project": "gatsbyjs_gatsby", "title": "[1.0] Ensure development server never loads HTML from the public folder", "description": "One possibility is to switch things so we're not using the public folder as a cache for generated images, etc. Instead put them in a .cache folder. This way we could wipe out the public folder on every build which would be ideal. This has some complexity though as the Webpack config would become more complicated. ", "code": [], "labels": ["v1"]}
{"project": "robovm_robovm", "title": "Use a sensible default initial heap size", "description": "ATM we don't set an initial heap size unless -rvm:ms=XX is specified as an argument to the executable. So we get the Boehm default which is 64kB. This is way too low for our needs so during startup we will see a large number of collections and heap expansions. We should use a more sensible default initial heap size, something like 4MB. This should also be the minimum. ", "code": [], "labels": ["enhancement"]}
{"project": "junegunn_fzf", "title": "[zsh] Howto guide fzf hosts completion for a specific command", "description": "Currently we have ssh ** and telnet **, how can I trigger fzf for hosts completion for other command, I usually write some scripts that need to trigger hosts completion. ", "code": [], "labels": ["question"]}
{"project": "phpmyadmin_phpmyadmin", "title": "(2.2.0) Table Aliases", "description": "PHPMyAdmin RC04 doesn\u2019t seem to correctly execute \nmysql queries when they contain table aliases. \nFor example: (Assuming db name is &quot;foo_db&quot;)\nSELECT a.id FROM table01 a, table02 b WHERE \na.name_id=b.id; The above will return:\nMySQL said:  Table \u2018foo_db.a\u2019 doesn\u2019t exist I have so far tested RC03 with the same queries and \nreceived the correct results (support of aliases). - Original URL: <URL>\n- Original author: anonymous\n- *Found in version**: 2.2.0 ", "code": [], "labels": ["bug"]}
{"project": "linuxmint_cinnamon", "title": "Hide individual tray icons", "description": " In this case, I'm unable to hide Skype's icon from the panel. If I were to right-click it at the top of the panel, I have the option to \"Remove this applet.\" Unfortunately this will actually remove the System Tray applet, which includes other icons like the Update Manager's. I would like to have an option to hide each individual application icon that puts itself into the System Tray. Of course there would have to be a way to un-hide icons as well. ", "code": [], "labels": ["FEATURE REQUEST"]}
{"project": "ppy_osu", "title": "Android builds no longer deploy to emulator", "description": "Seems to have regressed in #5665. DllNotFoundException on startup (both debug and release). Needs further investigation as it is blocking deployment of android builds. ", "code": [], "labels": ["bug", "pending review", "android"]}
{"project": "magento_magento2", "title": "A failure while creating a configurable product: \u00abURL key for specified store already exists\u00bb", "description": "Surely, while autogenerate simple variants of a configurable product the system need to check whether an autogenerated url key conflicts with an already existed product. <URL> ", "code": [], "labels": ["bug report"]}
{"project": "magento_magento2", "title": "Admin main menu possible issue in DEV RC", "description": "There might be a possible issue with the new design for the admin menu in dev RC.\nIf I add too many top level menu items I don't get to see the bottom ones.\nI know this is a bad practice and you should not have too many top level menu items, but for sure this will happen eventually for someone.\nI think a vertical scroll is needed in case there are a lot of menu items.\nI attached a screenshot to explain it better.\nNotice that \"menu 6\" is cut off and there are other menu items below that and I have no way of accessing them.  ", "code": [], "labels": ["bug report", "CS", "Issue: Ready for Work"]}
{"project": "endless-sky_endless-sky", "title": "[bug] Minor mission error", "description": "<URL> This mission has the blue circle surrounding the destination, but it doesn't have the system indicator, making it look like it's pointing randomly into the middle of endless space (see what I did there?) Edit: even after accepting, doing this: <URL> ", "code": [], "labels": ["bug"]}
{"project": "npm_npm", "title": "npm i --no-save ../foo alters foo's node_modules", "description": "related to #17099. npm seems to be doing a three-step tango now where it will overwrite a locally-installed npm package's node_modules directory with only the dependencies of that directory (or sometimes will actually delete it outright). This is a RL setup with the libraries I am trying to develop. Plump Core is the base functionality, Plump Rest is the plugin for using Plump models in a browser against a REST endpoint. So: <CODE> here's a gist: <URL> the deleted_everything.log is the log from when ../core ends up with no node_modules, left_pri_deps is when it created a node_modules directory with only the primary dependencies, and the initial_install is the first time, which works. My hypothesis is that installing the local directory a second time on top of the same local directory (as I tweak plump-core, I have to reinstall it in the dependent library to make sure things work). ", "code": ["git clone https://github.com/ericeslinger/plump-store-rest.git rest\ngit clone https://github.com/ericeslinger/plump.git core\ncd core\nrm package-lock.json\nnpm i\nls node_modules\n# some stuff in there\ncd ../rest\nrm package-lock.json\nnpm i\nnpm i --no-save ../core\nls ../core/node_modules\n# it is fine, still plenty of stuff\nnpm i --no-save ../core\nls ../core/node_modules\n# error file not found - node_modules is missing\nnpm i --no-save ../core\nls ../core/node_modules\n# now node_modules is there, but only contains the direct dependencies in core's package.json\n"], "labels": ["npm5", "bug"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Consistency (order of truncate/drop)", "description": "In the tables list view, the first icon is truncate, \nthe second is drop.\nBut in the dropdown, the first entry is drop, the \nsecond is truncate. In the table view, the first key is primary, the \nsecond is index and the third is unique.\nSwitching the last two would be more logical. - Original URL: <URL>\n- Original author: olafvdspek\n- Found in version: 2.8.0-beta1 ", "code": [], "labels": ["bug"]}
{"project": "matomo-org_matomo", "title": "Add new segment Operating System Version", "description": "The segment name will be operatingSystemVersion. This is especially useful when using in combination with operatingSystemCode. ", "code": [], "labels": ["Enhancement"]}
{"project": "DataDog_dd-agent", "title": "[activemq] fix ci file", "description": "Rubocop and formatting changed. ", "code": [], "labels": ["regression"]}
{"project": "pymedusa_Medusa", "title": "[APP SUBMITTED]: TypeError: index() got an unexpected keyword argument '\">'", "description": "Python Version: 2.7.16 (default, Apr 11 2019, 01:11:37) [GCC 4.2.1 Compatible FreeBSD Clang 6.0.0 (tags/RELEASE_600/final 326565)]\nOperating System: FreeBSD-11.2-STABLE-amd64-64bit-ELF\nLocale: UTF-8\nBranch: master\nDatabase: 44.14\nCommit: baad1e5\nLink to Log: <URL> <CODE> STAFF NOTIFIED: @pymedusa/support @pymedusa/moderators ", "code": ["2019-09-14 12:18:46 ERROR    Thread_2 :: [baad1e5] Exception generated: index() got an unexpected keyword argument '\">'\nTraceback (most recent call last):\n  File \"/usr/local/medusa/medusa/server/web/core/base.py\", line 251, in async_call\n    result = function(**kwargs)\nTypeError: index() got an unexpected keyword argument '\">'\n"], "labels": ["triage"]}
{"project": "NuGet_Home", "title": "multiple dotnet standard frameworks in a single NuGet package gives error in VS2013", "description": "For all details , see aspnet/PlatformAbstractions#42 ", "code": [], "labels": ["Area:Restore"]}
{"project": "GoogleChrome_lighthouse", "title": "DevTools Error: Unable to load page: failed document request (net::ERR_EMPTY", "description": "Initial URL: <URL>\nChrome Version: 63.0.3239.132\nError Message: Unable to load page: failed document request (net::ERR_EMPTY_RESPONSE)\nStack Trace: <CODE> ", "code": ["Error: Unable to load page: failed document request (net::ERR_EMPTY_RESPONSE)\n    at Function.assertPageLoaded (chrome-devtools://devtools/remote/serve_file/@2e6edcfee630baa3775f37cb11796b1603a64360/audits2_worker/audits2_worker_module.js:826:73)\n    at pass.then._ (chrome-devtools://devtools/remote/serve_file/@2e6edcfee630baa3775f37cb11796b1603a64360/audits2_worker/audits2_worker_module.js:830:224)\n    at <anonymous>\n"], "labels": ["duplicate"]}
{"project": "OrchardCMS_Orchard", "title": "Fail to Set blog as homepage and show on main menu [5388 (4ee7a3f3c797)]", "description": "Yinhaixia created:\n<URL> Log on the Orchard site as admin and create a new blog, check \"Set as homepage\", and \"Show on main menu\", then input the menu text, save\nGo to the home page\nExpected: The homepage is the new created blog\nResult: The homepage is still \"Welcome to Orchard\", and the new created blog cannot show on main menu ", "code": [], "labels": ["bug"]}
{"project": "facebook_react-native", "title": "[REACT-NATIVE-WINDOWS] Picker don't work inside a DrawerNavigator", "description": "Environment:\nOS: Windows 10\nNode: 9.11.1\nYarn: 1.6.0\nnpm: 5.6.0\nWatchman: Not Found\nXcode: N/A\nAndroid Studio: Version  3.0.0.0 AI-171.4443003 Packages: (wanted => installed)\nreact: ^16.4.1 => 16.4.1\nreact-native: ^0.55.0 => 0.55.4 When i try to use the  element inside a StackNavigator it work perfectly but it don't work when i am into a drawernavigator. For exemple : my login screen : const AuthStack = createStackNavigator({ Login: Login },{headerMode:'none'}); If i use a Picker inside this screen it will work perfectly : \n But if i change : const AuthStack = createStackNavigator({ Login: Login },{headerMode:'none'}); with : const AuthStack = createDrawerNavigator({ Login: Login },{headerMode:'none'}); my Picker is always visible but nothing append when i try to use it, nothing... and this is the same result for all my other screen..  <CODE> ", "code": ["this.state = {\n    villeRisk : \"prs\",\n}\n\n<Picker\n    selectedValue={this.state.villeRisk}\n    style={{ height: 30, width: 200 }}\n    onValueChange={(itemValue, itemIndex) => this.setState({villeRisk: itemValue})}\n>\n    <Picker.Item label=\"Toulouse\" value=\"tls\" />\n    <Picker.Item label=\"Paris\" value=\"prs\" />\n</Picker>\n"], "labels": ["Resolution: Locked"]}
{"project": "dart-lang_sdk", "title": "pub install - DirectoryIOException after moving package directory", "description": "This issue was originally filed by kguggisberg...@gmail.com What steps will reproduce the problem? cd my_lib\necho \"name: my_lib\" >> pubspec.yaml\necho \"dependenices:\" >> pubspec.yaml\necho \"  args: any\" >> pubspec.yaml pub install cd ..\nmv my_lib my_new_lib\ncd my_new_lib pub install\nDirectoryIOException: Directory listing failed, path = /path/to/my_new_lib/test/packages (OS Error: No such file or directory, errno = 2) What is the expected output? What do you see instead?\npub install should probably recreate symbolic links. Or it should provide a command line option to \"reset\" the package links. What version of the product are you using? On what operating system? Please provide any additional information below. ", "code": [], "labels": ["Type-Defect", "closed-duplicate"]}
{"project": "opentx_opentx", "title": "Automatic addition of calculated telemetry sensors", "description": "In OpenTX 2.1 I have to manually add a few sensors for each model.\n-Consumption\n-Power\n-Lowest cell\n-Individual cells\nIt would be great to have a button that will add these automatically based in the type of sensors found. ", "code": [], "labels": ["stale"]}
{"project": "HandBrake_HandBrake", "title": "Detelecine \"skip-top=0\" crashes HandBrake", "description": "Using Detelecine > Custom > filter: \"skip-top=0\" crashes HandBrake\nWith SD content, crashes about 2/3 of the time. With HD content, always crashes.\n\"skip-top\" values \u2265 1 seem to work. All other \"skip-___\" filters work with values \u2265 0. (I originally thought the issue was with HB's handling of SD DVD content because I'd never had a HD telecine source to re-encode before. However, I stumbled upon the true cause when I found the need to detelecine what appears to be VFR HD PAL content.) 1.3.0 (install & standalone), plus all nightlies since (up to 20200104-d6b65cc30).\nAlso present in at least 1.2.2 (and probably further back than that). Windows 10 Pro 1909 x64 (build 18363.535). On crash, system just shows a generic \"HandBrake has stopped working\" plus \"reporting to Windows\" dialog. Windows Event Log .NET Runtime, event ID: 1026 <CODE> Application Error, event ID: 1000, task category: (100) <CODE> <CODE> End of log since HandBrake crashes here. EDIT: I just realized the build versions I used are different between Windows log (1.3.0) and HandBrake log (nightly). However, the substance of both logs is identical except for the versions numbers. ", "code": ["Application: HandBrake.exe\nFramework Version: v4.0.30319\nDescription: The process was terminated due to an unhandled exception.\nException Info: exception code c0000005, exception address 000000006F38C1DB\n", "Faulting application name: HandBrake.exe, version: 1.3.0.0, time stamp: 0x5dc73718\nFaulting module name: hb.DLL, version: 0.0.0.0, time stamp: 0x00000000\nException code: 0xc0000005\nFault offset: 0x000000000008c1db\nFaulting process id: 0x1c04\nFaulting application start time: 0x01d5b68cc88aba24\nFaulting application path: C:\\Program Files\\Handbrake\\1.3.0\\HandBrake.exe\nFaulting module path: C:\\Program Files\\Handbrake\\1.3.0\\hb.DLL\nReport Id: 16fb89bd-5405-4101-bdf2-9bf865bd532b\nFaulting package full name:\nFaulting package-relative application ID: \n", "HandBrake Nightly 20191229213216-0b089e9-master (2019122901)\nOS: Microsoft Windows NT 6.2.9200.0\nCPU: Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz\nRam: 8169 MB, \nGPU Information:\n  NVIDIA GeForce GTX 460M - 23.21.13.8857\nScreen: 1920x1080\nTemp Dir: C:\\Users\\David\\AppData\\Local\\Temp\\\nInstall Dir: X:\\Installers\\HandBrake-20191229-0b089e9d1_x86_64-Win_GUI\nData Dir: C:\\Users\\David\\AppData\\Roaming\\HandBrake\\Nightly\n\n-------------------------------------------\n\n\n# Starting Encode ...\n\n[04:27:53] base preset: HD Detel (Modified)\n[16:27:53] hb_init: starting libhb thread\n[16:27:53] Starting work at: Sat Jan 04 16:27:53 2020\n[16:27:53] 1 job(s) to process\n[16:27:53] json job:\n{\n  \"Audio\": {\n    \"AudioList\": [\n      {\n        \"DRC\": 0.0,\n        \"Encoder\": \"copy\",\n        \"Gain\": 0.0,\n        \"Mixdown\": -1,\n        \"NormalizeMixLevel\": false,\n        \"Samplerate\": 0,\n        \"Track\": 0,\n        \"DitherMethod\": 0\n      }\n    ],\n    \"CopyMask\": [\n      \"copy:aac\",\n      \"copy:ac3\",\n      \"copy:dtshd\",\n      \"copy:dts\",\n      \"copy:eac3\",\n      \"copy:flac\",\n      \"copy:mp3\",\n      \"copy:truehd\"\n    ],\n    \"FallbackEncoder\": \"ac3\"\n  },\n  \"Destination\": {\n    \"ChapterList\": [\n      {\n        \"Name\": \"Chapter 1\"\n      }\n    ],\n    \"ChapterMarkers\": true,\n    \"AlignAVStart\": false,\n    \"File\": \"X:\\\\TEST.mkv\",\n    \"Mp4Options\": {\n      \"IpodAtom\": false,\n      \"Mp4Optimize\": false\n    },\n    \"Mux\": \"mkv\"\n  },\n  \"Filters\": {\n    \"FilterList\": [\n      {\n        \"ID\": 2,\n        \"Settings\": {\n          \"skip-bottom\": \"0\",\n          \"skip-left\": \"0\",\n          \"skip-right\": \"0\",\n          \"skip-top\": \"0\"\n        }\n      },\n      {\n        \"ID\": 12,\n        \"Settings\": {\n          \"crop-bottom\": \"0\",\n          \"crop-left\": \"0\",\n          \"crop-right\": \"0\",\n          \"crop-top\": \"0\",\n          \"height\": \"1080\",\n          \"width\": \"1920\"\n        }\n      },\n      {\n        \"ID\": 6,\n        \"Settings\": {\n          \"mode\": \"0\"\n        }\n      }\n    ]\n  },\n  \"PAR\": {\n    \"Num\": 1,\n    \"Den\": 1\n  },\n  \"Metadata\": {},\n  \"SequenceID\": 0,\n  \"Source\": {\n    \"Angle\": 1,\n    \"Range\": {\n      \"Type\": \"chapter\",\n      \"Start\": 1,\n      \"End\": 1\n    },\n    \"Title\": 1,\n    \"Path\": \"N:\\\\Music\\\\-----\\\\----------.mpg\"\n  },\n  \"Subtitle\": {\n    \"Search\": {\n      \"Burn\": false,\n      \"Default\": false,\n      \"Enable\": false,\n      \"Forced\": false\n    },\n    \"SubtitleList\": []\n  },\n  \"Video\": {\n    \"Encoder\": \"x264\",\n    \"Level\": \"auto\",\n    \"TwoPass\": false,\n    \"Turbo\": false,\n    \"ColorMatrixCode\": 0,\n    \"Options\": \"rc-lookahead=60:bframes=5:ref=3:merange=64:analyse=all:trellis=2\",\n    \"Preset\": \"medium\",\n    \"Profile\": \"auto\",\n    \"Quality\": 16.0,\n    \"QSV\": {\n      \"Decode\": false,\n      \"AsyncDepth\": 0\n    }\n  }\n}\n[16:27:53] CPU: Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz\n[16:27:53]  - Intel microarchitecture Sandy Bridge\n[16:27:53]  - logical processor count: 8\n[16:27:53] Intel Quick Sync Video support: no\n[16:27:53] hb_scan: path=N:\\Music\\-----\\----------.mpg, title_index=1\nudfread ERROR: ECMA 167 Volume Recognition failed\nsrc/libbluray/disc/disc.c:323: failed opening UDF image N:\\Music\\-----\\----------.mpg\nsrc/libbluray/disc/disc.c:424: error opening file BDMV\\index.bdmv\nsrc/libbluray/disc/disc.c:424: error opening file BDMV\\BACKUP\\index.bdmv\nsrc/libbluray/bluray.c:2585: nav_get_title_list(N:\\Music\\-----\\----------.mpg\\) failed\n[16:27:53] bd: not a bd - trying as a stream/file instead\nlibdvdnav: Using dvdnav version 6.0.1\nlibdvdread:DVDOpenFileUDF:UDFFindFile /VIDEO_TS/VIDEO_TS.IFO failed\nlibdvdread:DVDOpenFileUDF:UDFFindFile /VIDEO_TS/VIDEO_TS.BUP failed\nlibdvdread: Can't open file VIDEO_TS.IFO.\nlibdvdnav: vm: failed to read VIDEO_TS.IFO\n[16:27:53] dvd: not a dvd - trying as a stream/file instead\n[16:27:53] file is MPEG Program Stream\n[16:27:53] Probing 1 unknown stream\n[16:27:53]     Probe: Found stream mpegvideo. stream id 0xe0-0x0\n[16:27:53] Found the following streams\n[16:27:53]     Video Streams :\n[16:27:53]       0xe0-0x0 type MPEG2 (0x2)\n[16:27:53]     Audio Streams :\n[16:27:53]       0xbd-0x80 type AC3 (0x81)\n[16:27:53]     Subtitle Streams :\n[16:27:53]     Other Streams :\n[16:27:53] stream id 0xbd (type 0x81 substream 0x80) audio 0x8000bd\n[16:27:53] scan: decoding previews for title 1\n[16:27:53] file is MPEG Program Stream\n[16:27:53] Probing 1 unknown stream\n[16:27:53]     Probe: Found stream mpegvideo. stream id 0xe0-0x0\n[16:27:53] scan: audio 0x8000bd: ac3, rate=48000Hz, bitrate=256000 Unknown (AC3) (2.0 ch) (256 kbps)\n[16:27:54] stream: 343 good frames, 0 errors (0%)\n[16:27:54] scan: 10 previews, 1920x1080, 29.970 fps, autocrop = 0/0/0/0, aspect 16:9, PAR 1:1\n[16:27:54] libhb: scan thread found 1 valid title(s)\n[16:27:54] Starting Task: Encoding Pass\n[16:27:54] Skipping crop/scale filter\n[16:27:54] Auto Passthru: allowed codecs are AAC, AC3, E-AC3, TrueHD, DTS, DTS-HD, MP3, FLAC\n[16:27:54] Auto Passthru: fallback is AC3\n[16:27:54] Auto Passthru: using AC3 Passthru for track 1\n[16:27:54] work: only 1 chapter, disabling chapter markers\n[16:27:54] job configuration:\n[16:27:54]  * source\n[16:27:54]    + N:\\Music\\-----\\----------.mpg\n[16:27:54]    + title 1, chapter(s) 1 to 1\n[16:27:54]  * destination\n[16:27:54]    + X:\\TEST.mkv\n[16:27:54]    + container: Matroska (libavformat)\n[16:27:54]  * video track\n[16:27:54]    + decoder: mpeg2video\n[16:27:54]      + bitrate 200 kbps\n[16:27:54]    + filters\n[16:27:54]      + Detelecine (pullup) (skip-left=0:skip-right=0:skip-top=0:skip-bottom=0)\n[16:27:54]      + Framerate Shaper (mode=0)\n[16:27:54]        + frame rate: same as source (around 29.970 fps)\n[16:27:54]    + Output geometry\n[16:27:54]      + storage dimensions: 1920 x 1080\n[16:27:54]      + pixel aspect ratio: 1 : 1\n[16:27:54]      + display dimensions: 1920 x 1080\n[16:27:54]    + encoder: H.264 (libx264)\n[16:27:54]      + preset:  medium\n[16:27:54]      + options: rc-lookahead=60:bframes=5:ref=3:merange=64:analyse=all:trellis=2\n[16:27:54]      + profile: auto\n[16:27:54]      + level:   auto\n[16:27:54]      + quality: 16.00 (RF)\n[16:27:54]      + color profile: 1-1-1\n[16:27:54]  * audio track 1\n[16:27:54]    + decoder: Unknown (AC3) (2.0 ch) (256 kbps) (track 1, id 0x8000bd)\n[16:27:54]      + bitrate: 256 kbps, samplerate: 48000 Hz\n[16:27:54]    + AC3 Passthru\n[16:27:54] file is MPEG Program Stream\n[16:27:54] Probing 1 unknown stream\n[16:27:54]     Probe: Found stream mpegvideo. stream id 0xe0-0x0\n[16:27:54] sync: expecting 123052 video frames\n[16:27:54] encx264: min-keyint: 30, keyint: 300\n[16:27:54] encx264: encoding at constant RF 16.000000\n[16:27:54] encx264: unparsed options: rc-lookahead=60:bframes=5:merange=64:analyse=all:trellis=2\nx264 [info]: using SAR=1/1\nx264 [info]: using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX\nx264 [info]: profile High, level 4.0, 4:2:0, 8-bit\n[16:27:54] sync: first pts video is 0\n[16:27:54] sync: first pts audio 0x8000bd is 0\n"], "labels": ["Bug"]}
{"project": "magento_magento2", "title": "magento 2 import product from csv and attribute variation change automatially", "description": "Hello Dear, I have faced issue when import product in magento 2.When i have add more then one product in then product variation automatically. From:Ravi Nama ", "code": [], "labels": ["forum"]}
{"project": "dotnet_csharplang", "title": "MethodGroup causes ambiguity over the same lambda expression", "description": "Given the following interface: <CODE> The following does not compile: <CODE>  However, if you pass a lambda expression which just invokes Source then it compiles fine: builder.Property( () => Source() ); Why is the first call (using method grouping) failing? A bug..? ", "code": ["public interface IBuilder\n{\n    void Property( Func<ValueTask<string>> source );\n    void Property( Func<Task<string>> source );\n}\n", "class Program\n{\n    static void Main( string[] args )\n    {\n        IBuilder builder = null;\n\n        builder.Property( Source );\n    }\n\n    private static ValueTask<string> Source()\n    {\n        return new ValueTask<string>();\n    }\n}\n"], "labels": ["Discussion"]}
{"project": "bumptech_glide", "title": "transform method not called up in SvgTransformation", "description": "Glide Version: 4.3.1\nimplementation 'com.github.bumptech.glide:glide:4.3.1'\nannotationProcessor 'com.github.bumptech.glide:compiler:4.3.1' Integration libraries: Device/Android Version: All devices Issue details / Repro steps / Use case background: I am trying to scale PictureDrawable created from SVG by using library 'com.caverock:androidsvg:1.2.1' according to image view width and height. So I created my Custom transform class named SvgTransformation implements Transformation. Issue is : transform method is not called. Glide load line / GlideModule (if any) / list Adapter code (if any): My custom SvgTransfromation class code is And My Glide module is Layout XML: Stack trace / LogCat: ", "code": [], "labels": ["stale", "needs triage"]}
{"project": "lodash_lodash", "title": "_.intersection does not work on DOMTokenList", "description": "I was trying to get an element's classList to see if it had one of a particular list of classes: However, while findClasses is definitely an instance of Array, classes is an instance of DOMTokenList. This object is iterable, but it is not strictly an instance of Array. So I get this: In lodash.src.js:5297, the variable classes will fail the isArray() test, since Array.isArray(classes) is false. Any other function that depends on isArray() will also likely exhibit the same behavior, though I didn't try to find any others. The same code works in Underscore, since Underscore doesn't seem to use Array.isArray as a prerequisite for iterating through the objects. ", "code": [], "labels": ["invalid"]}
{"project": "Homebrew_homebrew-cask", "title": "1password-cli version is up to date but", "description": "I followed the instructions and the version does match, but there are not instructions on what to do if the versions do match. I was trying to install 1password-cli and got a checksum error even though the versions match. <CODE> <CODE> <CODE> <CODE> ", "code": ["brew cask install 1password-cli\n", "==> Cask::Installer#install\n==> Printing caveats\n==> Cask::Installer#fetch\n==> Satisfying dependencies\n==> Downloading\n==> Downloading https://cache.agilebits.com/dist/1P/op/pkg/v0.5.5/op_darwin_amd64_v0.5.5.zip\n/usr/bin/curl -q --show-error --user-agent Homebrew/2.1.1-88-g718a435\\ \\(Macintosh\\;\\ Intel\\ Mac\\ OS\\ X\\ 10.14.3\\)\\ curl/7.54.0 --location --silent --head --request GET https://cache.agilebits.com/dist/1P/op/pkg/v0.5.5/op_darwin_amd64_v0.5.5.zip\nAlready downloaded: /Users/katrina/Library/Caches/Homebrew/downloads/a9f835f6159e7c717d76be6bcad303f6b00f2a15b9adbca8ece27c49744254b3--op_darwin_amd64_v0.5.5.zip\n==> Checking quarantine support\n/usr/bin/xattr\n/usr/bin/swift /usr/local/Homebrew/Library/Homebrew/cask/utils/quarantine.swift\n==> Quarantine is available.\n==> Verifying Gatekeeper status of /Users/katrina/Library/Caches/Homebrew/downloads/a9f835f6159e7c717d76be6bcad303f6b00f2a15b9adbca8ece27c49744254b3--op_darwin_amd64_v0.5.5.zip\n/usr/bin/xattr -p com.apple.quarantine /Users/katrina/Library/Caches/Homebrew/downloads/a9f835f6159e7c717d76be6bcad303f6b00f2a15b9adbca8ece27c49744254b3--op_darwin_amd64_v0.5.5.zip\n==> /Users/katrina/Library/Caches/Homebrew/downloads/a9f835f6159e7c717d76be6bcad303f6b00f2a15b9adbca8ece27c49744254b3--op_darwin_amd64_v0.5.5.zip is quarantined\n==> Downloaded to -> /Users/katrina/Library/Caches/Homebrew/downloads/a9f835f6159e7c717d76be6bcad303f6b00f2a15b9adbca8ece27c49744254b3--op_darwin_amd64_v0.5.5.zip\n==> Verifying SHA-256 checksum for Cask '1password-cli'.\n==> Note: Running `brew update` may fix SHA-256 checksum errors.\nError: can't modify frozen String\n/usr/local/Homebrew/Library/Homebrew/cask/cmd.rb:161:in `rescue in run'\n/usr/local/Homebrew/Library/Homebrew/cask/cmd.rb:146:in `run'\n/usr/local/Homebrew/Library/Homebrew/cask/cmd.rb:123:in `run'\n/usr/local/Homebrew/Library/Homebrew/cmd/cask.rb:9:in `cask'\n/usr/local/Homebrew/Library/Homebrew/brew.rb:102:in `<main>'\n", "==> Homebrew Version\n2.1.1-88-g718a435\n==> macOS\n10.14.3\n==> SIP\nEnabled\n==> Java\n10.0.2, 1.8.0_162\n==> Gatekeeper support\nEnabled\n==> Homebrew Cask Install Location\n<NONE>\n==> Homebrew Cask Staging Location\n/usr/local/Caskroom\n==> Homebrew Cask Taps:\n/usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask (4018 casks)\n==> Contents of $LOAD_PATH\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/simplecov-cobertura-1.3.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/ruby-macho-2.2.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rubocop-rspec-1.32.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rubocop-0.67.2/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/unicode-display_width-1.5.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/ruby-progressbar-1.10.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-wait-0.0.9/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-retry-0.6.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-its-1.3.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-3.8.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-mocks-3.8.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-expectations-3.8.3/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-core-3.8.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rspec-support-3.8.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/ronn-0.7.3/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rdiscount-2.2.0.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/extensions/universal-darwin-18/2.3.0/rdiscount-2.2.0.1\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/rainbow-3.0.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/psych-3.1.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/extensions/universal-darwin-18/2.3.0/psych-3.1.0\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/plist-3.5.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/parser-2.6.2.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/parallel_tests-2.28.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/parallel-1.17.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/mustache-1.1.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/mechanize-2.7.6/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/webrobots-0.1.2/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/ntlm-http-0.1.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/nokogiri-1.10.3/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/extensions/universal-darwin-18/2.3.0/nokogiri-1.10.3\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/mini_portile2-2.4.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/net-http-persistent-3.0.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/net-http-digest_auth-1.4.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/mime-types-3.2.2/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/mime-types-data-3.2019.0331/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/jaro_winkler-1.5.2/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/extensions/universal-darwin-18/2.3.0/jaro_winkler-1.5.2\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/http-cookie-1.0.3/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/hpricot-0.8.6/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/extensions/universal-darwin-18/2.3.0/hpricot-0.8.6\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/domain_name-0.5.20180417/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/unf-0.1.4/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/unf_ext-0.0.7.6/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/extensions/universal-darwin-18/2.3.0/unf_ext-0.0.7.6\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/diff-lcs-1.3/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/coveralls-0.8.22/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/thor-0.19.4/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/term-ansicolor-1.7.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/tins-1.20.2/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/simplecov-0.16.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/simplecov-html-0.10.2/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/docile-1.3.1/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/json-2.2.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/extensions/universal-darwin-18/2.3.0/json-2.2.0\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/connection_pool-2.2.2/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/backports-3.14.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/ast-2.4.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/activesupport-5.2.3/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/tzinfo-1.2.5/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/thread_safe-0.3.6/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/minitest-5.11.3/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/i18n-1.6.0/lib\n/usr/local/Homebrew/Library/Homebrew/vendor/bundle/bundler/../ruby/2.3.0/gems/concurrent-ruby-1.1.5/lib\n/Library/Ruby/Site/2.3.0\n/Library/Ruby/Site/2.3.0/x86_64-darwin18\n/Library/Ruby/Site/2.3.0/universal-darwin18\n/Library/Ruby/Site\n/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/vendor_ruby/2.3.0\n/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/vendor_ruby/2.3.0/x86_64-darwin18\n/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/vendor_ruby/2.3.0/universal-darwin18\n/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/vendor_ruby\n/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0\n/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/x86_64-darwin18\n/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/universal-darwin18\n/usr/local/Homebrew/Library/Homebrew\n==> Environment Variables\nLC_ALL=\"en_US.UTF-8\"\nPATH=\"/usr/local/Homebrew/Library/Homebrew/shims/scm:/usr/bin:/bin:/usr/sbin:/sbin\"\nSHELL=\"/bin/bash\"\n", "git-duet/tap\nheroku/brew\nhomebrew/cask\nhomebrew/core\nneovim/neovim\n"], "labels": ["outdated"]}
{"project": "microsoft_vscode", "title": "get rid of the Java extensions", "description": "I don't know how it happened, but every few times when I open an Eclipse project in VS Code (currently v1.32.3 on Windows 10) it starts rebuilding the project and doing various other things to get in my way. I just want an editor. If I want an IDE, I'll open Eclipse. The problem is that I can't seem to turn this off, and I don't know how I got this functionality in the first place. I once installed Red Hat XML support, so maybe that brought it in, as a dependency, but I don't even see Red Hat XML support in my list of extensions anymore. But I don't see \"Debugger for Java\", \"Java Dependency Viewer\", or \"Java Test Runner\" in my list of extension! Furthermore, if I disable \"Language Support for Java by Red Hat\", every time VS Code updates to a new version (now several times a month) it re-enables these extensions, and then tries to rebuild my entire codebase every time I open VS Code just to make an edit. Ironically, the reason I'm opening VS Code is to get a lightweight editor so I don't have Eclipse rebuilding everything just to make a tweak in something (e.g. when deploying something via the command line). Arg, how do I turn this off? And why aren't these listed in my extensions, anyway? ", "code": [], "labels": ["extensions"]}
{"project": "joomla_joomla-cms", "title": "JViewLegacy in JControllerLegacy", "description": "In component controller. <CODE> Class \\JViewLegacy Redirect to dashboard. Method creating view. /libraries/src/MVC/Controller/BaseController.php:821\nArgument $type is optional, but if not transfer to method - will result in an error. I testing on Joomla 3.9.11 ", "code": ["class ExampleController extends JControllerLegacy {\n    public function display($cachable = false, $urlparams = array()) {\n        $this->getView();\n}\n"], "labels": ["No Code Attached Yet", "J3 Issue"]}
{"project": "dart-lang_sdk", "title": "Delete breakpoints from Breakpoints window", "description": "This issue was originally filed by @zoechi What steps will reproduce the problem?\n1.\nBreakpoints in Breakpoints window can only be disabled but not deleted\n2.\nContext menu shows \"Go to file\" and \"Paste\" (disabled though but what for)\nDelete key only leads to a beep\n3. What is the expected output? What do you see instead?\nOption to delete a breakpoint in Breakpoints window\nusing the context menu or the delete key. What version of the product are you using? On what operating system?\nDart Editor version 0.8.7_r29341\nDart SDK version 0.8.7.0_r29341 Please provide any additional information below. ", "code": [], "labels": ["Type-Enhancement"]}
{"project": "godotengine_godot", "title": "ink-godot-example project crashes on start", "description": "Godot version:\n3.1 Alpha 2 Mono, 64-bit OS/device including version:\nWindows 10/Acer Aspire E 15 Issue description:\nink-godot-example project crashes on start. All worked fine on 3.1 Alpha 1 Mono. Steps to reproduce: Minimal reproduction project:\n<URL> ", "code": [], "labels": ["archived", "bug", "topic:mono"]}
{"project": "iterative_dvc", "title": "[Easy] Get rid of pathlib library", "description": "Most of the code uses standard os library as a filesystem utility but some modules (init.py) use pathlib. Let's get rid of pathlib. It will unify the code and decrease the package size. ", "code": [], "labels": ["enhancement"]}
{"project": "steelbrain_linter", "title": "No linter interface in Atom on Mac", "description": "Successfully using this on Windows, but on Mac I am not even getting an interface in Atom?\nRunning Atom 1.16 on Sierra 10.12.4. Are there more dependencies?  ", "code": [], "labels": ["question"]}
{"project": "capistrano_capistrano", "title": ":repo_tree configuration doesn't work with Mercurial", "description": "Hi, I'm using Capistrano 3.7.1 and I wanted to use the repo_tree option.\nUnfortunately with Mercurial it doesn't work, and deployment fails. <CODE> git archive writes to the standard output, but hg archive doesn't. ", "code": ["00:02 hg:create_release\n      01 hg archive --type tgz -p . -I website --rev develop | tar -x --strip-components 1 -f - -C /var/www/html/releases/20170217155548\n      01 hg archive: invalid arguments\n      01 tar: This does not look like a tar archive\n      01 tar: Skipping to next header\n      01 tar: Exiting with failure status due to previous errors\n"], "labels": ["confirmed bug"]}
{"project": "nopSolutions_nopCommerce", "title": "non-localizable text for payment methods page.", "description": "non-localizable text for payment methods page. NotSupported, Manuel, Automatic...  ", "code": [], "labels": ["functionality / feature"]}
{"project": "TryGhost_Ghost", "title": "Standardise on camelCase property names in the client", "description": "Currently we have client-side model definitions that define underscored_properties such as the following from the Tag model: This breaks Ember conventions and has led to some confusing situations such as the following taken from the tag validator: Wherein we have both metaTitle and meta_title and the need to remember which is used where both inside the validator and when interacting with it externally. I suggest that we modify our serializers to automatically convert from underscored to camelCase and back much like Ember Data's default active-model-serialzer. The changes required in the serialiser are quite minimal but making the change will also entail updating all the models and anywhere we access those properties directly. ", "code": [], "labels": ["admin-client"]}
{"project": "dgraph-io_dgraph", "title": "dgraphassigner crashed with numCpu>=2", "description": "My config:\n8G ram, Macbook Pro\ngo version go1.6.3 darwin/amd64 We clear away the \"u\" directory and ran the following command:\ndgraphassigner --numInstances 1 --instanceIdx 0 --rdfgzips rdf-films.gz --uids u --numCpu=2 After getting to:\nINFO[0025] Counters                                      ignored=0 len_cnq=9744 package=loader parsed=621296 pending=12740 processed=608556 read=631180\nINFO[0026] Counters                                      ignored=0 len_cnq=10000 package=loader parsed=643131 pending=12997 processed=630134 read=653132 We got errors beginning with: runtime/cgo: pthread_create failed: Resource temporarily unavailable\nSIGABRT: abort\nPC=0x7fff91ed4f06 m=2 goroutine 0 [idle]: goroutine 1 [semacquire]:\nsync.runtime_Semacquire(0xc82013e90c)\n/usr/local/Cellar/go/1.6.3/libexec/src/runtime/sema.go:47 +0x26\nsync.(*WaitGroup).Wait(0xc82013e900)\n/usr/local/Cellar/go/1.6.3/libexec/src/sync/waitgroup.go:127 +0xb4\ngithub.com/dgraph-io/dgraph/loader.AssignUids(0x5680550, 0xc820162000, 0x0, 0x1, 0x0, 0x0, 0x0)\n/Users/jchiu/go/src/github.com/dgraph-io/dgraph/loader/loader.go:321 +0x2ac\nmain.main()\n/Users/jchiu/go/src/github.com/dgraph-io/dgraph/cmd/dgraphassigner/main.go:93 +0x1520 ...... ", "code": [], "labels": ["kind/bug"]}
{"project": "jekyll_jekyll", "title": "Liquid Exception: Liquid error: Cannot sort a null object.", "description": " use jekyll server error: <CODE> Can anyone tell me how to fix it? Thanks! ", "code": ["  Liquid Exception: Liquid error: Cannot sort a null object. in _includes/sidebar-popular-repo.html, included in _layouts/page.html\njekyll 3.0.1 | Error:  Liquid error: Cannot sort a null object.\n"], "labels": ["frozen-due-to-age"]}
{"project": "golang_go", "title": "cmd/dist: missing zversion.go when building for windows on mac", "description": "Please answer these questions before submitting your issue. Thanks! cmd/dist\ngo: open /usr/local/go/src/runtime/internal/sys/zversion.go: no such file or directory ", "code": [], "labels": ["FrozenDueToAge", "WaitingForInfo"]}
{"project": "electron-userland_electron-builder", "title": "Is it possible to signing to dmg, not app ?", "description": "electron-updater version: 2.21.4 content is same with title, is it possible to signing to dmg? not app.\nI already signing on app, and It works well.\nbut, I faced the trouble that is the chrome browser blocked download my app even has no problem my build process (include signing my app).\nSo I thought I could solve it by signing app and dmg.\nplease tell me know about this problem ( point is chrome blocked my app (It is already signed) )\nand please tell me the way about signing on dmg ", "code": [], "labels": ["backlog"]}
{"project": "GoogleChrome_lighthouse", "title": "DevTools Error: PROTOCOL_TIMEOUT", "description": "Chrome Version: 73.0.3683.86\nError Message: PROTOCOL_TIMEOUT\nStack Trace: <CODE> ", "code": ["LHError: PROTOCOL_TIMEOUT\n    at eval (chrome-devtools://devtools/remote/serve_file/@f9b0bec6063ea50ce2b71f5b9abbae7beee319a6/audits2_worker/audits2_worker_module.js:1027:210)\n"], "labels": ["duplicate"]}
{"project": "runelite_runelite", "title": "Change vanilla xp drop Color if damage boost prayer is active.", "description": "Changing XP drop colour to (red -> melee damage boosting prayer), (blue -> mage damage boosting prayer), (green -> range damage boosting prayer), will allow the player to know if the pray flick actually was activated at the time the damage was dealt. Keep the XP drop as it is, but just change the font colour to the corresponding prayer active. ", "code": [], "labels": ["feature-request"]}
{"project": "appium_appium", "title": "How to simulate Android app update?", "description": "I'm trying to write an automated test using Appium, where an app update is being performed. To be more specific, I have 2 Apks of the same app - one with an old version and another with a new version. I use AppiumDriver to install the old version. Now I want to install the new version. I tried using another driver in which the \"app\" capability points to the new apk. That seems to uninstall the old version and then install the new one. But that's not what I want. I want to perform an update (there's code in the app that is triggered when an update occurs, but not when a fresh installation is performed). So my questions are: ", "code": [], "labels": ["Enhancement"]}
{"project": "valor-software_ngx-bootstrap", "title": "combine bootstraps?", "description": "@Mlaval has a Carousel and @SebastianM also made a progressbar how can we combine all efforts? Or is it a race to the first one who finishes the conversion ", "code": [], "labels": ["enhancement"]}
{"project": "rancher_rancher", "title": "Service Log Journal", "description": "Add ability for users to view a journal of all actions taken during the creation of the service. When service deployment fails in Rancher, it is extremely hard to pinpoint what was the original cause of the problem.  This should help better provide visibility into bugs like:\n#4235\n#3950 ", "code": [], "labels": ["kind/feature"]}
{"project": "katzer_cordova-plugin-local-notifications", "title": "Android Wear support", "description": "Hi,\nSorry if this isn't the right place for this sort of question but wondering if you looked at the Android Wear SDK/stuff and if, apart from the default support for notification, there is anything that can be done in this project to support Android Wear features? TIA and love your work\nMolly ", "code": [], "labels": ["enhancement", "android"]}
{"project": "Ultimaker_Cura", "title": "'getSettingValue' Log Errors", "description": "Not sure how important these are, but thought I would report it anyway: cura.log.txt ", "code": [], "labels": ["Type: Bug"]}
{"project": "vector-im_riot-web", "title": "Stop voip calls being placed if you have no net connection", "description": "And if they do, don't get horribly stuck ", "code": [], "labels": ["major", "bug", "p2"]}
{"project": "jsbin_jsbin", "title": "A Gallery of Good items ?", "description": "I am sure many people create cool stuffs on jsbin. Dont you think it would be nice to have a separate gallery page (jsbin.com/gallery)\nwhere you could select and list some of the really good experiments/demos/items ? It would be great from an inspirational and learning perspective. Just a suggestion, nothing serious :) ", "code": [], "labels": ["feature request"]}
{"project": "signalapp_Signal-Android", "title": "Use direct photo capture to create 'video' GIFs", "description": "As soon as GIF support is integrated... Maybe like you mentioned in #3564 by holding the shutter ", "code": [], "labels": ["feature"]}
{"project": "darktable-org_darktable", "title": "Enabling Framing causes DT to crash", "description": "Describe the bug\nDuring a session, framing was working and at one point framing started crashing DT on any image I tried to add a frame.\nRan dt with \"-d all\". The log file generated when it crashed on activating the framing module is attached. darktable-log.txt The last line of the log has a path, this path doesn't exist on my system.\n\"file F:/msy80.s6459/ho46me/85\" Version : darktable-2.7.0+1933~g6e33f89a8-win64 OS : Win 10 Temporary Workaround :  Copy framing from a history of another image and paste it into the image from lightable view. This allows me to get into framing module and make changes if necessary. ", "code": [], "labels": ["bug"]}
{"project": "godotengine_godot", "title": "OpenVR interface does not exist in the ARVRServer in Godot 3.1", "description": "Godot version: 3.1 OS/device including version: Windows 10 64-bit, HTC Vive, Nvidia RTX 2070 GeForce Game Ready Version 419.17 Issue description: The OpenVR interface in ARVRServer does not exist, even when SteamVR is running and the OpenVR package is installed. This issue only happens on Godot 3.1, it does not happen in 3.0 (I tested it on 3.0 with the exact same project in the same session and it worked). Steps to reproduce: Minimal reproduction project: ARVR.zip ", "code": [], "labels": ["archived"]}
{"project": "qgis_QGIS", "title": "Move color wheel in symbology below drop down arrow or right-click position", "description": "Author Name: Jean-Fran\u00e7ois Bourdon (@jfbourdon)\nOriginal Redmine Issue: 19592 Redmine category:gui As shown in the picture attached, would it be possible to make the color wheel appearing directly below the drop down arrow? To me, it's more logical as it's where the user had clicked to make it opens. That being said, I just realised that we can right-click anywhere on the color bar to open the color wheel... but even then, it always opens at the far left of the bar. Can we make it appearing just below the position where the user right-clicked instead? ", "code": [], "labels": ["Feature Request", "GUI/UX"]}
{"project": "ionic-team_ionic", "title": "How to include third party libs into ionic 2 RC0 ?", "description": "For example I want to include the lib lazy.js, before RC0 I used \"require(\"lazy.js\"). Now it's broken :/ So I haven't informations about install a third party libs. The example in your FAQ with @typings install doesn't work. My ionic 2 application in production is now blocked by this issue :/ Thanks for you informations ", "code": [], "labels": ["v2"]}
{"project": "dart-lang_sdk", "title": "Vm/Sdk: Classes mixing in _ServiceObject should implement its abstract members", "description": "The _ServiceObject class looks like this (from sdk/lib/io/service_object.dart): The non-abstract _NativeSocket class (from runtime/bin/socket_patch.dart): But it does not implement the abstract getter String get _serviceTypePath ! So the question is: /cc @lrhn @floitschG (for language)\n/cc @johnmccutchan (for service) Maybe I overlooked something here? ", "code": [], "labels": ["area-vm"]}
{"project": "odoo_odoo", "title": "[11.0][12.0] Wrong FIFO with Inter-warehouse moves", "description": "11.0, 12.0 10 units which were sent to customer has 1000 as its valuation.\nIt seems that Odoo does not regconize that the first 5 units were sent out priorly, then it uses the price unit from the first stock-in move (100*10 = 1000) It is expected to have 1500 as the valuation: 100 * 5 + 200 * 5 I am not sure if this is desired behaviour? I don't see this issue if the first 5 is sent to customer. ", "code": [], "labels": ["12.0", "Logistics", "11.0"]}
{"project": "endless-sky_endless-sky", "title": "Bug: switching landing sites still refers to first landing site", "description": "If you are in a system with multiple landing sites, you will see the following message when pressing the \"l\" key to land (for this example I'm in the Tarazed system): If you press \"l\" again, you switch landing sites (say, to Echo), however no new log message is produced, this continues to be the case until the original message \"fades\" after 30 seconds or so. I think the game should show a new log message when one switches landing targets, something like to give a visual indication that the landing target has indeed changed. ", "code": [], "labels": ["enhancement"]}
{"project": "jekyll_jekyll", "title": "0-exit code on LiquidException", "description": "Example below shows a 0 exit code when a Liquid Exception is thrown. I firmly believe this should be a non-zero exit code as builds should fail (pragmatically detectably) when such an issue occurs. If an uncaught exception is thrown something has gone wrong and this risks a user deploying a broken site as it's hard to pickup in a CI or any other build or deployment environment. In the below example the 0 exit code makes it difficult to tell the different between the working and failing. <CODE> ", "code": ["~/Projects/danielgroves_net develop_instagram\n\u2192 bundle exec rake build\nNotice: for 10x faster LSI support, please install http://rb-gsl.rubyforge.org/\njekyll 2.2.0\n\n\n =========================\nCleaning previous builds\n\n\n =========================\nBuilding for production\nNotice: for 10x faster LSI support, please install http://rb-gsl.rubyforge.org/\nConfiguration file: /Users/danielsgroves/Projects/danielgroves_net/_config.yml\n            Source: /Users/danielsgroves/Projects/danielgroves_net\n       Destination: /Users/danielsgroves/Projects/danielgroves_net/_site\n      Generating... \n        Pagination: Pagination is enabled, but I couldn't find an index.html page to use as the pagination template. Skipping pagination.\nConfiguration file: /Users/danielsgroves/Projects/danielgroves_net/_config.yml\n  Liquid Exception: GET https://api.instagram.com/v1/users/1358824988/media/recent.json?max_timestamp=1420027199&min_timestamp=1388534400: 400: Missing client_id or access_token URL parameter. in photo365/index.md\njekyll 2.2.0 | Error:  GET https://api.instagram.com/v1/users/1358824988/media/recent.json?max_timestamp=1420027199&min_timestamp=1388534400: 400: Missing client_id or access_token URL parameter.\n\n~/Projects/danielgroves_net develop_instagram\n\u2192 echo $?\n0\n"], "labels": ["support", "frozen-due-to-age"]}
{"project": "godotengine_godot", "title": "Bug in release Android export templates. 11/07/16", "description": "Operating system or device - Windows10-64  Godot version: 2.1alfa  11/07/16 01:17 Android Export templates builds , but release export template builds without Godot libs.\nDebug template is full and work sucessfull. Compile with:\nscons platform=android target=release_debug\ngradlew build in bin folder:\n11.07.2016  10:39         9\u00a0657\u00a0862 android_debug.apk\n11.07.2016  10:39         1\u00a0543\u00a0280 android_release.apk Release templates is without Godot libs. ", "code": [], "labels": ["topic:buildsystem", "bug", "platform:android"]}
{"project": "microsoft_TypeScript", "title": "[Errors] public method of exported class with parameter of a private type", "description": "Expected: Parameter 'm1_c3_f4_arg' of public method from exported class has or is using private type 'C2_private'. Actual: no error ", "code": [], "labels": ["Fixed"]}
{"project": "microsoft_vscode-cpptools", "title": "Auto-complete issue with Conda headers", "description": "Copied from #962.\nFrom @dcervenkov I've a replicable situation of the problem with the \"Default\" IntelliSense engine. I've just tested it on a brand new Ubuntu 16.04.3 64-bit VM. The procedure is as follows: <CODE> (I'll assume you installed miniconda to ~/miniconda3/) <CODE> ", "code": ["wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n", "conda config --add channels https://conda.anaconda.org/NLeSC\nconda create --name=rootenv root=6 python=3\nsource activate rootenv\n"], "labels": ["bug", "Language Service"]}
{"project": "microsoft_TypeScript", "title": "How to write a definition file for a commonjs module without typings.", "description": "<CODE> So I can use relative path to import this moudle import * as SpinnerDialog from '../../../plugins/com.filfatstudios.spinnerdialog/www/SpinnerDialog'; ", "code": ["//./SpinnerDialog.js\n'use strict'\n\nconst exec = require('cordova/exec')\n\nmodule.exports = {\n  show: function (title, message, cancelCallback) {\n    if (cancelCallback === true && typeof cancelCallback !== 'function') {\n      cancelCallback = function () {}\n    }\n    exec(cancelCallback, null, 'SpinnerDialog', 'show', [ title, message, !!cancelCallback ])\n  },\n  hide: function (success, fail) {\n    exec(success, fail, 'SpinnerDialog', 'hide', [ '', '' ])\n  }\n}\n"], "labels": ["Question"]}
{"project": "argoproj_argo-cd", "title": "SyncError app condition disappears during app reconciliation", "description": "Describe the bug\nSyncError condition should be added to the app if auto-sync failed. The condition is set as expected but controller might delete it during next app reconciliation. To Reproduce Expected behavior\nThe condition should be removed only if app is synced successfully. ", "code": [], "labels": ["bug"]}
{"project": "marktext_marktext", "title": "Easier Sidebar Opening", "description": "Feature Request:\nMake it easier to open the side bar. Currently, the only way to open it is to use the menu:\n Possible suggestions: ", "code": [], "labels": [" feature request"]}
{"project": "gohugoio_hugo", "title": "docs: \"Installing on Windows\" rendering", "description": "Got some raw markdown and what looks like mis-rendering in the \"installing on Windows\" doc page.\n\nRenders fine on the GitHub page ", "code": [], "labels": ["Docs"]}
{"project": "scylladb_scylla", "title": "Scyllatop exits w/o a reason many times", "description": "Running Scyllatop exits many times with this message:\nAttributeError: 'NoneType' object has no attribute 'groupdict' Nothing special is needed to achieve it, seems almost random. ", "code": [], "labels": ["bug", "high"]}
{"project": "trailofbits_algo", "title": "Fail2ban addition", "description": "Is your feature request related to a problem? Please describe.\nAfter deploying the server, the first thing I did was SSH in and install fail2ban, to block IPs which failed to SSH into the server. Describe the solution you'd like\nInclude a simple playbook which installs a basic fail2ban SSH configuration. Describe alternatives you've considered\nRely on existing publickey protection for SSH. Additional context\nNone ", "code": [], "labels": ["wontfix"]}
{"project": "handsontable_handsontable", "title": "how create multi tab sheet like excel ? multi tab :  tab 1, tab 2 , tab 3 ,this is my picture", "description": " pls help me! multi tab :  tab 1, tab 2 , tab 3........ ", "code": [], "labels": ["Type: Duplicate"]}
{"project": "NixOS_nixpkgs", "title": "Chromium is not built on unstable or master", "description": "Chromium doesn't have successful builds since March 11 -- <URL> . The reason is \"Output exceeded\" (I haven't known that Hydra has output size limits, BTW). This includes latest unstable channel, so we don't have binary substitutions for Chromium on NixOS unstable. ", "code": [], "labels": ["0.kind: bug"]}
{"project": "yajra_laravel-datatables", "title": "Can", "description": "Hi @yajra , can I ask is it possible to use @can  to hide the delete button if the user is not enough permission? Here is my code but I am having problem in applying @can <CODE> Thank you in advance. ", "code": ["       return Datatables::of($d)\n\n            ->addColumn('action', function ($c) {\n                return '<a href=\"cu/' . $c->id . '/edit\" > Edit</a>\n\n                    <a href=\"#\">Delete</a>\n\n                ';\n\n            })\n            ->make(true);\n\n"], "labels": ["question"]}
{"project": "Chocobozzz_PeerTube", "title": "Peertube crash where login containt upercase or special char", "description": "Hello\nActually, when I try to login, server crash when I tip an uppercase later or special char (an email adresse) Regard :) Sdtoud log <CODE> ", "code": ["debug: [peertube.drycat.fr:443] Getting User (username: Dryusdan, password: personal).\ndebug: [peertube.drycat.fr:443] Executing (default): SELECT \"id\", \"password\", \"username\", \"email\", \"displayNSFW\", \"role\", \"createdAt\", \"updatedAt\" FROM \"Users\" AS \"User\" WHERE \"User\".\"username\" = 'Dryusdan' LIMIT 1;\nSegmentation fault (core dumped)\n\nnpm info lifecycle peertube@0.0.1~start: Failed to exec start script\nnpm ERR! Linux 4.9.26-xxxx-std-ipv6-64\nnpm ERR! argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"start\"\nnpm ERR! node v6.11.0\nnpm ERR! npm  v3.10.10\nnpm ERR! code ELIFECYCLE\nnpm ERR! peertube@0.0.1 start: `node dist/server`\nnpm ERR! Exit status 139\nnpm ERR!\nnpm ERR! Failed at the peertube@0.0.1 start script 'node dist/server'.\nnpm ERR! Make sure you have the latest version of node.js and npm installed.\nnpm ERR! If you do, this is most likely a problem with the peertube package,\nnpm ERR! not with npm itself.\nnpm ERR! Tell the author that this fails on your system:\nnpm ERR!     node dist/server\nnpm ERR! You can get information on how to open an issue for this project with:\nnpm ERR!     npm bugs peertube\nnpm ERR! Or if that isn't available, you can get their info via:\nnpm ERR!     npm owner ls peertube\nnpm ERR! There is likely additional logging output above.\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     /PeerTube/npm-debug.log\n"], "labels": ["Type: Bug "]}
{"project": "emqx_emqx", "title": "how can i bind emqttd to a specific ip address?", "description": "now emqttd listen on 0.0.0.0:1883 by default, how can i make it to bind address 192.168.33.13:1883? ", "code": [], "labels": ["question"]}
{"project": "catapult-project_catapult", "title": "Add a 'instantiation' test view to the unittest system.", "description": " Issue by natduca\nMonday Sep 22, 2014 at 20:09 GMT\nOriginally opened as google/trace-viewer#272 From dsinclair@chromium.org on June 26, 2013 11:07:56 We have a few 'instantiation' tests that draw to the screen and need to be visually verified. We'd like to add a link into the test system that will just pull out all of the instantiate tests and display their output on the same screen. This would make the verification easier. Original issue: <URL> ", "code": [], "labels": ["Enhancement", "Infrastructure", "P2"]}
{"project": "saltstack_salt", "title": "file.managed gives UnboundLocalError: local variable 'ret' referenced before assignment", "description": "I'm running off a git checkout of the 2018.3 branch. I have this state: <CODE> <CODE> Looking briefly at the code in question, it looks like the ret variable is only set inside of an if statement which might not always be true, but I wasn't able to figure out what the purpose of it was, so I couldn't submit a PR. <CODE> ", "code": ["/etc/motd:\n  file.managed:\n    - contents: {{ pillar.get('motd', '') | json }}\n", "          ID: /etc/motd\n    Function: file.managed\n      Result: False\n     Comment: An exception occurred in this state: Traceback (most recent call last):\n                File \"/var/tmp/.salt_08831c_salt/py3/salt/state.py\", line 1905, in call\n                  **cdata['kwargs'])\n                File \"/var/tmp/.salt_08831c_salt/py3/salt/loader.py\", line 1830, in wrapper\n                  return f(*args, **kwargs)\n                File \"/var/tmp/.salt_08831c_salt/py3/salt/states/file.py\", line 2396, in managed\n                  **kwargs\n                File \"/var/tmp/.salt_08831c_salt/py3/salt/modules/file.py\", line 4738, in check_managed_changes\n                  group, mode, attrs, saltenv, contents)\n                File \"/var/tmp/.salt_08831c_salt/py3/salt/modules/file.py\", line 4845, in check_file_meta\n                  differences = get_diff(name, tmp, show_filenames=False)\n                File \"/var/tmp/.salt_08831c_salt/py3/salt/modules/file.py\", line 5011, in get_diff\n                  return ret\n              UnboundLocalError: local variable 'ret' referenced before assignment\n     Started: 01:13:42.231258\n    Duration: 39.385 ms\n     Changes:  \n", "$ salt-ssh --versions\nSalt Version:\n           Salt: 2018.3.0-362-g245d62c\n \nDependency Versions:\n           cffi: Not Installed\n       cherrypy: Not Installed\n       dateutil: Not Installed\n      docker-py: Not Installed\n          gitdb: Not Installed\n      gitpython: Not Installed\n          ioflo: Not Installed\n         Jinja2: 2.10\n        libgit2: Not Installed\n        libnacl: Not Installed\n       M2Crypto: Not Installed\n           Mako: Not Installed\n   msgpack-pure: Not Installed\n msgpack-python: 0.5.6\n   mysql-python: Not Installed\n      pycparser: Not Installed\n       pycrypto: 2.6.1\n   pycryptodome: Not Installed\n         pygit2: Not Installed\n         Python: 3.5.3 (default, Jan 19 2017, 14:11:04)\n   python-gnupg: Not Installed\n         PyYAML: 3.12\n          PyZMQ: 17.0.0\n           RAET: Not Installed\n          smmap: Not Installed\n        timelib: Not Installed\n        Tornado: 4.5.3\n            ZMQ: 4.1.6\n \nSystem Versions:\n           dist: debian 9.4 \n         locale: UTF-8\n        machine: x86_64\n        release: 4.9.0-6-amd64\n         system: Linux\n        version: debian 9.4\n"], "labels": ["Fixed Pending Verification", "Bug"]}
{"project": "smartstore_SmartStoreNET", "title": "Make return request list searchable/filterable", "description": "Do not forget the Id. ", "code": [], "labels": ["enhancement"]}
{"project": "Komodo_KomodoEdit", "title": "SDK for adding your own colors to color scheme editor", "description": "title \ud83d\ude1b ", "code": [], "labels": ["Type: Enhancement"]}
{"project": "dotnet_cli", "title": "CLI breaks when installed to path containing ` ` character", "description": "Install the CLI using an MSI, or copy to path with spaces. Run any command that leverages msbuild, such as dotnet restore Restore succeeds <CODE> ", "code": ["dotnet restore\nMSBUILD : error MSB1009: Project file does not exist.\nSwitch: Files\\dotnet\\sdk\\1.0.0-preview3-004005\\dotnet.dll;ea17a368-d90b-4f01-b310-b70a37d26bf7\n"], "labels": ["1 - Ready"]}
{"project": "docker_compose", "title": "Docker-compose dependency on healthy containers", "description": "Back in docker-compose v2.1 there was a possibility to make a dependency based on a healthy service. In version 3 this option is missing as described here: <URL> Since Docker recognizes the difference between Healthy/Unhealthy service I am wondering why is this not supported any more. Let's say I need to start a workload with multiple services connecting to the same database: making a dependency. With the approach as described in the stackoverflow post I would need to create custom entrypoints for every single service which seems crazy to me. I am using docker-compose version 1.22.0, build f46880fe, Docker version 18.06.1-ce, build e68fc7a. ", "code": [], "labels": ["kind/question"]}
{"project": "DemocracyOS_democracyos", "title": "When clicking in a topic that has been voted it refreshes with the previous vote", "description": "if you vote and click on the topic again it will refresh with the vote that was cast before, or if any it will seem that you didn't vote yet. When you refresh the page you can see your vote correctly. ", "code": [], "labels": ["bug"]}
{"project": "x64dbg_x64dbg", "title": "Icons are too small in 4k display", "description": "using an Alienware 15 R2  ", "code": [], "labels": ["gui"]}
{"project": "h5bp_html5-boilerplate", "title": "Revisit lang attribute", "description": "I maintain the W3C HTML Checker and in looking at statistics logged  by it I notice there are a significant number of sites built from HTML5 Boilerplate that have <html class=\"no-js\" lang=\"\">. That is, they have the empty string as the value for the lang attribute, even when the document is clearly in English or another identifiable language. I think this problem could maybe be prevented if HTML5 Boilerplate instead used something like <html class=\"no-js\" lang=\"CHANGE_ME\"> rather than <html class=\"no-js\" lang=\"\">. ", "code": [], "labels": ["awaiting feedback"]}
{"project": "facebook_react", "title": "Old app with componentWillReceiveProps freezes browser, adding UNSAFE_ fixes it", "description": "Do you want to request a feature or report a bug?\nbug What is the current behavior?\nThe app freezes the browser/tab for like 28 seconds until I changed maybe 20+ componentWillReceiveProps to UNSAFE_componentWillReceiveProps or used the codemod. The components with the method haven't been loaded yet, as It uses react-loadable, and is in a login component only. In chrome dev tools however, it stays a long time in a webpackerrormessage js file. Just found it weird, it runs on my iMac immediately, but previously not on my 2nd gen i5 with 12gb of ram laptop, until I changed this, it's a large codebase btw, but still some mighty performance impact for an error message. Just wanted a heads up, some folks out there who ignore eslint warnings \ud83d\ude2c until its time to clean up the app might just ignore this casually, i dunno. I only tested this on development, haven't tried doing a build with no sourcemaps to see if that is a problem too. If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (<URL> or CodeSandbox (<URL> example below: Tried doing some nested components with the lifecycle method in the sandbox, doesn't lag, so its probably with eslint-react? What is the expected behavior?\nShould have lagged with the aforementioned lifecycle method, but it probably doesnt since there's no eslint configured Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?\nThis is on react 16.5.0, eslint 5.6.1 ", "code": [], "labels": ["Resolution: Needs More Information"]}
{"project": "qgis_QGIS", "title": "Error writing output shapefile while building Voronoi polygons", "description": "Author Name: dr - (dr -)\nOriginal Redmine Issue: 9264\nAffected QGIS version: master\nRedmine category:processing/qgis Test case: Test data in attachment. ", "code": [], "labels": ["Processing", "Bug"]}
{"project": "elastic_elasticsearch", "title": "Cannot order by Group By aggregation results in SQL", "description": "Elasticsearch version (bin/elasticsearch --version): Version: 7.0.0-alpha1-SNAPSHOT, Build: default/zip/707ba28/2018-04-27T09:12:51.745354Z, JVM: 1.8.0_144 Plugins installed: none JVM version (java -version): java version \"1.8.0_144\"\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode) OS version (uname -a if on a Unix-like system): Darwin MustafaAkin.local 17.4.0 Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64 Description of the problem including expected versus actual behavior: Steps to reproduce: For reference, the query is as follows: <CODE> But the results is not ordered and it can be seen from translate API as well. <CODE> ", "code": ["GET _xpack/sql?format=txt\n{\n    \"query\": \"SELECT avg(system.process.memory.rss.bytes) AS total, system.process.name FROM metricbeat* GROUP BY system.process.name ORDER BY total LIMIT 100\"\n}\n\n       total        |system.process.name\n--------------------+-------------------\n3.3009664E7         |CalendarAgent      \n3.3805892963265306E8|Google Chrome      \n2.754828747755102E8 |Google Chrome H    \n2.34139648E8        |Slack Helper       \n1.3305953523809524E8|Spotify            \n8.14535317979798E8  |Spotify Helper     \n1.3287424E7         |XprotectService    \n3.394526625185185E8 |goland             \n1.9761845169230768E8|iTerm2             \n1.0084054522828283E9|idea               \n1.5776596712727273E9|java               \n2.3113728E7         |metricbeat         \n2.38579712E8        |node               \n1.644544E7          |quicklookd         \n6209536.0           |zsh               \n", "{\n  \"size\": 0,\n  \"_source\": false,\n  \"stored_fields\": \"_none_\",\n  \"aggregations\": {\n    \"groupby\": {\n      \"composite\": {\n        \"size\": 100,\n        \"sources\": [\n          {\n            \"123671\": {\n              \"terms\": {\n                \"field\": \"system.process.name\",\n                \"order\": \"asc\"\n              }\n            }\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"123838\": {\n          \"avg\": {\n            \"field\": \"system.process.memory.rss.bytes\"\n          }\n        }\n      }\n    }\n  }\n}\n"], "labels": [">bug", ":Search/SQL"]}
{"project": "ionic-team_ionic", "title": "Unit Tests Break with Latest @ionic/angular Version", "description": "Ionic version:  (check one with \"x\")\n(For Ionic 1.x issues, please use <URL>\n[ ] 2.x\n[ ] 3.x\n[ x] 4.x I'm submitting a ...  (check one with \"x\")\n[ x] bug report\n[ ] feature request Current behavior: Repo: <URL>\nI have a blank v4 project with the following modifications: With the latest version of @ionic/angular, I get the following with npm test: <CODE> Rolling back to version 0.0.2-28 (npm i @ionic/angular@0.0.2-28) results in a properly working test. So: Expected behavior: Should work, or we need to document a modified unit test setup. Steps to reproduce: Related code:\n<URL> Other information: Ionic info: (run ionic info from a terminal/cmd prompt and paste output below): <CODE> ", "code": ["Chrome 64.0.3282 (Mac OS X 10.13.3) ERROR\n  {\n    \"message\": \"Uncaught Error: ionic.js script missing from index.html\nat http://localhost:9877/_karma_webpack_/vendor.bundle.js:769:5\nError: ionic.js script missing from index.html\\n    at Object.../../../../@ionic/angular/dist/index.js (http://localhost:9877/_karma_webpack_/vendor.bundle.js:769:11)\n    at __webpack_require__ (http://localhost:9877/_karma_webpack_/inline.bundle.js:55:30)\\n    at Object.../../../../../src/app/app.component.spec.ts (http://localhost:9877/_karma_webpack_/main.bundle.js:59:17)\n    at __webpack_require__ (http://localhost:9877/_karma_webpack_/inline.bundle.js:55:30)\\n    at webpackContext (http://localhost:9877/_karma_webpack_/main.bundle.js:10:9)\nat Array.map (<anonymous>)\\n    at Object.../../../../../src/test.ts (http://localhost:9877/_karma_webpack_/main.bundle.js:194:16)\n    at __webpack_require__ (http://localhost:9877/_karma_webpack_/inline.bundle.js:55:30)\n    at webpackJsonpCallback (http://localhost:9877/_karma_webpack_/inline.bundle.js:26:23)\n    at http://localhost:9877/_karma_webpack_/main.bundle.js:1:1\",\n", "~/Projects/Home/test-blank (master): ionic info\ncli packages: (/usr/local/lib/node_modules)\n\n   @ionic/cli-utils  : 2.0.0-alpha.f69a036f\n   ionic (Ionic CLI) : 4.0.0-alpha.f69a036f\n\nlocal packages:\n\n   @angular/cli    : 1.6.8\n   @ionic/core     : 0.0.4-1\n   Ionic Framework : @ionic/angular 0.0.2-29\n\nSystem:\n\n   Node : v8.9.0\n   npm  : 5.6.0 \n   OS   : macOS High Sierra\n"], "labels": ["triage"]}
{"project": "xonsh_xonsh", "title": "When using \"Open In Terminal\" option in Nautilus/Nemo, Xonsh starts in ~ instead of the current directory.", "description": "I can't figure out if this is a configuration error on my part or a yet-to-be-implemented feature. Currently I have gnome-terminal configured to launch xonsh instead of my default shell. It always launches it in my home directory. I've tried numerous hacks to make it work but was unsuccessful \ud83d\ude15 ", "code": [], "labels": ["question"]}
{"project": "spring-projects_spring-boot", "title": "Upgrade to Spring Amqp 2.2.2.RELEASE", "description": "\nNo description provided.\n ", "code": [], "labels": ["type: dependency-upgrade"]}
{"project": "ariya_phantomjs", "title": "Openning a web page after changing view port using 'casper.viewport(width, height)' does not respect provided size", "description": "Thanks.\nAlinoson ", "code": [], "labels": ["stale"]}
{"project": "checkstyle_checkstyle", "title": "Duplicate error message for static final field in DeclarationOrder check", "description": "Incorrect position of static final field is reported once as static variable and then as variable in DeclarationOrder. <CODE> ", "code": ["[checkstyle] com\\puppycrawl\\tools\\checkstyle\\checks\\blocks\\AvoidNestedBlocksCheck.java:100:5: Static variable definition in wrong order.\n[checkstyle] com\\puppycrawl\\tools\\checkstyle\\checks\\blocks\\AvoidNestedBlocksCheck.java:100:5: Variable access definition in wrong order.\n"], "labels": ["bug", "approved"]}
{"project": "spring-projects_spring-framework", "title": "Server Side Event - Socket is not released. [SPR-14819]", "description": "Harshal Vora opened SPR-14819 and commented While using SSE Emitter, consider a scenario where\na) Client & Server are in a different LAN. Client is behind a NAT, server can be on a public IP or behind a NAT.\nb) Server is deployed on Tomcat7\nc) Timeout is set to infinite (i.e. never times out) If the client kills the connection, the socket on the server goes into Close_Wait state.\nThis socket is never closed even if you try to send something via sseEmitter until and unless In the second case, connection goes into LAST_ACK state and then gets closed.\nSSE thread gets killed but sseComplete method is not called. This behaviour is not seen if both the client and server are part of the same LAN. The difference that we have observed at the TCP level is that there is no Reset packet when the client and the server are on a different LAN whereas a Reset packet is received by the server if both of them are within the same LAN which kills the connection on the server side and thus sseEmitter thread. We have also done some testing with Netcat utility and a minimal Java Socket program and they always close the socket on the server side if the client dies. Currently we have to kill the server side thread on timeout, but this means that the thread is running till timeout is reached (timeout is calculated from the time the connection is created and not from the time the client dies). This has two disadvantages Is there any solution for this? Kindly Note: We are using \"org.springframework:spring-webmvc:4.2.1.RELEASE\" jar.\nIt does not give me an option to select 4.2.1.RELEASE in the \"Affects Version/s\" section. No further details from SPR-14819 ", "code": [], "labels": ["status: declined", "type: enhancement", "in: web"]}
{"project": "mesosphere_marathon", "title": "Running integration tests should be configurable", "description": "Current situation while running integration tests on Mac is, that mesos claims that it supports the flag --no-systemd_enable_support but when passing this flag to mesos on Mac it results in an error. Therefore the usage of this flag should be configured in <URL> ", "code": [], "labels": ["enhancement"]}
{"project": "mapbox_rasterio", "title": "property-based testing with hypothesis", "description": "Investigate the use of hypothesis for more robust testing. We hardcode a lot of test fixtures; the idea of property-based testing is to randomly generate input data from a specified domain in order to discover edge cases that break your assumptions. First obvious spot: look at our hardcoded EPS globals and find where the precision breaks. ", "code": [], "labels": ["testing"]}
{"project": "eclipsesource_tabris-js", "title": "[Android] Setting font to 'initial' in constructor prints warning", "description": "Warning says \"Could not create object \"tabris.TextView\" on tabris.TextView (Reason: Attempt to invoke virtual method 'boolean com.eclipsesource.tabris.client.core.model.Font.isBold()' on a null object reference)\" May or may not also prevent the widget from appearing on screen. ", "code": [], "labels": ["bug", "android"]}
{"project": "spring-projects_spring-boot", "title": "ConfigFileEnvironmentPostProcessor does not log anything anymore", "description": "ConfigFileEnvironmentPostProcessor is using a DeferredLog to cache log messages until the logging system is actually initialized. The processing of the configuration is made on one instance created by EnvironmentPostProcessingApplicationListener while further events (including the one that is triggering the logs) on another one. Could it be that the second is created by ConfigFileApplicationContextInitializer? I can see that ConfigFileEnvironmentPostProcessor is registered twice in spring.factories as well. ", "code": [], "labels": ["type: bug"]}
{"project": "dotnet_aspnetcore", "title": "Razor Components - Disable PreRendering", "description": "Is there a way to disable Razor Components prerendering? With the API changing in Startup.cs at the same time as prerendering was enabled in the razor components template, I can't find any guidance on how to run from an index.html file instead of index.cshtml. ", "code": [], "labels": ["area-blazor"]}
{"project": "vaadin_framework", "title": "Grid: Layout Errors if (short) Caption is used", "description": "Originally by jonas.hahn When setting a caption on the grid the column-width is not calculated correctly. The columns are too short and do not expand to the full width which leaves an ugly white space. Strangely, when setting a bit longer caption (only some chars longer) the layout is ok. The reason is probably this performance enhancement which does not recalculate in all cases: vaadin/vaadin@7.5.0...7.5.2diff-dd75891e13dbe33c15cc7a8da99f88b2R7698 [[Image(boring.png)]]\n[[Image(unicorn.png)]] <CODE> I temporarily fixed it by reintroducing the recalculation after attach by creating an extension, containing the following code: <CODE> Imported from <URL> issue #18517 ", "code": ["#!java\n        VerticalLayout layout = new VerticalLayout();\n        Grid grid = new Grid();\n\n        String columnTitlePrefix = \"TestColumn \";\n        String cellContent = \"TestCell\";\n\n        for (int x = 1; x <= 7; x++)\n        {\n            grid.addColumn(columnTitlePrefix + x);\n\n        }\n\n        for (int i = 0; i < 100; i++)\n        {\n            grid.addRow(cellContent,cellContent,cellContent,cellContent,cellContent,cellContent,cellContent);\n        }\n\n\n        grid.setSizeFull();\n        grid.setCaption(\"Boring Test\");\n        //grid.setCaption(\"Unicorn Power\");\n        layout.addComponent(grid);\n        setContent(layout);\n", "#!java\n   @Override\n    protected void extend(ServerConnector target)\n    {\n        getGrid().addAttachHandler(this);\n    }\n\n    private void fixMissingColumnRecalculation() {\n        Scheduler.get().scheduleDeferred(new Scheduler.ScheduledCommand() {\n\n            @Override\n            public void execute() {\n                getGrid().recalculateColumnWidths();\n            }\n\n        });\n    }\n\n    @Override\n    public void onAttachOrDetach(AttachEvent event)\n    {\n        if (event.isAttached())\n        {\n            fixMissingColumnRecalculation();\n        }\n    }\n\n"], "labels": ["bug"]}
{"project": "cython_cython", "title": "major performance bug with special functions", "description": "I found (and, I think, fixed) a major performance bug with special functions in Cython. If you define a special function (__len__, __add__, __getattr__, etc.) in a cdef class, and then inherit from that class with a non-cdef class (either a Cython class that's not cdef, or a Python class), then calling the special function on the subclass will be vastly slower than necessary. For example, with this Cython code: <CODE> I get these timings: <CODE> where it takes about 170ns extra to call the method in the subclass.  (The overhead differs by special function; for __getattr__ it's more like 700ns of overhead on the same machine.) After my patch, the timings become: <CODE> That is, to within measurement error, the special function on the subclass is exactly the same speed as the special function on the superclass. What's going on (described in terms of __getattr__/.tp_getattro, but the same thing happens for any special function): In typeobject.c, there's a subtle interplay between the contents of\nthe .tp_getattro slot and the \"__getattr__\" in the type's dictionary,\nto make sure they always match.  When defining a type in C, you can\nset .tp_getattro, and typeobject.c:add_operators() will create a\n\"__getattr__\" containing a wrapper for the .tp_getattro function.\nWhen defining a type in Python, you can set __getattr__, and\ntypeobject.c:update_one_slot() will set .tp_getattro to a function\nthat will look up __getattr__ and call it. If you define a type in C, that sets .tp_getattro (so add_operators()\ncreates a __getattr__ wrapper), and then inherit from the type in\nPython, it needs to avoid setting .tp_getattro to the function that\nlooks up __getattr__; instead, it should leave .tp_getattro alone\n(inherited from its parent).  This case is detected in\nupdate_one_slot() by checking if __getattr__ is a wrapper object; if\nso, it was presumably created by add_operators(), and presumably\nmatches .tp_getattro, so nothing has to be done. Cython was breaking this optimization by setting both .tp_getattro and\n__getattr__.  Then update_one_slot() notices that __getattr__ is set,\nand is not a wrapper object; so it sets .tp_getattro to call `````` getattr```. The fix is simple... just don't create the Python versions of the methods and let PyType_Ready (which calls add_operators()) do it for you. I do know of one behavioral change with this patch: if you define __getattr__ in a cdef class, then Python introspection will claim that you implemented __getattribute__ instead.  (There may be other similar changes.) I tested the patch as follows: applied it to Cython 0.12.1, Cython 0.13.beta0, and current cython-devel; and ran the test suite.  All tests passed (except the two failures reported by Arfrever for Cython 0.13.beta0).  I then applied it to the Sage Cython spkg from Sage 4.5.1, rebuilt Sage's cython code using the new version (\"sage -ba\"), and ran the entire test suite (\"make ptestlong\").  All tests passed. I'm not sure if it's too late, but I think this patch (or something like it) should be seriously considered for 0.13. At 2010-07-27T06:20:14Z @cwitty added attachment trac_561-cython-special-functions.patch At 2010-07-28T01:02:24Z @cwitty added attachment trac_561-test-suite.patch At 2010-08-12T18:00:20Z @cwitty added attachment trac_561-python3-doctest-fixes.patch Migrated from <URL> <CODE> ", "code": ["cdef class NullAdder:\n    def __add__(self, other):\n        return self\n\nclass NullAdder2(NullAdder):\n    pass\n", "sage: na = NullAdder()\nsage: timeit('na + na', number=10^5, repeat=30)\n100000 loops, best of 30: 94.3 ns per loop\nsage: na2 = NullAdder2()\nsage: timeit('na2 + na2', number=10^5, repeat=30)\n100000 loops, best of 30: 261 ns per loop\n", "sage: na = NullAdder()\nsage: timeit('na + na', number=10^5, repeat=30)\n100000 loops, best of 30: 92 ns per loop\nsage: na2 = NullAdder2()\nsage: timeit('na2 + na2', number=10^5, repeat=30)\n100000 loops, best of 30: 92.9 ns per loop\n", ""], "labels": ["enhancement", "Code Generation"]}
{"project": "eslint_eslint", "title": "prefer-object-spread should discuss spec availability", "description": "the prefer-spread page helpfully discusses the fact that it's new to ES2015, but there is no such info on the prefer-object-spread page which makes it read like people should be able to readily use it. unfortunately, it's new to ES2018, and even then, going by the MDN page, Edge & Safari don't yet support it. ", "code": [], "labels": ["help wanted", "documentation", "archived due to age", "accepted", "good first issue"]}
{"project": "grails_grails-core", "title": "GRAILS-3915: Cannot upgrade Grails 1.0.4 projec with Captcha Plugin (com.octo.captcha.*)", "description": "Original Reporter: hansamann\nEnvironment: Mac 10.5, java6, \nVersion: 1.1-beta3\nMigrated From: <URL> I just tried to upgrade the grails podcast grails app to the latest version, when typing grails upgrade I get this: Grails home is set to: /Users/haiges/grails/grails-1.1-beta3 Base Directory: /Users/haiges/ws/gspot\nRunning script /Users/haiges/grails/grails-1.1-beta3/scripts/Upgrade.groovy\nEnvironment set to development\nNOTE: Your application currently expects grails version [1.0.4], this target will upgrade it to Grails 1.1-beta3 \u2026 ```\n    WARNING: This target will upgrade an older Grails application to 1.1-beta3.\n    However, tag libraries provided by earlier versions of Grails found in grails-app/taglib will be removed. \n    The target will not, however, delete tag libraries developed by yourself.\n    Are you sure you want to continue? \n                (y, n)\n``` y\n   [delete] Deleting directory /Users/haiges/.grails/1.1-beta3/projects/gspot/resources\nError executing script Upgrade: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed, script1233429401200.groovy: 4: unable to resolve class com.octo.captcha.service.multitype.GenericManageableCaptchaService\n @ line 4, column 1.script1233429401200.groovy: 5: unable to resolve class com.octo.captcha.engine.GenericCaptchaEngine\n @ line 5, column 1.script1233429401200.groovy: 6: unable to resolve class com.octo.captcha.image.gimpy.GimpyFactory\n @ line 6, column 1.script1233429401200.groovy: 7: unable to resolve class com.octo.captcha.component.word.wordgenerator.RandomWordGenerator\n @ line 7, column 1.script1233429401200.groovy: 8: unable to resolve class com.octo.captcha.component.image.wordtoimage.ComposedWordToImage\n @ line 8, column 1.script1233429401200.groovy: 9: unable to resolve class com.octo.captcha.component.image.fontgenerator.RandomFontGenerator\n @ line 9, column 1.script1233429401200.groovy: 10: unable to resolve class com.octo.captcha.component.image.backgroundgenerator.GradientBackgroundGenerator\n @ line 10, column 1.script1233429401200.groovy: 11: unable to resolve class com.octo.captcha.component.image.color.SingleColorGenerator\n @ line 11, column 1.script1233429401200.groovy: 12: unable to resolve class com.octo.captcha.component.image.textpaster.NonLinearTextPaster\n @ line 12, column 1.\n9 errors gant.TargetExecutionException: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed, script1233429401200.groovy: 4: unable to resolve class com.octo.captcha.service.multitype.GenericManageableCaptchaService\n @ line 4, column 1.script1233429401200.groovy: 5: unable to resolve class com.octo.captcha.engine.GenericCaptchaEngine\n @ line 5, column 1.script1233429401200.groovy: 6: unable to resolve class com.octo.captcha.image.gimpy.GimpyFactory\n @ line 6, column 1.script1233429401200.groovy: 7: unable to resolve class com.octo.captcha.component.word.wordgenerator.RandomWordGenerator\n @ line 7, column 1.script1233429401200.groovy: 8: unable to resolve class com.octo.captcha.component.image.wordtoimage.ComposedWordToImage\n @ line 8, column 1.script1233429401200.groovy: 9: unable to resolve class com.octo.captcha.component.image.fontgenerator.RandomFontGenerator\n @ line 9, column 1.script1233429401200.groovy: 10: unable to resolve class com.octo.captcha.component.image.backgroundgenerator.GradientBackgroundGenerator\n @ line 10, column 1.script1233429401200.groovy: 11: unable to resolve class com.octo.captcha.component.image.color.SingleColorGenerator\n @ line 11, column 1.script1233429401200.groovy: 12: unable to resolve class com.octo.captcha.component.image.textpaster.NonLinearTextPaster\n @ line 12, column 1.\n9 errors I had no issues upgrading before Grails 1.0.4, also the libary is in the lib directory. ", "code": [], "labels": ["Won't Fix", "Bug", "Minor"]}
{"project": "mkdocs_mkdocs", "title": "Either don't use six or support an older version (like 1.4)", "description": "This is causing quite a few users problems, particularly on OSX. See #576, #590 and a mailing list post. There are possible workarounds for this in the issues and email thread. ", "code": [], "labels": ["Bug"]}
{"project": "joomla_joomla-cms", "title": "[4.0] JS Error: Uncaught Error: Tooltip is transitioning", "description": "Sometime i get a js error in the frontend.\nI have yet no way to reproduce it 100% of the times but try this: No js error. 4.0 latest seems the same issue described here twbs/bootstrap#21607 and seems to be fixed in bootstrap 4 beta 1 so i guess updating bootstrap would solve this @dgt41 can you check? ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "mozilla-mobile_fenix", "title": "[Bug] name in about:support isn't Fenix", "description": "open up 'about:support' url on Fenix Name field is \"Fenix\". Name field is \"Fennec\" ", "code": [], "labels": [" bug"]}
{"project": "mapbox_mapbox-gl-native", "title": "Provide \"mapType\"-like abstraction for built-in styles", "description": "MapKit and Google Maps both specify enumerate type constants for map styles, which makes setting and comparing trivial. I think MBGL should provide a similar abstraction for built-in styles. We currently ask developers to implement their own style infrastructure, even for built-in styles: ", "code": [], "labels": ["iOS", "feature"]}
{"project": "ansible_ansible", "title": "ternary module not working.", "description": "When I want to use skip the task if the extra-vars parameter is passed like default [] in playbook from the role ansible-core <CODE> <CODE> CentOS Linux release 7.5.1804 (Core) #####Ansible command\nansible-playbook -vv --vault-id sre@/opt/sre  -i /etc/ansible/inventories/funccphosts test.yml --extra-vars \"host=node1,node2 servicename=[]\" I want to just skip the task of service if I am not passing any service name variable <CODE> ", "code": ["ansible 2.6.1\n  config file = /etc/ansible/playbooks/example/ansible.cfg\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.5 (default, Apr 11 2018, 07:36:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)]\n", "ansible 2.6.1\n  config file = /etc/ansible/playbooks/example/ansible.cfg\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.5 (default, Apr 11 2018, 07:36:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)]\n", "TASK [common_role_ : Reloading Service on node1] ****************************\ntask path: /etc/ansible/roles/common_role_cow/tasks/main.yml:17\nThursday 27 September 2018  13:06:27 +0000 (0:00:00.529)       0:00:09.391 ****\nfatal: [node1]: FAILED! =>\n  msg: '''list object'' has no attribute ''split'''\n\n"], "labels": ["bug", "support:core", "affects_2.6"]}
{"project": "Vincit_objection.js", "title": "pluck, pick, and omit depreciation", "description": "QueryBuilder#[pluck|pick|omit] are all now deprecated according to the warnings as of v2. I just want to confirm because the changelog, migration guide, nor the docs reference the deprecations. Is the idea that Objection is getting out of the business of collection manipulation and the caller is expected to cover the utility work? Which is fine, of course, I just don't want to go down the wrong path while migrating. For example, I currently have this use of pluck: ... and while the following is equivalent, without pluck, is it the recommended approach now? ", "code": [], "labels": ["enhancement", "docs"]}
{"project": "filecoin-project_go-filecoin", "title": "Enable Client Storage Demo", "description": "", "code": [], "labels": ["Epic"]}
{"project": "flutter_flutter", "title": "Flutter relative path dependency are awkward", "description": "Is there any solution to the flutter relative path? It's somewhat frustrating having to change it for every app I want to build: I noticed there was a ticket in pub here: dart-lang/pub#1358\nIt seems there is no intention of supporting environment variables. I'm assuming the end goal is to push flutter to pub, but until then is there any sane best practice people are using that I'm not realizing? ", "code": [], "labels": ["dependency: dart", "affects: dev experience"]}
{"project": "jekyll_jekyll", "title": "Can't run jekyll with pygments", "description": "I'm trying to run jekyll on my OS X, but get the error: <CODE> ", "code": ["Configuration file: /Users/antonshuvalov/Desktop/largescalejs/_config.yml\n            Source: /Users/antonshuvalov/Desktop/largescalejs\n       Destination: /Users/antonshuvalov/Desktop/largescalejs/_site\n      Generating... /Applications/Server.app/Contents/ServerRoot/usr/lib/ruby/Gems/1.9.1/gems/posix-spawn-0.3.8/lib/posix/spawn.rb:187: [BUG] Segmentation fault\nruby 2.0.0p247 (2013-06-27 revision 41674) [universal.x86_64-darwin13]\n\n-- Crash Report log information --------------------------------------------\n   See Crash Report log file under the one of following:\n     * ~/Library/Logs/CrashReporter\n     * /Library/Logs/CrashReporter\n     * ~/Library/Logs/DiagnosticReports\n     * /Library/Logs/DiagnosticReports\n   the more detail of.\n"], "labels": ["frozen-due-to-age"]}
{"project": "dart-lang_sdk", "title": "Fix syntax highlighting of reserved words", "description": "Stop syntax highlighting reserved words or letters that are part of a larger lexical patterns.\n////////////////////////////////////////////////////////////////////////////////////\nEditor: 9261\nOS: Mac OS X - x86_64 (10.7.4)\nJVM: 1.6.0_33 SDK installed: true\nDartium installed: true ", "code": [], "labels": ["Type-Defect", "closed-cannot-reproduce"]}
{"project": "snowplow_snowplow", "title": "Clojure Collector: update CORS configuration", "description": "Tomcat 8.0.53 changed their default CORS configuration, from CVE-2018-8014: We might want to replicate the approach taken in the ssc:  instead of relying on a configuration file:  cc @jbeemster ", "code": [], "labels": ["security", "bug"]}
{"project": "dotnet_roslyn", "title": "ArgumentException is thrown by foreach statement refactoring code", "description": "If a foreach loop is used for a two-dimensional array and you apply the \"convert to for\" loop refactoring and then run the generated code, it throws an ArgumentException. Steps: int[,] numbers2D = { { 9, 99 }, { 3, 33 }, { 5, 55 } };\nforeach (int i in numbers2D) { System.Console.Write($\"{i} \"); } int[,] numbers2D = { { 9, 99 }, { 3, 33 }, { 5, 55 } }; System.Collections.IList list = numbers2D;\nfor (int i1 = 0; i1 < list.Count; i1++)\n{\nint i = (int)list[i1];\nSystem.Console.Write($\"{i} \");\n} Actual result\nAn ArgumentException is thrown: Unhandled Exception: System.ArgumentException: Array was not a one-dimensional array.\nat System.Array.GetValue(Int32 index)\nat System.Array.System.Collections.IList.get_Item(Int32 index)\nat csharp_console.Program.Print() in C:\\Users\\gewarren\\source\\repos\\csharp-console\\csharp-console\\Program.cs:line 29\nat csharp_console.Program.Main(String[] args) in C:\\Users\\gewarren\\source\\repos\\csharp-console\\csharp-console\\Program.cs:line 12 Expected result\nNo runtime exception from auto-generated code. ", "code": [], "labels": ["Resolution-Fixed", "Area-IDE", "Bug"]}
{"project": "tarantool_tarantool", "title": "addrinfo is leaked in lua/socket.cc in case of Lua API error", "description": "After switching off EXTERNAL UNWIND, freeaddrinfo() may be not called in luasocket.cc in case of API error.\nSimilar problem exists in lbox_socket_accept() (fd may be leaked) and recvfrom (buffer may be leaked). In a similar vein, some region memory may be leaked in lua/pickle.c in case one of the Lua  API calls\nthrows an error. ", "code": [], "labels": ["bug"]}
{"project": "moby_moby", "title": "BitTorrent protocol support for image fetching", "description": "A typical software release at a large organization could involve hundreds or thousands of Docker hosts.  Having all of the hosts fetch images via the Docker registry at once can cause a \"thundering herd\" effect, depriving the registry of network bandwidth and significantly slowing the overall deployment process (or causing it to fail altogether due to network timeouts). As one method of avoiding this problem, Docker should have the ability to use BitTorrent to fetch images. ", "code": [], "labels": ["area/distribution"]}
{"project": "moxiecode_plupload", "title": "FileUploaded event has no object, contains responseText", "description": "File plupload.dev.js contains <CODE> But in jquery.ui.plupload.js third argument is missed <CODE> I think it must be like this: <CODE> ", "code": ["up.trigger('FileUploaded', file, {\n    response : xhr.responseText,\n    status : xhr.status,\n    responseHeaders: xhr.getAllResponseHeaders()\n});\n", "uploader.bind('FileUploaded', function(up, file) {\n    self._handleFileStatus(file);\n    self._trigger('uploaded', null, { up: up, file: file } );\n});\n", "uploader.bind('FileUploaded', function(up, file, data) {\n    self._handleFileStatus(file);\n    self._trigger('uploaded', null, { up: up, file: file, data: data } );\n});\n"], "labels": ["Fixed"]}
{"project": "rust-lang_rust", "title": "String::from_with_capacity(\"hello\", 30);", "description": "In some situations it would be useful to create a string from a &str with a bigger capacity if it is know that the string is extended later on. <CODE> To not have unused capacity, I wonder if we could have something like String::from_with_capacity() <CODE> This would be a shorter way of writing ", "code": ["len: 11, cap: 11\nlen: 51, cap: 60\n", "len: 11, cap: 51\nlen: 51, cap: 51\n"], "labels": ["T-libs", "C-feature-request"]}
{"project": "artf_grapesjs", "title": "[Bug] Error when trying to move cell from row.", "description": "Bug #2478 after release still exists. Repeat steps and you will get error Uncaught TypeError: Cannot read property 'indexEl' of undefined.\nIt can be to reproduce in your demo ", "code": [], "labels": ["bug"]}
{"project": "kubernetes_test-infra", "title": "`hack/update-generated-docs.sh` is not hermetic", "description": "Related to kubernetes/kubernetes#66098 When I run hack/update-generated-docs.sh, it lists all kubectl commands, including my personal plugins. Later, when hack/verify-generated-docs.sh runs in pre-submit, the list is obviously different. /assign @ixdy ", "code": [], "labels": ["lifecycle/rotten"]}
{"project": "flutter_flutter", "title": "Flutter does not refresh UI contents immediately when resize FlutterView", "description": "example code: Screen capture:\n <CODE> ", "code": ["Doctor summary (to see all details, run flutter doctor -v):\n[\u2713] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.1 18B75, locale en-CN)\n[\u2713] Android toolchain - develop for Android devices (Android SDK 28.0.3)\n[!] iOS toolchain - develop for iOS devices (Xcode 10.1)\n    \u2717 libimobiledevice and ideviceinstaller are not installed. To install with Brew, run:\n        brew update\n        brew install --HEAD usbmuxd\n        brew link usbmuxd\n        brew install --HEAD libimobiledevice\n        brew install ideviceinstaller\n    \u2717 ios-deploy not installed. To install with Brew:\n        brew install ios-deploy\n    \u2717 CocoaPods not installed.\n        CocoaPods is used to retrieve the iOS platform side's plugin code that responds to your plugin usage on the Dart side.\n        Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS.\n        For more info, see https://flutter.io/platform-plugins\n      To install:\n        brew install cocoapods\n        pod setup\n[\u2713] Android Studio (version 3.1)\n[!] IntelliJ IDEA Community Edition (version 2018.1.1)\n    \u2717 Flutter plugin not installed; this adds Flutter specific functionality.\n    \u2717 Dart plugin not installed; this adds Dart specific functionality.\n[\u2713] VS Code (version 1.30.0)\n[\u2713] Connected device (1 available)\n"], "labels": ["a: existing-apps", "framework", "engine"]}
{"project": "getnikola_nikola", "title": "cli imporvements to add support for argparse, --output and --define flags", "description": "Hi,\nI have a pull request to add to Nikola cli few features: Thanks ", "code": [], "labels": ["feature request"]}
{"project": "PokemonGoF_PokemonGo-Bot", "title": "can not start unrecognized arugments", "description": "<CODE> <CODE> as above OS: ubuntu 14.04 lts\nGit Commit: (run 'git log -n 1 --pretty=format:\"%H\"' and paste it here) ", "code": ["/home/cwh/.conda/envs/pokemon/bin/python pokecli.py -a google -u cwh -p 1234 --location \"New York, Washington Square\"\n", "/home/cwh/.conda/envs/pokemon/bin/python pokecli.py -a google -u cwh -p 1234 --location \"New York, Washington Square\"\nusage: pokecli.py [-h] [-cf CONFIG]\npokecli.py: error: unrecognized arguments: -a google -u cwhgooglezero -p 1234 --location New York, Washington Square\n"], "labels": ["Invalid"]}
{"project": "simple-icons_simple-icons", "title": "Home Assistant", "description": "Name: Home Assistant\nWebsite: <URL>\nAlexa Rank: ~9k\nColour: #41bdf5\nOfficial resources for icon and color: Their assets repo or, more specifically, this SVG  ", "code": [], "labels": ["new icon"]}
{"project": "edenhill_librdkafka", "title": "KAFKA-2946: implement DeleteTopic api", "description": "DeleteTopic api landed in Kafka 0.10.1.x It'd be useful to have this supported by librdkafka ", "code": [], "labels": ["enhancement", "duplicate"]}
{"project": "openhab_openhab-addons", "title": "[ipp] Malformed URL with IPP Binding and IP V6", "description": "The IPP Binding is using the IPv6 Address when discovering my CUPS Printserver, when operating an Network in Dualstack IP Mode (V4 and V6 together) As a result the openhab logfile contains errors such as these: [ERROR] [inding.ipp.handler.IppPrinterHandler] - malformed url http://2003:50:f44:5400:216:3eff:fedc:d0bc:631/printers/FS-1370DN, printer thing creation failed Manually reconfiguring the thing url, via Paper UI, will work until restart of openhab. After restart the initial IPv6 address is used again. I would expect the IPP Binding to properly format the url. The IP part of the url should be encapsulated in square brackets, when the address is an IPv6 Address with Port extension.\nhttp://[2003:50:f44:5400:216:3eff:fedc:d0bc]:631/printers/FS-1370DN The second expected behaviour is that overridden configuration settings should be persisted and not be reset on restart of openhab. Especially when it's changed from IP address to a fully qualified domain name. The url is formatted via ip:port, which results in the errors as there's no differentiation between the host and port part of the url. The status of the thing is online, even when the ab Manual reconfiguration of the thing is overwritten on restart or not persisted upon shutdown. Issues makes the use of the binding impossible, as the printer is not accessible via the incorrect url parameter and violates RFC2732 which defines the format of literal IPv6 Addresses in url's.\nSee <URL> ", "code": [], "labels": ["bug"]}
{"project": "symfony_symfony", "title": "constructor executing automatically", "description": "Not sure whether this is a default behaviour or a bug but there is strange behaviour while using dependency injection with console command.\nNo matter which command I run, the constructor of my custom class is being executed. Here is steps to reproduce it. <CODE> <CODE> now running any unrelated command that does not have dependency for the class e.g: bin/console bin/console about bin/console doctrine:schema:update or custom app command will execute the constructor of the class TestA and dump the text. ", "code": ["<?php\n\nnamespace App\\Command;\n\nuse App\\TestA;\nuse Symfony\\Component\\Console\\Command\\Command;\nuse Symfony\\Component\\Console\\Input\\InputInterface;\nuse Symfony\\Component\\Console\\Output\\OutputInterface;\n\nclass TestCommand extends Command\n{\n    public function __construct(TestA $a)\n    {\n        parent::__construct();\n    }\n\n    protected function configure()\n    {\n        $this->setName('app:test');\n    }\n\n    protected function execute(InputInterface $input, OutputInterface $output)\n    {\n    }\n}\n", "<?php\n\nnamespace App;\n\nclass TestA\n{\n    public function __construct()\n    {\n        dump('this is being executed');\n    }\n}\n"], "labels": ["Status: Waiting feedback", "Bug", "Status: Needs Review", "Unconfirmed"]}
{"project": "tabalinas_jsgrid", "title": "Scrolling by jsGrid DIV cuts off headers", "description": "Seems as though when i place Overflow-x: scroll into this:\n<div id=\"jsGrid_Pending\" style=\"overflow-x: scroll; box-shadow: rgba(0, 0, 0, 0.55) 0px 5px 6px -4px; border-radius: 4px; border: 1px solid rgb(204, 204, 204); position: relative;\" class=\"jsgrid\"> It cuts off the headers whereever the width of the table is:\n So i'm not really sure how to correct that. However, when I add this css: <CODE> It DOES show all the header names but also shows another scrollbar under the headers:\n How can I hide the scrollbar UNDER the headers but still have the outter scrollbar in order to move left and right without the header being cut off? ", "code": [".jsgrid-grid-header,\n.jsgrid-grid-body {\n        overflow: auto !important;\n}\n"], "labels": ["help wanted"]}
{"project": "jekyll_jekyll", "title": "I've updated my mac to 10.14, but \"jekyll serve\" not work any more.", "description": "I've updated my mac to 10.14, and \"jekyll serve\" not work any more. In the terminal, I've got: <CODE> and I've tried\ngem pristine --all\nand I've got this: <CODE> then I tried sudo gem pristine --all, and I've got the same thing. ", "code": ["Ignoring eventmachine-1.2.7 because its extensions are not built. Try: gem pristine eventmachine --version 1.2.7\nIgnoring ffi-1.9.25 because its extensions are not built. Try: gem pristine ffi --version 1.9.25\nIgnoring http_parser.rb-0.6.0 because its extensions are not built. Try: gem pristine http_parser.rb --version 0.6.0\n\njekyll 3.8.3 | Error:  Operation not supported on socket @ rb_sysopen - /Users/zhongshu/Library/Application Support/Logitech/LGS_LED_SDK\n", "ERROR:  While executing gem ... (Gem::FilePermissionError)\n    You don't have write permissions for the /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/gems/2.3.0 directory.\n"], "labels": ["frozen-due-to-age"]}
{"project": "ytdl-org_youtube-dl", "title": "\"token\" parameter not in video info; please report this issue....", "description": "This link: <URL> ", "code": [], "labels": ["incomplete"]}
{"project": "tensorflow_tensorflow", "title": "Strange issue converting Tensorflow model to TFLite using toco", "description": "I have a tensorflow model, in two formats, the first in a frozen graph definition (pb) file, and the second in a Keras model (h5) file. Via pb file: <CODE> Yields: <CODE> Interestingly the 90746776 (axis) value in the error changes between successive calls Via the h5 file <CODE> Yields: <CODE> ", "code": ["toco --graph_def_file=./model.pb --output_file=./model.tflite --inference_type=FLOAT --input_type=FLOAT --input_arrays=input_1 --output_arrays=out0 --allow_custom_operators\n", "2018-10-09 12:24:55.039391: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 5705 operators, 7732 arrays (0 quantized)\n2018-10-09 12:24:55.664965: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 5705 operators, 7732 arrays (0 quantized)\n2018-10-09 12:24:56.867861: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 4908 operators, 9078 arrays (0 quantized)\n2018-10-09 12:24:57.400037: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1442] Check failed: axis < input_shape.dimensions_count() (90746776 vs. 4)\nAborted (core dumped)'\nNone\n", "toco --keras_model_file=./model.h5 --output_file=./model.tflite --inference_type=FLOAT --input_type=FLOAT --input_arrays=input_1 --output_arrays=out0 --allow_custom_ops\n", "Traceback (most recent call last):\n  File \"/home/joseph/.local/bin/toco\", line 11, in <module>\n    sys.exit(main())\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 412, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 408, in run_main\n    _convert_model(tflite_flags)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 100, in _convert_model\n    converter = _get_toco_converter(flags)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 87, in _get_toco_converter\n    return converter_fn(**converter_kwargs)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/lite.py\", line 368, in from_keras_model_file\n    keras_model = _keras.models.load_model(model_file)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py\", line 230, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py\", line 310, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\n    printable_module_name='layer')\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 1298, in from_config\n    process_layer(layer_data)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 1284, in process_layer\n    layer = deserialize_layer(layer_data, custom_objects=custom_objects)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\n    printable_module_name='layer')\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/sequential.py\", line 340, in from_config\n    model.add(layer)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/training/checkpointable/base.py\", line 474, in _method_wrapper\n    method(self, *args, **kwargs)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/sequential.py\", line 175, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/wrappers.py\", line 213, in build\n    self.layer.build(tuple(child_input_shape))\n  File \"/home/joseph/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py\", line 933, in build\n    raise ValueError('The last dimension of the inputs to `Dense` '\nValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\n"], "labels": ["comp:lite"]}
{"project": "valhalla_valhalla", "title": "tyr::actor_t: curl as a requirement", "description": "It looks like libcurl is required by Valhalla lib when using tyr::actor_t even if it is compiled with <CODE> Is there any reason for it or is it just remains of HTTP API? ", "code": ["cmake .. -DCMAKE_INSTALL_PREFIX:PATH=/usr -DBUILD_SHARED_LIBS=OFF -DBUILD_STATIC_LIBS=ON -DENABLE_DATA_TOOLS=OFF -DENABLE_PYTHON_BINDINGS=OFF -DENABLE_SERVICES=OFF\n"], "labels": ["enhancement"]}
{"project": "jruby_jruby", "title": "Open3.capture3 error on Windows", "description": "Ubuntu Raring + Ruby 2.0 MRI <CODE> jruby 1.7.6 (2.0.0p195) 2013-10-22 6004147 on Java HotSpot(TM) 64-Bit Server VM 1.7.0_17-b02 [Windows 7-amd64] <CODE> ", "code": ["vagrant@vagrant-ubuntu-raring-64:~$ irb\n2.0.0p247 :001 > require 'open3'\n => true\n2.0.0p247 :002 > o, e, s = Open3.capture3(\"ruby -wc\", stdin_data: \"puts 1\")\n => [\"Syntax OK\\n\", \"\", #<Process::Status: pid 9819 exit 0>]\n", "irb(main):001:0> require 'open3'\ntrue\nirb(main):002:0> o, e, s = Open3.capture3(\"jruby -wc\", stdin_data: \"puts 1\")\nIOError: Cannot run program \"jruby -wc\" (in directory \"c:\\jruby-1.7.6\"): CreateProcess error=2, The system cannot find the file specified.\n    from org/jruby/RubyIO.java:4337:in `popen3'\n    from C:/jruby-1.7.6/lib/ruby/1.9/open3.rb:74:in `popen3'\n    from C:/jruby-1.7.6/lib/ruby/1.9/open3.rb:272:in `capture3'\n    from (irb):2:in `evaluate'\n    from org/jruby/RubyKernel.java:1121:in `eval'\n    from org/jruby/RubyKernel.java:1517:in `loop'\n    from org/jruby/RubyKernel.java:1282:in `catch'\n    from org/jruby/RubyKernel.java:1282:in `catch'\n    from C:\\jruby-1.7.6\\/bin/jirb_swing:53:in `(root)'\n"], "labels": ["windows", "JRuby 9000", "core"]}
{"project": "servo_servo", "title": "Intermittent TIMEOUT /2dcontext/imagebitmap/createImageBitmap-transfer.html", "description": "<CODE> ", "code": [" \u25b6 TIMEOUT [expected ERROR] /2dcontext/imagebitmap/createImageBitmap-transfer.html\n  \u2502 \n  \u2502 VMware, Inc.\n  \u2502 softpipe\n  \u2502 3.3 (Core Profile) Mesa 18.1.0-devel\n  \u2502 0:00:00.040711370 73605 0x7fc8a402d230 WARN                typefind gsttypefindelement.c:856:gst_type_find_get_extension:<typefind> could not find uri extension in appsrc://\n  \u2514 0:00:00.045652871 73605 0x7fc8940039e0 WARN                typefind gsttypefindelement.c:856:gst_type_find_get_extension:<typefind> could not find uri extension in appsrc://\n"], "labels": ["I-intermittent"]}
{"project": "travis-ci_travis-ci", "title": "Xcode 8 Beta (initial release) support", "description": "We've added Xcode 8 Beta support with osx_image: xcode8 Docs: <URL>\nBlog post: <URL> ", "code": [], "labels": ["mac"]}
{"project": "NodeBB_NodeBB", "title": "Plugin languages are overwritten by the defaultLang", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug"]}
{"project": "aspnet_AspNetCore.Docs", "title": "Which file to edit?", "description": "In the section [Out-of-process hosting model|<URL>], you mention to edit some XML, specifically I assume, this goes to the csproj file. However, there is no note on where to do this. This problem occurs on several occasions through the document. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["Source - Docs.ms", "doc-enhancement", "P2"]}
{"project": "fishtown-analytics_dbt", "title": "compiled schema test names can be too long", "description": "This can cause OS Errors and is otherwise generally unpleasant. Can we instead hash the parameters provided to a test to generate a shorter unique node name / filename? ", "code": [], "labels": ["bug"]}
{"project": "microsoft_WSL", "title": "hello everyone !! how can control wifi adapter for kali in WSL for using airng", "description": "This bug-tracker is monitored by developers and other technical types.  We like detail!  So please use this form and tell us, concisely but precisely, what's up.  Please fill out ALL THE FIELDS!  Issues with missing or incomplete issue templates will be closed. If you have a feature request, please post to the UserVoice. If this is a console issue (a problem with layout, rendering, colors, etc.), please post to the console issue tracker. Important: Do not open GitHub issues for Windows crashes (BSODs) or security issues.  Please direct all Windows crashes and security issues to secure@microsoft.com.  Ideally, please configure your machine to capture minidumps, repro the issue, and send the minidump from \"C:\\Windows\\minidump\". Please fill out the below information: See our contributing instructions for assistance. ", "code": [], "labels": ["duplicate"]}
{"project": "ansible_ansible", "title": "consul_kv misnamed in", "description": "typo: 'lookup: cartesian' should read 'lookup: consul_kv'\n ", "code": [], "labels": ["support:core", "needs_info", "affects_2.5", "needs_template"]}
{"project": "phpmyadmin_phpmyadmin", "title": "after droping db some links are missing", "description": "- create db\n- drop db\n  -> missing links: variables, runtime, rights, \u2026. also, possible after droping a db we should lead to\nanother page \u2026 server_databases or server_sql? - Original URL: <URL>\n- Original author: cybot_tm\n- Found in version: 2.6.4-pl3 ", "code": [], "labels": ["bug"]}
{"project": "microsoft_vscode", "title": "Comments precondition not respected", "description": "Refs: #74472 Have an extension (you can take the comment sample) that contribues the following in the package.json <CODE> Note that this action should always be disabled, since the precondition is the opposite of the when clause. However the action does not appear as disabled, but enabled  ", "code": ["{\n\t\t\t\t\t\"command\": \"mywiki.startDraft\",\n\t\t\t\t\t\"group\": \"inline\",\n\t\t\t\t\t\"precondition\": \"commentThread == draft\",\n\t\t\t\t\t\"when\": \"commentThread != draft\"\n\t\t\t\t}\n"], "labels": ["*duplicate"]}
{"project": "pypa_pip", "title": "Deprecate --default-vcs option", "description": "It clotters the code from one function call to the other to end up only being used here:\n It does not seem that useful and is an hidden option dating from f5da534, for backward compatibility with poacheggs... cc @pypa/pip-committers ", "code": [], "labels": ["S: auto-locked"]}
{"project": "redhat-developer_vscode-java", "title": "Provide configuration page", "description": "GITLENS provides its extension own setting page: <URL> Java extension has the similar requirement for the settings page to provide a user friendly UI and advanced features besides VSCode default setting editor: ", "code": [], "labels": ["documentation", "enhancement"]}
{"project": "MicrosoftDocs_azure-docs", "title": "Add accounts button disabled", "description": "I'm trying to add a sharepoint UPS account to the AAD DC Service Accounts group as per the above instructions however the add button is disabled. The account I'm logged in with is a member of the AAD DC Administrators group on Azure AD. I get the error message: you do not have permissions to modify the group domain.onmicrosoft.com/Users/AAD DC Service Accounts. Please help. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["active-directory/svc", "triaged", "in-progress", "product-question", "cxp"]}
{"project": "vaadin_framework", "title": "uitest.war web.xml does not validate", "description": "Originally by @Artur- Since #9987 web.xml in uitest.war no longer validates, causing jboss and other tests to fail: <CODE> Imported from <URL> issue #10040 ", "code": ["  Deployment \"vfszip:/home/integration/deploy/jboss-5.0.1.GA/server/default/deploy/demo.war/\" is in error due to the following reason(s): org.xml.sax.SAXException: The content of element type \"servlet\" must match \"(icon?,servlet-name,display-name?,description?,(servlet-class|jsp-file),init-param*,load-on-startup?,run-as?,security-role-ref*)\". @ vfszip:/home/integration/deploy/jboss-5.0.1.GA/server/default/deploy/demo.war/WEB-INF/web.xml[71,12]\n"], "labels": ["bug"]}
{"project": "spring-projects_spring-framework", "title": "Replace iText 2.1.7 dependency with OpenPDF 1.0.5 [SPR-16352]", "description": "Andreas R\u00f8sdal opened SPR-16352 and commented I propose to replace the iText 2.1.7 dependency in Spring (spring-webmvc) with OpenPDF 1.0.5. OpenPDF is a maintained fork of iText 4.x which still has a LGPL license. The project is maintained on GitHub: <URL> These are some references to iText 2.1.7 in Spring:\n<URL>\n<URL> Project GitHub page:\n<URL> OpenPDF contains a fix for CVE-2017-9096 iText XML External Entity Vulnerability\nLibrePDF/OpenPDF#56\nThis sercurity vulerability has not been fixed in iText 2.1.7, since it is no longer maintained. Issue Links: Referenced from: commits 7a55d93 ", "code": [], "labels": ["in: web", "type: task"]}
{"project": "strapi_strapi", "title": "Help replace Text Editor default in strAPI with CKEditor", "description": "Informations Hi everyone, my English is not good. I want to replace Text Type default in strapi with CK Editor. But i can not find documentation to help. Please help me how to replace Text Editor Type Default ( StrAPI) with CKeditor. Thanks so much ", "code": [], "labels": ["type: help wanted "]}
{"project": "facebook_react-native", "title": "npm start fails with \"Watcher took too long to load\"", "description": "When I run npm start, it fails indicating a timeout. (This is on a circa-2011 Mac laptop.) <CODE> I've rebooted just to be sure nothing else is running. To rule out a race, I've increased the MAX_WAIT_TIME on line 21 of react-native/packager/react-packager/src/FileWatcher/index.js to as much as 2 minutes, but this doesn't resolve the issue. I've installed node and watchman via brew: <CODE> and I'm running the latest version of OS X: <CODE> I have all of this running successfully on another machine, so this will probably boil down to finding out what the critical difference between the two is. ", "code": ["Mike-Fikess-MacBook-Pro:react-native mfikes$ npm start\n\n> react-native@0.0.1 start /Users/mfikes/Documents/Projects/react-native\n> ./packager/packager.sh\n\n\n ===============================================================\n |  Running packager on port 8081.       \n |  Keep this packager running while developing on any JS         \n |  projects. Feel free to close this tab and run your own      \n |  packager instance if you prefer.                              \n |                                                              \n |     https://github.com/facebook/react-native                 \n |                                                              \n ===============================================================\n\n\nReact packager ready.\n\n[Error: Watcher took too long to load.]\nError: Watcher took too long to load.\n    at null._onTimeout (/Users/mfikes/Documents/Projects/react-native/packager/react-packager/src/FileWatcher/index.js:37:16)\n    at Timer.listOnTimeout [as ontimeout] (timers.js:112:15)\n\n  >>> ERROR: could not create packager - please shut down any existing instances that are already running.\n", "Mike-Fikess-MacBook-Pro:~ mfikes$ brew list\nnode        pcre        watchman\n", "Mike-Fikess-MacBook-Pro:~ mfikes$ uname -a\nDarwin Mike-Fikess-MacBook-Pro.local 14.1.0 Darwin Kernel Version 14.1.0: Mon Dec 22 23:10:38 PST 2014; root:xnu-2782.10.72~2/RELEASE_X86_64 x86_64\n"], "labels": ["Resolution: Locked"]}
{"project": "glpi-project_glpi", "title": "Add notepad for groups", "description": "<URL> ", "code": [], "labels": ["enhancement"]}
{"project": "home-assistant_home-assistant", "title": "Bootstrapping / first start fails when installing as user outside of venv", "description": "Home Assistant release with the issue:\n0.74.2 Operating environment (Hass.io/Docker/Windows/etc.): Component/platform:\nHA core/bootstrapping (no specific component) Description of problem:\nWhen HA is installed outside of an virtual environment as a normal user the modules that are installed during bootstrapping are not found and (depending on how important the package is) the start of HA stops. Only on a subsequent start the package is found. Steps to reproduce Problem-relevant configuration.yaml entries and (fill out even if it seems unimportant):\n(No config is needed, config is autogenerated during bootstrapping) Traceback (if applicable):\nThe following logfile was obtained from a Linux installation (Docker boot2docker 4.9.93 with python base image). Check Lines 65-86 and 88-101 to see the failing import Additional information:\nI already checked a couple of things: ", "code": [], "labels": ["auto-closed", "waiting-for-reply"]}
{"project": "knative_serving", "title": "Named all service ports following istio-naming convention?", "description": "What about naming all service ports following istio-naming convention? <URL> ", "code": [], "labels": ["area/API", "lifecycle/stale", "kind/question", "area/networking"]}
{"project": "netblue30_firejail", "title": "With v. 0.9.34 services don't start anymore", "description": "I have unbound and dnscrypt-proxy sandboxed with Firejail. Unfortunately, with v. 0.9.34 those services don't start anymore with my old self-made profile. But even with the default server.profile it doesn't work. Example: <CODE> And for unbound: <CODE> Both services start normally once un-firejailed. So something has changed in v. 0.9.34 but I can't figure out what exactly. ", "code": ["dnscrypt-proxy.service - DNSCrypt client proxy\n   Loaded: loaded (/usr/lib/systemd/system/dnscrypt-proxy.service; enabled; vendor preset: disabled)\n  Drop-In: /etc/systemd/system/dnscrypt-proxy.service.d\n           \u2514\u2500override.conf\n   Active: inactive (dead) since Mo 2015-11-09 14:56:15 CET; 9s ago\n  Process: 9259 ExecStart=/usr/bin/firejail --profile=/etc/firejail/server.profile /usr/bin/dnscrypt-proxy --ephemeral-keys --resolver-name=dnscrypt.eu-nl --local-address=127.0.0.1:40 --user=nobody (code=exited, status=0/SUCCESS)\n Main PID: 9259 (code=exited, status=0/SUCCESS)\n\nNov 09 14:56:15 hannibal firejail[9259]: Reading profile /etc/firejail/disable-mgmt.inc\nNov 09 14:56:15 hannibal firejail[9259]: [INFO] + DNS Security Extensions are supported\nNov 09 14:56:15 hannibal firejail[9259]: [INFO] - [dnscrypt.eu-nl] does not support Namecoin domains\nNov 09 14:56:15 hannibal firejail[9259]: [INFO] + Provider supposedly doesn't keep logs\nNov 09 14:56:15 hannibal firejail[9259]: [NOTICE] Starting dnscrypt-proxy 1.6.0\nNov 09 14:56:15 hannibal firejail[9259]: [INFO] Ephemeral keys enabled - generating a new seed\nNov 09 14:56:15 hannibal firejail[9259]: [INFO] Done\nNov 09 14:56:15 hannibal firejail[9259]: Parent pid 9259, child pid 9260\nNov 09 14:56:15 hannibal firejail[9259]: The new log directory is /proc/9260/root/var/log\nNov 09 14:56:15 hannibal firejail[9259]: parent is shutting down, bye...\n", "unbound.service - Unbound DNS Resolver\n   Loaded: loaded (/usr/lib/systemd/system/unbound.service; enabled; vendor preset: disabled)\n  Drop-In: /etc/systemd/system/unbound.service.d\n           \u2514\u2500override.conf\n   Active: failed (Result: start-limit) since Mo 2015-11-09 15:05:13 CET; 3s ago\n  Process: 12103 ExecStart=/usr/bin/firejail --profile=/etc/firejail/server.profile /usr/bin/unbound -d (code=exited, status=0/SUCCESS)\n  Process: 12101 ExecStartPre=/bin/cp -f /etc/trusted-key.key /etc/unbound/ (code=exited, status=0/SUCCESS)\n Main PID: 12103 (code=exited, status=0/SUCCESS)\n\nNov 09 15:05:13 hannibal systemd[1]: unbound.service: Service hold-off time over, scheduling restart.\nNov 09 15:05:13 hannibal systemd[1]: Stopped Unbound DNS Resolver.\nNov 09 15:05:13 hannibal systemd[1]: unbound.service: Start request repeated too quickly.\nNov 09 15:05:13 hannibal systemd[1]: Failed to start Unbound DNS Resolver.\nNov 09 15:05:13 hannibal systemd[1]: unbound.service: Unit entered failed state.\nNov 09 15:05:13 hannibal systemd[1]: unbound.service: Failed with result 'start-limit'.\n"], "labels": ["bug"]}
{"project": "naver_pinpoint", "title": "Why Pinpoint need second zookeeper?", "description": "Please check the FAQ, and search existing issues for similar questions before creating a new issue.YOU MAY DELETE THIS PREREQUISITES SECTION. I am curious why Pinpoint need its own zookeeper? I am not asking about why it doesn\u2019t share with hbase. I want to understand how the zookeeper is used? For collector discovery? Many thx! ", "code": [], "labels": ["question"]}
{"project": "kubernetes_kubernetes", "title": "SecurityContext privileged not working as expected...", "description": "Is this a request for help? (If yes, you should use our troubleshooting guide and community support channels, see <URL> No What keywords did you search in Kubernetes issues before filing this one? (If you have found any duplicates, you should instead reply there.): Docker privileged securitycontext Is this a BUG REPORT or FEATURE REQUEST? (choose one): BUG REPORT Kubernetes version (use kubectl version): 1.4.1 Environment: Linux m15 4.4.24-hypriotos-v7+ #1 SMP PREEMPT Tue Oct 11 17:15:58 UTC 2016 armv7l GNU/Linux What happened: I have a Docker image that accesses /sys/devices. When I run the container by hand on that box using the following cmd, the application works as expected. docker run -it --privileged  fred However is I set up the same image under kubernetes using the following yaml, the application fail on the very same box. kind:       Deployment\napiVersion: extensions/v1beta1\nmetadata:\nname: fred\nspec:\nreplicas: 1\ntemplate:\nspec:\ncontainers:\n- name:  fred\nsecurityContext:\nprivileged: true\nimage: fred What you expected to happen: Setting the podSecurityContext privilege option works as if I ran the container with docker directly. Perhaps I am missing the intent here, but I was expecting this to work and if not what else do I need to specify to allow the container to access system level resources on the host machine.  I have tried setting the runAsUser to root but to no avail. How to reproduce it (as minimally and precisely as possible): Sadly not short way to repro + using private docker image Anything else do we need to know: I need to tell kubernetes that this container needs to run with the docker --privileged argument. How does one achieve this behavior. ", "code": [], "labels": ["area/kubectl", "team/cluster", "lifecycle/rotten", "sig/node", "kind/bug"]}
{"project": "hapijs_hapi", "title": "Add UTF8 support for string regex validation", "description": "Currently the pattern must be an instance of RegExp and cannot validate UTF8 string.  It would be useful integrate library like XRegExp. ", "code": [], "labels": ["feature"]}
{"project": "CleverRaven_Cataclysm-DDA", "title": "Mannwurst cannot be cooked from frozen components", "description": "Unlike bratwurst that is non-human counterpart of the recipe. 2019.07.06.zip 0.D-5362-ga8d0753359-dirty ", "code": [], "labels": ["Crafting / Construction / Recipes", "<Bug>"]}
{"project": "NodeBB_NodeBB", "title": "send notification when someone follows you", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement"]}
{"project": "codecombat_codecombat", "title": "CoffeeScript has a snippet that inserts a Python try/except", "description": "That doesn't make any sense. ", "code": [], "labels": ["bug"]}
{"project": "keepassxreboot_keepassxc", "title": "Add the function \"Number of records in the database\"", "description": "I used all the settings and did not find the number of passwords in the database.\nI can not understand which database is newer, in which more passwords are written, in which there are fewer ", "code": [], "labels": ["duplicate"]}
{"project": "Graylog2_graylog2-server", "title": "Web UI: Make contents of imported content packs inspectable", "description": "Expanding on graylog-labs/graylog2-web-interface#1396. As of 1.3, there is no way to inspect the contents of an imported content pack other than looking at its title/description/source code which makes managing them unnecessary tedious. I suggest to display a tree representation or similar of all contained inputs, outputs, streams, etc. ", "code": [], "labels": ["feature", "triaged", "web"]}
{"project": "ytdl-org_youtube-dl", "title": "ITV BTCC videos support?", "description": "Add the -v flag to your command line you run youtube-dl with (youtube-dl -v <your command line>), copy the whole output and insert it here. It should look similar to one below (replace it with your log inserted between triple ```): <CODE> ITV separated the BTCC race videos from the hub (which also seems to be having issues as per #15925)\nLately the video are hosted at <URL> (ie for a particular weekend all videos are posted at individual pages like: <URL> Skimming the source code of this sample weekend page, I extracted the vid params and built a test page: Question 1: is the log error above pointing just to a geo restriction error or is there anything else involved that I missed? (ie: like writing some header to force the ITV scrapper to act instead of a generic one) <CODE> Question 2: is there any way to generate a playlist of downloadable items based on pages like <URL> with youtube-dl? ", "code": ["$ youtube-dl -v https://pastebin.com/raw/KxD6rhpF --geo-bypass-country UK\n[debug] System config: []\n[debug] User config: []\n[debug] Custom config: []\n[debug] Command-line args: [u'-v', u'https://pastebin.com/raw/KxD6rhpF', u'--geo-bypass-country', u'UK']\n[debug] Encodings: locale UTF-8, fs UTF-8, out UTF-8, pref UTF-8\n[debug] youtube-dl version 2018.04.09\n[debug] Python version 2.7.13 (CPython) - Linux-4.9.62-v7+-armv7l-with-debian-9.4\n[debug] exe versions: ffmpeg 3.2.10-1, ffprobe 3.2.10-1\n[debug] Proxy map: {}\n[debug] Using fake IP None (UK) as X-Forwarded-For.\n[generic] KxD6rhpF: Requesting header\nWARNING: Falling back on generic information extractor.\n[generic] KxD6rhpF: Downloading webpage\n[generic] KxD6rhpF: Extracting information\n[download] Downloading playlist: Brightcove video tester\n[generic] playlist Brightcove video tester: Collected 1 video ids (downloading 1 of them)\n[download] Downloading video 1 of 1\n[debug] Using fake IP None (UK) as X-Forwarded-For.\n[debug] Using fake IP None (UK) as X-Forwarded-For.\n[brightcove:new] 5766870719001: Downloading webpage\n[brightcove:new] 5766870719001: Downloading JSON metadata\nERROR: Access to this resource is forbidden by access policy.\nYou might want to use a VPN or a proxy server (with --proxy) to workaround.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/brightcove.py\", line 706, in _real_extract\n    json_data = self._download_json(api_url, video_id, headers=headers)\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/common.py\", line 692, in _download_json\n    encoding=encoding, data=data, headers=headers, query=query)\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/common.py\", line 634, in _download_webpage\n    res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal, encoding=encoding, data=data, headers=headers, query=query)\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/adobepass.py\", line 1332, in _download_webpage_handle\n    *args, **compat_kwargs(kwargs))\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/common.py\", line 539, in _download_webpage_handle\n    urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal, data=data, headers=headers, query=query)\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/common.py\", line 528, in _request_webpage\n    raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)\nExtractorError: Unable to download JSON metadata: HTTP Error 403: Forbidden (caused by HTTPError()); please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/YoutubeDL.py\", line 789, in extract_info\n    ie_result = ie.extract(url)\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/common.py\", line 440, in extract\n    ie_result = self._real_extract(url)\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/brightcove.py\", line 712, in _real_extract\n    self.raise_geo_restricted(msg=message)\n  File \"/usr/local/lib/python2.7/dist-packages/youtube_dl/extractor/common.py\", line 743, in raise_geo_restricted\n    raise GeoRestrictedError(msg, countries=countries)\nGeoRestrictedError: Access to this resource is forbidden by access policy.\n", "<!doctype html>\n<html> \n<head>\n    <meta charset=\"UTF-8\">\n    <title>Brightcove video tester</title>\n   <style>\n    .video-js {\n      height: 360px;\n      width: 640px;\n    }\n    .video-js.vjs-mouse .vjs-big-play-button {\n      background-color: red;\n      opacity: .3;\n    }\n   </style>\n   <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js\"></script>\n</head>\n\n<body>\n\t<video data-id=\"id3809566268703\" data-video-id=\"5766870719001\" data-account=\"1582188683001\" data-player=\"HkiHLnNRx\" data-embed=\"default\" data-application-id=\"\" data-fc-id=\"87459\" class=\"video-js\" controls=\"\">\n\t</video>\n\n\t<script src=\"https://players.brightcove.net/1582188683001/HkiHLnNRx_default/index.min.js\">\n\t</script>\n</body>\n</html>\n"], "labels": ["fixed"]}
{"project": "golemfactory_golem", "title": "Some CLI commands fail", "description": "Due to recent changes not all commands work properly. Identify and fix the failing commands. ", "code": [], "labels": ["user interface", "bug"]}
{"project": "aio-libs_aiohttp", "title": "Redirects for HEAD requests should use HEAD", "description": "I'm trying to do a HEAD request to a service that returns a 303 redirect. aiohttp then does a full GET on the new location. aiohttp should instead do a HEAD on the new URL. aiohttp does a GET on the new URL The code responsible is here: <URL>\nThis references this PR from the requests library: <URL> However, the requests library is preserving the HEAD method for subsequent requests. ", "code": [], "labels": ["outdated", "bug", "client"]}
{"project": "postmanlabs_postman-app-support", "title": "Body content for GET request still set in pre-request script request.data", "description": "If a request has content set in the body and the method is changed to GET, the body tab is no longer active or available to be selected.  However, in a pre-request script the content from the body tab is still available in request.data. Given that the body tab is disabled my expectation would be that there is no body content at all. Version Info Steps to reproduce the problem ", "code": [], "labels": ["bug"]}
{"project": "dotnet_docs", "title": "My Malware Bytes doesn't like this", "description": "Tried to run this project (at the first point in the tutorial where it said to run the project,  so I hadn't done very many changes) , and VS gave me this error: Error while trying to run project: Unable to start program 'C:\\Users\\Developer\\source\\repos\\ExpenseIT\\ExpenseIT\\bin\\Debug\\ExpenseIT.exe'.\nThe request is not supported. If it matters, I'm using VS 2017, not 2019,  Community version. And my Malware Bytes gave me this report: Malwarebytes\nwww.malwarebytes.com -Log Details-\n...... -Software Information-\nVersion: 3.8.3.2965\nComponents Version: 1.0.627\nUpdate Package Version: 1.0.12673\nLicense: Premium -System Information-\nOS: Windows 10 (Build 17134.706)\nCPU: x64\nFile System: NTFS\nUser: System\n-Blocked Malware Details-\nFile: 1\nMachineLearning/Anomalous.95%, C:\\Users\\Developer\\source\\repos\\ExpenseIT\\ExpenseIT\\bin\\Debug\\ExpenseIT.exe, Quarantined,\n..... Is anyone else having this simple WPF blocked by Malware Bytes as a Machine Learning Anomalous.95 error? ", "code": [], "labels": ["resolved-by-customer"]}
{"project": "ctfs_write-ups-2016", "title": "IceCTF 2016 Dear diary team ISITDTU", "description": "<URL>\n[click on title to read at ctftime.org] ", "code": [], "labels": ["link"]}
{"project": "wix_react-native-navigation", "title": "[V2][iOS] leftButtons or rightButtons properties crash the app when added to topBar", "description": "I'm using an example from migration docs to apply colors to topBar buttons <URL> <CODE> When this is added the app crashes. In the console I see the next error: <CODE> Please see above ", "code": ["Navigation.setDefaultOptions( {\ntopBar: {\n  rightButtons: [\n    {\n      color: 'red'\n    }\n  ],\n  leftButtons: [\n    {\n      color: 'red'\n    }\n  ],\n  backButton: {\n    color: 'red'\n  }\n}\n})\n", "Aug 21 15:21:41 users-MacBook-Pro MyApp[39778]: *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '*** -[__NSCFConstantString stringByAppendingString:]: nil argument'\n\t*** First throw call stack:\n\t(\n\t\t0   CoreFoundation                      0x0000000104a2bd85 __exceptionPreprocess + 165\n\t\t1   libobjc.A.dylib                     0x00000001037ecdeb objc_exception_throw + 48\n\t\t2   CoreFoundation                      0x0000000104a2bcbd +[NSException raise:format:] + 205\n\t\t3   Foundation                          0x000000010339902a -[NSString stringByAppendingString:] + 96\n\t\t4   MyApp                            0x0000000102a1d834 -[RNNNavigationButtons buildButton:defaultStyle:] + 372\n\t\t5   MyApp                            0x0000000102a1d231 -[RNNNavigationButtons setButtons:side:animated:defaultStyle:] + 545\n\t\t6   MyApp                            0x0000000102a1cf8c -[RNNNavigationButtons applyLeftButtons:rightButtons:defaultLeftButtonStyle:defaultRightButtonStyle:] + 252\n\t\t7   MyApp                            0x00000001029c31c5 -[RNNTopBarOptions applyOn:] + 7637\n\t\t8   MyApp                            0x00000001029dbe0d -[RNNNavigationOptions applyOn:] + 125\n\t\t9   MyApp                            0x00000001029b3c9a -[RNNRootViewController viewWillAppear:] + 122\n\t\t10  UIKit                               0x00000001066812bd -[UIViewController _setViewAppearState:isAnimating:] + 710\n\t\t11  UIKit                               0x0000000106681958 -[UIViewController __viewWillAppear:] + 149\n\t\t12  UIKit                               0x00000001066c0c83 -[UINavigationController _startTransition:fromViewController:toViewController:] + 781\n\t\t13  UIKit                               0x00000001066c1c4d -[UINavigationController _startDeferredTransitionIfNeeded:] + 890\n\t\t14  UIKit                               0x00000001066c2d0b -[UINavigationController __viewWillLayoutSubviews] + 57\n\t\t15  UIKit                               0x0000000106871503 -[UILayoutContainerView layoutSubviews] + 248\n\t\t16  UIKit                               0x000000010659b980 -[UIView(CALayerDelegate) layoutSublayersOfLayer:] + 703\n\t\t17  QuartzCore                          0x0000000106252c00 -[CALayer layoutSublayers] + 146\n\t\t18  QuartzCore                          0x000000010624708e _ZN2CA5Layer16layout_if_neededEPNS_11TransactionE + 366\n\t\t19  QuartzCore                          0x0000000106246f0c _ZN2CA5Layer28layout_and_display_if_neededEPNS_11TransactionE + 24\n\t\t20  QuartzCore                          0x000000010623b3c9 _ZN2CA7Context18commit_transactionEPNS_11TransactionE + 277\n\t\t21  QuartzCore                          0x0000000106269086 _ZN2CA11Transaction6commitEv + 486\n\t\t22  QuartzCore                          0x00000001062697f8 _ZN2CA11Transaction17observer_callbackEP19__CFRunLoopObservermPv + 92\n\t\t23  CoreFoundation                      0x0000000104950c37 __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__ + 23\n\t\t24  CoreFoundation                      0x0000000104950ba7 __CFRunLoopDoObservers + 391\n\t\t25  CoreFoundation                      0x00000001049467fb __CFRunLoopRun + 1147\n\t\t26  CoreFoundation                      0x00000001049460f8 CFRunLoopRunSpecific + 488\n\t\t27  GraphicsServices                    0x000000010963bad2 GSEventRunModal + 161\n\t\t28  UIKit                               0x00000001064e0f09 UIApplicationMain + 171\n\t\t29  MyApp                            0x00000001029acdbf main + 111\n\t\t30  libdyld.dylib                       0x0000000107b6992d start + 1\n"], "labels": [" stale"]}
{"project": "odoo_odoo", "title": "Changing a user-defined standard value with umlauts results in an error message", "description": "Changing or creating user-defined standard value with umlauts results in an error message. (copied issues from launchpad <URL> ) Impacted Versions: please confirm it and give high priority as its blocking points. Server Traceback (most recent call last):\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/addons/web/session.py\", line 89, in send\nreturn openerp.netsvc.dispatch_rpc(service_name, method, args)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/netsvc.py\", line 296, in dispatch_rpc\nresult = ExportService.getService(service_name).dispatch(method, params)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/service/web_services.py\", line 626, in dispatch\nres = fn(db, uid, _params)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/osv/osv.py\", line 190, in execute_kw\nreturn self.execute(db, uid, obj, method, *args, *_kw or {})\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/osv/osv.py\", line 132, in wrapper\nreturn f(self, dbname, _args, *_kwargs)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/osv/osv.py\", line 199, in execute\nres = self.execute_cr(cr, uid, obj, method, _args, *_kw)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/addons/audittrail/audittrail.py\", line 524, in execute_cr\nreturn fct_src(cr, uid, model, method, _args, *_kw)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/osv/osv.py\", line 187, in execute_cr\nreturn getattr(object, method)(cr, uid, _args, *_kw)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/osv/orm.py\", line 4546, in create\nresult += self._columns[field].set(cr, self, id_new, field, vals[field], user, rel_context) or []\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/osv/fields.py\", line 1159, in set\nself._fnct_inv(obj, cr, user, id, name, value, self._fnct_inv_arg, context)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/addons/base/ir/ir_values.py\", line 125, in _value_pickle\nself.write(cursor, user, id, {name[:-9]: value}, context=ctx)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/osv/orm.py\", line 4226, in write\n'where id IN %s', upd1 + [sub_ids])\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/sql_db.py\", line 161, in wrapper\nreturn f(self, _args, *_kwargs)\nFile \"/home/odoo/runbot/static/openerp-dev-7-0-30742/server/openerp/sql_db.py\", line 226, in execute\nres = self._obj.execute(query, params)\nDataError: invalid byte sequence for encoding \"UTF8\": 0xc1 0x0a ", "code": [], "labels": ["Framework"]}
{"project": "OnsenUI_OnsenUI", "title": "ons-pull-hook is showed after popPage()", "description": "Environment  <CODE> Encountered problem The contents in <ons-pull-hook> is showed after popping a page since 2.5.0. How to reproduce <URL> ", "code": ["[Core]\n    onsenui 2.5.0\n\n[Framework]\n    angular1 1.6.5\n\n[Framework binding]\n    angular-onsenui 2.5.0\n\n[Additional libraries]\n    none\n\n[Platform]\n    Desktop - macOS Sierra\n\n[Browser]\n    Desktop - Chrome 59.0.3071.115\n"], "labels": ["outdated"]}
{"project": "golang_go", "title": "net: flaky TestReloadResolvConfFail", "description": "<CODE> ", "code": ["it sometimes fails on darwin:\n\n-- FAIL: TestReloadResolvConfFail (1.21s)\n    dnsclient_unix_test.go:182: goLookupIP(missing; good) failed: stat /var/folders/7d/d3y9vsls2yd880k121jmzcyr0000gn/T/resolvConfTest018927742/resolv.conf: no such file or directory\nFAIL"], "labels": ["FrozenDueToAge", "Testing"]}
{"project": "xamarin_xamarin-macios", "title": "[XM]SceneKitViewer failed to build with native linking failure with xcode10", "description": "App builds successfully App fails to build with a native linking failure. There is a fatal error that cmath file cannot be found in Xcode10. This was working with Xcode9.x. <URL> Build Log: <URL> mac-samples/ScenekitViewer ", "code": [], "labels": ["macOS", "bug"]}
{"project": "wechaty_wechaty", "title": "can't upload video over 1 MB", "description": "localhost:wechaty-getting-started samhoo$ npm run doctor\nnpm ERR! Darwin 16.7.0\nnpm ERR! argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"run\" \"doctor\"\nnpm ERR! node v6.11.5\nnpm ERR! npm  v3.10.10 npm ERR! missing script: doctor\nnpm ERR!\nnpm ERR! If you need help, you may report this error at:\nnpm ERR!     <URL> npm ERR! Please include the following file with any support request:\nnpm ERR!     /Users/heido/highlightmoment/chatd/docker/wechaty-getting-started/npm-debug.log When trying to send video file by modifying mybot.js,  I get an \"socket hang up\" error  if  file size over 1MB.  And everything would be ok if size of file is less than 1MB According wechat protocol, it should be split to chunks to post, when uploading a large file. here is code snippet(modified from mybot.js):\n.....\nif (/hello/.test(content)) {\nm.say(\"hello how are you\")\nm.say(new MediaMessage('chunks.mp4'))\n}\n..... localhost:wechaty-getting-started xxx$ ls -l chunks.mp4\n-rw-r--r--@ 1 samhoo  admin  1506366 10 29 11:20 chunks.mp4 1.start bot : node mybot.js\n2.send message to bot: hello\n3.bot echo message: hello how are you.  & send a video ", "code": [], "labels": ["duplicate"]}
{"project": "kubernetes_kubernetes", "title": "Issues after moving PR e2e jobs under source control", "description": "\nNo description provided.\n ", "code": [], "labels": ["priority/backlog", "area/test-infra"]}
{"project": "syncthing_syncthing-android", "title": "config data erased after adding repo", "description": "Trying todays version (0.3.3)... After creating a repository and save the information, the built-in webserver does not respond anymore. Trying to restart the app results in \"Waiting for Gui\" - which does not appear - and finally \"Syncthing does not respond\". After rebooting the phone Syncthing is generating new keys. Perhaps the config file is not closed properly? ", "code": [], "labels": ["duplicate", "frozen-due-to-age"]}
{"project": "spring-projects_spring-framework", "title": "no dependencyManagement in spring-framework-bom [SPR-15890]", "description": "Micha\u0142 Sobkiewicz opened SPR-15890 and commented There is no <dependencyManagement> section in spring-framework-bom.pom in recent builds*. Please, compare\n<URL>\nwith\n<URL> *) 2eeb428#diff-db75b55a99552a4638e4bdfe275c4a5e maybe? Affects: 5.0 RC4 Issue Links: ", "code": [], "labels": ["type: bug"]}
{"project": "weaveworks_weave", "title": "support IPv6", "description": "Weave currently only works over IPv4. Main areas that need attention in order to support IPv6 are ", "code": [], "labels": ["feature"]}
{"project": "xitu_gold-miner", "title": "\u7533\u8bf7\u6210\u4e3a\u8bd1\u8005", "description": "", "code": [], "labels": ["\u7533\u8bf7\u8bd1\u8005"]}
{"project": "bumptech_glide", "title": "Wrong package of ProGuard ImageHeaderParser config", "description": "TL;DR\nJust change in proguard: <CODE> to <CODE> Glide Version: 4.6.1\nDevice/Android Version: Sony Xperia X Compact / Android 7.1.1\nIssue details / Repro steps / Use case background:\nWhen try to build app with enabled proguard I received errors when try open Activity with ImageView with Glide loaded image. Stack trace: <CODE> <CODE> How to fix it:\nIn proguard just change <CODE> to <CODE> ", "code": ["-keep public enum com.bumptech.glide.load.resource.bitmap.ImageHeaderParser$** {\n", "-keep public enum com.bumptech.glide.load.ImageHeaderParser$** {\n", "Fatal Exception: java.lang.AssertionError: impossible\n       at java.lang.Enum$1.create(Enum.java:269)\n       at java.lang.Enum$1.create(Enum.java:260)\n       at libcore.util.BasicLruCache.get(BasicLruCache.java:58)\n       at java.lang.Enum.getSharedConstants(Enum.java:286)\n       at java.lang.Class.getEnumConstantsShared(Class.java:2291)\n       at java.lang.JavaLangAccess.getEnumConstantsShared(JavaLangAccess.java:40)\n       at java.util.EnumSet.getUniverse(EnumSet.java:389)\n       at java.util.EnumSet.noneOf(EnumSet.java:107)\n       at java.util.EnumSet.of(EnumSet.java:245)\n       at com.bumptech.glide.load.resource.bitmap.Downsampler.(Downsampler.java:116)\n       at com.bumptech.glide.Glide.(Glide.java:328)\n       at com.bumptech.glide.GlideBuilder.build(GlideBuilder.java:472)\n       at com.bumptech.glide.Glide.initializeGlide(Glide.java:264)\n       at com.bumptech.glide.Glide.initializeGlide(Glide.java:1219)\n       at com.bumptech.glide.Glide.getRetriever(Glide.java:670)\n       at com.bumptech.glide.Glide.with(Glide.java:722)\n       at pl.solutionslab.tikrow.data.network.GlideApp.with(GlideApp.java:104)\n       at pl.solutionslab.tikrow.view.offer.details.OfferActivity.displayHeaderImg(OfferActivity.kt:169)\n       at pl.solutionslab.tikrow.view.offer.details.OfferActivity.onCreate(OfferActivity.kt:123)\n       at android.app.Activity.performCreate(Activity.java:6720)\n       at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1119)\n       at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2673)\n       at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2781)\n       at android.app.ActivityThread.-wrap12(ActivityThread.java)\n       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1508)\n       at android.os.Handler.dispatchMessage(Handler.java:102)\n       at android.os.Looper.loop(Looper.java:241)\n       at android.app.ActivityThread.main(ActivityThread.java:6274)\n       at java.lang.reflect.Method.invoke(Method.java)\n       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:886)\n       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:776)\n", "Caused by java.lang.NoSuchMethodException: values []\n       at java.lang.Class.getMethod(Class.java:1981)\n       at java.lang.Class.getDeclaredMethod(Class.java:1960)\n       at java.lang.Enum$1.create(Enum.java:265)\n       at java.lang.Enum$1.create(Enum.java:260)\n       at libcore.util.BasicLruCache.get(BasicLruCache.java:58)\n       at java.lang.Enum.getSharedConstants(Enum.java:286)\n       at java.lang.Class.getEnumConstantsShared(Class.java:2291)\n       at java.lang.JavaLangAccess.getEnumConstantsShared(JavaLangAccess.java:40)\n       at java.util.EnumSet.getUniverse(EnumSet.java:389)\n       at java.util.EnumSet.noneOf(EnumSet.java:107)\n       at java.util.EnumSet.of(EnumSet.java:245)\n       at com.bumptech.glide.load.resource.bitmap.Downsampler.(Downsampler.java:116)\n       at com.bumptech.glide.Glide.(Glide.java:328)\n       at com.bumptech.glide.GlideBuilder.build(GlideBuilder.java:472)\n       at com.bumptech.glide.Glide.initializeGlide(Glide.java:264)\n       at com.bumptech.glide.Glide.initializeGlide(Glide.java:1219)\n       at com.bumptech.glide.Glide.getRetriever(Glide.java:670)\n       at com.bumptech.glide.Glide.with(Glide.java:722)\n       at pl.solutionslab.tikrow.data.network.GlideApp.with(GlideApp.java:104)\n       at pl.solutionslab.tikrow.view.offer.details.OfferActivity.displayHeaderImg(OfferActivity.kt:169)\n       at pl.solutionslab.tikrow.view.offer.details.OfferActivity.onCreate(OfferActivity.kt:123)\n       at android.app.Activity.performCreate(Activity.java:6720)\n       at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1119)\n       at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2673)\n       at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2781)\n       at android.app.ActivityThread.-wrap12(ActivityThread.java)\n       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1508)\n       at android.os.Handler.dispatchMessage(Handler.java:102)\n       at android.os.Looper.loop(Looper.java:241)\n       at android.app.ActivityThread.main(ActivityThread.java:6274)\n       at java.lang.reflect.Method.invoke(Method.java)\n       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:886)\n       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:776)\n", "-keep public enum com.bumptech.glide.load.resource.bitmap.ImageHeaderParser$** {\n", "-keep public enum com.bumptech.glide.load.ImageHeaderParser$** {\n"], "labels": ["documentation", "bug"]}
{"project": "jOOQ_jOOQ", "title": "Bad Javadoc on DeleteResultStep", "description": "Copy pasted from UpdateResultStep... ", "code": [], "labels": ["R: Fixed", "C: Documentation", "T: Defect", "P: Low"]}
{"project": "redux-form_redux-form", "title": "Submit two forms in order", "description": "I have two forms that I validate from a parent container, each form is posting data in an API onSubmit. I need them to be posted in order. I would like to be able to do something like that: Any other way I could do the same?\nThanks. ", "code": [], "labels": ["question"]}
{"project": "rubygems_bundler", "title": "Deadlock error", "description": "Please fill out answers to these questions, it'll help us figure out\nwhy things are going wrong. Not yet. <CODE> <CODE> <CODE> ", "code": ["fatal: No live threads left. Deadlock?\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/worker.rb:43:in `pop'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/worker.rb:43:in `deq'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/installer/parallel_installer.rb:131:in `process_specs'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/installer/parallel_installer.rb:102:in `call'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/installer/parallel_installer.rb:77:in `call'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/installer.rb:199:in `install_in_parallel'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/installer.rb:166:in `install'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/installer.rb:80:in `run'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/installer.rb:24:in `install'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/cli/install.rb:70:in `run'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/cli.rb:181:in `block in install'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/settings.rb:99:in `temporary'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/cli.rb:180:in `install'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/vendor/thor/lib/thor/invocation.rb:126:in `invoke_command'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/vendor/thor/lib/thor.rb:359:in `dispatch'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/cli.rb:20:in `dispatch'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/vendor/thor/lib/thor/base.rb:440:in `start'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/cli.rb:11:in `start'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/exe/bundle:32:in `block in <top (required)>'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/lib/bundler/friendly_errors.rb:121:in `with_friendly_errors'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/gems/bundler-1.14.6/exe/bundle:24:in `<top (required)>'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/bin/bundle:22:in `load'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/bin/bundle:22:in `<main>'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/bin/ruby_executable_hooks:15:in `eval'\n  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1/bin/ruby_executable_hooks:15:in `<main>'\n", "Bundler   1.14.6\nRubygems  2.6.11\nRuby      2.3.1p112 (2016-04-26 revision 54768) [x86_64-darwin16]\nGEM_HOME  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1\nGEM_PATH  /Users/ashleyschauer/.rvm/gems/ruby-2.3.1:/Users/ashleyschauer/.rvm/gems/ruby-2.3.1@global\nRVM       1.29.1 (latest)\nGit       2.10.2\nPlatform  x86_64-darwin-16\nOpenSSL   OpenSSL 1.0.2j  26 Sep 2016\nrubygems-bundler (1.4.4)\n", ""], "labels": ["type: bug report"]}
{"project": "ampache_ampache", "title": "username flagged as too long after upgrading to ubuntu 16.04", "description": "Describe your settings or attach ampache.cfg.php after removing sensitive information (server host, database connection...)\nampache.cfg.php.txt With previously working long usernames I now get 'username' too long errors. I had a working ampache server running on Ubuntu 15.10 with user names like 'rick.sorensen@gmail.com', and then I upgraded to Ubuntu 16.04.  At that point, I had to make some modifications to the Php 7.0 install for php libraries before the login screen showed up.  After the login screen was appearing, on the first login attempt with login 'rick.sorensen@gmail.com' I saw nothing happen (no messages on the screen.)  I then tried to login as 'admin' which worked. I then turned on debug and retried- saw the 'username' too long error message.  I did a few experiments (see log file) with creating usernames 40, 30, 20, and 10 characters- and only usernames with length <20 (<16?) worked.  Again- no notification of error on the browser login window. Note that as admin I could create all these username (long names, long names with spaces, long names with '@', ....) and enter them in the database.  Database queries return the entered usernames.\nNote also that if I enter a long username with an incorrect password I do get an invalid login message. I suspect this is related to php 7. I tried searching the code but did not find a length check in the code (find . -name '*.php' -exec grep username {}; | grep 'too long')(I also tried searching for debug and error, and *.inc files, but don't know php very well) [Ampache logs](annotated by me- with #comments) ampache.20160427.log.annotate.txt ", "code": [], "labels": ["bug"]}
{"project": "jupyterlab_jupyterlab", "title": "Where to put type declaration file for JSX", "description": "I am working on the input/output collapsing and trying to use basic txs syntax in a few places. I have it working, but can't figure out where to put the d.ts file with the JSX type information. The code looks something like this: I have been successful in putting this code in two places: I have tried a million ways to put that in a separate d.ts file but it won't work. I put it into typings/jsx/jsx.d.ts and added a /// reference in the src/typings file, but that won't pick it up. I need to use this file in multiple jlab packages, so having a quick and reusable way to handle it is desirable. I know there are broader issues around TSX and vdom stuff, but I don't want to solve them now, I just want to start using basic TSX syntax in a few places. ", "code": [], "labels": ["status:resolved-locked"]}
{"project": "eslint_eslint", "title": "ESLint cannot find errors connected with react prop-types when using mobX decorators with stateless components", "description": "Tell us about your environment What parser (default, Babel-ESLint, etc.) are you using? Please show your full configuration: What did you do? Please include the actual source code causing the issue, as well as the command that you used to run ESLint. What did you expect to happen? - That componentId is missing in props validation What actually happened? Please include the actual, raw output from ESLint. Nothing happens. \u0421ode passes verification successfully <CODE> Are you willing to submit a pull request to fix this bug? - No ", "code": ["yarn run v1.12.3\n$ eslint **/*.js\n\n<rootFolder>\\src\\modules\\Main\\UserInfo\\Form\\index.js\n  10:28  warning  Unexpected console statement  no-console\n\n\u2716 1 problem (0 errors, 1 warning)\n\nDone in 9.38s.\n"], "labels": ["needs info", "triage", "bug", "archived due to age"]}
{"project": "matomo-org_matomo", "title": "3 problems - SEO - quickedit - link", "description": "Hello ! Thanks for Piwik ! you guys rock ! We have an issue with piwik though... I had to de activate it because every time I activate it my Yoast SEO plugin does not work, nothing happens when I click quickedit and nothing happens when I try to add a link. This is all inside wordpress by the way. Cheers Raul ", "code": [], "labels": ["answered"]}
{"project": "smartstore_SmartStoreNET", "title": "MegaSearch does not search manufacturer part number of attribute combinations", "description": "\nNo description provided.\n ", "code": [], "labels": ["review"]}
{"project": "Alamofire_Alamofire", "title": "Send digest authentication. Need help!", "description": "Hi, i am trying to send authen:\ncurl -L --location-trusted -k --anyauth --user ABC:XYZ <URL> -X POST -d '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?><auth><id><corp>31856</corp><user>601</user></id></auth>' --verbose I tried this but no luck:\nvar xmlRequest = URLRequest(url: requestUrl)\n xmlRequest.httpBody = xmlParams.data(using: String.Encoding.utf8, allowLossyConversion: true)\nxmlRequest.httpMethod = method.rawValue\nxmlRequest.addValue(\"application/xml\", forHTTPHeaderField: \"Content-Type\")\nmanager.request(xmlRequest)\n .authenticate(user: user, password: password)\n .responseData { (response) in\n Logger.debug(message: response)\n } Pls help me call it by Alamofire. Thanks! ", "code": [], "labels": ["support"]}
{"project": "Andersbakken_rtags", "title": "Assertion triggered in EmbeddedLinkedList", "description": "Found a possible assert violation in EmbeddedLinkedList. Sorry I'm not sure how to reproduce this issue right now, but will update when possible. <CODE> ", "code": ["rdm: /home/user1/.builds/rtags/src/rct/rct/EmbeddedLinkedList.h:60: void EmbeddedLinkedList<T>::remove(const T&) [with T = CompletionThread::SourceFile*]: Assertion `mCount == 1' failed.\n"], "labels": ["bug"]}
{"project": "jessesquires_JSQMessagesViewController", "title": "Hide Keyboard", "description": "Hi, I've seen a couple issues with the following problem - however, I am not sure how to fix this for projects iOS 7+. Do you have any ideas / know how to do this? Thanks! ", "code": [], "labels": ["questions & help"]}
{"project": "WP-API_WP-API", "title": "Wp Api - Menu plugin error", "description": "I'm trying to retrieve data from my menus, but when I install the plugin that is on the docs of Wp API for this, it's give an error in line 183. Exists another way to get data from Wp menus? ", "code": [], "labels": ["Support"]}
{"project": "openhab_openhab1-addons", "title": "Initial version of an X10 binding via Mochad X10", "description": "Hi, I've been working on a binding to control my Marmitek CM15Pro X10 controller. The binding makes use of the open source mochad x10 daemon (<URL> which actually controls the CM15Pro. I'm currently testing it and it works for Switch, Dimmer, and Rollershutter items. As it is now, it's a passive binding so it only sends commands to the CM15Pro and does not react to messages from CM15Pro. I'm not really familar with Github, but is there some short document explaining how to correctly submit new binding code to the repository? What are my next steps to share this binding with the openhab community? Kind regards,\nJack Sleuters ", "code": [], "labels": ["question"]}
{"project": "istio_istio", "title": "Egress: VirtualService with domain name not working.", "description": "Describe the bug\nI have NodeJS client which uploads files to AWS S3. If I enable Istio on the K8S cluster, service is not able to reach sts.amazonaws.com or *.s3.amazonaws.com Config used is as follows: I am getting ECONNRESET whenever the connection request is sent. If I specifically add my AWS Bucket URL <bucker_name_here>.s3.amazonaws.com, then only the connection is established, Expected behavior\nIstio Egress to allow traffic without any error. Steps to reproduce the bug\nConfig shared above Version\n{{ What version of Istio and Kubernetes are you using? Use istioctl version --remote and kubectl version }}\nKubectl : 1.9.3\nIstioctl : 1.0.6 Installation\n{{ Please describe how Istio was installed }}\nIstio installation done through curl request on setup page, followed by CRDs and scaffolding config Environment\n{{ Which environment, cloud vendor, OS, etc are you using? }}\nBaremetal K8S cluster with CentOS nodes Cluster state\n{{ If you're running on Kubernetes, consider following the\ninstructions\nto generate \"istio-dump.tar.gz\", then attach it here by dragging and dropping\nthe file onto this issue. }} ", "code": [], "labels": ["area/networking"]}
{"project": "ytdl-org_youtube-dl", "title": "Downloading from southpark.cc.com fails.", "description": "Add -v flag to your command line you run youtube-dl with, copy the whole output and insert it here. It should look similar to one below (replace it with your log inserted between triple ```): <CODE> Downloading from southpark.cc.com fails. Using OS X 10.12.1, with Python 2.7.12. ", "code": ["sh-3.2$ youtube-dl -v http://southpark.cc.com/full-episodes/s20e10-the-end-of-serialization-as-we-know-it#source=06bb4aa7-9917-4b6a-ae93-5ed7be79556a:879fd28e-c96b-4f9d-a437-e05c1bcf80aa&position=10\n[1] 13081\nsh-3.2$ [debug] System config: []\n[debug] User config: []\n[debug] Command-line args: [u'-v', u'http://southpark.cc.com/full-episodes/s20e10-the-end-of-serialization-as-we-know-it#source=06bb4aa7-9917-4b6a-ae93-5ed7be79556a:879fd28e-c96b-4f9d-a437-e05c1bcf80aa']\n[debug] Encodings: locale UTF-8, fs utf-8, out UTF-8, pref UTF-8\n[debug] youtube-dl version 2016.12.09\n[debug] Python version 2.7.12 - Darwin-16.1.0-x86_64-i386-64bit\n[debug] exe versions: ffmpeg 2.8.4, ffprobe 2.8.4, rtmpdump 2.4\n[debug] Proxy map: {}\n[southpark.cc.com] s20e10-the-end-of-serialization-as-we-know-it: Downloading webpage\n[southpark.cc.com] 2c762ec7-8b59-4628-bd23-416a3dd6136d: Downloading info\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/bin/youtube-dl/__main__.py\", line 19, in <module>\n  File \"/usr/local/bin/youtube-dl/youtube_dl/__init__.py\", line 444, in main\n  File \"/usr/local/bin/youtube-dl/youtube_dl/__init__.py\", line 434, in _real_main\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 1791, in download\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 694, in extract_info\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/common.py\", line 357, in extract\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/mtv.py\", line 232, in _real_extract\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/mtv.py\", line 191, in _get_videos_info\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/mtv.py\", line 196, in _get_videos_info_from_url\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/common.py\", line 540, in _download_xml\n  File \"/usr/local/bin/youtube-dl/youtube_dl/compat.py\", line 2526, in compat_etree_fromstring\n  File \"/usr/local/bin/youtube-dl/youtube_dl/compat.py\", line 2515, in _XML\n  File \"/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py\", line 1653, in feed\n    self._raiseerror(v)\n  File \"/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py\", line 1517, in _raiseerror\n    raise err\nxml.etree.ElementTree.ParseError: mismatched tag: line 128, column 196\n\n[1]+  Done(1)                 youtube-dl -v http://southpark.cc.com/full-episodes/s20e10-the-end-of-serialization-as-we-know-it#source=06bb4aa7-9917-4b6a-ae93-5ed7be79556a:879fd28e-c96b-4f9d-a437-e05c1bcf80aa\nsh-3.2$ \n"], "labels": ["invalid"]}
{"project": "bokeh_bokeh", "title": "Exceptions when updating plots in new example", "description": "I created a pretty cool application with bokeh, which shows functionality that is not yet covered by any existing example. The code is attached to this issue and can freely be used as an official example. In the code custom barplots (not charts) for year, month, daily and named data were created. Tapping on a year will trigger a server side select of a month and refreshes the month plot data. The month plot then at the same time selects a day and refreshes the daily data and so on. You should give it a try it is very cool. Download and unpack bars_example.zip Start the bokeh server (iam using bokeh 0.11.1): <CODE> run the example with: <CODE> Try selecting a year/month/day and see how everything is adapting x_range, y_range, secondary y_range. Also a mechanism was implemented to make it impossible to not have selected any bar. (Try clicking on the white space next to a bar). The example was created with the goal to be able to continuously add more data and have the barplots adapt accordingly live. E.g. adding data from year 2017 will create the bar 2017 and directly show it if it does not exist yet. A secondary mode was created which continuously adds days, which will create new month and even years. If new data was created it is directly selected and displayed. You can execute this mode by: <CODE> The mode works pretty well but if you wait a few minutes the following exception will appear. I tried it on multiple machines .. if you wait long enough the exception always appears. Sometimes no exception appears and cpu usage by bokeh server is 100% and firefox and chrome usage also goes to 100%, while the plots stop updating. The Exception that shows up is: <CODE> And sometimes directly after starting the program: <CODE> ", "code": ["bokeh serve\n", "python bars_example.py\n", "python bars_example.py --follow\n", "ERROR:bokeh.server.protocol.server_handler:error handling message Message 'PATCH-DOC' (revision 1): KeyError('references',)\nDEBUG:bokeh.server.protocol.server_handler:  message header {u'msgid': u'718900fc-f196-4b36-84b9-f1ee7a3654bc', u'msgtype': u'PATCH-DOC'} content {}\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/bokeh/server/protocol/server_handler.py\", line 38, in handle\n    work = yield handler(message, connection)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/gen.py\", line 1008, in run\n    value = future.result()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/concurrent.py\", line 232, in result\n    raise_exc_info(self._exc_info)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/gen.py\", line 1017, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python2.7/dist-packages/bokeh/server/session.py\", line 42, in _needs_document_lock_wrapper\n    result = yield yield_for_all_futures(func(self, *args, **kwargs))\n  File \"/usr/local/lib/python2.7/dist-packages/bokeh/server/session.py\", line 212, in _handle_patch\n    message.apply_to_document(self.document)\n  File \"/usr/local/lib/python2.7/dist-packages/bokeh/server/protocol/messages/patch_doc.py\", line 85, in apply_to_document\n    doc.apply_json_patch(self.content)\n  File \"/usr/local/lib/python2.7/dist-packages/bokeh/document.py\", line 836, in apply_json_patch\n    references_json = patch['references']\nKeyError: 'references'\n", "ERROR:bokeh.server.views.ws:Bokeh Server protocol error: No 'msgtype'\n"], "labels": ["reso: completed", "type: discussion"]}
{"project": "haskell_cabal", "title": "Cabal download page should be behind a CDN", "description": "From email thread with @mietek ", "code": [], "labels": ["website"]}
{"project": "pantsbuild_pants", "title": "Optional pants modules need a way to register pantsbuild source roots for targets they export", "description": "Right now source roots are registered globally (via contrib/BUILD instead of via plugin - which is a secondary issue).  Since they are registered globally, any invocation of pants using the checked-in pants.ini will need to have all contrib plugins loaded that define source roots for the targets they export.  This conflicts with the goals of - for example - the self-publish CI check which tries to verify all plugins are publishable and consumable independently of one another.  Devise and deploy a means to achieve both simple contrib addition and separation for the purposes of certain tests. ", "code": [], "labels": ["bug"]}
{"project": "keeweb_keeweb", "title": "Open file directly by the system application associated file or include PDF reader", "description": "Hi, the problem start when often I must open PDF file from keeweb. Every time I must do Shift + click, save in somewhere folder, open that folder, open the file and then delete it.\nThere are two option to speed up these steps: Which is the best option?\nApp version 1.3.3 Thanks a lot,\nCheers ", "code": [], "labels": ["ux", "enhancement"]}
{"project": "ornicar_lila", "title": "Activity log privacy", "description": "Minimum: Users should be able to delete or hide entries in their activity log.\nMaximum: Users should be able to control the visibility of the activity log. Show activity to everyone, or only to friends. Could be configurable per event type, e.g. show games to everyone, show follows only to friends, show tactics to no one. In my case I followed someone by mistake, and quickly unfollowed. I do not want them to know about my account. However currently, both my activity log and their activity log show that I followed them. ", "code": [], "labels": ["stale"]}
{"project": "vuematerial_vue-material", "title": "Cannot read property 'indexOf' of undefined - md-select", "description": "Hello,\nI have the following error when I use select with property \"multiple\" and the md-option with v-for.\n\u201cCannot read property 'indexOf' of undefined \u201c\nMy component is as follows:\n<URL>\nAnd I'm calling this way: <template>\n <div>\n<dsg-select dsgpLabel=\"teste\" :dsgpItens=\"dsgpItens\"\n:dsgpVmodel=\"dsgpItens\" :dsgpMultiplo=\"true\" :dsgpChange=\"teste()\">\n</dsg-select>\n</div>\n</template>\n<script>\nimport dsgSelect from './dsgSelect.vue'\nexport default {\nname: 'hello',\ndata () {\nreturn {\ndsgpItens:[\n{'id':'1', 'texto':'teste1'},\n{'id':'2', 'texto':'teste2'},\n{'id':'3', 'texto':'teste3'},\n{'id':'4', 'texto':'teste4'},\n]\n}\n},\ncomponents:{\ndsgSelect\n},\n}\n}\n</script> ", "code": [], "labels": ["needs repro"]}
{"project": "Tencent_wepy", "title": "wepy build \u628a\u4e0d\u76f8\u5173\u7684\u5e93\u4e5f\u6253\u5305\u8fdb\u53bb\u4e86", "description": "\u5728\u914d\u7f6eredux\u7684\u65f6\u5019 \uff0c\u4f7f\u7528\u4e86redux-logger\uff0c\u7ed3\u679c\u6253\u5305\u7684\u65f6\u5019\u4e5f\u8f93\u51fa\u5230\u4e86dist\u6587\u4ef6\u5939 [Description of the issue] <CODE> wepy build\u7684\u65f6\u5019 \uff0c\u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u5c31\u7b97\u6ce8\u91ca\u6389\uff0c\u90fd\u4f1a\u6253\u5305\u5230dist/npm/ \u4e0b\u9762\uff0c\u53ea\u6709\u5220\u6389\u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\uff0c\u6253\u5305\u540e\u624d\u4e0d\u4f1a\u51fa\u73b0\u5728dist/npm \u4e0b\u9762 \u5e0c\u671b\u53ef\u4ee5\u6839\u636eNODE_ENV\u5224\u65ad\u662f\u5426\u6253\u5305\uff0c\u6216\u8005\u81f3\u5c11\u6211\u6ce8\u91ca\u6389\u4ee3\u7801\u7684\u65f6\u5019 \u4e0d\u5e94\u8be5\u4e5f\u6253\u5305\u8fdb\u53bb\u4e86\n[Expected Results]  ", "code": ["if (process.env.NODE_ENV !== 'production') {\n  const createLogger = require('redux-logger').createLogger;\n  middlewares.push(createLogger());\n}\n"], "labels": ["inactive"]}
{"project": "foundation_foundation-sites", "title": "[Top Bar] ISSUE NAME HERE", "description": "How can we reproduce this bug? What did you expect to happen? What happened instead? Test case Here Give us a link to a CodePen or JSFiddle that recreates the issue. ", "code": [], "labels": ["javascript"]}
{"project": "qgis_QGIS", "title": "Unable to run any grass process under macOS X.13.4", "description": "Author Name: Ronan L (Ronan L)\nOriginal Redmine Issue: 18992\nAffected QGIS version: 3.4.3\nRedmine category:grass After clean install on MacOS X 10.13.4, I was not able to run any off the grass tools.\nFirst error was \"python3 file not found\" this was easy to fix by adding the good path in my PATH variable Capture d\u2019\u00e9cran 2018-05-20 \u00e0 10.09.34.png shows the error when running grass\nThe error shows a missing folder // I tried to create this folder and gives it full rights:\nsudo mkdir -p \"//\" ; sudo chmod -R ugo+rwx \"/\" After that I still can't run v.drape tool (Capture d\u2019\u00e9cran 2018-05-20 \u00e0 10.35.08.png)\nError is: MAPSET  - permission denied Finally I tried to add a TERM=xterm but I got the same MAPSET  - permission denied ", "code": [], "labels": ["High Priority", "GRASS", "Regression", "Bug"]}
{"project": "tmrowco_electricitymap-contrib", "title": "Optimise weather data transfer", "description": "Because we fetch a forecast for before and after now, we should only re-ask for weather data when data expires. ", "code": [], "labels": ["enhancement"]}
{"project": "dart-lang_sdk", "title": "dart editor: does not colorize text correctly in multi-line comments with embedded ${}", "description": "This issue was originally filed by jackpa...@google.com Open attached file in Dart Editor Expected:File is syntax highlighted correctly.\nActual: Text after the ${} feature is not highlighted correctly. Attachment:\nbug.dart (161 Bytes) ", "code": [], "labels": ["Type-Defect"]}
{"project": "istio_istio", "title": "Make containerPorts not required", "description": "Release 0.8 introduce the requirement to explicitly configure the containerPorts in the Pod to have Envoy intercept the traffic to those ports. To remove this requirement, we need to separate the inbound and outbound Listeners. Changes are required in Envoy. cc @PiotrSikora ", "code": [], "labels": ["area/networking"]}
{"project": "Polymer_old-docs-site", "title": "Add short doc on IDE plugins", "description": "@rictic to provide rough draft in whatever form suits him. ", "code": [], "labels": ["P1"]}
{"project": "wenzhixin_bootstrap-table", "title": "queryParams can't pass to server when multiple sort server", "description": "when using multiple-sort extension, the ajax only pass original params({\"sortName\":\"\",\"sortOrder\":\"asc\",\"pageSize\":10,\"pageNumber\":1,\"multiSort\":[{\"sortName\":\"flowPath\",\"sortOrder\":\"asc\"}]}) to server,  however the custom queryParams can't be send to server.\nif custom params are passed by queryParams? if not, how to pass custom parameter to server when multiple sort in server? Thanks! ", "code": [], "labels": ["fixed"]}
{"project": "nodejs_node", "title": "Doc: Running in low memory environments (--max_old_space_size) seems to be undocumented", "description": "There used to be an entry (the only entry!) in the github wiki FAQ about running in low memory. It looks like the wiki has been deleted without moving its contents to other documentation / website. Consider this issue a request to have this documented. (and a complaint that the issue about deleting the wiki should not have been closed until its contents were properly moved to a maintained location, not an unadvertised archive repo). ", "code": [], "labels": ["meta", "doc"]}
{"project": "Polymer_polymer", "title": "ZIP download missing minified webcomponents.js", "description": "It appears when we handed off webcomponents.js to Web Components.org, we had a change in the way the polyfills were packaged. Now, if  you install Polymer from a ZIP file, you don't get the webcomponents.min.js file. This confuses people because we've updated all of the examples to show webcomponents.min.js. When you install from Bower, you get the minified file, so not sure what's going on there. ", "code": [], "labels": ["p1"]}
{"project": "nextcloud_server", "title": "No e-mail notification - event update only aceppted", "description": "Steps to reproduce Expected behaviour\nno notification by email Actual behaviour\nnotification by email Server configuration\nnot significant, general\nNextcloud Version 16 I understand the necessary notification if there are any changes or the event is declined.\nBut there is no need for email notification if the event is only acepted, the email text is more confucing than productive.\nNextcloud notifications are really enough. ", "code": [], "labels": ["0. Needs triage", "bug"]}
{"project": "NativeScript_NativeScript", "title": "Http failure during parsing", "description": "I was calling the post request as below <CODE> but I was getting the error like \"Http failure during parsing\". After digging a lot, I come to know that this._setResponseType(); from the tns-core-modules/xhr/xhr.ts was giving the issue. <URL> If I am already setting the responseType: 'text' then this function is overriding and setting the responseType as json thats why when the response is text it is throwing the error. If possible, please remove that so, it will work perfectly. Want to back this issue? Post a bounty on it! We accept bounties via Bountysource.\n ", "code": ["this.http.post(API_ENDPOINT + url, obj, { responseType: 'text'})\n"], "labels": ["http"]}
{"project": "npm_npm", "title": "npm issue", "description": "\nNo description provided.\n ", "code": [], "labels": ["support"]}
{"project": "moby_moby", "title": "Enable Secrets to be Consumed as Environment Variables", "description": "Description Not all applications make it  easy to load secrets from file, and I'd prefer not to create complicated entry point scripts. So it would be nice if Docker Swarm provided a means to transform our secrets to the Linux environment for our applications to consume. I believe this is possible through -e MYSQL_ROOT_PASSWORD='/run/secrets/file', but that's extra configuration and I imagine this would work better with syntax like the following: <CODE> When this is available in Swarm, I guess we'd also need to modify docker/compose syntax v3 to include something akin to the Kubernetes spec: <CODE> ", "code": ["$ docker service create \\\n    # Not exposes to environment \\\n    --secret source=mysql_user_password,target=mysql_user_password \\\n    # Exposed to environment \\\n    --secret source=mysql_root_password,target=mysql_root_password,env=MYSQL_ROOT_PASSWORD\n", "      env:\n        - name: SECRET_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: username\n"], "labels": ["area/swarm"]}
{"project": "angular_material", "title": "feat(panel): Configuration ID for tracking", "description": "Actual Behavior: CodePen (or steps to reproduce the issue): * Angular Versions: * Additional Information: Ping @ErinCoughlan ", "code": [], "labels": ["type: enhancement", "has: Pull Request", "type: feature"]}
{"project": "OpenTTD_OpenTTD", "title": "Placeholder for #4278", "description": "In order for GitHub issue numbers to be in sync with FlySpray issue numbers during migration, these empty issues are created to bump the number on GitHub.\nThe idea behind this is to make referencing issue numbers easy; everything is available on GitHub under the same number as it was on FlySpray. ", "code": [], "labels": ["flyspray"]}
{"project": "swoole_swoole-src", "title": "exit Swoole\\ExitException \u4e8c\u6b21\u5f00\u53d1\u6709\u4e9b\u573a\u666f\u4e0d\u592a\u53cb\u597d", "description": "Please answer these questions before submitting your issue. Thanks! <CODE> swoole 4.1.0 \u95ee\u9898\uff1a 4.0.1 \u7248\u672c\uff0c\u5728\u4f7f\u7528 exit \u7684\u65f6\u5019\uff0c\u629b\u51fa\u4e00\u4e2a Swoole\\ExitException \u9519\u8bef\uff0c\u5728 server \u7684\u56de\u8c03\u51fd\u6570\u4e2d\u5f00\u53d1\u65f6\u975e\u5e38\u53cb\u597d\uff0c\u4f46\u662f\u5728\u547d\u4ee4\u884c\u5f00\u53d1\u65f6\uff0c\u5bfc\u81f4\u6211\u65e0\u6cd5\u53cb\u597d\u7684\u7ec8\u6b62\u5f53\u524d\u8fdb\u7a0b\uff0c\u53ea\u80fd\u4f7f\u7528 kill -9  \u8fd9\u6837\u7684\u65b9\u5f0f\u3002 \u6bd4\u5982\uff1a\n\u547d\u4ee4\u884c\u542f\u52a8\u591a\u4e2a\u534f\u7a0b\uff0c\u6709\u4e9b\u65f6\u5019\u6211\u9700\u8981\u7ec8\u6b62\u6574\u4e2a\u7a0b\u5e8f\uff0cexit\u5728\u534f\u7a0b\u4e2d\u6267\u884c\uff0c\u53ea\u4f1a\u629b\u51fa Swoole\\ExitException \uff0c\u5982\u679ctry\u6355\u83b7\uff0c\u5c06\u65e0\u6cd5\u9000\u51fa\uff0c\u4e0d\u6355\u83b7\u5c06\u6709\u5f02\u5e38\u629b\u51fa\u5230\u7ec8\u7aef\uff0c\u6211\u53ea\u662f\u60f3\u4e3b\u52a8\u9000\u51fa\u4f46\u786e\u629b\u51fa\u4e86\u4e00\u4e2a\u9519\u8bef\uff0c\u800c\u4e14\u6211\u65e0\u6cd5\u53bb\u6389\u4ed6\u3002 \u540c\u7406\u5728\u591a\u8fdb\u7a0b\u5f00\u53d1\u65f6\uff0c\u5f53\u60f3\u9000\u51fa\u4e3b\u8fdb\u7a0b\u65f6\uff0c\u4e5f\u9762\u4e34\u8fd9\u4e2a\u95ee\u9898\u3002 \u5efa\u8bae\u589e\u52a0\u4e00\u4e2a\u53ef\u5f3a\u5236\u9000\u51fa\u8fdb\u7a0b\u7684\u51fd\u6570\uff0c\u4fdd\u7559\u7528\u6237\u8be5\u9879\u80fd\u529b\u3002 ", "code": ["Swoole\\ExitException\n"], "labels": ["question"]}
{"project": "microsoft_TypeScript", "title": "Incorrect type inference in promise.all", "description": "TypeScript Version:  3.7.x-dev.201xxxxx Search Terms: Code Expected behavior:\nWorks correctly in typescript 3.6.4, but failed to compile in typescript@latest and typescript@next with error Argument of type 'B | undefined' is not assignable to parameter of type 'B'. ", "code": [], "labels": ["Needs Investigation"]}
{"project": "angular_angular.js", "title": "$anchorScrollProvider.disableAutoScrolling() is not working when using $routeProvider", "description": "When auto scrolling is disabled and hash is changed, the page still get scrolled to the hash element. ", "code": [], "labels": ["resolution: fixed"]}
{"project": "hashicorp_terraform", "title": "core: provide a method to re-run a provisioner", "description": "Currently, if a provisioner fails during apply, we have no way to re-run that provisioner automatically using terraform. A -provision=resource flag for apply could trigger the provisioner to run again on the targeted resource. ", "code": [], "labels": ["enhancement", "core"]}
{"project": "DeviaVir_zenbot", "title": "[discussion] engine rearchitecting", "description": "@defkev brought up some interesting points recently about potential changes to the engine.js. I'd like to start a larger discussion about some bigger goals for the engine in hopes that if a comprehensive overhaul is to happen, it can encompass some extra ideas. Goal 1: I want it to be possible to run multiple coins. Right now I can set --buy_max_amt and run 2 separate bots, and with a strategy configured to switch modes based on whether or not I have a positive asset balance, they do indeed play nicely together without overspending beyond that buy_max_amt. However, because they, on Binance at least, are running 2 separate polls to Binance, I get my IP throttled when I try. You can implement websockets for multiple coins at 1 time, but how do you get 2 instances of Zenbot to share that stream of trades? Definitely need a major change for that. Goal 2: Fix the madness of this setTimeout chain. It's entirely possible (and happens to me on occasion) for an error to trigger a retry of the callback chain of an order, and then in the next period, an entirely separate chain of callbacks to trigger on the same order. There's no way for the engine to recognize that it's already looping through a bunch of setTimeouts and so they start stepping on each others' toes. The best case scenario is they both try to place an order, and the exchange sends an \"insufficient funds\" error causing 1 chain to die. Timing should somehow be more explicit. Either decisions should be made as callbacks from web socket streams, or after time passes, it should be saying \"with the current state of things, what should I be doing with my current order?\" instead of hoping that the setTimeout dance in the ether will figure itself out. There's multiple related bugs that this could solve. ", "code": [], "labels": ["enhancement"]}
{"project": "google_ExoPlayer", "title": "Upgrade from 1.4.2 to 1.5.0: Android Studio shows compiler errors but \"cannot resolve symbol\"", "description": "I just tried to upgrade from version 1.4.2 to version 1.5.0 (or any version above that). The sync after the change in my build.gradle worked and the build/intermediates/exploded-aar/com.google.android.exoplayer/exoplayer/r1.5.0/jars/classes.jar does exist. So, it seems that AS was able to download the new version of Exoplayer. Also, I get compiler errors for changed method signatures, for example, BaseChunkSampleSourceEventListener. And yet, AS at the same time claims that it cannot resolve any symbol from the Exoplayer library, all the exoplayer imports are marked as errors and Alt-Enter does not propose to import the class. I've also tried \"Invalidate caches & restart' as well as completely re-importing the project as a Gradle project. Nothing worked. I have never this when upgrading any other depedency, nor with earlier Exoplayer updates, but I do not seem to be the only one with this problem: <URL> What is going on? ", "code": [], "labels": ["question"]}
{"project": "fuse-box_fuse-box", "title": "Sparky.watch - browser auto-reloading", "description": "It would be great to be able to manually reload a browser window whenever the defined files are changed using Sparky.watch. The browser reloading could be done by some build-in functionality or external package. Here is an example of how to do this by gulp and browser-sync and having a similar functionality would be nice. <CODE> If this is already possible now, please, let me know how to do it. ", "code": ["var gulp        = require('gulp');\nvar browserSync = require('browser-sync').create();\nvar reload      = browserSync.reload;\n\n// Save a reference to the `reload` method\n\n// Watch scss AND html files, doing different things with each.\ngulp.task('serve', function () {\n\n    // Serve files from the root of this project\n    browserSync.init({\n        server: {\n            baseDir: \"./\"\n        }\n    });\n\n    gulp.watch(\"*.html\").on(\"change\", reload);\n});\n"], "labels": ["enhancement"]}
{"project": "kubernetes_kubernetes", "title": "Figure out the root cause for 1000 node cluster density flakes", "description": "In some of the runs we observe pod startup lantencies > 1m and we have no idea how. cc @kubernetes/goog-control-plane @brendandburns @wojtek-t @fgrzadkowski @davidopp ", "code": [], "labels": ["team/control-plane", "sig/scalability", "priority/important-soon"]}
{"project": "npm_npm", "title": "error upon npm install apic -g on windows 8.1 remote error repository not found", "description": "I am getting error on: <CODE> ", "code": ["85 error Windows_NT 6.3.9600\n86 error argv \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Program Files\\\\nodejs\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"install\" \"apic\" \"-g\"\n87 error node v5.11.0\n88 error npm  v3.8.6\n89 error code 128\n90 error Command failed: git -c core.longpaths=true clone --template=C:\\Users\\Aaron\\AppData\\Roaming\\npm-cache\\_git-remotes\\_templates --mirror git://github.com/euforic/superagent.git C:\\Users\\Aaron\\AppData\\Roaming\\npm-cache\\_git-remotes\\git-github-com-euforic-superagent-git-6b14b02d\n90 error Cloning into bare repository 'C:\\Users\\Aaron\\AppData\\Roaming\\npm-cache\\_git-remotes\\git-github-com-euforic-superagent-git-6b14b02d'...\n90 error fatal: remote error:\n90 error   Repository not found.\n91 error If you need help, you may report this error at:\n91 error     <https://github.com/npm/npm/issues>\n92 verbose exit [ 1, true ]\n"], "labels": ["windows", "bot-closed", "support", "git"]}
{"project": "microsoft_vscode", "title": "Dependency cycle between remote and tunnelView", "description": "<CODE> ", "code": ["/Users/isidor/Development/vscode/out/vs/loader.js:1591 There is a dependency cycle between 'vs/workbench/contrib/remote/browser/remote' and 'vs/workbench/contrib/remote/browser/tunnelView'. The cyclic path follows:\n\nvs/workbench/contrib/remote/browser/remote => \nvs/workbench/contrib/remote/browser/tunnelView => \nvs/workbench/contrib/remote/browser/remote\n"], "labels": ["bug"]}
{"project": "pantsbuild_pants", "title": "duplicated error from build graph exception", "description": "Same error popped twice, so at least a UX issue. If this surfaces duplication in build graph searching, then that'll be more interesting. <CODE> ", "code": ["$ ./pants --no-print-exception-stacktrace list src/123\nException caught: (<class 'pants.build_graph.address_lookup_error.AddressLookupError'>)\n\nException message: Build graph construction failed: ExecutionError Multiple exceptions encountered:\n  ResolveError: Path \"src/123\" contains no BUILD files.\n  ResolveError: Path \"src/123\" contains no BUILD files.\n"], "labels": ["UX"]}
{"project": "fish-shell_fish-shell", "title": "Way to manually apply syntax coloring", "description": "I have a function which prepends sudo  to the commandline and then runs commandline -f execute. This is a simplified version: <CODE> This all works fine but the syntax highlighting of the commandline isn't updated after prepending sudo. Is there a command to manually update syntax highlighting that I could add to the function? fish, version 2.7.1 on ArchLinux ", "code": ["function __fish_plz_bind\n    set -l cmdln_old (commandline)\n    set -l cmdln_new 'sudo '\"$cmdln_old\"\n    commandline -r $cmdln_new\n    commandline -f execute\nend\n\nbind \\ep __fish_plz_bind\n"], "labels": ["duplicate"]}
{"project": "docker_compose", "title": "docker-compose build does not accept self-signed root CA", "description": "Running docker-compose within a network that is behind a Firewall-Gateway which is doing SSL inspection. Manually imported self-signed root CA in the host system is working properly with binaries like curl, wget etc. Also docker pull is able to connect via SSL. However running docker-compose build fails and does not recognize the imported root CA. <CODE> <CODE> <CODE> Accept SSL/TLS connection due to imported root CA cert. ", "code": ["#docker-compose version\ndocker-compose version 1.24.0, build 0aa59064\ndocker-py version: 3.7.2\nCPython version: 3.6.8\nOpenSSL version: OpenSSL 1.1.0j  20 Nov 2018\n", "# docker version\nClient: Docker Engine - Community\n Version:           19.03.4\n API version:       1.40\n Go version:        go1.12.10\n Git commit:        9013bf583a\n Built:             Fri Oct 18 15:52:34 2019\n OS/Arch:           linux/amd64\n Experimental:      false\n\nServer: Docker Engine - Community\n Engine:\n  Version:          19.03.4\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.10\n  Git commit:       9013bf583a\n  Built:            Fri Oct 18 15:51:05 2019\n  OS/Arch:          linux/amd64\n  Experimental:     false\n containerd:\n  Version:          1.2.10\n  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339\n runc:\n  Version:          1.0.0-rc8+dev\n  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657\n docker-init:\n  Version:          0.18.0\n  GitCommit:        fec3683\n\n", "# docker-compose build\nBuilding db\nStep 1/9 : FROM postgres:9.4-alpine\n ---> e4b871fd6469\nStep 2/9 : ENV DEFAULT_TIMEZONE UTC\n ---> Using cache\n ---> 697788f1c69a\nStep 3/9 : RUN apk add --no-cache       build-base       curl       libc6-compat       libffi-dev       linux-headers       python-dev       py-pip       py-cryptography     && pip --no-cache-dir install 'wal-e<1.0.0' envdir     && rm -rf /var/cache/apk/* /tmp/* /var/tmp/*\n ---> Running in b28ebac4aa6e\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.10/community/x86_64/APKINDEX.tar.gz\n(1/48) Installing binutils (2.32-r0)\n(2/48) Installing libmagic (5.37-r1)\n. . .\n(45/48) Installing py2-cryptography (2.6.1-r1)\n(46/48) Installing py-setuptools (40.8.0-r1)\n(47/48) Installing py2-pip (18.1-r0)\n(48/48) Installing python2-dev (2.7.16-r1)\nExecuting busybox-1.30.1-r2.trigger\nExecuting ca-certificates-20190108-r0.trigger\nOK: 255 MiB in 76 packages\nCollecting wal-e<1.0.0\n  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)'),)': /simple/wal-e/\n  Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)'),)': /simple/wal-e/\n  Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)'),)': /simple/wal-e/\n  Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)'),)': /simple/wal-e/\n  Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)'),)': /simple/wal-e/\n  Could not fetch URL https://pypi.org/simple/wal-e/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/wal-e/ (Caused by SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)'),)) - skipping\n  Could not find a version that satisfies the requirement wal-e<1.0.0 (from versions: )\nNo matching distribution found for wal-e<1.0.0\nCould not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)'),)) - skipping\n"], "labels": ["status/0-triage"]}
{"project": "HabitRPG_habitica", "title": "An in-range update of hellojs is breaking the build \ud83d\udea8", "description": "\ud83d\udea8 View failing branch. This version is covered by your current version range and after updating it in your project the build failed. hellojs is a direct dependency of this project, and it is very likely causing it to break. If other packages depend on yours, this update is probably also breaking those in turn. Your Greenkeeper Bot \ud83c\udf34 ", "code": [], "labels": ["greenkeeper"]}
{"project": "nestjs_nest", "title": "Update roadmap", "description": "<URL> ", "code": [], "labels": ["type: question "]}
{"project": "fail2ban_fail2ban", "title": "Customize fail2ban Log Message", "description": "fail2ban logs bans with this message: 2019-04-02 15:27:42,318 fail2ban.actions: WARNING [apache] Ban 44.110.20.110\nIt is possible to add the log-file at the end of this message. So I can see in which log-File the ban is happend. 2019-04-02 15:27:42,318 fail2ban.actions: WARNING [apache] Ban 44.110.20.110 /var/log/apache2/error.log Because I work with wildcards so there are many log-files /var/log/sites/*/log/error.log and I cannot see which log-file will be found from fail2ban. ", "code": [], "labels": ["enhancement"]}
{"project": "microsoft_vscode-python", "title": "Drop the tpn directory from the .vsix", "description": "People don't need the code to generate the third-party notices file in their installation. \ud83d\ude09 ", "code": [], "labels": ["feature-*", "needs PR", "type-code health"]}
{"project": "logaretm_vee-validate", "title": "Validate whole number and fractional number(Decimal) in Vee-validate v3", "description": "I was looking for any rule that validates a decimal number. I saw the list of rules here: <URL> Does it mean that there is no way in this package to validate fractional number(decimal)? Can you please suggest something? ", "code": [], "labels": [" question"]}
{"project": "Tribler_tribler", "title": "Changing settings won't work after a restart", "description": "Changing the port won't update the new port.\nSetting a new download location won't update and defaults back to the TriblerDownloads folder on the Desktop. win 8.1 FIX:\nStart program as Administrator; should be forced. ", "code": [], "labels": ["bug"]}
{"project": "robolectric_robolectric", "title": "Remove classes @Deprecated in 3.3", "description": "", "code": [], "labels": ["cleanup"]}
{"project": "fex-team_webuploader", "title": "IE9\u4ee5\u4e0b\u5728iframe\u4e2d\u70b9\u51fb\u6309\u94ae\u4e0d\u5f39\u51fa\u6587\u4ef6\u5bf9\u8bdd\u6846", "description": "\u5982\u679c\uff0c\u628a\u9875\u9762\u79fb\u51faiframe\u5916\u76f4\u63a5\u6d4f\u89c8\u6b63\u5e38\uff0c\u8c03\u7528\u7684\u662fflash\uff0c\u8bf7\u95ee\u9700\u8981\u5982\u4f55\u8bbe\u7f6e\uff0c\u662f\u4e0d\u662f\u56e0\u4e3aflash\u7684\u5b89\u5168\u8bbe\u7f6e\u95ee\u9898\uff1f ", "code": [], "labels": ["bug"]}
{"project": "arendst_Tasmota", "title": "Reverse blind direction/toggle interlocked relays", "description": "Have you look for this feature in other issues and in the wiki?\nYes. Is your feature request related to a problem? Please describe.\nNo. Describe the solution you'd like\nIf I enable the interlock feature to control my window blinds motor, and the blinds are currently moving up, and while still moving, a down command is issued, the relays should both toggle immediately to reverse direction.\nRight now, if I turn on the up relay and change my mind while the motor is running, and I press the down button, nothing happens, because the interlock feature decides not to turn on the second relay. Instead, the up relay should be turned off and the down relay on. Describe alternatives you've considered\nI can implement this with NodeRED via MQTT, but I also want this feature for the buttons in the web interface, for rule usage and for directly connected buttons. ", "code": [], "labels": ["question"]}
{"project": "tutao_tutanota", "title": "DBTransaction: 'event.stopPropagation' is undefined", "description": "Seen this reported for Firefox 70 and for iOS 12 and 13 <CODE> ", "code": ["Client: ios\nTutanota version: 3.60.6\nUser agent:\nMozilla/5.0 (iPhone; CPU iPhone OS 12_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148\nTypeError\nError message: event.stopPropagation is not a function. (In 'event.stopPropagation()', 'event.stopPropagation' is undefined)\nStacktrace: \nvalue@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/worker.js:1:477325\nfile:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/worker.js:1:475832\na@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:73170\nfromCallback@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:41328\na@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:73170\n_settlePromiseFromHandler@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:46546\n_settlePromise@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:47367\n_settlePromise0@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48055\n_settlePromises@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:49408\n_fulfill@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48426\n_settlePromiseFromHandler@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:46712\n_settlePromise@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:47367\n_settlePromise0@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48055\n_settlePromises@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:49408\n_fulfill@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48426\n_settlePromiseFromHandler@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:46712\n_settlePromise@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:47367\n_settlePromise0@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48055\n_settlePromises@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:49408\n_fulfill@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48426\n_settlePromiseFromHandler@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:46712\n_settlePromise@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:47367\n_settlePromise0@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48055\n_settlePromises@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:49408\n_fulfill@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48426\n_settlePromiseFromHandler@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:46712\n_settlePromise@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:47367\n_settlePromise0@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48055\n_settlePromises@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:49408\n_fulfill@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:48426\nfile:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/libs.js:26:37186\nonsuccess@file:///var/containers/Bundle/Application/8918E7BD-EEE1-4BAB-8A29-9D0C5FBB0835/tutanota.app/build/dist/worker.js:1:475774\n"], "labels": ["bug", "tested"]}
{"project": "MicrosoftDocs_azure-docs", "title": "FunctionApp 2.0", "description": "Seems this is not compatible with FunctionApp v2.0. Here, the configuration is read by Microsoft.Extensions.Configuration \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["doc-enhancement", "app-service/svc", "triaged", "assigned-to-author"]}
{"project": "facebook_react-native", "title": "Vanilla react-native build fails when using Auth0's react-native-lock", "description": "The Auth0 team says this is a React Native issue: auth0/react-native-lock#60 ", "code": [], "labels": ["Resolution: Locked"]}
{"project": "grpc_grpc", "title": "bins/ubsan/h2_ssl_proxy_test stream_compression_ping_pong_streaming GRPC_POLL_STRATEGY=epollex", "description": "<CODE> <URL> ", "code": ["D1213 20:56:51.489097299    3850 ev_posix.cc:128]            Using polling engine: epollex\nD1213 20:56:51.489228349    3850 dns_resolver.cc:293]        Using native dns resolver\nI1213 20:56:51.489331036    3850 stream_compression_ping_pong_streaming.cc:41] Running test: test_pingpong_streaming/chttp2/simple_ssl_fullstack\nD1213 20:56:51.492630376    3850 proxy.cc:89]                PROXY ADDR:localhost:10426 BACKEND:localhost:17343\nI1213 20:56:51.743481443    3850 stream_compression_ping_pong_streaming.cc:41] Running test: test_pingpong_streaming/chttp2/simple_ssl_fullstack\nD1213 20:56:51.748499786    3850 proxy.cc:89]                PROXY ADDR:localhost:23283 BACKEND:localhost:20837\nI1213 20:56:51.875736795    3850 stream_compression_ping_pong_streaming.cc:41] Running test: test_pingpong_streaming/chttp2/simple_ssl_fullstack\nD1213 20:56:51.878515252    3850 proxy.cc:89]                PROXY ADDR:localhost:7221 BACKEND:localhost:2082\nI1213 20:56:52.001568521    3850 stream_compression_ping_pong_streaming.cc:41] Running test: test_pingpong_streaming/chttp2/simple_ssl_fullstack\nD1213 20:56:52.004655249    3850 proxy.cc:89]                PROXY ADDR:localhost:16434 BACKEND:localhost:7312\n\n2017-12-13 21:12:00,269 TIMEOUT: bins/ubsan/h2_ssl_proxy_test stream_compression_ping_pong_streaming GRPC_POLL_STRATEGY=epollex [pid=3850, time=908.8sec]\n"], "labels": ["infra/BUILDPONY"]}
{"project": "spring-projects_spring-security", "title": "SEC-2310: Web Extender failed to start on Linux 6 using Tomcat HTTPS Connector", "description": "Nicholas M (Migrated from SEC-2310) said: After setting up an HTTPS Connector with Tomcat config file server.xml, the Web Extender consistently fails to start. This only happens when HTTPS Connector is being used on Linux 6. I've tried this on RHEL 5 and it works just fine with the default start level. Stack Trace:\norg.springframework.osgi.service.ServiceUnavailableException: service matching filter=[(objectClass=org.apache.catalina.Service)] unavailable\nat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1420)\nat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:519)\nat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)\nat org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:291)\nat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\nat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:288)\nat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:190)\nat org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:580)\nat org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:895)\nat org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:425)\nat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext.access$301(AbstractDelegatedExecutionApplicationContext.java:62)\nat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext$1.run(AbstractDelegatedExecutionApplicationContext.java:170)\nat org.springframework.osgi.util.internal.PrivilegedUtils.executeWithCustomTCCL(PrivilegedUtils.java:87)\nat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext.normalRefresh(AbstractDelegatedExecutionApplicationContext.java:166)\nat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext$NoDependenciesWaitRefreshExecutor.refresh(AbstractDelegatedExecutionApplicationContext.java:80)\nat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext.refresh(AbstractDelegatedExecutionApplicationContext.java:159)\nat org.springframework.osgi.web.extender.internal.activator.WarListenerConfiguration.(WarListenerConfiguration.java:115)\nat org.springframework.osgi.web.extender.internal.activator.WarLoaderListener$1.run(WarLoaderListener.java:366)\nat java.lang.Thread.run(Thread.java:662)\nCaused by: org.springframework.osgi.service.ServiceUnavailableException: service matching filter=[(objectClass=org.apache.catalina.Service)] unavailable\nat org.springframework.osgi.service.importer.support.internal.aop.ServiceDynamicInterceptor.getTarget(ServiceDynamicInterceptor.java:406)\nat org.springframework.osgi.service.importer.support.internal.aop.ServiceInvoker.invoke(ServiceInvoker.java:62)\nat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)\nat org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:131)\nat org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:119)\nat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)\nat org.springframework.osgi.service.importer.support.LocalBundleContextAdvice.invoke(LocalBundleContextAdvice.java:59)\nat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)\nat org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:131)\nat org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:119)\nat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)\nat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)\nat $Proxy2.getName(Unknown Source)\nat org.springframework.osgi.web.deployer.tomcat.TomcatWarDeployer.afterPropertiesSet(TomcatWarDeployer.java:91)\nat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1477)\nat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1417)\n... 18 more ", "code": [], "labels": ["Closed", "type: jira", "in: web", "type: bug", "status: invalid"]}
{"project": "vector-im_riot-android", "title": "Settings: move the Devices section after the Cryptography section", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement", "P2"]}
{"project": "PokemonGoF_PokemonGo-Bot", "title": "Permanent ban wave is now! \"My account got (hard) ban?\"", "description": "My account got (hard) ban? <CODE> And I got: KeyError: u'inventory_delta' ", "code": ["inventory_req = self.get_inventory_data()\ninventory_dict = inventory_req['responses']['GET_INVENTORY'][\n            'inventory_delta']['inventory_items']\n"], "labels": ["Duplicate"]}
{"project": "asciidoctor_asciidoctor", "title": "Embedded Vimeo/YouTube videos don't display", "description": "It appears that Asciidoctor is omitting https in the link is the cause; when I add that, the videos display properly. <URL> Loving Asciidoctor! Thank you for the hard work! ", "code": [], "labels": ["improvement"]}
{"project": "qgis_QGIS", "title": "Display pixel value", "description": "Author Name: luca bellani (luca bellani)\nOriginal Redmine Issue: 20509 Redmine category:map_canvas I would like to propose the integration of a small window next to the coordinates, at the bottom of the canvas. To be able to visualize the pixel value of a layer. That would avoid having to use plug in, and would save space for this same panel.\nThank you very much for the availability.\nLuca ", "code": [], "labels": ["Feature Request", "Map and Legend"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Blank page - fresh install - 2.6.2 - cookie authentication", "description": "This may or may not be a bug. I downloaded the phpMyAdmin-2.6.2.tar.gz file on Sat\nApr 23 09:47:21 SAST 2005. I did a normal tar zxvf phpMyAdmin-2.6.2.tar.gz of the\ndistribution and a ln -s phpMyAdmin-2.6.2 phpMyAdmin. Then I edited the config.in.php file as I have many\ntimes before. I selected cookie authentication mode. I also created the phpmyadmin database with all the\ntables for the bookmarks, etc\u2026 Then I proceeded to access phpMyAdmin via\n<URL> and was presented with\na blank page. I examined the /var/log/httpd/error_log file and found\nthe following errors: [client 165.165.222.107] PHP Warning: \nmain(./libraries/auth/coookie.auth.lib.php): failed to\nopen stream: No such file or directory in\n/var/www/html/phpMyAdmin-2.6.2/libraries/common.lib.php\non line 1220\n[client 165.165.222.107] PHP Fatal error:  main():\nFailed opening required\n\u2018./libraries/auth/coookie.auth.lib.php\u2019\n(include_path=\u2018.:/usr/share/pear\u2019) in\n/var/www/html/phpMyAdmin-2.6.2/libraries/common.lib.php\non line 1220 I then went to ./libraries/auth/ and did a ln -s\ncookie.auth.lib.php coookie.auth.lib.php, which fixed\nthe problem. Hope this helps. Regards,\n-Carl - Original URL: <URL>\n- Original author: carlswart ", "code": [], "labels": ["question"]}
{"project": "qgis_QGIS", "title": "can't merge features if restrictive foreign key in place", "description": "Author Name: Gavin Fleming (@gubuntu)\nOriginal Redmine Issue: 14247\nAffected QGIS version: 2.8.5\nRedmine category:digitising I merged two features, a new one and an old one, keeping the attributes of the one that was already in the database. I expected QGIS to add the merged feature before deleting the old one but instead it tries to delete the old one first and fails because that would cascade to a table with a restrictive FK. Is this intended and if so does this mean I have to drop the FK when I want to merge or can this behaviour be improved? Related issue(s): #15668 (relates)\nRedmine related issue(s): 6422 ", "code": [], "labels": ["Digitizing", "Bug"]}
{"project": "composer_composer", "title": "create-project fails with composer.json not found", "description": "So when creating a new project it's failing saying no composer.json file found.\nWhen I create the project folder and put the composer.json file inside fails saying \"project directory must be empty\" Chicken and egg problem?? ", "code": [], "labels": ["Support"]}
{"project": "kubernetes_kubernetes", "title": "Kubelet TLS Bootstrap issued certificate is not valid for hostName of node", "description": "/kind bug What happened:\nI am trying to use api-server kubelet-client certificate creation as per the TLS Bootstrap guide for the Kubelet TLS Bootstrap feature (kubernetes/enhancements#43). While the node join and certificate handshake works fine, it seems that the certificate does not get created correctly.\nAfter the node successfully joined the cluster I get a\n\u00b4\u00b4\u00b4certificate is valid for system:node:, not for \u00b4\u00b4\u00b4\nwhen trying to issue any command on a pod running on that node (i.e. kubectl logs or kubectl exec).\nWhat is missing from the CNF, I think, is a proper alt-name for the hostname as it only has the CN set as system:node. What you expected to happen:\nThe nodes joins and I can issue kubectl commands perfectly fine. How to reproduce it (as minimally and precisely as possible):\nI am using these kubelet.service definitions: And my API Servers start like that: Anything else we need to know?: Environment: ", "code": [], "labels": ["kind/bug", "sig/cluster-lifecycle"]}
{"project": "fritzing_fritzing-app", "title": "disconnected traces freak out the panelizer", "description": "From irasc...@gmail.com on November 03, 2011 20:32:13 either ignore disconnected traces, put up a warning in some step of the panelizer process, or figure out a way to draw them as they are Original issue: <URL> ", "code": [], "labels": ["bug", "Priority-High"]}
{"project": "bytedeco_javacv", "title": "\"amr_nb\" codec  not found in javacv", "description": "can you add \"amr_nb\" audio codec support in javacv,please ", "code": [], "labels": ["enhancement"]}
{"project": "microsoft_vscode", "title": "Git: Support to bulk resolve merge changes", "description": "The git stash conflict handle doesn't has a option to apply all current changes or incoming changes, you must apply the changes one by one\uff0cWhat if we add two new menu item to support apply all current changes or incoming changes, like:  ", "code": [], "labels": ["feature-request", "git"]}
{"project": "microsoft_vscode", "title": "Edited but unsaved content appears in the \"Search in Folders\" result", "description": "This problem also exists in the insiders version. Steps to Reproduce: folder like this: <CODE> body1.js like this: <CODE>  Remarks: After this result, I just try to type in the body.js file and the result will disappear Does this issue occur when all extensions are disabled?: Yes ", "code": ["- FolderA\n - body.js\n- FolderB\n", "content\n"], "labels": ["search", "bug", "verified"]}
{"project": "snowplow_snowplow", "title": "EmrEtlRunner: add unit test for add_trailing_slashes function", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement", "3. ETL"]}
{"project": "almende_vis", "title": "Is it possible to change the style of the Item's title?", "description": "I need to Use the 'title* to show a discription to the items. Is it possible to change the style of the Item's title?\nand also it is possible to use another library with the vis timeline to show the discription like a ballon on top of the items of the timeline, when moving the muse over the item? Thanks alot ", "code": [], "labels": ["Timeline", "Question"]}
{"project": "akiran_react-slick", "title": "focusOnSelect(true) + infinite(false) = a strange interaction", "description": "When I use the following configuration, I find a strange interaction that scrolls out of range when I click to the last few. In addition, it is the same behavior if you use keyboard events. What I want is not to go beyond the scope so as not to cause strange interactions. Just like this. ", "code": [], "labels": ["stale"]}
{"project": "ansible_ansible", "title": "nxos_config: Not idempotent when used with src", "description": "nxos_command <CODE> Running the following playbook shows a change <CODE> Note that depending when you look at this bug you may have to comment out the - \"result.updates is not defined\" tests ", "code": ["b8d308d919c89d86dc72d4fd62335b9f948544f1\n", "cd test/integration\ntime ANSIBLE_ROLES_PATH=targets  ansible-playbook -vvvvv  -i  inventory.network-jobarker nxos.yaml  -e \"limit_to=nxos_config\"\n"], "labels": ["nxos", "networking", "module", "affects_2.3", "bug", "cisco"]}
{"project": "termux_termux-packages", "title": "Ping not working!", "description": "however, it is working fine termux arch, as we can see above^ ", "code": [], "labels": ["information"]}
{"project": "qgis_QGIS", "title": "Filter expressions to postgres provider", "description": "Author Name: Edward H (Edward H)\nOriginal Redmine Issue: 14030\nAffected QGIS version: master\nRedmine category:data_provider/postgis\nAssignee: Matthias Kuhn Option \"Execute expressions on postgres server side if possible\" (in Options>Data Sources) works perfectly in QGIS 2.12.x\nBut in QGIS master, this option does not work and the query is no longer optimal : 2 seconds in QGIS 2.12.x vs 2 minutes in QGIS master In my case, there is 4 tables (2 with geometry and 2 without geometry) with 1-n relations (in Project Properties > Relations) storing in PostgreSQL 9.3 and Postgis 2.2 ", "code": [], "labels": ["High Priority", "Bug", "Data Provider"]}
{"project": "golang_go", "title": "all: Go 1.10 release status", "description": "<CODE> \u2014 golang.org/x/build/cmd/releasebot, Jan 25 16:14:28 UTC ", "code": ["2018/01/25 11:12:11 starting\n2018/01/25 11:12:11 working in /usr/local/google/home/andybons/go-releasebot-work/go1.10\n2018/01/25 11:12:11 $ git clone https://go.googlesource.com/go /usr/local/google/home/andybons/go-releasebot-work/go1.10/gitmirror\n2018/01/25 11:12:24 $ git config gc.auto 0\n2018/01/25 11:12:24 $ git ls-remote --heads --exit-code https://go.googlesource.com/go release-branch.go1.10\n2018/01/25 11:12:25 $ git checkout -b release-branch.go1.10 origin/master\n2018/01/25 11:12:26 $ git push origin release-branch.go1.10\n2018/01/25 11:14:23 $ git checkout master\n2018/01/25 11:14:23 $ git branch -D release-branch.go1.10\n2018/01/25 11:14:23 $ git fetch origin release-branch.go1.10\n2018/01/25 11:14:24 $ git clone --reference /usr/local/google/home/andybons/go-releasebot-work/go1.10/gitmirror -b release-branch.go1.10 https://go.googlesource.com/go /usr/local/google/home/andybons/go-releasebot-work/go1.10/gitwork\n2018/01/25 11:14:28 $ git codereview change relwork\n2018/01/25 11:14:28 $ git config gc.auto 0\n2018/01/25 11:14:28 $ git rev-parse go1.10\n2018/01/25 11:14:28 gerritQuery: HTTP status 400 Bad Request; query is empty\n2018/01/25 11:14:28 HTTP status 400 Bad Request; query is empty\n2018/01/25 11:14:28 \n\nPANIC: HTTP status 400 Bad Request; query is empty\n\n\ngoroutine 93 [running]:\nruntime/debug.Stack(0xc420b6ba18, 0xa29d60, 0xc420a64060)\n\t/usr/lib/google-golang/src/runtime/debug/stack.go:24 +0xa7\nmain.(*Work).recover(0xc4211d06c0)\n\t/usr/local/google/home/andybons/gocode/src/golang.org/x/build/cmd/releasebot/main.go:219 +0x71\npanic(0xa29d60, 0xc420a64060)\n\t/usr/lib/google-golang/src/runtime/panic.go:502 +0x229\nlog.(*Logger).Panic(0xc42117d770, 0xc420b6bbd8, 0x1, 0x1)\n\t/usr/lib/google-golang/src/log/log.go:212 +0xb4\nmain.(*Work).gerritQuery(0xc4211d06c0, 0x0, 0x0, 0x0, 0x0, 0x0)\n\t/usr/local/google/home/andybons/gocode/src/golang.org/x/build/cmd/releasebot/gerrit.go:34 +0x241\nmain.(*Work).queryGerritCLs(0xc4211d06c0)\n\t/usr/local/google/home/andybons/gocode/src/golang.org/x/build/cmd/releasebot/gerrit.go:47 +0x189\nmain.(*Work).doRelease(0xc4211d06c0)\n\t/usr/local/google/home/andybons/gocode/src/golang.org/x/build/cmd/releasebot/main.go:302 +0x374\nmain.main.func1(0xc421074920, 0xc4211d06c0)\n\t/usr/local/google/home/andybons/gocode/src/golang.org/x/build/cmd/releasebot/main.go:112 +0x51\ncreated by main.main\n\t/usr/local/google/home/andybons/gocode/src/golang.org/x/build/cmd/releasebot/main.go:110 +0x4a2\n"], "labels": ["FrozenDueToAge"]}
{"project": "spring-projects_spring-boot", "title": "Fail the build if the additional meta-data format is invalid", "description": "Various typos were introduced  by the PID update (ea61622 and becced5). As a result, all the additional meta-data of the actuator modules were gone because the annotation processor simply logs a warning if it can't merge the manual meta-data. That warning never shows up in the Maven console. I would advocate for actually failing the build with an error message that provides the actual error. ", "code": [], "labels": ["type: enhancement"]}
{"project": "nuxt_nuxt.js", "title": "Dynamic Nested Routes Not Support", "description": "v1.4.2 null my pages  <CODE> <CODE> I dont want that '?' , is that a bug? ", "code": ["routes: [\n\t\t{\n\t\t\tpath: \"/brand/brief/:categoryId/:brandId\",\n\t\t\tcomponent: \"pages/brand/brief/_category/_brandId/index.vue\",\n\t\t\tname: \"brand-brief-categoryId-brandId\"\n\t\t},\n],  \n", "routes: [\n\t\t{\n\t\t\tpath: \"/brand/brief/:categoryId?/:brandId?\",\n\t\t\tcomponent: \"pages/brand/brief/_category/_brandId/index.vue\",\n\t\t\tname: \"brand-brief-categoryId-brandId\"\n\t\t},\n],  \n"], "labels": ["cmty:bug-report"]}
{"project": "phan_phan", "title": "Phan should warn about printf with no arguments", "description": "Currently, it only warns when the format string is known. (NoSpecifiers). It should also warn when the format string is unknown. ", "code": [], "labels": ["enhancement"]}
{"project": "mozilla-mobile_fenix", "title": "[Bug] Build failure on geckonightlydebug", "description": "Run ./gradlew clean installgeckonightlydebug Build completes Build fails, with: <CODE> ", "code": ["> Task :app:compileGeckoNightlyDebugKotlin FAILED\ne: /Users/no-junpark/mozilla-mobile/fenix/app/src/main/java/org/mozilla/fenix/FenixApplication.kt: (115, 48): Function invocation 'settings(...)' expected\ne: /Users/no-junpark/mozilla-mobile/fenix/app/src/main/java/org/mozilla/fenix/FenixApplication.kt: (126, 14): Function invocation 'settings(...)' expected\n"], "labels": [" bug"]}
{"project": "godotengine_godot", "title": "3.2 Beta 1: Exported with embedded pck is broken", "description": "Godot version: 3.2 beta 1 OS/device including version:\nWindows 10 Issue description:\nRunning an executable that was exported with embedded pck fails to run with the following error:\nError: Could not load game data at path '.'. Is the .pck file missing? Steps to reproduce: Minimal reproduction project: ", "code": [], "labels": ["topic:editor", "bug"]}
{"project": "ionic-team_ionic", "title": "Input fields within list items not clickable", "description": "I use Ionic2 beta.\nThe documentation shows ion-label and ion-input within an ion-item of an ion-list.\nWhen I do the same, the input fields are not clickable. I analyzed the code a bit and found, that there is a CSS rule for ion-item that prevents the click: pointer-events: none;\nIf I disable the rule, the click works.\nAm I doing something wrong or can you reproduce the issue? ", "code": [], "labels": ["v2"]}
{"project": "codecentric_spring-boot-admin", "title": "Can not build spring-boot-admin-server-ui project", "description": "Hi,\nI download source spring-boot-admin-server-ui project from git but cannot build it, I used nodejs v5.0.0. Please help me resolved this bug. When run:\nnpm run build `     @ ./~/css-loader?-minimize!./third-party/googlefonts/googlefonts.css 6:572-608\nChild extract-text-webpack-plugin:\n[1] ./core/img/spring-logo.png 0 bytes [built] [failed]\n[3] ./core/img/platform-spring-boot.png 0 bytes [built] [failed]\n+ 2 hidden modules <CODE> Thanks, ", "code": ["ERROR in ./core/img/spring-logo.png\nModule parse failed: E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\core\\img\\spring-logo.png Unexpected character '\ufffd' (1:0)\nYou may need an appropriate loader to handle this file type.\nSyntaxError: Unexpected character '\ufffd' (1:0)\n    at Parser.pp$4.raise (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\acorn\\dist\\acorn.js:2221:15)\n    at Parser.pp$7.getTokenFromCode (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\acorn\\dist\\acorn.js:2756:10)\n    at Parser.pp$7.readToken (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\acorn\\dist\\acorn.js:2477:17)\n    at Parser.pp$7.nextToken (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\acorn\\dist\\acorn.js:2468:15)\n    at Parser.parse (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\acorn\\dist\\acorn.js:515:10)\n    at Object.parse (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\acorn\\dist\\acorn.js:3098:39)\n    at Parser.parse (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\lib\\Parser.js:902:15)\n    at DependenciesBlock.<anonymous> (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\lib\\NormalModule.js:104:16)\n    at DependenciesBlock.onModuleBuild (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\webpack-core\\lib\\NormalModuleMixin.js:310:10)\n    at nextLoader (E:\\AngularExample\\spring-boot-admin-master\\spring-boot-admin-server-ui\\node_modules\\webpack\\node_modules\\webpack-core\\lib\\NormalModuleMixin.js:275:25)`\n"], "labels": ["help wanted"]}
{"project": "buefy_buefy", "title": "Numberinput  input digit only", "description": "Numberinput  can input  'e' or 'eeeee'.\nI need Numberinput  input digit number only. ", "code": [], "labels": ["stale"]}
{"project": "sphinx-doc_sphinx", "title": "Create Graphviz graphs from sphinx-apidoc", "description": "Hi,\nI made (more than one month ago) a little patch (against the 24ad0c778dad commit) to implement a new commandline option of apidoc.py: -G (--graph) will add the needed directives in conf.py and *.rst files to generate the inheritance graphs using graphviz ( 'patch' attached) I tried to make a queue patch right here, but I think I did something wrong (I can't do a pull request), then I tried to post my patch in the google group (<URL>, but recieved no response. Hope this helps. PS: If I need to do something more to make your work easier, just tell me and I'll try to. ", "code": [], "labels": ["proposal", "prio:low", "enhancement"]}
{"project": "hashicorp_vagrant", "title": "New list-providers command", "description": "It would be nice to have a new \"list-providers\" command that lists all providers that are available to the current installation of Vagrant, and shows whether they are supported on the current host. ", "code": [], "labels": ["enhancement", "core"]}
{"project": "OpenRCT2_OpenRCT2", "title": "BACKTRACE 44b527", "description": "", "code": [], "labels": ["crash", "backtrace.io"]}
{"project": "pypa_warehouse", "title": "Redirect users to the login view when they don't have permission", "description": "We need to configure Pyramid so that it will redirect users to the login view whenever they don't have permission to do something (maybe conditionally on if they are already logged in). ", "code": [], "labels": ["good first issue"]}
{"project": "spack_spack", "title": "Missing line in spec for `spack environment`", "description": "@scheibelp I've come across a bug in Spack Environments that is stumping me, would you be able to please take a look?  One of the packages is in the DAG and concretization, but it's not printing properly.  I don't know if it would install properly with spack env install, but I think it might not. <CODE> The spack env c3 list and spack spec commands should produce the same result. pkgconf was omitted from spack env c3 list.  It was included in spack env c3 concretize, and is also found in environment.json. Use the features/context branch (#7843) ", "code": ["$ rm -rf var/spack/environments/c3\n$ bin/spack --debug env c3 create\n$ bin/spack --debug env c3 add emacs\n$ bin/spack --debug env c3 concretize\n==> Installing /Users/rpfische/spack/env/var/spack/repos/builtin/packages/emacs/package.py to /var/folders/n2/0ll2lwm50b91f5ppmyggd_g4cdc3y3/T/tmpmp6J4I/repo/packages/emacs\n==> Installing /Users/rpfische/spack/env/var/spack/repos/builtin/packages/ncurses/sed_pgi.patch to /var/folders/n2/0ll2lwm50b91f5ppmyggd_g4cdc3y3/T/tmpmp6J4I/repo/packages/ncurses\n==> Installing /Users/rpfische/spack/env/var/spack/repos/builtin/packages/ncurses/patch_gcc_5.txt to /var/folders/n2/0ll2lwm50b91f5ppmyggd_g4cdc3y3/T/tmpmp6J4I/repo/packages/ncurses\n==> Installing /Users/rpfische/spack/env/var/spack/repos/builtin/packages/ncurses/package.py to /var/folders/n2/0ll2lwm50b91f5ppmyggd_g4cdc3y3/T/tmpmp6J4I/repo/packages/ncurses\n==> Installing /Users/rpfische/spack/env/var/spack/repos/builtin/packages/pkgconf/package.py to /var/folders/n2/0ll2lwm50b91f5ppmyggd_g4cdc3y3/T/tmpmp6J4I/repo/packages/pkgconf\n==> Installing /Users/rpfische/spack/env/var/spack/repos/builtin/packages/zlib/w_patch.patch to /var/folders/n2/0ll2lwm50b91f5ppmyggd_g4cdc3y3/T/tmpmp6J4I/repo/packages/zlib\n==> Installing /Users/rpfische/spack/env/var/spack/repos/builtin/packages/zlib/package.py to /var/folders/n2/0ll2lwm50b91f5ppmyggd_g4cdc3y3/T/tmpmp6J4I/repo/packages/zlib\n$ bin/spack env c3 list -rlI\n========= emacs\n[+]  pxwm7iq  emacs@25.3%clang@9.0.0-apple~X~tls toolkit=gtk arch=darwin-sierra-x86_64 \n[+]  nurizsk      ^ncurses@6.0%clang@9.0.0-apple patches=f84b2708a42777aadcc7f502a261afe10ca5646a51c1ef8b5e60d2070d926b57 ~symlinks~termlib arch=darwin-sierra-x86_64 \n[+]  xmqhozr      ^zlib@1.2.11%clang@9.0.0-apple+optimize+pic+shared arch=darwin-sierra-x86_64 \n$ bin/spack spec -lI emacs\nInput spec\n--------------------------------\n     emacs\n\nConcretized\n--------------------------------\n[+]  pxwm7iq  emacs@25.3%clang@9.0.0-apple~X~tls toolkit=gtk arch=darwin-sierra-x86_64 \n[+]  nurizsk      ^ncurses@6.0%clang@9.0.0-apple patches=f84b2708a42777aadcc7f502a261afe10ca5646a51c1ef8b5e60d2070d926b57 ~symlinks~termlib arch=darwin-sierra-x86_64 \n     iwpioab          ^pkgconf@1.4.0%clang@9.0.0-apple arch=darwin-sierra-x86_64 \n[+]  xmqhozr      ^zlib@1.2.11%clang@9.0.0-apple+optimize+pic+shared arch=darwin-sierra-x86_64 \n"], "labels": ["bug"]}
{"project": "serde-rs_serde", "title": "[Design] type-directed serialisation", "description": "Hi. At the moment, the usage of the de::Deserializer trait seems to work under the assumption that the input syntactically discriminates between scalar, sequence-like and map-like values. I had a go at using serde to implement serialization for lisp-like s-expressions, which only have scalars and lists in the base syntax, and so because most of the visitors call into the de::Deserializer#visit method, I found that I was having to add explicit tags for whether a value was an integer, float, list, or a map. Given that we'll know the type of the value we're attempting to de-serialize at compile time, can you think of any particular reason why it might not be feasible to remove the #visit method, and just rely on types to direct what kind of syntactic construct we should expect? Put another way, if we have a grammar with multiple potential start-rules, I'd like to be able to use the expected type to decide which start-rule to use. ", "code": [], "labels": ["enhancement"]}
{"project": "Security-Onion-Solutions_security-onion", "title": "/usr/local/sbin/nsm_server_del: line 192: [: eq: binary operator expected", "description": "<CODE> Original issue reported on code.google.com by doug.bu...@gmail.com on 24 Jan 2012 at 1:37 ", "code": ["/usr/local/sbin/nsm_server_del: line 192: [: eq: binary operator expected\n"], "labels": ["auto-migrated", "Priority-Medium", "Type-Defect"]}
{"project": "cockroachdb_cockroach", "title": "sql: support postgresql foreign data wrapper", "description": "We'd like to build a large scale CMS with postgresql as source of truth + cockroachdb as denormalized data store for public access. To keep both systems in sync via transactions I'd like to use a foreign data wrapper. As per the documentation of postgresql foreign data wrapper module postgresql executes a few commands on client connection startup such as 'set timezone' etc.. (see documentation: <URL> => F.32.5.) These sql commands are currently not supported by cockroachdb.\nA possible workaround could be to use pg_notify to inform an external application to sync changes. However we'd lose transactions this way which is a blocker. ", "code": [], "labels": ["C-enhancement", "A-sql-pgcompat", "O-community"]}
{"project": "vector-im_riot-web", "title": "Auto-upload images referenced by markdown as an easy CLI way to inline 'em", "description": "Created by @ matthew:matrix.org. ", "code": [], "labels": ["ui/ux", "feature", "p2"]}
{"project": "divio_django-cms", "title": "django.views.i18n.set_language() compatibility", "description": "implementing the default django method  to  sets a user\u2019s language preference (POST to django.views.i18n.set_language())\non a page of django-cms the request is ignored. django.views.i18n.set_language() save the language preference in session[LANGUAGE_SESSION_KEY] and in browser cookie settings.LANGUAGE_COOKIE_NAME\nIn this case, the view cms.views.details does not properly recognize the language set.\nProbably , language codes in url  (used in redirect) is the preferred choice in the definition of language to be applied Contest : Python 2.7.8\nDjango==1.7.1\ndjango-cms==3.0.7 Note:\nI installed django-cms under url \"/cms\"\nurl(r'^cms/', include('cms.urls',None,'cms')), ", "code": [], "labels": ["kind: bug", "status: accepted"]}
{"project": "Semantic-Org_Semantic-UI-React", "title": "handle Popup with ref", "description": "Support to handle Popup component with ref prop. Improve DX Something like: ", "code": [], "labels": ["wontfix"]}
{"project": "bcit-ci_CodeIgniter", "title": "ORDER BY QUERY BUILDER ISSUE", "description": "I hava a test query :\nCode:\n$this->db->where('1 IS NOT NULL',NULL,FALSE)->WHERE('X>','0')->FROM('X')->ORDER_BY('X','ASC')->count_all_results(); and it is generating error: Code:\nError Number: 42000/1033 [Microsoft][ODBC Driver 11 for SQL Server][SQL Server]The ORDER BY clause is invalid in views, inline functions, derived tables, subqueries, and common table expressions, unless TOP, OFFSET or FOR XML is also specified. SELECT COUNT(*) AS \"numrows\" FROM ( SELECT * FROM \"X\" WHERE 1 IS NOT NULL AND \"X\" > '0' ORDER BY \"X\" ASC ) CI_count_all_results ", "code": [], "labels": ["Regression", "Bug"]}
{"project": "wazuh_wazuh", "title": "API: Flask - Migration - HTTPS configuration", "description": "This issue is related to #2413 We must consider the use case of upgrading node API to python API. Some configuration is written in nodejs code, so we should adapt to the new solution. Furthermore, some params could not make sense for python API. Tasks: ", "code": [], "labels": ["API"]}
{"project": "googleapis_google-cloud-java", "title": "DataSore does not return any result when cursor pointing to entity gets updated but retains its position in list", "description": "I'm using google datastore to get data of a user: This is what i'm trying to do: ", "code": [], "labels": ["priority: p2", "type: question", "api: datastore"]}
{"project": "ansible_ansible", "title": "gather_timeout is used by \"ansible-playbook\" but not by \"ansible\"", "description": "Configuration gather_timeout in ansible.cfg <CODE> gather_timeout = 30 in ansible.cfg From Debian Stretch (testing) to Debian Jessie (8.5) I was caught by the bug #10779 and while trying to increase the timeout through gather_timeout, I noticed it worked only for ansible-playbook, not ansible. Although the gather_timeout is set to 30, this command always fails after 13 sec (ie. 3s for sudo password input, plus the 10s default gather_timeout): <CODE> The sudo lsblk command duration itself is about 14s: <CODE> While the ansible-playbook is OK: <CODE> Both commands ansible and ansible-playbook should have read ansible.cfg configuration in the same way. Only ansible-playbook seems to have read ansible.cfg's gather_timeout configuration. ", "code": ["ansible 2.2.0 (devel 1c33b5a9f0) last updated 2016/08/30 12:20:57 (GMT +200)\n  lib/ansible/modules/core: (detached HEAD 5310bab12f) last updated 2016/08/30 12:21:13 (GMT +200)\n  lib/ansible/modules/extras: (detached HEAD 2ef4a34eee) last updated 2016/08/30 12:21:14 (GMT +200)\n  config file = /home/.../ansible.cfg\n  configured module search path = Default w/o overrides\n", "ansible -i '192.168.1.123,' -u testuser all --sudo --ask-sudo-pass -m setup\nSUDO password:\n192.168.1.123 | FAILED! => {\n    \"changed\": false,\n    \"cmd\": \"/bin/lsblk --list --noheadings --paths --output NAME,UUID\",\n    \"failed\": true,\n    \"msg\": \"Traceback (most recent call last):\\n  File \\\"/tmp/ansible_tYiFjl/ansible_modlib.zip/ansible/module_utils/basic.py\\\", line 2203, in run_command\\n    rfd, wfd, efd = selec\nt.select(rpipes, [], rpipes, 1)\\n  File \\\"/tmp/ansible_tYiFjl/ansible_modlib.zip/ansible/module_utils/facts.py\\\", line 116, in _handle_timeout\\n    raise TimeoutError(error_message)\n\\nTimeoutError: Timer expired\\n\",\n    \"rc\": 257\n}\n", "time sudo /bin/lsblk --list --noheadings --paths --output NAME,UUID\n/dev/fd0\n/dev/sda\n/dev/sda1  bf79e994-5016-80d6-405c-d18d01a59b1d\n/dev/md0\n/dev/md0p1 eaee12dd-0291-4980-9c9a-9309da3b1019\n/dev/md0p2\n/dev/md0p5 59ec8bb7-a77d-4bee-b555-8e75364c99ec\n/dev/md0p6 7628ee5b-face-4c96-868f-9dc52f230c2c\n/dev/sdb\n/dev/sdb1  bf79e994-5016-80d6-405c-d18d01a59b1d\n/dev/md0\n/dev/md0p1 eaee12dd-0291-4980-9c9a-9309da3b1019\n/dev/md0p2\n/dev/md0p5 59ec8bb7-a77d-4bee-b555-8e75364c99ec\n/dev/md0p6 7628ee5b-face-4c96-868f-9dc52f230c2c\n/dev/sr0\n\nreal    0m13.139s\nuser    0m0.004s\nsys     0m0.012s\n", "ansible-playbook playbooks/Servers.yml -l 192.168.1.123 --sudo --ask-sudo-pass\n...\nPLAY [Servers] *****************************************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.1.123]\n...\n"], "labels": ["bug", "affects_2.2"]}
{"project": "qgis_QGIS", "title": "Impossible to see selection or current identify feature if using data defined colours", "description": "Author Name: Nyall Dawson (@nyalldawson)\nOriginal Redmine Issue: 9551\nAffected QGIS version: master Assignee: Martin Dobias I'm marking this as a blocker as it's a regression from 2.0. If a layer uses data defined colours, it's currently impossible to see which feature is highlighted by either a selection or the identify tool. It looks like QGIS is just redrawing the selection/identify result using the data defined colour, rather then the selection/identify colour. ", "code": [], "labels": ["Bug"]}
{"project": "OpenTTD_OpenTTD", "title": "left-mouse-button-scroll", "description": "aapo opened the ticket and wrote: Attachments Reported version: trunk\nOperating system: All ", "code": [], "labels": ["patch from FlySpray", "flyspray", "Interface"]}
{"project": "ariya_phantomjs", "title": "Remote debugging not working on PhantomJs (2.1.1) (Windows 10)", "description": "Version 2.1.1 Just try to enable remote debugger - specify any known available port --remote-debugger-port=XXXX Then use netstat -abno and nothing will appear as listening on port XXXX\nAttempts to connect using chrome to that port fail for site not found\nNo visible errors in phantomjs debug console output Windows 10 Binary ", "code": [], "labels": ["stale"]}
{"project": "realm_realm-java", "title": "Low Memory 1GB device and Realm Crashes", "description": "We are getting lots of invalid argument bad file format crashes on various low memory devices on Android 4.x. The only thing they have in common is all the devices have only 1gb of installed ram. Device range from 2013 models to early 2015 models and cpus include both mediatek and Qualcomm. Realm encryption is enabled and we suspect that may be the culprit, for now. We are in the process of purchasing a crashing device to track the source but want to see if the realm team has seen these type of strange crashes. ", "code": [], "labels": ["T-Bug"]}
{"project": "framework7io_framework7", "title": "Pass HTML to Smart Select?", "description": "Can we make it that you can pass html to a smart select? Like bold or even style tags? ", "code": [], "labels": ["outdated"]}
{"project": "microsoft_vcpkg", "title": "Library request: QuantLib", "description": "<URL> I tried to create the port myself, but it is beyond me. They have both CMake and MSBuild projects, but neither appears entirely usable: As for building dynamic, there is the additional problem that neither the word \"dllexport\" nor any .def file appears anywhere in the source tree. Consequently, the DLL that the CMake project produces has no exported symbols. Changing the .vcxproj to build a DLL leads to the same result. Applying the workaround from <URL> produces an import library, but I have not yet tested if it works. ", "code": [], "labels": ["new port request - consider making a PR!"]}
{"project": "ionic-team_ionic", "title": "bug: Input label and icon overlap", "description": "Type: bug Platform: all See <URL> When I try to put an icon in front of a list with an input, the input label and item icon overlap. I debugged a bit and the padding from class item-icon-left gets overwritten with the no-padding from class item-input. If I add a css line that reinstates the padding-left, the bug goes away.  ", "code": [], "labels": ["v1"]}
{"project": "highcharts_highcharts", "title": "After series update null values show instead of actual data", "description": "We have a Line chart graph with 3 series and nulls in between series, after 10 seconds we have a graph update with new series. The whole graph should shift left and show new lines, well new series. For the first time the Graph show all 3 series with no errors, but after the 10 seconds update, the values at the end of the line where before the update were the null values, now show null values for the same TimeStamp as before where the actual values were present. A bit confusing i know, check the live Demo. After research i found out that on the Highcharts version 7.0.4 the graph behaves as expected and it works as it should. <URL> Higcharts: 7.1.2 Firefox, chrome ", "code": [], "labels": ["Type: Duplicate"]}
{"project": "microsoft_TypeScript", "title": "Unable to overload function signatures via global", "description": "TypeScript Version:  Version 2.9.0-dev.20180426 overload, global: Code Expected behavior:\nNo errors. Actual behavior:\n\"Overload signatures must all be exported or non-exported.\" Playground Link: \nN/A Related Issues:\n#16430 ", "code": [], "labels": ["Bug", "Fixed"]}
{"project": "holoviz_holoviews", "title": "Plot a line by specifying slope and intercept?", "description": "Is there an simple way to plot a line by specifying slope and intercept? VLine and HLine are extreme cases. In R there's a function named abline which can do this easily. <URL> ", "code": [], "labels": ["feature"]}
{"project": "CartoDB_cartodb", "title": "Map not created after importing dataset from synced URL dataset", "description": "This problem is reproduced: The dataset is imported but the map is not created. cc @xavijam ", "code": [], "labels": ["minor", "Frontend", "bug", "3 - Done"]}
{"project": "arangodb_arangodb", "title": "invalid fullCount value returned from AQL", "description": "Perhaps this is intended but I feel that I should let you know in case it is not. with the following collection named \"test\": <CODE> and the following AQL in shell: <CODE> we get \"stats\" : \"fullCount\" : 3 when the actual result is only 2. the interesting thing is that the following AQL: <CODE> (I simply removed the || entry.name=='foo' part)\nreturns the correct number \"stats\" : \"fullCount\" : 2 the LIMITS actually do not affect the above AQLs from what I saw on my tests. Again, I am not sure if this is inteded since the document states \"This sub-attribute will contain the number of documents in the result before the last LIMIT in the query was applied. It can be used to count the number of documents that match certain filter criteria, but only return a subset of them, in one go.\" and I can't really understand what applies here. ", "code": ["[{\"_id\":\"test/1524810864350\",\"_key\":\"1524810864350\",\"_rev\":\"1524823512798\",\"entries\":[{\"name\":\"foo\"},{\"name\":\"bar\"}]},{\"_id\":\"test/1524827838174\",\"_key\":\"1524827838174\",\"_rev\":\"1524832163550\",\"entries\":[{\"name\":\"hello\"},{\"name\":\"world\"}]},{\"_id\":\"test/1524833277662\",\"_key\":\"1524833277662\",\"_rev\":\"1524836226782\",\"entries\":[{\"name\":\"foobar\"},{\"name\":\"bar\"}]}]\n", "stmt = db._createStatement({ \"count\":true, \"options\":{\"fullCount\":true}, \"query\": \"FOR d IN test LET entries = d.entries LET found = (FOR entry IN entries FILTER entry.name == 'bar' || entry.name=='foo' LIMIT 1 RETURN true) FILTER LENGTH(found) > 0 LIMIT 10 RETURN d\"});  cursor = stmt.execute(); cursor.getExtra();\n", "stmt = db._createStatement({ \"count\":true, \"options\":{\"fullCount\":true}, \"query\": \"FOR d IN test LET entries = d.entries LET found = (FOR entry IN entries FILTER entry.name == 'bar' LIMIT 1 RETURN true) FILTER LENGTH(found) > 0 LIMIT 10 RETURN d\"});  cursor = stmt.execute(); cursor.getExtra();\n"], "labels": ["3 AQL", "1 Bug"]}
{"project": "iterative_dvc", "title": "Don't forget to checkout state files on 'dvc merge'", "description": "Currently only symlinks are restored, which is not correct. ", "code": [], "labels": ["bug"]}
{"project": "scala-js_scala-js", "title": "Change JSDelete to contain a JS{Dot, Bracket}Select", "description": "Follow-up of #1028. Instead of implicitly assuming JSDelete is a bracket select, make this explicit by removing its prop argument and requiring the containing tree to be a select. This is consistent with Assign. ", "code": [], "labels": ["internal"]}
{"project": "postmanlabs_postman-app-support", "title": "Postman throws error and when environment value is null", "description": "<CODE> <CODE>  Steps to Reproduce: Request: <CODE> Response: <CODE> Tests: <CODE> Above works fin when requested manually, hangs when requested in collection run or throws error in newman with:\nCannot read property 'toString' of null. ", "code": ["Postman for Mac\nVersion 5.5.3 (5.5.3)\nOS X 10.13.3 / x64\n", "Errors were encountered running your collection: Objectmessage: \"Cannot read property 'toString' of null\"name: \"TypeError\"stack: \"TypeError: Cannot read property 'toString' of null\u21b5    at PostmanVariable.toString (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/collection/variable.js:108:34)\u21b5    at /Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/superstring/index.js:221:53\u21b5    at /Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/superstring/index.js:47:23\u21b5    at RegExp.[Symbol.replace] (<anonymous>)\u21b5    at String.replace (native)\u21b5    at SuperString.replace (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/superstring/index.js:45:34)\u21b5    at Substitutor.parse (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/superstring/index.js:132:27)\u21b5    at Function.replaceSubstitutions (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/collection/property.js:222:69)\u21b5    at Function.<anonymous> (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/collection/property.js:253:25)\u21b5    at /Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/collection/property.js:247:40\u21b5    at /Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/node_modules/lodash/lodash.js:4944:15\u21b5    at baseForOwn (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/node_modules/lodash/lodash.js:3001:24)\u21b5    at Function.forOwn (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/node_modules/lodash/lodash.js:13002:24)\u21b5    at Function.<anonymous> (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/collection/property.js:246:19)\u21b5    at /Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/lib/collection/property.js:247:40\u21b5    at /Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/node_modules/lodash/lodash.js:4944:15\u21b5    at baseForOwn (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/node_modules/lodash/lodash.js:3001:24)\u21b5    at Function.forOwn (/Applications/Postman.app/Contents/Resources/app/node_modules/postman-collection/node_modules/lodash/lodash.js:13002:24)\"__proto__: Object__defineGetter__: __defineGetter__()__defineSetter__: __defineSetter__()__lookupGetter__: __lookupGetter__()__lookupSetter__: __lookupSetter__()constructor: Object()hasOwnProperty: hasOwnProperty()isPrototypeOf: isPrototypeOf()arguments: nullcaller: nulllength: 1name: \"isPrototypeOf\"__proto__: ()[[FunctionLocation]]: <unknown>propertyIsEnumerable: propertyIsEnumerable()toLocaleString: toLocaleString()toString: toString()valueOf: valueOf()get __proto__: __proto__()set __proto__: __proto__()arguments: nullcaller: nulllength: 1name: \"set __proto__\"__proto__: ()\nonEndRun @ runner.js:247328\n", "PATCH url HTTP/1.1\nHost: qa-secure1.host.com\nAuthorization: Bearer eyJ0eXAiOi----token\nContent-Type: application/json\nCache-Control: no-cache\nPostman-Token: a11247d9-f2e6-e6b7-edfd-1cae0e26c3c3\n\n[\n  { \"op\": \"replace\", \"path\": \"/address1\", \"value\": \"US\"},\n  { \"op\": \"replace\", \"path\": \"/address2\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/city\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/state\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/zip\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/primaryPhone\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/secondaryPhone\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/fax\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/email\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/notes\", \"value\": \"\"},\n  { \"op\": \"replace\", \"path\": \"/latitude\", \"value\": \"37.09024\"},\n  { \"op\": \"replace\", \"path\": \"/longitude\", \"value\": \"-95.712891\"},\n  { \"op\": \"replace\", \"path\": \"/fullAddress\", \"value\": \"US\"}\n]\n", "{\n    \"customerId\": 10262666,\n    \"industryTypeId\": \"[Other]\",\n    \"name\": \"customer alpha\",\n    \"address1\": \"US\",\n    \"address2\": \"\",\n    \"city\": \"\",\n    \"state\": \"\",\n    \"zip\": \"\",\n    \"primaryPhone\": \"\",\n    \"secondaryPhone\": \"\",\n    \"fax\": \"\",\n    \"isActive\": true,\n    \"creationDate\": \"2018-02-15T14:05:13.233\",\n    \"lastModDate\": \"2018-02-15T14:14:38.320061-05:00\",\n    \"portalId\": 90056,\n    \"moduleID\": null,\n    \"email\": \"\",\n    \"notes\": \"\",\n    \"createdBy\": \"6b04388b-22be-7a37-b69f-b398f72d4668@email.com\",\n    \"updatedBy\": \"6b04388b-22be-7a37-b69f-b398f72d4668@email.com\",\n    \"dataGroupId\": null,\n    \"listId\": null,\n    \"editSequence\": null,\n    \"lastImport\": null,\n    \"lastExport\": null,\n    \"termsId\": null,\n    \"customerTypeId\": null,\n    \"customerType\": null,\n    \"businessUnitId\": null,\n    \"countryId\": \"US\",\n    \"lastOpenedBy\": null,\n    \"lastOpenedTime\": null,\n    \"lastOpenedLocation\": null,\n    \"parentId\": null,\n    \"billToParent\": null,\n    \"latitude\": 37.09024,\n    \"longitude\": -95.712891,\n    \"fullAddress\": \"US\",\n    \"doNotText\": true,\n    \"cleanPrimaryPhone\": \"\",\n    \"cleanSecondaryPhone\": \"\",\n    \"contacts\": [],\n    \"customFields\": [],\n    \"taxId\": null\n}\n", "tests[\"Status code is 200\"] = responseCode.code === 200;\ntests[\"Response time is less than 5 seconds\"] = responseTime < 5000;\n\nvar obj = JSON.parse(responseBody);\n    \ntests[\"portalId matches environment var\"] = environment.portal_id == obj.portalId;\ntests[\"customerId is \" + obj.customerId ] = responseBody.has(\"customerId\");\ntests[\"industryTypeId is \" + obj.industryTypeId ] = responseBody.has(\"industryTypeId\");\ntests[\"name is \" + obj.name ] = responseBody.has(\"name\");\ntests[\"address1 is \" + obj.address1 ] = responseBody.has(\"address1\");\ntests[\"address2 is \" + obj.address2 ] = responseBody.has(\"address2\");\ntests[\"city is \" + obj.city ] = responseBody.has(\"city\");\ntests[\"state is \" + obj.state ] = responseBody.has(\"state\");\ntests[\"zip is \" + obj.zip ] = responseBody.has(\"zip\");\ntests[\"primaryPhone is \" + obj.primaryPhone ] = responseBody.has(\"primaryPhone\");\ntests[\"secondaryPhone is \" + obj.secondaryPhone ] = responseBody.has(\"secondaryPhone\");\ntests[\"fax is \" + obj.fax ] = responseBody.has(\"fax\");\ntests[\"isActive is \" + obj.isActive ] = responseBody.has(\"isActive\");\ntests[\"creationDate is \" + obj.creationDate ] = responseBody.has(\"creationDate\");\ntests[\"lastModDate is \" + obj.lastModDate ] = responseBody.has(\"lastModDate\");\ntests[\"portalId is \" + obj.portalId ] = responseBody.has(\"portalId\");\ntests[\"moduleID is \" + obj.moduleID ] = responseBody.has(\"moduleID\");\ntests[\"email is \" + obj.email ] = responseBody.has(\"email\");\ntests[\"notes is \" + obj.notes ] = responseBody.has(\"notes\");\ntests[\"createdBy is \" + obj.createdBy ] = responseBody.has(\"createdBy\");\ntests[\"updatedBy is \" + obj.updatedBy ] = responseBody.has(\"updatedBy\");\ntests[\"dataGroupId is \" + obj.dataGroupId ] = responseBody.has(\"dataGroupId\");\ntests[\"listId is \" + obj.listId ] = responseBody.has(\"listId\");\ntests[\"editSequence is \" + obj.editSequence ] = responseBody.has(\"editSequence\");\ntests[\"lastImport is \" + obj.lastImport ] = responseBody.has(\"lastImport\");\ntests[\"lastExport is \" + obj.lastExport ] = responseBody.has(\"lastExport\");\ntests[\"termsId is \" + obj.termsId ] = responseBody.has(\"termsId\");\ntests[\"customerTypeId is \" + obj.customerTypeId ] = responseBody.has(\"customerTypeId\");\ntests[\"businessUnitId is \" + obj.businessUnitId ] = responseBody.has(\"businessUnitId\");\ntests[\"countryId is \" + obj.countryId ] = responseBody.has(\"countryId\");\ntests[\"lastOpenedBy is \" + obj.lastOpenedBy ] = responseBody.has(\"lastOpenedBy\");\ntests[\"lastOpenedTime is \" + obj.lastOpenedTime ] = responseBody.has(\"lastOpenedTime\");\ntests[\"lastOpenedLocation is \" + obj.lastOpenedLocation ] = responseBody.has(\"lastOpenedLocation\");\ntests[\"parentId is \" + obj.parentId ] = responseBody.has(\"parentId\");\ntests[\"billToParent is \" + obj.billToParent ] = responseBody.has(\"billToParent\");\ntests[\"latitude is \" + obj.latitude ] = responseBody.has(\"latitude\");\ntests[\"longitude is \" + obj.longitude ] = responseBody.has(\"longitude\");\ntests[\"fullAddress is \" + obj.fullAddress ] = responseBody.has(\"fullAddress\");\ntests[\"doNotText is \" + obj.doNotText ] = responseBody.has(\"doNotText\");\ntests[\"cleanPrimaryPhone is \" + obj.cleanPrimaryPhone ] = responseBody.has(\"cleanPrimaryPhone\");\ntests[\"cleanSecondaryPhone is \" + obj.cleanSecondaryPhone ] = responseBody.has(\"cleanSecondaryPhone\");\ntests[\"contacts is \" + obj.contacts ] = responseBody.has(\"contacts\");\ntests[\"customFields is \" + obj.customFields ] = responseBody.has(\"customFields\");\n    \n//set back to the original values      \ntests[\"address1 matches environment \"] = environment.original_customer_address1 == obj.address1; \ntests[\"address2 matches environment \"] = environment.original_customer_address2 == obj.address2; \ntests[\"city matches environment \"] = environment.original_customer_city == obj.city; \ntests[\"state matches environment \"] = environment.original_customer_state == obj.state; \ntests[\"zip matches environment \"] = environment.original_customer_zip == obj.zip; \ntests[\"primaryPhone matches environment \"] = environment.original_customer_primaryPhone == obj.primaryPhone; \ntests[\"secondaryPhone matches environment \"] = environment.original_customer_secondaryPhone == obj.secondaryPhone; \ntests[\"fax matches environment \"] = environment.original_customer_fax == obj.fax;  \ntests[\"email matches environment \"] = environment.original_customer_email == obj.email; \ntests[\"notes matches environment \"] = environment.original_customer_notes == obj.notes; \ntests[\"fullAddress matches environment \"] = environment.original_customer_fullAddress == obj.fullAddress;\n"], "labels": ["needs-investigation", "runtime", "bug"]}
{"project": "assimp_assimp", "title": "Loading IFC4 content", "description": "Is IFCV4 supported ? regards Eddy ", "code": [], "labels": ["feature request"]}
{"project": "ValveSoftware_Proton", "title": "Pathologic Classic HD (384110)", "description": "Distro: Linux Mint 19.1 Tessa (64 bit)\nGPU: Vega 56\nDriver/LLVM version: Mesa 19.1.0-devel/9.0.0\nKernel version: 5.0.7-050007-generic\nProton version: 4.2-3 On launch there is a black screen for a couple of seconds and then the game exits.\nmedia_info.txt\nsteam-384110.log\nsystem_info.txt in the log I see quartz related things, and videos appear to be wmv Just launch the game ", "code": [], "labels": ["Game compatibility - Unofficial"]}
{"project": "ant-design_ant-design-mobile", "title": "Antd t-mobile external introduction of CSS file is invalid", "description": "  ", "code": [], "labels": ["Invalid"]}
{"project": "microsoft_vscode", "title": "Displays visible trailing whitespaces on sidebar's folder name", "description": " Currently you can create a folder with any trailing whitespaces they are difficult to find and make confuse. Could it be? Reproduce environment:\nOS: macOS 10.13.3\nVSCode version: 1.24.1 ", "code": [], "labels": ["file-explorer"]}
{"project": "appium_appium", "title": "org.openqa.selenium.SessionNotCreatedException: Unable to create new remote session.", "description": "I am facing issues while running my test scripts for android and getting below exception Kindly Help As Run option is also not showing for test methods. //Environment Details:\nDriver: Android driver\nOS version:10.13.6 --MACOs -Sierra\nJava Client version:4.1.2\nappium version:v1.6.3 //Exception Trace log//\nappium --session-override -p 4723\njava.lang.UNIXProcess@12c8a2c0\n[Appium] Welcome to Appium v1.6.3\n[Appium] Non-default server args:\n[Appium]   sessionOverride: true\nError: listen EADDRINUSE 0.0.0.0:4723\nat Object._errnoException (util.js:1022:11)\nat _exceptionWithHostPort (util.js:1044:20)\nat Server.setupListenHandle [as _listen2] (net.js:1367:14)\nat listenInCluster (net.js:1408:12)\nat doListen (net.js:1517:7)\nat _combinedTickCallback (internal/process/next_tick.js:141:11)\nat process._tickCallback (internal/process/next_tick.js:180:9) org.openqa.selenium.SessionNotCreatedException: Unable to create new remote session. desired capabilities = Capabilities [{app=/Users/a1yiot05/idea Projects/selfcare-automation/App/playstoreSelfcareQA-206-4.3.2.0_master.apk, noReset=false, newCommandTimeout=0, platformName=Android, deviceName=ZY2222N9J7, avd=ZY2222N9J7, autoAcceptAlerts=true}], required capabilities = Capabilities [{}]\nBuild info: version: '3.3.1', revision: '5234b325d5', time: '2017-03-10 09:10:29 +0000'\nSystem info: host: 'LTA1YIOT05-MAC.local', ip: 'fe80:0:0:0:8d3:d969:a3a4:dbc2%en0', os.name: 'Mac OS X', os.arch: 'x86_64', os.version: '10.13.6', java.version: '1.8.0_151'\nDriver info: driver.version: AndroidDriver at org.openqa.selenium.remote.ProtocolHandshake.createSession(ProtocolHandshake.java:126)\nat org.openqa.selenium.remote.HttpCommandExecutor.execute(HttpCommandExecutor.java:141)\nat io.appium.java_client.remote.AppiumCommandExecutor.execute(AppiumCommandExecutor.java:69)\nat org.openqa.selenium.remote.RemoteWebDriver.execute(RemoteWebDriver.java:604)\nat io.appium.java_client.DefaultGenericMobileDriver.execute(DefaultGenericMobileDriver.java:40)\nat io.appium.java_client.AppiumDriver.execute(AppiumDriver.java:1)\nat io.appium.java_client.android.AndroidDriver.execute(AndroidDriver.java:1)\nat org.openqa.selenium.remote.RemoteWebDriver.startSession(RemoteWebDriver.java:244)\nat org.openqa.selenium.remote.RemoteWebDriver.(RemoteWebDriver.java:131)\nat org.openqa.selenium.remote.RemoteWebDriver.(RemoteWebDriver.java:144)\nat io.appium.java_client.DefaultGenericMobileDriver.(DefaultGenericMobileDriver.java:36)\nat io.appium.java_client.AppiumDriver.(AppiumDriver.java:114)\nat io.appium.java_client.AppiumDriver.(AppiumDriver.java:132)\nat io.appium.java_client.android.AndroidDriver.(AndroidDriver.java:92)\nat com.airtel.appium.common.helper.common.DriverHelper.initiateAndroidInstance(DriverHelper.java:78)\nat Controller.eBillsi.TC_eBill_02_manager.validateTest(TC_eBill_02_manager.java:25)\nat com.airtel.appium.Ebillsi.TC_eBill_02.TC_eBill_02(TC_eBill_02.java:24)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:498)\nat org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:124)\nat org.testng.internal.Invoker.invokeMethod(Invoker.java:571)\nat org.testng.internal.Invoker.invokeTestMethod(Invoker.java:707)\nat org.testng.internal.Invoker.invokeTestMethods(Invoker.java:979)\nat org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125)\nat org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109)\nat org.testng.TestRunner.privateRun(TestRunner.java:648)\nat org.testng.TestRunner.run(TestRunner.java:505)\nat org.testng.SuiteRunner.runTest(SuiteRunner.java:455)\nat org.testng.SuiteRunner.runSequentially(SuiteRunner.java:450)\nat org.testng.SuiteRunner.privateRun(SuiteRunner.java:415)\nat org.testng.SuiteRunner.run(SuiteRunner.java:364)\nat org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)\nat org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:84)\nat org.testng.TestNG.runSuitesSequentially(TestNG.java:1187)\nat org.testng.TestNG.runSuitesLocally(TestNG.java:1116)\nat org.testng.TestNG.runSuites(TestNG.java:1028)\nat org.testng.TestNG.run(TestNG.java:996)\nat org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72)\nat org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123) My POM File \n4.0.0 <CODE> ", "code": ["<groupId>appium.framework</groupId>\n<artifactId>appium.framework.1.0.0</artifactId>\n<version>1.0-SNAPSHOT</version>\n<properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <jre.level>1.8</jre.level>\n    <jdk.level>1.8</jdk.level>\n</properties>\n<build>\n    <plugins>\n        <!-- Compiler plug-in -->\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <version>3.6.2</version>\n            <configuration>\n                <source>1.8</source>\n                <target>1.8</target>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n<dependencies>\n    <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-core</artifactId>\n        <version>2.9.0</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-api</artifactId>\n        <version>2.9.0</version>\n    </dependency>\n    <!-- Extent Report dependency -->\n    <dependency>\n        <groupId>com.relevantcodes</groupId>\n        <artifactId>extentreports</artifactId>\n        <version>2.41.2</version>\n    </dependency>\n    <dependency>\n        <groupId>org.testng</groupId>\n        <artifactId>testng</artifactId>\n        <version>6.11</version> <!-- Issue was coming with latest testng jar 6.9.13.6 after script execution... -->\n    </dependency>\n    <dependency>\n        <groupId>org.json</groupId>\n        <artifactId>json</artifactId>\n        <version>20160810</version>\n    </dependency>\n    <dependency>\n        <groupId>net.sf.opencsv</groupId>\n        <artifactId>opencsv</artifactId>\n        <version>2.3</version>\n    </dependency>\n    <!-- https://mvnrepository.com/artifact/io.rest-assured/rest-assured -->\n    <dependency>\n        <groupId>io.rest-assured</groupId>\n        <artifactId>rest-assured</artifactId>\n        <version>3.0.3</version>\n    </dependency>\n    <dependency>\n        <groupId>com.google.code.gson</groupId>\n        <artifactId>gson</artifactId>\n        <version>2.3.1</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.poi</groupId>\n        <artifactId>poi-ooxml</artifactId>\n        <version>3.11-beta2</version>\n    </dependency>\n    <!-- https://mvnrepository.com/artifact/javax.xml/jaxb-api -->\n    <dependency>\n        <groupId>javax.xml</groupId>\n        <artifactId>jaxb-api</artifactId>\n        <version>2.1</version>\n    </dependency>\n    <!-- https://mvnrepository.com/artifact/com.flipkart.zjsonpatch/zjsonpatch -->\n    <dependency>\n        <groupId>com.flipkart.zjsonpatch</groupId>\n        <artifactId>zjsonpatch</artifactId>\n        <version>0.3.4</version>\n    </dependency>\n    <!-- https://mvnrepository.com/artifact/com.jayway.jsonpath/json-path -->\n    <dependency>\n        <groupId>com.jayway.jsonpath</groupId>\n        <artifactId>json-path</artifactId>\n        <version>2.4.0</version>\n    </dependency>\n    <!-- https://mvnrepository.com/artifact/com.github.fge/json-schema-validator -->\n    <dependency>\n        <groupId>com.github.fge</groupId>\n        <artifactId>json-schema-validator</artifactId>\n        <version>2.2.6</version>\n    </dependency>\n    <dependency>\n        <groupId>com.googlecode.json-simple</groupId>\n        <artifactId>json-simple</artifactId>\n        <version>1.1.1</version>\n    </dependency>\n    <dependency>\n        <groupId>com.oracle</groupId>\n        <artifactId>ojdbc6</artifactId>\n        <version>11.2.0.3</version>\n    </dependency>\n    <dependency>\n        <groupId>org.mongodb</groupId>\n        <artifactId>mongo-java-driver</artifactId>\n        <version>3.4.1</version>\n    </dependency>\n    <dependency>\n        <groupId>com.aerospike</groupId>\n        <artifactId>aerospike-client</artifactId>\n        <version>4.0.6</version>\n    </dependency>\n    <dependency>\n        <groupId>com.jcraft</groupId>\n        <artifactId>jsch</artifactId>\n        <version>0.1.53</version>\n    </dependency>\n    <dependency>\n        <groupId>org.testng</groupId>\n        <artifactId>testng</artifactId>\n        <version>6.13.1</version>\n    </dependency>\n    <dependency>\n        <groupId>io.appium</groupId>\n        <artifactId>java-client</artifactId>\n        <version>4.1.2</version>\n    </dependency>\n    <dependency>\n        <groupId>org.seleniumhq.selenium</groupId>\n        <artifactId>selenium-server-standalone</artifactId>\n        <version>2.53.0</version>\n    </dependency>\n    <dependency>\n        <groupId>com.google.guava</groupId>\n        <artifactId>guava</artifactId>\n        <version>21.0</version>\n    </dependency>\n    <dependency>\n        <groupId>org.seleniumhq.selenium</groupId>\n        <artifactId>selenium-firefox-driver</artifactId>\n        <version>3.3.1</version>\n    </dependency>\n</dependencies>\n"], "labels": ["NeedsInfo", "NotABug"]}
{"project": "openshift_origin", "title": "Authentication extended tests don't use core.sh", "description": "Authentication extended tests currently use test/extended/authentication.sh for set-up, but this makes it so that one cannot choose to run an arbitrary test from one starting point and, if more authentication tests are added that do not require that set-up, one would fail to run all authentication tests as they require different set-ups. We need to move that set-up into the ginkgo BeforeEach hook and guard the set-up work with a sanity check so we don't re-setup when we don't need to, a la Kube's e2e. ", "code": [], "labels": ["area/tests", "priority/P3"]}
{"project": "magento_magento2", "title": "Customer sign in renders webshop unresponsive", "description": "This in fact doesn't happen with all customer accounts, just with a single account in my webshop. The account has been created earlier, but had been removed and recreated later on. Ever since being recreated, it's impossible for the customer to navigate through the webshop and the account section after signing in. I've checked what I could check: MySQL doesn't seem to be the culprit as the queries run through the database quickly. Nginx and Varnish both aren't the culprit, based on the top output and neither is redis, which has a very low memory usage. PHP-FPM does seem to be the problem here: it keeps running at ~98% CPU usage (let's round it up to 100%), but stays rather low on memory, eventhough the memory usage seems to be rising slowly. I've set the server to allow 1GB of memory for PHP processes which should be more than enough. ", "code": [], "labels": ["Issue: Format is valid", "Issue: Clear Description"]}
{"project": "phpmyadmin_phpmyadmin", "title": "phpmyadmin ALMOST works", "description": "Hi I have installed: PhP5.0 (with mysqli, mysql, mbstring extensions)\nMySQl 5\non IIS Finally phpMyAdmin 2.10. My problems are: when i try and access the php page for myphpadmin (index.php) I am met with \u2018php error\u2019 in red then when I press \u2018refresh\u2019 am taken to a basic mpa screen. I am able to to view all my databases but not make any changes ie (not even change the theme of the control panel). I have changed the config.default file to add mysql password which has atleast allowed me to login. I feel I am almost there but am sure I have missed something quite basic. Any ideas? Ravster73 - Original URL: <URL>\n- Original author: ravster73\n- Found in version: Latest_Git ", "code": [], "labels": ["question"]}
{"project": "scala-js_scala-js", "title": "The linker must check the validity of inheritance relationships", "description": "Some examples: I'm not sure yet whether this should go to 0.6.x or 1.x. ", "code": [], "labels": ["enhancement"]}
{"project": "ant-design_ant-design", "title": "antd\u7a7f\u68ad\u6846\u6709bug,\u4f7f\u7528\u9ed8\u8ba4\u7684\u975echeckStrictly\u6a21\u5f0f,\u9009\u4e2d\u7236\u8282\u70b9,\u5b50\u8282\u70b9\u65e0\u6cd5\u53d6\u6d88\u9009\u62e9", "description": "The issue which is not created via <URL> will be closed immediately. \u6ce8\u610f\uff1a\u4e0d\u662f\u7528 <URL> \u521b\u5efa\u7684 issue \u4f1a\u88ab\u7acb\u5373\u5173\u95ed\u3002\n<URL>\n\u672c\u5730\u548c\u5728codesandbox\u6d4b\u8bd5\u7ed3\u679c\u662f\u4e00\u81f4\u7684 ", "code": [], "labels": ["Invalid"]}
{"project": "foundation_foundation-sites", "title": "Reveal Animation Bug", "description": "Hi,\nI downloaded the latest complete css version, In Reveal Plugin when i tried to add data-animation attribute it doesn't work, I coped the same code in the docs and it doesn't work ether, just the gray overlay show up! ", "code": [], "labels": ["javascript", "bug"]}
{"project": "neoclide_coc.nvim", "title": "Improve plugin update experience with human commit messages", "description": "When using the release branch with vim-plug: <CODE> My :PlugUpdate` experience looks something like this:  The release commits are just a hash that means nothing to me. It would be nice if updates provided some actual info about what changed. This is especially true for potential breaking changes. ", "code": ["Plug 'neoclide/coc.nvim', {'branch': 'release'}\n"], "labels": ["enhancement"]}
{"project": "systemd_systemd", "title": "FE: Support similar functionality to incrond - passing notify options to service Units", "description": "It would be great if systemd path units let you pass information to the service Unit. Similar to what incrond does, you can pass the specific file that changed or the type of inotify event. This would be handy as the service Unit could act on this information passed by systemd. ", "code": [], "labels": ["RFE "]}
{"project": "ampproject_amphtml", "title": "Analytics: Expand extraUrlParams in vendor-requests.json", "description": "In amp-analytics text names vendor request tests, we check for all the requests generated by the vendors. Currently the extraUrlParams variable in the requests shows up as $extraUrlParams.  Expanding the variable to contain all the extra parameters will make the test more meaningful. ", "code": [], "labels": ["WG: analytics"]}
{"project": "platformio_platformio-core", "title": "espressif8266_stage fails to install on PlatformIO 3.3.0a3", "description": "Operating system: OS X 10.11.6 PlatformIO Version (platformio --version): PlatformIO, version 3.3.0a3 espressif8266_stage fails to install on PlatformIO 3.3.0a3 git version 2.11.0\nCloning into '/Users/xxx/.platformio/platforms/installing-a7czZ2-package'...\nremote: Counting objects: 92, done.\nremote: Compressing objects: 100% (59/59), done.\nremote: Total 92 (delta 46), reused 54 (delta 24), pack-reused 0\nUnpacking objects: 100% (92/92), done.\nplatform-espressif8266 @ 4e64659 has been successfully installed!\nError: Unknown platform '/Users/xxx/.platformio/platforms/platform-espressif8266/.git/.piopkgmanager.json' No error. ", "code": [], "labels": ["bug"]}
{"project": "eslint_eslint", "title": "Port JSCS requireObjectKeysOnNewLine rule", "description": "What version of ESLint are you using? <CODE> What parser (default, Babel-ESLint, etc.) are you using? <CODE> Please show your full configuration:\n.eslintrc <CODE> eslint.json What did you do? Please include the actual source code causing the issue.\ntried to lint this line of code\nvar e2eTask = new E2ETask({ ui: this.ui, analytics: this.analytics, project: this.project });\nWhat did you expect to happen?\nexpected it to give error in favor of below, one key per line <CODE> What actually happened? Please include the actual, raw output from ESLint.\nno error ", "code": ["\"eslint\": \"^2.4.0\",\n", "espree\n", "{\n  \"ecmaFeatures\": {\n    \"modules\": true,\n    \"module\":  true\n  },\n  \"env\": {\n    \"mocha\": true,\n    \"node\":  true,\n    \"es6\":   true\n  }\n}\n", "var e2eTask = new E2ETask({ \n  ui: this.ui, \n  analytics: this.analytics, \n  project: this.project \n});\n"], "labels": ["rule", "feature", "archived due to age", "accepted"]}
{"project": "saltstack_salt", "title": "Modify recursive ownership management of file.directory", "description": "Hi, I wonder if there is a way to apply mode/user/group attributes in file.directory requisite only to content of directory, but not to directory itself. For example: <CODE> will apply mode/user/group for /usr/local/etc/namedb/ and for all it's content as expected. But all directories in /usr/local/etc/ by default owned by root:wheel, which I don't want to change -- I want /usr/local/etc/namedb/ stays owned by root:wheel and it's content by bind:bind. So if there is a workaround to do so? <CODE> ", "code": ["/usr/local/etc/namedb/:\n  file.directory:\n    - user: bind\n    - group: bind\n    - dir_mode: 755\n    - file_mode: 644\n    - recurse:\n      - user\n      - group\n      - mode\n", "Salt Version:\n           Salt: 2015.8.7\n\nDependency Versions:\n         Jinja2: 2.7.3\n       M2Crypto: 0.22\n           Mako: Not Installed\n         PyYAML: 3.11\n          PyZMQ: 14.3.1\n         Python: 2.7.11 (default, Feb 29 2016, 14:33:19)\n           RAET: Not Installed\n        Tornado: 4.3\n            ZMQ: 4.0.4\n           cffi: Not Installed\n       cherrypy: Not Installed\n       dateutil: 2.2\n          gitdb: Not Installed\n      gitpython: Not Installed\n          ioflo: Not Installed\n        libgit2: Not Installed\n        libnacl: Not Installed\n   msgpack-pure: Not Installed\n msgpack-python: 0.4.7\n   mysql-python: Not Installed\n      pycparser: Not Installed\n       pycrypto: 2.6.1\n         pygit2: Not Installed\n   python-gnupg: Not Installed\n          smmap: Not Installed\n        timelib: Not Installed\n\nSystem Versions:\n           dist:   \n        machine: amd64\n        release: 10.2-STABLE-r286912\n"], "labels": ["Platform", "State Module", "Feature"]}
{"project": "chef_chef", "title": "chef 12 ignores default_release for apt_package", "description": "I just figured out an issue after upgrading to chef 12. When specifying a default_release option for apt_package this option will be ignored. Small example: I would expect that chef installs 1.9.1-1~bpo70+1, but it actually installs 1.4-4. Using chef 11.16 this works as expected and installs haveged from backports. Please have a look below for a full recipe that illustrates the issue. I'm able to reproduce this issue on two clean VMs, installed only Chef 11.16.4 on the first one and 12.0.1 on the second. After executing the example recipe below I get haveged 1.9.1-1~bpo70+1 on the first VM and 1.4-4 on the second. The only difference between these two machines is the chef version. Full example recipe to reproduce the issue: ", "code": [], "labels": ["Type: Bug"]}
{"project": "grafana_grafana", "title": "Is there any lite libary bulit with JavaScript to show powerful graphics", "description": "As we all know that grafana is well supported for graphically showing data based on ElasticSearch, and I just want to ask an issue whether there is a lite edition of library built with JavaScript like any graphic components, to show such powerful graphics. I have rencently wanted to used Grafana to combine with a company's project. ", "code": [], "labels": ["type/question"]}
{"project": "symless_synergy-core", "title": "Show on Mac doesn't function the same as Show on Windows.", "description": "Imported issue: Steps to reproduce: Actual: When I click on Show in the menu bar, it just shows the Synergy app in the dock. Expected: I expect that when I click on Show in the menu bar on the Mac that the Synergy window would open, like it does on Windows. Versions and operating systems: Mac OS X 10.8.3\nSynergy for Mac 1.4.12 This happens regardless of whether I am using Synergy to access my Mac's mouse, or using the actual touchpad on the Mac, so I don't think the Windows version matters. Temporary workarounds: Click on the Synergy icon in Mac, click on Show, click on the synergy app icon in the dock, now the window shows. Additional comments: Thanks for an awesome program!  It has been SUCH a time saver!! ", "code": [], "labels": ["obsolete"]}
{"project": "kubesphere_kubesphere", "title": "ks\u63a7\u5236\u53f0\u901a\u8fc7\u4e00\u4e2a\u5916\u90e8nginx\u8f6c\u53d1\u8bbf\u95ee\u8bf7\u6c42\u65e0\u6cd5\u767b\u9646\u5bb9\u5668\u7ec8\u7aef", "description": "ks\u7684\u5e73\u53f0\u662f30880\u7aef\u53e3\u7684\uff0c\u6211\u5728\u5916\u90e8\u4f7f\u7528\u4e86\u4e00\u4e2anginx\u505a\u4e86\u57df\u540d\u8f6c\u53d1\uff0c\u4f8b\u5982ks.xxx.com\uff0c\u4f7f\u7528https\u8f6c\u53d1\u5230ks\u5e73\u53f0\u4e00\u4e2amaster\u8282\u70b9\u768430880\u7aef\u53e3\uff0c\u767b\u9646\u5e73\u53f0\u90fd\u6ca1\u4ec0\u4e48\u95ee\u9898\uff0c\u4f46\u662f\u5728\u767b\u9646\u5bb9\u5668\u7ec8\u7aef\u65f6\u63d0\u793a\u6ca1\u6709\u6743\u9650\u65e0\u6cd5\u767b\u9646\uff0c\u65e0\u8bba\u4efb\u4f55\u6743\u9650\u7684\u5e10\u53f7\u90fd\u65e0\u6cd5\u767b\u9646\uff0c\u4f46\u662f\u5982\u679c\u7528ks\u5e73\u53f0master\u5b9e\u9645\u7684\u5730\u5740\u6216\u57df\u540d\u89e3\u6790\u5230ks\u5e73\u53f0\u5b9e\u9645\u7684ip\u5730\u5740+30880\u7aef\u53e3\u90fd\u53ef\u4ee5\u6b63\u5e38\u8bbf\u95ee\u7684\uff0c\u662f\u5426\u5728\u767b\u9646\u7ec8\u7aef\u5224\u65ad\u6743\u9650\u65f6\u6709\u4ec0\u4e48\u6765\u6e90\u63a7\u5236\u8fd8\u662f\u4ec0\u4e48\u95ee\u9898\uff0c\u5bfc\u81f4\u4ece\u5916\u90e8nginx\u8f6c\u53d1\u8fc7\u6765\u7684\u8bf7\u6c42\u65e0\u6cd5\u8bbf\u95ee\u767b\u9646\u5bb9\u5668\u7ec8\u7aef\uff1f\n ", "code": [], "labels": ["help wanted"]}
{"project": "puphpet_puphpet", "title": "Parallels NFS server_values is false", "description": "I'm trying to use Puphet to setup a Parallels box.\nWhen I do vagrant up, if I use nfs as the sync_type, I get the following error message: <CODE> However, if I change the sync_type to default the error goes away. Also, this may or may not be related, when using default as the sync_type, my shared folder ends up mounted to /vagrant instead of /var/www as indicated in my config.yaml.\nWhen I use default I see this in the output of vagrant up: <CODE> For reference, this is my config.yaml: ", "code": ["Error: $server_values is false, not a hash or array at /tmp/vagrant-puppet-3/manifests/manifest.pp:189 on node packer-parallels-iso.localdomain\n", "default: Mounting shared folders...\ndefault: /var/www => /Users/adear/Documents/localDevelopment/www.mysite.com\ndefault: /vagrant => /Users/adear/Documents/localDevelopment/www.mysite.com\n"], "labels": ["bug"]}
{"project": "ccxt_ccxt", "title": "OKEX BTC/USD Sudden Volume Drop on Every Friday 08:00 UTC", "description": "Hi, I was using ccxt to fetch daily volumes of okex exchange. Today, I realized that every Friday at 08:00 UTC, the volume of BTC/USD is dropping suddenly. I have checked BTC/USDT; there is not a sudden decrease in it. You can see two examples here: Are these problems coming from ccxt or okex API? Thanks ", "code": [], "labels": ["question"]}
{"project": "Automattic_mongoose", "title": "How to get parent and child both schema with discriminator in plugin?", "description": "Do you want to request a feature or report a bug?\nI don't know this is a bug or not. I want to know how to access parent & child schema in plugin when using discriminator What is the current behavior?\nI am having diffrent schemas like below: user-model.js <CODE> patient-model.js <CODE> doctor-model.js <CODE> title-case-plugin.js <CODE> when i use plugin with discriminator i am getting only child schema (doctor schema). when i debug schema with console.log(schema) in title-case-plugin.js, i notice that .js file iterate over 4 times like user schema, patient schema then again user schema and doctor schema so  in titleCase array i am getting only last schema's path like [hospital_name, city, state, country'] but i want all its parent and child schema path with title case true eg. [gender, hospital_name, city, state, country'].  node.js : 8.9.3\nmongoose: 5.0.11\nMongoDB: 3.4 ", "code": ["var userSchema = new Schema({\n  firstname: {type: String, required: true},\n  lastname: {type: String, required: true},\n  email: {type: String, required: true, unique: true, lowercase: true},\n  password: {type: String, required: true, select: false},\n  type: {type: String, required: true},\n  gender: {type: String, lowercase: true, titleCase: true},\n}, {timestamps: true, discriminatorKey: 'type'});\n\nuserSchema.plugin(TitleCasePlugin);\nmodule.exports = mongoose.model('User', userSchema);\n", "var patientSchema= new Schema({\n  medicines: [{type: Schema.Types.ObjectId, ref: 'Medicine'}],\n  address_1: {type: String},\n  address_2: {type: String},\n  city: {type: String, required: true, lowercase: true, titleCase: true},\n  state: {type: String, required: true, lowercase: true, titleCase: true},\n  country: {type: String, required: true, lowercase: true, titleCase: true},\n});\n\npatientSchema.plugin(TitleCasePlugin);\nmodule.exports = User.discriminator('patient', patientSchema);\n", "var doctorSchema= new Schema({\n  hospital_name: {type: String, required: true, titleCase: true},\n  city: {type: String, required: true, lowercase: true, titleCase: true},\n  state: {type: String, required: true, lowercase: true, titleCase: true},\n  country: {type: String, required: true, lowercase: true, titleCase: true},\n});\n\ndoctorSchema.plugin(TitleCasePlugin);\nmodule.exports = User.discriminator('doctor', doctorSchema);\n", "module.exports = exports = function titleCasePlugin(schema) {\n  console.log(schema);\n  var titleCase = [];\n  schema.eachPath(function(pathname, schemaType) {\n    if (schemaType.options && schemaType.options.titleCase) {\n      if (titleCase.indexOf(pathname) <= -1) titleCase.push(pathname);\n    }\n  });\n  schema.options.toObject = schema.options.toObject || {};\n  schema.options.toObject.transform = function(doc, response) {\n    titleCase.forEach(function(pathname) {\n      if (pathname in response ) {\n        var split = response[pathname].toLowerCase().split(' ');\n        for (var i = 0; i < split.length; i++) {\n          split[i] = split[i].charAt(0).toUpperCase() + split[i].substring(1);\n        }\n        response[pathname] = split.join(' ');\n      }\n    });\n    return response;\n  };\n};\n"], "labels": ["needs clarification"]}
{"project": "bigbluebutton_bigbluebutton", "title": "External video sync requests are ignored after losing presenter", "description": "Steps to reproduce: Expected result:\nThe video in both clients should pause. Actual result:\nThe video in client 2 will pause, but the video in client 1 will keep playing. Other information:\nIf there's a third client it will also pause when client 2 does. Any seek or play changes are also ignored by client 1. ", "code": [], "labels": ["HTML5 Client"]}
{"project": "spring-projects_spring-boot", "title": "Spring boot is truncating cookie values at the first '=' character", "description": "When a cookie value is submitted to a rest controller, the value is truncated at the first '=' character.\nfor example, if I have a cookie: named fooCookie with the value \"a==4=2==1\" then the cookie value passed to the rest controller is \"a\".\nThis causes problems when base-64 values are submitted as cookie values. <CODE> ", "code": ["@ResponseStatus(HttpStatus.OK)\n@RequestMapping(value=\"/sampleGet\", method=RequestMethod.GET)\npublic String cookieProcess(@CookieValue(value=\"fooCookie\", required=false) String fooCookie, HttpServletRequest request) {\n    //At this point fooCookie is truncated \n    for (Cookie cookie : request.getCookies()) {\n        if (cookie.getName().equals(\"fooCookie\")) {`\n            //this cookie value is truncated as well`\n    }\n}\n"], "labels": ["status: invalid"]}
{"project": "M66B_XPrivacy", "title": "Low Priority Suggestion - Change the function of the new ? box", "description": "Specifically,  this box\n Any chance we can use this \"area\", not to enable/disable on demand for the app,  but to Select all or Unselect all  \"?\" If there is room, maybe add the enable disable of prompt in the same fasion you have for the restrictions, like this  Only a suggestion, if you think it is a good idea, only when you guys can, more then willing to wait until stable release or when you guys have time......just a possible reminder for github ", "code": [], "labels": ["enhancement"]}
{"project": "c3js_c3", "title": "Colorize datapoints", "description": "Hi. Is it possible to colorize special datapoints in a linegraph? From a backend server i get jsondata structured something like this I am able to plot this data with c3.\nWhile everything is plotted in pure black, i need to hightlight this special datapoint in red.\nIs it possible to highlight single datapoints using c3, or can you implement something like this in the future? ", "code": [], "labels": ["question"]}
{"project": "linq2db_linq2db", "title": "Columns to List Query", "description": "Hello, I have the following classes: and this Query: As result I got LinqToDB.Linq.LinqException: 'Invalid expression  p.Extras.Any(b => b.Value == \"Hello World\")'  <CODE> I know this seems a little bit arbitary, but we need to map a rather \"dynamic\" table structure in a more generic data structure (list). EDIT: Linq2DB 2.4.0 ", "code": ["   at LinqToDB.Linq.Builder.SelectContext.GetMemberExpression(Expression newExpression, Expression expression, Int32 level) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 1084\n   at LinqToDB.Linq.Builder.SelectContext.ProcessMemberAccess[T](Expression expression, MemberExpression levelExpression, Int32 level, Func`6 action) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 980\n   at LinqToDB.Linq.Builder.SelectContext.IsExpressionInternal(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 731\n   at LinqToDB.Linq.Builder.SelectContext.IsExpression(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 627\n   at LinqToDB.Linq.Builder.SelectContext.ProcessMemberAccess[T](Expression expression, MemberExpression levelExpression, Int32 level, Func`6 action) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 973\n   at LinqToDB.Linq.Builder.SelectContext.IsExpressionInternal(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 731\n   at LinqToDB.Linq.Builder.SelectContext.IsExpression(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 627\n   at LinqToDB.Linq.Builder.SelectContext.ProcessMemberAccess[T](Expression expression, MemberExpression levelExpression, Int32 level, Func`6 action) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 973\n   at LinqToDB.Linq.Builder.SelectContext.IsExpressionInternal(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 731\n   at LinqToDB.Linq.Builder.SelectContext.IsExpression(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 627\n   at LinqToDB.Linq.Builder.SelectContext.ProcessMemberAccess[T](Expression expression, MemberExpression levelExpression, Int32 level, Func`6 action) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 973\n   at LinqToDB.Linq.Builder.SelectContext.IsExpressionInternal(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 731\n   at LinqToDB.Linq.Builder.SelectContext.IsExpression(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 627\n   at LinqToDB.Linq.Builder.SelectContext.ProcessMemberAccess[T](Expression expression, MemberExpression levelExpression, Int32 level, Func`6 action) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 973\n   at LinqToDB.Linq.Builder.SelectContext.IsExpressionInternal(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 731\n   at LinqToDB.Linq.Builder.SelectContext.IsExpression(Expression expression, Int32 level, RequestFor requestFlag) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\SelectContext.cs:line 627\n   at LinqToDB.Linq.Builder.ExpressionBuilder.ConvertObjectComparison(ExpressionType nodeType, IBuildContext leftContext, Expression left, IBuildContext rightContext, Expression right) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.SqlBuilder.cs:line 1838\n   at LinqToDB.Linq.Builder.ExpressionBuilder.ConvertCompare(IBuildContext context, ExpressionType nodeType, Expression left, Expression right) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.SqlBuilder.cs:line 1593\n   at LinqToDB.Linq.Builder.ExpressionBuilder.ConvertPredicate(IBuildContext context, Expression expression) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.SqlBuilder.cs:line 1378\n   at LinqToDB.Linq.Builder.ExpressionBuilder.ConvertPredicate(IBuildContext context, Expression expression) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.SqlBuilder.cs:line 1448\n   at LinqToDB.Linq.Builder.ExpressionBuilder.BuildSearchCondition(IBuildContext context, Expression expression, List`1 conditions, Boolean isNotExpression) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.SqlBuilder.cs:line 2581\n   at LinqToDB.Linq.Builder.ExpressionBuilder.BuildSearchCondition(IBuildContext context, Expression expression, List`1 conditions, Boolean isNotExpression) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.SqlBuilder.cs:line 2484\n   at LinqToDB.Linq.Builder.ExpressionBuilder.BuildWhere(IBuildContext parent, IBuildContext sequence, LambdaExpression condition, Boolean checkForSubQuery, Boolean enforceHaving) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.SqlBuilder.cs:line 48\n   at LinqToDB.Linq.Builder.WhereBuilder.BuildMethodCall(ExpressionBuilder builder, MethodCallExpression methodCall, BuildInfo buildInfo) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\WhereBuilder.cs:line 23\n   at LinqToDB.Linq.Builder.ExpressionBuilder.BuildSequence(BuildInfo buildInfo) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.cs:line 175\n   at LinqToDB.Linq.Builder.FirstSingleBuilder.BuildMethodCall(ExpressionBuilder builder, MethodCallExpression methodCall, BuildInfo buildInfo) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\FirstSingleBuilder.cs:line 25\n   at LinqToDB.Linq.Builder.ExpressionBuilder.BuildSequence(BuildInfo buildInfo) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.cs:line 175\n   at LinqToDB.Linq.Builder.ExpressionBuilder.Build[T]() in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Builder\\ExpressionBuilder.cs:line 146\n   at LinqToDB.Linq.Query`1.CreateQuery(IDataContext dataContext, Expression expr) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Query.cs:line 269\n   at LinqToDB.Linq.Query`1.GetQuery(IDataContext dataContext, Expression& expr) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\Query.cs:line 233\n   at LinqToDB.Linq.ExpressionQuery`1.GetQuery(Expression& expression, Boolean cache) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\ExpressionQuery.cs:line 84\n   at LinqToDB.Linq.ExpressionQuery`1.System.Linq.IQueryProvider.Execute[TResult](Expression expression) in C:\\projects\\linq2db\\Source\\LinqToDB\\Linq\\ExpressionQuery.cs:line 165\n   at System.Linq.Queryable.SingleOrDefault[TSource](IQueryable`1 source)\n"], "labels": ["type: question"]}
{"project": "saltstack_salt", "title": "Command crashed minion: salt '*' sys.doc", "description": "This is going to sound strange, but this command, run from the salt-master, crashed one of my minions: <CODE> The minion in question is a VM running CentOS 7. All other minions are Windows-based and were unaffected. The salt-master is running in a Docker container (also CentOS 7). The weird part ... is that I was unable to SSH into the minion after this happened. When checking virt-manager on the host running the VM, the VM had been shut down! The host running the VM is also the salt-master ...which makes this case a bit tangled. Does this make any sense to you? Full output from my terminal, seems like a loop to me: <CODE> salt-master versions report: <CODE> When having the VM/minion up again, I was greeted by this upon logging in: <CODE> Checking some of the files in there: <CODE> Please note: rmanpy is a server running on that VM. Is it possible that this salt command really crashed the VM so bad it took down the whole system? The timing makes me think so. ", "code": ["salt '*' sys.doc\n", "[root@salt /]# salt '*' sys.doc\n[ERROR   ] An un-handled exception was caught by salt's global exception handler:\nTypeError: string indices must be integers, not str\nTraceback (most recent call last):\n  File \"/usr/bin/salt\", line 10, in <module>\n    salt_main()\n  File \"/usr/lib/python2.7/site-packages/salt/scripts.py\", line 458, in salt_main\n    client.run()\n  File \"/usr/lib/python2.7/site-packages/salt/cli/salt.py\", line 195, in run\n    self._output_ret(ret, out)\n  File \"/usr/lib/python2.7/site-packages/salt/cli/salt.py\", line 300, in _output_ret\n    self._print_docs(ret)\n  File \"/usr/lib/python2.7/site-packages/salt/cli/salt.py\", line 344, in _print_docs\n    if ret[host][fun]:\nTypeError: string indices must be integers, not str\n^XTraceback (most recent call last):\n  File \"/usr/bin/salt\", line 10, in <module>\n    salt_main()\n  File \"/usr/lib/python2.7/site-packages/salt/scripts.py\", line 458, in salt_main\n    client.run()\n  File \"/usr/lib/python2.7/site-packages/salt/cli/salt.py\", line 195, in run\n    self._output_ret(ret, out)\n  File \"/usr/lib/python2.7/site-packages/salt/cli/salt.py\", line 300, in _output_ret\n    self._print_docs(ret)\n  File \"/usr/lib/python2.7/site-packages/salt/cli/salt.py\", line 344, in _print_docs\n    if ret[host][fun]:\nTypeError: string indices must be integers, not str\n[root@salt /]# ^C\n", "Salt Version:\n           Salt: 2015.8.7\n\nDependency Versions:\n         Jinja2: 2.7.2\n       M2Crypto: Not Installed\n           Mako: Not Installed\n         PyYAML: 3.11\n          PyZMQ: 14.7.0\n         Python: 2.7.5 (default, Nov 20 2015, 02:00:19)\n           RAET: Not Installed\n        Tornado: 4.2.1\n            ZMQ: 4.0.5\n           cffi: Not Installed\n       cherrypy: Not Installed\n       dateutil: Not Installed\n          gitdb: 0.6.4\n      gitpython: 1.0.2\n          ioflo: Not Installed\n        libgit2: Not Installed\n        libnacl: Not Installed\n   msgpack-pure: Not Installed\n msgpack-python: 0.4.6\n   mysql-python: Not Installed\n      pycparser: Not Installed\n       pycrypto: 2.6.1\n         pygit2: Not Installed\n   python-gnupg: Not Installed\n          smmap: 0.9.0\n        timelib: Not Installed\n\nSystem Versions:\n           dist: centos 7.2.1511 Core\n        machine: x86_64\n        release: 3.10.0-123.el7.x86_64\n         system: CentOS Linux 7.2.1511 Core\n", "ABRT has detected 1 problem(s). For more info run: abrt-cli list --since 1456308662\n\n$ abrt-cli list --since 1456308662\n\nid 96e73227fa5015c109213b61f381b10299c729b6\nDirectory:      /var/tmp/abrt/oops-2016-02-25-13:57:41-731-0\ncount:          1\npackage:        kernel\ntime:           Thu 25 Feb 2016 01:57:41 PM CET\n\nThe Autoreporting feature is disabled. Please consider enabling it by issuing\n'abrt-auto-reporting enabled' as a user with root privileges\n", "$ cat reason\nBUG: soft lockup - CPU#0 stuck for 22s! [rmanpy:1865]\n\n$ cat analyzer\nKerneloops\n\n$ cat component\nkernel\n"], "labels": ["Pending Discussion", "Cannot Reproduce", "stale"]}
{"project": "spring-projects_spring-boot", "title": "Allow placeholders in `spring.datasource.url` property", "description": "I use 1.3.2.RELEASE, the property spring.datasource.url=jdbc:hsqldb:file:#{systemProperties['user.home']}/db/data in application.properties has an unwanted effect. ", "code": [], "labels": ["status: duplicate"]}
{"project": "ant-design_ant-design-mobile", "title": "Note: must use https://github.com/ant-design/babel-plugin-import .", "description": "\u4e00\u76f4\u63d0\u793a\u4e0b\u9762\u7684\u51fa\u9519 <CODE> \u4e0b\u9762\u662f\u6211\u7684\u4ee3\u7801 \u4e0b\u9762\u662f\u6211\u7684webpack\u914d\u7f6e ", "code": ["Note: must use https://github.com/ant-design/babel-plugin-import .\nFor more information, please see https://github.com/ant-design/ant-design-mobile/issues/602 \n"], "labels": ["invalid"]}
{"project": "vector-im_riot-web", "title": "Recents no longer reorders after you type in a room", "description": "Created by @ matthew:matrix.org. To reproduce, type a message in a room and observe that it no longer rises to the top of the Conversations list. Looks like we're missing a forced refresh of the RoomList or RoomSubList when the timeline for the room changes ", "code": [], "labels": ["bug", "p1"]}
{"project": "roundcube_roundcubemail", "title": "Unable to view e-mail with php code in it", "description": "Reported by stefan on 14 May 2013 07:44 UTC as Trac ticket #1489098 I've got an e-mail that is written in html and it works perfect in gmail, outlook, thunderbird etc. But roundcube cannot view the last part of the mail. It gets stuck at \"loading\". I will attach both the index.html and the .php file so that someone can troubleshoot this. /Stefan Keywords: php form\nMigrated-From: <URL> ", "code": [], "labels": ["worksforme", "C: Core functionality", "bug"]}
{"project": "alibaba_fastjson", "title": "JSONPath.eval \u652f\u6301\u5bf9\u6570\u7ec4\u7684\u63d0\u53d6", "description": "\u5728\u5b9e\u9645\u4f7f\u7528\u573a\u666f\u4e2d\uff0c\u9700\u8981\u5bf9\u6570\u7ec4\u4e2d\u7684\u5bf9\u8c61\u6309JSONPath\u8868\u8fbe\u5f0f\u63d0\u53d6\uff0c\u76ee\u524deval\u65b9\u6cd5\u4e0d\u652f\u6301\u6570\u7ec4\uff0c\u76f4\u63a5\u8fd4\u56denull\uff0c\u9ebb\u70e6\u652f\u6301\u4e00\u4e0b\uff0c\u8c22\u8c22\u3002 ", "code": [], "labels": ["bug"]}
{"project": "wordpress-mobile_WordPress-Android", "title": "Crash report 7.4: Helpshift NPE", "description": "<CODE> We must update the Helpshift library to 4.9.1 asap. ", "code": ["Fatal Exception: java.lang.RuntimeException: Unable to start activity ComponentInfo{org.wordpress.android/com.helpshift.campaigns.activities.NotificationActivity}: java.lang.NullPointerException\n       at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2118)\n       at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2145)\n       at android.app.ActivityThread.access$600(ActivityThread.java:130)\n       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1211)\n       at android.os.Handler.dispatchMessage(Handler.java:99)\n       at android.os.Looper.loop(Looper.java:137)\n       at android.app.ActivityThread.main(ActivityThread.java:4847)\n       at java.lang.reflect.Method.invokeNative(Method.java)\n       at java.lang.reflect.Method.invoke(Method.java:535)\n       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:786)\n       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:553)\n       at dalvik.system.NativeStart.main(NativeStart.java)\nCaused by java.lang.NullPointerException\n       at com.helpshift.campaigns.activities.NotificationActivity.onCreate(NotificationActivity.java:55)\n       at android.app.Activity.performCreate(Activity.java:5187)\n       at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1104)\n       at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2064)\n       at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2145)\n       at android.app.ActivityThread.access$600(ActivityThread.java:130)\n       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1211)\n       at android.os.Handler.dispatchMessage(Handler.java:99)\n       at android.os.Looper.loop(Looper.java:137)\n       at android.app.ActivityThread.main(ActivityThread.java:4847)\n       at java.lang.reflect.Method.invokeNative(Method.java)\n       at java.lang.reflect.Method.invoke(Method.java:535)\n       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:786)\n       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:553)\n       at dalvik.system.NativeStart.main(NativeStart.java)\n"], "labels": ["[Type] Crash"]}
{"project": "pqrs-org_Karabiner-Elements", "title": "`pointing_button` could not be passed to next rule in Complex Modifications?", "description": "I used the formula called Change mouse buttons (rev 2) from <URL> to use button4 and button5 to navigate backward and forward. And it works well for one of my mouse. While, the side buttons of my another mouse doesn't behave as button4 and button5. So I wrote a rule to map them as these two buttons. From events log in Karabiner EventViewer, it succeeded. The problem is that, the modified resulting buttons, button4 and button5, could not be used in the formula Change mouse buttons (rev 2) to trigger navigation backward/forward. Besides, I'm sure I gave proper priorities to these two rules. I guess some of the resulting modifications, like \"to\": [{\"pointing_button\": \"button4\"}], are not passed to, or not used in following rules. Is there a more detailed log to find what rule modifies what and what are the input, output of rules in Karabiner? I'll paste my rule of mapping buttons as button4, button5, and the Change button4,5 to back,forward (rev 1) rule from <URL> below for analysis. Part content of rule Change button4,5 to back,forward (rev 1): ", "code": [], "labels": ["stale"]}
{"project": "ansible_ansible", "title": "Assemble module should put a newline between each file", "description": "Bug Report ansible 1.5 / devel @ 04a6dc6 Unrelated but\nHost: OS 10.9.1,\nTarget: Centos 6.5 The assemble module (as of 3b2d409) ensures that a newline is placed after any delimiter usage but the module does not put a newline between each of the files. Without putting a blank line in each file (which can easily get accidentally removed) the first line of each file is concatenated with the last line of the preceding file.  This breaks a lot of configuration files that are \"assembled\" (e.g. iptables in my case). I would expect a newline between fragments. The first line of each file is concatenated with the last line of the preceding file Try the assemble module ", "code": [], "labels": ["P3", "bug"]}
{"project": "microsoft_TypeScript", "title": "Errors using lib.d.ts from 1.0", "description": "Using lib.d.ts from 1.0, against 1.5 you get errors for missing types: The missing types are all related to decorators, and for users not using decorators the error should be suppressed. ", "code": [], "labels": ["Bug", "Fixed"]}
{"project": "arendst_Tasmota", "title": "Pushbutton", "description": "Any chance to configure this firmare to act on the relay like a push button? E.g. mqtt command \"on for 10ms\" or \"on for 500ms\".\nI'd like to use it like a software-based push-button. actually to turn off / on a lamp with a pulse. And next to dimm that light be simulating a long pulse. ", "code": [], "labels": ["stale"]}
{"project": "ansible_ansible", "title": "enable winrm via Linux bastion hosts.", "description": "winrm connections should support connections via bastion hosts. The winrm.py module should support ssh_common_args, for circumstances where a network topology requires ansible to connect to a Windows host via a Linux intermediary. /usr/lib/python2.7/site-packages/ansible/plugins/connection/winrm.py <CODE> <CODE> <CODE> In group_vars for managed host: winrm.py detects that an ansible_winrm_ssh_proxy is defined and loads the appropriate connection, executing winrm commands after connection to the defined proxy. winrm.py does not evaluate ssh arguments. ", "code": ["ansible 2.6.1\n  config file = /etc/ansible/ansible.cfg\n  configured module search path = [u'/home/a317788/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.5 (default, Feb 20 2018, 09:19:12) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)]\n", "LOW_WORLD_READABLE_TMPFILES(/etc/ansible/ansible.cfg) = False\nDEFAULT_FORKS(/etc/ansible/ansible.cfg) = 50\nDEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = [u'/etc/ansible/hosts']\nDEFAULT_LOCAL_TMP(/etc/ansible/ansible.cfg) = /home/#redacted#/.ansible/tmp/ansible-local-13328hqrH3v\nDEFAULT_LOG_PATH(/etc/ansible/ansible.cfg) = /var/log/ansible.log\nDEFAULT_ROLES_PATH(/etc/ansible/ansible.cfg) = [u'/etc/ansible/roles']\nDEFAULT_TRANSPORT(/etc/ansible/ansible.cfg) = smart\nRETRY_FILES_ENABLED(/etc/ansible/ansible.cfg) = False\nSHOW_CUSTOM_STATS(/etc/ansible/ansible.cfg) = True\n", "Linux 3.10.0-693.11.6.el7.x86_64 #1 SMP Thu Dec 28 14:23:39 EST 2017 x86_64 x86_64 x86_64 GNU/Linux\n"], "labels": ["waiting_on_contributor", "feature", "support:core", "affects_2.6", "windows"]}
{"project": "rails_rails", "title": "Preloading associations with string foreign keys fails", "description": "See 4debc86#diff-b1215e38a98827a4b1b61271a6bf1ba8 Including an association with a string foreign key should not raise an exception. My association is: <CODE> Stacktrace: <CODE> Appears to be related to #14734 Rails version: 4.2.5 Ruby version: 2.3.1p112 (2016-04-26 revision 54768) [x64-mingw32] ", "code": ["\"undefined method `each' for nil:NilClass\"\n", "0: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader/association.rb:93:in `block in associated_records_by_owner'\"\n1: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader/association.rb:92:in `each'\"\n2: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader/association.rb:92:in `associated_records_by_owner'\"\n3: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader/singular_association.rb:9:in `preload'\"\n4: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader/association.rb:20:in `run'\"\n5: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:146:in `block (2 levels) in preloaders_for_one'\"\n6: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:144:in `each'\"\n7: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:144:in `map'\"\n8: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:144:in `block in preloaders_for_one'\"\n9: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:143:in `each'\"\n10: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:143:in `flat_map'\"\n11: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:143:in `preloaders_for_one'\"\n12: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:115:in `preloaders_on'\"\n13: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:103:in `block in preload'\"\n14: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:102:in `each'\"\n15: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:102:in `flat_map'\"\n16: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/associations/preloader.rb:102:in `preload'\"\n17: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/relation.rb:645:in `block in exec_queries'\"\n18: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/relation.rb:644:in `each'\"\n19: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/relation.rb:644:in `exec_queries'\"\n20: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/relation.rb:515:in `load'\"\n21: \"E:/dev/lang/Ruby23-x64/lib/ruby/gems/2.3.0/gems/activerecord-4.2.5/lib/active_record/relation.rb:243:in `to_a'\"\n"], "labels": ["activerecord"]}
{"project": "mautic_mautic", "title": "Db error during inserting page_hits", "description": "Obviously, it is because of referencing deleted email: I've checked, I do not have an email with id 8 right now, it was earlier deleted. How to fix it? I am getting such errors in my logs regularly - and it (I guess) breaks my AJAX segment email sending (which just gets stuck at the same time when I get such error message in my logs), so it's pretty important as it leads to duplicate emails sent to contacts. ", "code": [], "labels": ["Ready To Test", "Bug"]}
{"project": "toggl-open-source_toggldesktop", "title": "unhelpful \"Errors encountered while syncing data: Stop time must be after start time.\"", "description": "appeared after clicking on the second idle notification button.  ", "code": [], "labels": ["bug"]}
{"project": "holoviz_holoviews", "title": "Larger visualization in doc/example notebooks?", "description": "In doc/example notebooks, I think it would be nice to have larger\nvisualizations. However, doing so might cause other problems, or be difficult to\nachieve. Or maybe other people don't agree it would be better in the\nfirst place. I think the plots just come out at the backend's default size, maybe? One option would be to make all the visualizations bigger by adding\noutput size=150 or something at the start of every\ndoc/example notebook. That way, people would be aware of the\noption and could copy/change it in their own work. But seems a shame\nto have a distraction like that at the start of every notebook. Could put output_size=150 or whatever in the nbpublisher jupyter\nprofile instead of adding to individual notebooks. Might be\nproblematic for notebooks where the visualizations are already\nlarge. Wouldn't help users to have larger visualizations\nthemselves. Could make things difficult to debug: doc/example nbs will\nlook different when published vs when local. For instance, could decide to make any single plot take 80% of the\nspace, 2 plots to add up to 80% of the space, 3 to add up to 100% of\nthe space, 4 be like 3 but to split across lines, etc... Any other ideas? ", "code": [], "labels": ["docs"]}
{"project": "leela-zero_leela-zero", "title": "Where can i find new file Weights.txt after Zero train 18000 games? Need Zero for each level.", "description": "I think we should have a weights file for each stage like 10k games, 14kgames, 18k games, 20k games. And set it level. Not just build a strongest Zero. We need Zero for each level.\nI played with Leela Zero when Zero is 3k on kgs. It's really excited. ", "code": [], "labels": ["question"]}
{"project": "jspm_jspm-cli", "title": "cannot open .git/FETCH_HEAD: Permission denied error after running jspm install -y", "description": "OS: Windows 10 Pro\nJSPM: 0.16.19\nGit: 2.6.4.windows.1\nNPM: 3.5.2 Running jspm install -y causes the following error message: cannot open .git/FETCH_HEAD: Permission denied as shown in the following image. How do I rectify this issue? ", "code": [], "labels": ["support"]}
{"project": "AdguardTeam_AdGuardHome", "title": "How is this different from pihole?", "description": "This is just a question that I am trying to understand  - is this different from what is available already - PiHole ? Advantages ? ", "code": [], "labels": ["question"]}
{"project": "spring-cloud_spring-cloud-netflix", "title": "FormBodyWrapperFilter frequently new MappingJackson2HttpMessageConverter instance, cause  performance issue", "description": "in org.springframework.cloud.netflix.zuul.filters.pre.FormBodyWrapperFilter#run line 114/118, per request will new FormBodyRequestWrapper instance, class FormBodyRequestWrapper again create AllEncompassingFormHttpMessageConverter instance,so this will frequently create MappingJackson2HttpMessageConverter instance, and finally, will call java.lang.ClassLoader#loadClass(java.lang.String, boolean): that's all. ", "code": [], "labels": ["duplicate"]}
{"project": "sitespeedio_sitespeed.io", "title": "is there any way sending the json results to some service other than graphite? (windows os)", "description": "Im looking for a way to send the json results into any windows service that can be sourced with Grafana.\nI previously tried graphite on my windows pc, but it was really messy using VM and vagrant (took my a lot of time!). What im trying to achieve is viewing the results over Grafana without using Graphite.\nIs there any option to send the data somewhere else? for example ElasticSearch? I tried that within Gulp but it didn't work. Can anyone suggest a working solution over windows? ", "code": [], "labels": ["4.0"]}
{"project": "dotnet_aspnetcore", "title": "Server Side Blazor: CSS Animations Elements Run Twice", "description": "When you add css animations (such as animation.css) that start on display, they appear to run twice. This issue does not appear locally but does when hosted on a web server. Steps to reproduce the behavior: <CODE> Animations should run once (one fade in)  ", "code": ["<link href=\"https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.2/animate.min.css\" rel=\"stylesheet\"/>\n"], "labels": ["investigate", "area-blazor"]}
{"project": "dotnet_aspnetcore", "title": "Remove the call to add HSTS middleware from the API project template", "description": "HSTS is intended for browser scenarios, thus we should remove it from the API project template. ", "code": [], "labels": ["area-mvc", "PRI: 1 - Required", "Done", "cost: S", "bug"]}
{"project": "cakephp_cakephp", "title": "Make Date::jsonSerialize() consistent with ISO8601", "description": "As described in cakephp/chronos#93 the default JSON encode format should be compatible with ISO-8601, and not the approximate format it is using now. Targeting this for 3.next as changing the default format requires communication to developers as they might not want to have their date formats changed. ", "code": [], "labels": ["enhancement", "defect", "i18n"]}
{"project": "angular_angular", "title": "router.navigate() not working inside HttpInterceptor while route resolver is running", "description": "<CODE> routes.ts: <CODE> auth-interceptor.ts: <CODE> user-resolver.ts: <CODE> user-service.ts: <CODE> If a resolver fails fetching data, the app should be able to redirect the user to another route (a login prompt for instance) ", "code": ["\n[ ] Regression (a behavior that used to work and stopped working in a new release)\n[x] Bug report  \n[ ] Feature request\n[ ] Documentation issue or request\n[ ] Support request => Please do not submit support request here, instead see https://github.com/angular/angular/blob/master/CONTRIBUTING.md#question\n", "{ \n  path: ':id',\n  component: EditComponent,\n  resolve: {\n    user: UserResolver\n  }\n}\n", "@Injectable()\nexport class AuthenticationInterceptor implements HttpInterceptor {\n    constructor(private router: Router) {}\n    intercept(request: HttpRequest<any>, next: HttpHandler): Observable<HttpEvent<any>> {\n        return next.handle(request).do(event => {\n        }, error => {\n            if (error instanceof HttpErrorResponse && error.status === 401) {\n                this.router.navigate([ '/login' ]);\n            }\n            return error;\n        });\n    }\n}\n", "@Injectable()\nexport class EditResolver implements Resolve<UserModel[]> {\n    constructor(private userService: UserService, private router: Router) {}\n    public resolve(route: ActivatedRouteSnapshot, state: RouterStateSnapshot): Observable<any> {\n        return this.userService.getById(+route.params.id);\n    }\n}\n", "@Injectable()\nexport class UserService {\n    constructor(private http: HttpClient) {}\n    public getById(userId: Number): Observable<UserModel> {\n        return this.http.get('/api/1.0/users/' + userId);\n    }\n}\n"], "labels": ["comp: router"]}
{"project": "ccxt_ccxt", "title": "help installing and maybe partnership", "description": "can you help install to load test\nyou got my attention...i have seen so much junk out there is this yet another? can it be used in production? do you have a demo hosted somewhere? any whatsapp number or direct number in north america? ", "code": [], "labels": ["question"]}
{"project": "emberjs_data", "title": "ember-data 2.14.0: 'instrument' is imported from external module 'ember-data/-debug' but never used", "description": "Launching application: <CODE> ", "code": ["$ ember s\nLivereload server on http://localhost:49153\n'instrument' is imported from external module 'ember-data/-debug' but never used\n\nBuild successful (31681ms) \u2013 Serving on http://localhost:4200/\n"], "labels": ["Bug"]}
{"project": "realm_realm-js", "title": "Support all applicable JS Array methods on List and Results", "description": "From @appden : ", "code": [], "labels": ["P2", "T-Enhancement"]}
{"project": "Flexget_Flexget", "title": "imdb_list is labeling tv series as movies.", "description": "imdb_list setting series_name for a tv series. imdb_list is setting everything to movie_name. <CODE> <CODE> It looks like there is a \"TV series\" label in row 6 of the csv file from imdb to identify the type. I think this is the code: <CODE> Please verify that the following data is present before submitting your issue: -Paste or link to a paste service (pastebin for example) of relevant config (preferably full config including templates if present. Remember to redact any personal information! ", "code": ["paste relevant config\nuse paste service if config is too long\n", "2016-07-06 19:17 DEBUG    imdb_list     imdb_to_trakt_tv parsing line from csv: 1, tt2085059, Fri Jun  3 19:35:35 2016, Fri Jun  3 19:35:35 2016, , Black Mirror, TV Series, , , 8.8, 60, 2011, drama, sci_fi, thriller, 56397, 2011-12-04, http://www.imdb.com/title/tt2085059/\n2016-07-06 19:17 TRACE    entry         imdb_to_trakt_tv ENTRY SET: imdb_name = u'Black Mirror'\n2016-07-06 19:17 TRACE    entry         imdb_to_trakt_tv ENTRY SET: imdb_genres = [u'drama', u'sci_fi', u'thriller']\n2016-07-06 19:17 TRACE    entry         imdb_to_trakt_tv ENTRY SET: movie_name = u'Black Mirror'\n", "                entry = Entry({\n                    'title': '%s (%s)' % (row[5], row[11]) if row[11] != '????' else '%s' % row[5],\n                    'url': row[15],\n                    'imdb_id': row[1],\n                    'imdb_url': row[15],\n                    'imdb_list_position': int(row[0]),\n                    'imdb_list_created': datetime.strptime(row[2], '%a %b %d %H:%M:%S %Y') if row[2] else None,\n                    'imdb_list_modified': datetime.strptime(row[3], '%a %b %d %H:%M:%S %Y') if row[3] else None,\n                    'imdb_list_description': row[4],\n                    'imdb_name': row[5],\n                    'movie_name': row[5],\n"], "labels": ["Bug"]}
{"project": "IBM-Swift_Kitura", "title": "Build fails for swift-DEVELOPMENT-SNAPSHOT-2016-02-25-a", "description": "The problem does not occur when using swift-DEVELOPMENT-SNAPSHOT-2016-02-08-a. When trying to build with swift-DEVELOPMENT-SNAPSHOT-2016-02-25-a on OSX 10.11.3, there's a problem with including http_parser.h file: <CODE> After changing the include in Kitura-HttpParserHelper-0.2.0/utils.h file from: <CODE> to <CODE> the file is being found. However, than we're failing on -lpcre2-8: <CODE> which can be solved by changing `Kitura-Pcre2-0.2.0/module.modulemap' from <CODE> to <CODE> This makes swift build fail on familiar <CODE> However, than when trying to make the Kitura-net-0.3.1/Makefile there's an error: <CODE> coming from Kitura-HttpParserHelper-0.2.0/module.modulemap link: <CODE> which I have no idea how to solve right now. Do you know what might be a possible cause? The http_parser had been installed using brew. When building with swift-DEVELOPMENT-SNAPSHOT-2016-02-08-a, the library is found and linked properly. ", "code": ["Cloning https://github.com/IBM-Swift/Kitura-router.git\nResolved version: 0.3.2\nCloning https://github.com/IBM-Swift/Kitura-net.git\nResolved version: 0.3.1\nCloning https://github.com/IBM-Swift/Kitura-sys.git\nResolved version: 0.3.0\nCloning https://github.com/IBM-Swift/LoggerAPI.git\nResolved version: 0.2.0\nCloning https://github.com/IBM-Swift/BlueSocket.git\nResolved version: 0.0.4\nCloning https://github.com/IBM-Swift/Kitura-CurlHelpers.git\nResolved version: 0.2.0\nCloning https://github.com/IBM-Swift/Kitura-HttpParserHelper.git\nResolved version: 0.2.0\nCloning https://github.com/IBM-Swift/Kitura-Pcre2.git\nResolved version: 0.2.0\nCloning https://github.com/SwiftyJSON/SwiftyJSON.git\nResolved version: 2.3.3\nCompiling Swift Module 'SwiftyJSON' (1 sources)\nCompiling Swift Module 'LoggerAPI' (1 sources)\nCompiling Swift Module 'BlueSocket' (3 sources)\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:37:68: warning: __FUNCTION__ is deprecated and will be removed in Swift 3, please use #function\n    public static func verbose(msg: String, functionName: String = __FUNCTION__,\n                                                                   ^~~~~~~~~~~~\n                                                                   #function\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:38:24: warning: __LINE__ is deprecated and will be removed in Swift 3, please use #line\n        lineNum: Int = __LINE__, fileName: String = __FILE__ ) {\n                       ^~~~~~~~\n                       #line\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:38:53: warning: __FILE__ is deprecated and will be removed in Swift 3, please use #file\n        lineNum: Int = __LINE__, fileName: String = __FILE__ ) {\n                                                    ^~~~~~~~\n                                                    #file\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:43:64: warning: __FUNCTION__ is deprecated and will be removed in Swift 3, please use #function\n    public class func info(msg: String, functionName: String = __FUNCTION__,\n                                                               ^~~~~~~~~~~~\n                                                               #function\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:44:24: warning: __LINE__ is deprecated and will be removed in Swift 3, please use #line\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                       ^~~~~~~~\n                       #line\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:44:53: warning: __FILE__ is deprecated and will be removed in Swift 3, please use #file\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                                                    ^~~~~~~~\n                                                    #file\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:49:67: warning: __FUNCTION__ is deprecated and will be removed in Swift 3, please use #function\n    public class func warning(msg: String, functionName: String = __FUNCTION__,\n                                                                  ^~~~~~~~~~~~\n                                                                  #function\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:50:24: warning: __LINE__ is deprecated and will be removed in Swift 3, please use #line\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                       ^~~~~~~~\n                       #line\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:50:53: warning: __FILE__ is deprecated and will be removed in Swift 3, please use #file\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                                                    ^~~~~~~~\n                                                    #file\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:55:65: warning: __FUNCTION__ is deprecated and will be removed in Swift 3, please use #function\n    public class func error(msg: String, functionName: String = __FUNCTION__,\n                                                                ^~~~~~~~~~~~\n                                                                #function\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:56:24: warning: __LINE__ is deprecated and will be removed in Swift 3, please use #line\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                       ^~~~~~~~\n                       #line\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:56:53: warning: __FILE__ is deprecated and will be removed in Swift 3, please use #file\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                                                    ^~~~~~~~\n                                                    #file\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:61:65: warning: __FUNCTION__ is deprecated and will be removed in Swift 3, please use #function\n    public class func debug(msg: String, functionName: String = __FUNCTION__,\n                                                                ^~~~~~~~~~~~\n                                                                #function\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:62:24: warning: __LINE__ is deprecated and will be removed in Swift 3, please use #line\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                       ^~~~~~~~\n                       #line\n/Users/user/MyProjects/Kitura-sample/Packages/LoggerAPI-0.2.0/Sources/LoggerAPI/Logger.swift:62:53: warning: __FILE__ is deprecated and will be removed in Swift 3, please use #file\n        lineNum: Int = __LINE__, fileName: String = __FILE__) {\n                                                    ^~~~~~~~\n                                                    #file\nCompiling Swift Module 'KituraSys' (4 sources)\nCompiling Swift Module 'KituraNet' (12 sources)\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n<module-includes>:1:9: note: in file included from <module-includes>:1:\n#import \"utils.h\"\n        ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-HttpParserHelper-0.2.0/utils.h:20:10: error: 'http_parser.h' file not found\n#include \"http_parser.h\"\n         ^\n/Users/user/MyProjects/Kitura-sample/Packages/Kitura-net-0.3.1/Sources/KituraNet/HttpParser/HttpParser.swift:18:8: error: could not build Objective-C module 'http_parser_helper'\nimport http_parser_helper\n       ^\n/Users/user/MyProjects/Kitura-sample/Packages/SwiftyJSON-2.3.3/Source/SwiftyJSON.swift:399:47: warning: '++' is deprecated: it will be removed in Swift 3\n                return (String(self.arrayIndex++), JSON(o))\n                                              ^\n<unknown>:0: error: build had 1 command failures\n", "#ifndef utils_h\n#define utils_h\n\n#include \"http_parser.h\"\n", "#ifndef utils_h\n#define utils_h\n\n#include \"/usr/local/include/http_parser.h\"\n", "Compiling Swift Module 'Kiturasample' (1 sources)\nLinking Kitura-sample\nld: library not found for -lpcre2-8 for architecture x86_64\n<unknown>:0: error: build had 1 command failures\n", "module pcre2 [system] {\n    header \"common.h\"\n    header \"/usr/local/include/pcre2.h\"\n    link \"pcre2-8\"\n    export *\n}\n", "module pcre2 [system] {\n    header \"common.h\"\n    header \"/usr/local/include/pcre2.h\"\n    link \"pcre\"\n    export *\n", "ld: library not found for -lcurlHelpers for architecture x86_64\n<unknown>:0: error: build had 1 command failures\n", "Linking Kitura-sample\nld: library not found for -lhttp_parser for architecture x86_64\n<unknown>:0: error: build had 1 command failures\n", "module http_parser_helper {\n    header \"utils.h\"\n    link \"http_parser\"\n    link \"httpParserHelper\"\n    export *\n}\n"], "labels": ["build", "bug"]}
{"project": "mathjax_MathJax", "title": "Set mathvariant for \\square and other upright symbols", "description": "The symbols in the math0mi table should have mathvariant=\"normal\" so that NativeMML doesn't produce italic versions of them.  Also the font data files for the web fonts should have italic and other forms roll over to normal if not found in the specified variant. ", "code": [], "labels": ["Accepted"]}
{"project": "dart-lang_sdk", "title": "Error final field must be initialized in constructor even though null is the default", "description": "class X {\n\u00a0\u00a0final num a; \u00a0\u00a0const X([this.a]); \u00a0\u00a0const X.constant();     // Error \"The final field a must be initialized\"\n} If I change the X.constant constructor to be : \u00a0\u00a0\u00a0\u00a0\u00a0const X.constant() : this(); then it works. Seems a little wierd that a is already assigned to null shouldn't it just do that.  If I try to assign a outside of the initializer list then I'd expect an error can't change a final. ", "code": [], "labels": ["closed-invalid", "Type-Defect", "area-vm"]}
{"project": "RocketChat_Rocket.Chat", "title": "[FEATURE] Create slash command /hide to \"close\" direct messages", "description": "The slash commands /leave and /part only work on channels\nThe idea is to add /hide command to do the same as we do with the UI:  ", "code": [], "labels": ["Feature: Request"]}
{"project": "alibaba_fastjson", "title": "\u89e3\u6790\u8fd9\u6837\u7684json\u6570\u636e\u4f1a\u62a5\u9519", "description": "{\"error_code\": 0,\"reason\": \"Success\",\"result\": {\"data\":{ \"holiday\" : \"{\"name\":\"\u7aef\u5348\u8282\",\"festival\":\"2016-6-9\",\"desc\":\"6\u67089\u65e5\u81f311\u65e5\u653e\u5047\u8c03\u4f11\uff0c\u51713\u5929\u30026\u670812\u65e5\uff08\u661f\u671f\u65e5\uff09\u4e0a\u73ed\u3002\",\"list\":[{\"date\":\"2016-6-9\",\"status\":\"1\"},{\"date\":\"2016-6-10\",\"status\":\"1\"},{\"date\":\"2016-6-11\",\"status\":\"1\"},{\"date\":\"2016-6-12\",\"status\":\"2\"}]}\" , \"year\" : \"2016\" , \"year-month\" : \"2016-7\"}}} com.alibaba.fastjson.JSONException: syntax error, position at 55, name holiday\nat com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:479)\nat com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:425)\nat com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:425)\nat com.alibaba.fastjson.parser.DefaultJSONParser.parse(DefaultJSONParser.java:1183)\nat com.alibaba.fastjson.parser.DefaultJSONParser.parse(DefaultJSONParser.java:1152)\nat com.alibaba.fastjson.JSON.parse(JSON.java:101)\nat com.alibaba.fastjson.JSON.parse(JSON.java:92)\nat com.ch.test.TestJson.t1(TestJson.java:14)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\nat java.lang.reflect.Method.invoke(Unknown Source)\nat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\nat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\nat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\nat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\nat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\nat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\nat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\nat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\nat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\nat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\nat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\nat org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)\nat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\nat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\nat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\nat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\nat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192) ", "code": [], "labels": ["question"]}
{"project": "fossasia_badgeyay", "title": "Modularise the Photo Url for Firebase updation", "description": "I'm submitting a ... Current behavior:\nPhoto URL doesn't get updated in Firebase now, Expected behavior:\nIt should be modularised in order to update photo URL in both databases(local and Firebase) at the same time. Yes I am working on it. ", "code": [], "labels": ["has-PR"]}
{"project": "lodash_lodash", "title": "Defer calls to a curried function n times.", "description": "Problem: Is there a way where I can curry all the parameters yet defer the function call one (or n) more time(s)?\nLike: ", "code": [], "labels": ["question"]}
{"project": "danialfarid_ng-file-upload", "title": "MaxWidth/MaxHeight validations not working", "description": "<URL> Demo Fiddle Note that selecting an image larger than 500x500 does not trigger the validation to appear. This appears to have been introduced in the last few versions, as when I revert to v12.1.0 (<URL> the validation appears correctly. LMK if I can provide any further information of use. Thanks! ", "code": [], "labels": ["bug"]}
{"project": "microsoft_botframework-sdk", "title": "[Feature Request] Add payment support for Telegram and FB Messenger - Unify payments in Telegram, Skype and Facebook", "description": "Payments work only in WebChat and Skype\n<URL>  .\n<URL>\nPayments with platform UI instead redirecting to url feels more natural.\nPlease add payments support for Telegram, Facebook. Documentation - <URL>\n Documentation - <URL>\n Documentation - <URL>\n ", "code": [], "labels": ["Feature Request"]}
{"project": "wet-boew_wet-boew", "title": "Form validation: ariaLive and clearing errors", "description": "It looks like #3063 and it's fix in #3066 have broken the form validation plugin. Affected versions: Issues  ", "code": [], "labels": ["Query: Bug"]}
{"project": "mono_mono", "title": "Passing delegate to unmanaged code as function pointer", "description": "I am not sure is this a bug or am I missing something, but I've encountered following issue. I want my app with embedded Mono to call managed delegate as function pointer. I tried both Marshal.GetFunctionPointerForDelegate and method described here: <URL> All throw access violation exception. main.cpp: <CODE> Static1.cs: <CODE> Both compiled with Visual Studio 2017 15.8.5 at x64 configuration. I also can try to reproduce Marshal.GetFunctionPointerForDelegate case if needed. 0xC0000005: Access Violation Exception at string int ret_func_val = s_func() in main.cpp [v] Windows 10 1803 x64 Version Used:\nMono built from master branch as for September 30th, 2018 I tried to apply attributes UnmanagedFunctionPointer to corresponding delegate in case problem is with calling convention but it also haven't helped. ", "code": ["#include <string>\n#include <iostream>\n#include <mono/jit/jit.h>\n#include <mono/metadata/assembly.h>\n#include <mono/metadata/debug-helpers.h>\n#include <Windows.h>\n\nusing namespace std;\n\n//Define function pointer\ntypedef int (*UnmanagedNumberGenerator)();\n\nstatic UnmanagedNumberGenerator s_func = NULL;\n\nvoid RegCall(UnmanagedNumberGenerator f)\n{\n\tcout << \"RegCall called\" << endl;\n\tif (f == NULL)\n\t{\n\t\tcout << \"Managed delegate was proceed as NULL\" << endl;\n\t}\n\ts_func = f;\n}\n\nMonoDomain* mainDomain;\n\nstring GetExecPath()\n{\n\t//Get module handle\n\tHMODULE handle = GetModuleHandle(NULL);\n\t//Get path\n\tchar tmp_path[300];\n\tGetModuleFileName(handle, tmp_path, 300);\n\t//Convert to string\n\tstring path(tmp_path);\n\t//Delete filename from path\n\tfor (int i = path.length() - 1; i >= 0; i--)\n\t{\n\t\tif (path[i] == (char)92)\n\t\t{\n\t\t\tpath.resize(i);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\n\t//Return\n\treturn path;\n}\n\n\nint main()\n{\n\t//Set up mono\n\tmono_set_dirs((GetExecPath() + \"\\\\lib\").c_str(), (GetExecPath() + \"\\\\etc\").c_str());\n\t//Init mono domain\n\tmainDomain = mono_jit_init(\"mainDomain\");\n\t//Check\n\tif (!mainDomain)\n\t{\n\t\tcout << \"Unable to create mono domain!\" << endl;\n\t}\n\t//Load assembly\n\tMonoAssembly* mainAssembly = mono_domain_assembly_open(mainDomain, (GetExecPath() + \"\\\\ExperementalLib.dll\").c_str());\n\t//Check\n\tif (!mainAssembly)\n\t{\n\t\tcout << \"Unable to load assembly!\" << endl;\n\t}\n\t//Get assembly image\n\tMonoImage* mainImage = mono_assembly_get_image(mainAssembly);\n\t//Check\n\tif (!mainImage)\n\t{\n\t\tcout << \"Unable to get assembly image!\" << endl;\n\t}\n\n\tMonoClass* managedClass = mono_class_from_name(mainImage, \"ExperementalLib\", \"Static1\");\n\t\n\t//Add internal call\n\tmono_add_internal_call(\"ExperementalLib.Static1::RegisterCall\", RegCall);\n\n\tcout << s_func << endl;\n\n\t//Make runtime call\n\tMonoMethodDesc* caller_desc = mono_method_desc_new(\"ExperementalLib.Static1::MakeReg()\", true);\n\tMonoMethod* caller_meth = mono_method_desc_search_in_class(caller_desc, managedClass);\n\tif (!caller_meth)\n\t{\n\t\tcout << \"Unable to load method!\" << endl;\n\t}\n\tmono_runtime_invoke(caller_meth, NULL, NULL, NULL);\n\n\tvoid* CC = NULL;\n\tcout << CC << endl;\n\tcout << s_func << endl;\n\n\tint ret_func_val = s_func();\n\t\n\t{\n\t\tstring ttt;\n\t\twhile (getline(cin, ttt))\n\t\t{\n\n\t\t}\n\t}\n\treturn 0;\n}\n", "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing System.Threading.Tasks;\nusing System.Runtime.CompilerServices;\nusing System.Runtime.InteropServices;\n\nnamespace ExperementalLib\n{\n    public static class Static1\n    {\n        //[UnmanagedFunctionPointer(CallingConvention.Cdecl)]\n        public delegate int Numberer();\n\n        static Numberer ssdel;\n\n        static Static1()\n        {\n            \n        }\n\n        //Describe function\n        public static int GenerateNumber()\n        {\n            return 1337;\n        }\n\n        [MethodImpl(MethodImplOptions.InternalCall)]\n        extern public static void RegisterCall(Numberer n);\n\n        public static void MakeReg()\n        {\n            ssdel = new Numberer(GenerateNumber);\n            RegisterCall(ssdel);\n        }\n    }\n}\n"], "labels": ["question"]}
{"project": "godotengine_godot", "title": "Viewport \"Disable Input\" property not working", "description": "On godot 3.0 alpha 2 on linux64 (ubuntu 16.04)  ", "code": [], "labels": ["topic:core", "archived", "bug"]}
{"project": "ytdl-org_youtube-dl", "title": "[MoeVideo] Unable to extract OpenGraph title", "description": "<CODE> <URL> ", "code": ["$ y -v 'http://moevideo.net/video/00297.0036103fe3d513ef27915216fd29'\n[debug] System config: []\n[debug] User config: ['-4', '-f', 'best', '--prefer-free-formats', '--no-cache-dir', '--no-mtime', '--youtube-skip-dash-manifest']\n[debug] Command-line args: ['-v', 'http://moevideo.net/video/00297.0036103fe3d513ef27915216fd29']\n[debug] Encodings: locale UTF-8, fs utf-8, out UTF-8, pref UTF-8\n[debug] youtube-dl version 2016.08.28\n[debug] Python version 3.6.0a4 - Linux-4.7.0-rc7-686-i686-with-debian-stretch-sid\n[debug] exe versions: ffmpeg 3.1.3, ffprobe 3.1.3, rtmpdump 2.4\n[debug] Proxy map: {}\n[MoeVideo] 00297.0036103fe3d513ef27915216fd29: Downloading webpage\nERROR: Unable to extract OpenGraph title; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/youtube_dl/YoutubeDL.py\", line 691, in extract_info\n    ie_result = ie.extract(url)\n  File \"/usr/local/lib/python3.6/dist-packages/youtube_dl/extractor/common.py\", line 347, in extract\n    return self._real_extract(url)\n  File \"/usr/local/lib/python3.6/dist-packages/youtube_dl/extractor/moevideo.py\", line 66, in _real_extract\n    title = self._og_search_title(webpage)\n  File \"/usr/local/lib/python3.6/dist-packages/youtube_dl/extractor/common.py\", line 759, in _og_search_title\n    return self._og_search_property('title', html, **kargs)\n  File \"/usr/local/lib/python3.6/dist-packages/youtube_dl/extractor/common.py\", line 747, in _og_search_property\n    escaped = self._search_regex(og_regexes, html, name, flags=re.DOTALL, **kargs)\n  File \"/usr/local/lib/python3.6/dist-packages/youtube_dl/extractor/common.py\", line 650, in _search_regex\n    raise RegexNotFoundError('Unable to extract %s' % _name)\nyoutube_dl.utils.RegexNotFoundError: Unable to extract OpenGraph title; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n\n"], "labels": ["bug"]}
{"project": "apache_incubator-mxnet", "title": "Could not build with CUDA_ARCH_LIST=Common", "description": "I could not build with CUDA_ARCH_LIST=Common on ArchLinux. mxnet-git.log Same as #15263 (comment) ", "code": [], "labels": ["Build", "Question"]}
{"project": "qgis_QGIS", "title": "Georeferencer: Raster still not displayed (0.8.0, Mac OS X)", "description": "Author Name: christian-moe-hf-uio-no - (christian-moe-hf-uio-no -)\nOriginal Redmine Issue: 527 Redmine category:build/install\nAssignee: Tom Elwertowski I have read that this bug is supposed to be fixed, but the Georeferencer plugin still doesn't seem to display an unreferenced TIFF or JPEG raster. For that matter, it doesn't display a referenced TIFF either. The display remains black. I am using the 0.8.0 binary on Mac OS X 10.3.9. ", "code": [], "labels": ["Build/Install", "Bug"]}
{"project": "Winetricks_winetricks", "title": "add dotnet20sp1 support", "description": "<CODE> Original issue reported on code.google.com by daniel.r...@gmail.com on 29 Jun 2011 at 2:53 ", "code": ["http://bugs.winehq.org/show_bug.cgi?id=16956\ngives a successful recipe for dotnet20sp1 installation.\nWe should try to implement that in a new dotnet20sp1\nverb, and check to see if that recipe helps the\nexisting experimental dotnet20sp2 verb.\n"], "labels": ["auto-migrated", "Type-Defect"]}
{"project": "apostrophecms_apostrophe", "title": "apostrophe-headless-dashboard module as an admin-first homepage when there are no \"pages\"?", "description": "Would like to see if we can give editing with headless some love. Editing in modals and editing pages is clunky. ", "code": [], "labels": ["3.0"]}
{"project": "OrchardCMS_Orchard", "title": "Custom Forms permission provider performs a costly query", "description": "@pszmyd created:\n<URL> When fetching permission list, the provider from CustomForms module scans all content items just to get a list of distinct types. That impacts performance a lot when there are lots of items and one wants to list all available permissions. ", "code": [], "labels": ["medium"]}
{"project": "jekyll_jekyll", "title": "Set meaningful file modification times", "description": "My workflow to use Jekyll is: This causes every file to be republished every time because jekyll sets the file modification times to the current time. I recommend that each built file have a modification time equal to the latest modification time of any of its input files. ", "code": [], "labels": ["frozen-due-to-age"]}
{"project": "OpenTTD_OpenTTD", "title": "AI forgets to attach wagons to trains", "description": "George opened the ticket and wrote: Attachments Reported version: trunk\nOperating system: Windows ", "code": [], "labels": ["duplicate", "flyspray"]}
{"project": "twbs_bootstrap", "title": "Smooth scroll on iOS", "description": "I have some troubles having a smooth scroll in touch screen devices for a form. Something is wrong but I can't figure out what: not sure if it's a bug. Here is my index (pug and Angular 2): <CODE> (Please note that I have removed angular code for better clarity) My app code: <CODE> and my form: <CODE> ", "code": ["doctype html\n  html\n   head\n    base(href=\"/\")\n\n    title MyApp\n\n    meta(charset='utf-8')\n    meta(name='viewport', content='width=device-width, initial-scale=1, shrink-to-fit=no')\n    meta(http-equiv='x-ua-compatible', content='ie=edge')\n\n    link(rel='icon', href='images/favicon.ico')\n    link(rel='stylesheet', type='text/css', href='stylesheets/bootstrap-flex-4.alpha5.min.css')\n    script(type='text/javascript' src='javascripts/bootstrap-4.alpha5.min.js')\n    body\n        my-app(style='height:100%')\n            #loader\n", "div#main.container-fluid(style='width:100%; height:100%;')\n   #content.row.flex-items-xs-center(style='min-height:100%;')\n     .col-xs-12.col-sm-10.col-md-8.col-lg-6\n         router-outlet\n", "div.survey\n  div.row(style='margin-bottom:30px;')\n    h3.col-xs-12.col-sm-12.col-md-12 Hello\n\nform([formGroup]='form', novalidate='', (ngSubmit)='postSurvey(form.value, form.valid)')\n    div(style='margin-bottom:80px')\n        div.row.question-row(*ngFor='let item of survey.pages[page].questions; let idx=index', [formGroupName]='idx')\n            // INFO\n            div.col-xs-12.col-sm-12.col-md-12\n                label.question {{ (item.id | findItem:questions).question[lang]}}\n            // NUMBER\n            div.col-xs-12.col-sm-12.col-md-12\n                .form-group\n                    label.form-control-label.question {{ (item.id | findItem:questions).question[lang] }}\n                        span.required\n                    input.form-control(number, name='answer', type='number', placeholder='Reponse', formControlName='answer')\n\n            // TEXTAREA\n            div.col-xs-12.col-sm-12.col-md-12\n                .form-group\n                    label.form-control-label.question {{ (item.id | findItem:questions).question[lang] }}\n                        span.required\n                    textarea.form-control(autosize, name='answer', placeholder='Reponse', formControlName='answer')\n"], "labels": ["awaiting reply"]}
{"project": "MicrosoftDocs_azure-docs", "title": "Error", "description": "Hi\nusing the recommended link (vs 2017), using a vanilla IoT Edge Project, I get an error (I cannot attach an image). The error message is a 400 error, ArgumentInvalid: BadRequest, absolutely no other info. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["iot-edge/svc", "triaged", "support-request", "cxp"]}
{"project": "zephyrproject-rtos_zephyr", "title": "Bluetooth Mesh: Periodic Publishing", "description": "Describe the bug\nI am working with bbc_microbit modules, using Bluetooth-Mesh examples from the Bluetooth official website as a base (self provisioning and configuring). I want to set a periodic publishing but the callback function is not being called. To Reproduce\nSteps to reproduce the behavior: Inside the configuration function: Relevant Kernel configs: <CODE> Expected behavior\nSeeing the printk on the callback function (*update) every n seconds (as set on the bt_mesh_cfg_mod_pub .period) in order to update the message to be published Impact\nI want to set up an experiment where multiple sensors publish at different/random moments in time. Not having the periodic callbacks complicates the development. Environment (please complete the following information): ", "code": ["CONFIG_BT=y \nCONFIG_BT_BROADCASTER=y\nCONFIG_BT_OBSERVER=y\nCONFIG_BT_MESH=y  \nCONFIG_BT_MESH_RELAY=y\nCONFIG_BT_DEBUG_LOG=y\nCONFIG_BT_MESH_DEBUG=y\n"], "labels": ["priority: low", "area: Bluetooth", "bug"]}
{"project": "microsoft_TypeScript", "title": "Suggestion: Union types and string constants", "description": "It is great to know that the next TypeScript will come with Union Types. This will allow to tighten up those previously any parameter definitions that accept more than one type. One thing that I wanted to bring up which is very common in JavaScript is parameters or objects that take documented string constants. For example assume we have the following function that takes a width and a color: My suggestion is let us include string constants in Union Types, so that we can have: Then we can have tools suggest those especial strings in tooltips or intellisense, and catch more errors. For example: Thanks! ", "code": [], "labels": ["Duplicate", "Suggestion"]}
{"project": "the-control-group_voyager", "title": "Undefined variable: dataRow (View:  bread/edit-add.blade.php)", "description": "Hi, I have issues with  Add BREAD to this table. I created new table at tools/database without create model after that i tried tools/bread  Add BREAD to this table with this error: ErrorException (E_ERROR)\nUndefined variable: dataRow (View: /Users/michalnosil/Sites/voyager/vendor/tcg/voyager/resources/views/tools/bread/edit-add.blade.php) THX ", "code": [], "labels": ["duplicate"]}
{"project": "hashicorp_vagrant", "title": "global-status does not work but local status (and the VMs in general) does", "description": "Vagrant 2.2.5 Windows 10 Ubuntu 16.04 LTS Not Applicable <URL> global-status should list all my VMs Note that vagrant status within the project directory works fine.. and all VMs are fine and work. It's just global-status which does not work. For more context of this issue see this SO post <URL> No other issues, just this SO post (same as above) <URL> ", "code": [], "labels": ["waiting-reply"]}
{"project": "symfony_symfony", "title": "Add support to get env in custom router at server:start/server:run", "description": "The commands server:start/server:run from FrameworkBundle have option to a custom router, however is not possible get the env options at the custom router. ", "code": [], "labels": ["Feature"]}
{"project": "protocolbuffers_protobuf", "title": "gcc-5.2 {PROJECT}.pb.cc.o undefined reference to symbol '_ZN6google8protobuf2io16CodedInputStream20ReadVarint64FallbackEv' CPP", "description": "With gcc 5.2 i get this error /usr/bin/ld: PROJECT.pb.cc.o undefined reference to symbol _ZN6google8protobuf2io16CodedInputStream20ReadVarint64FallbackEv'> /usr/lib/libprotobuf.so.10: error adding symbols: DSO missing from command line  I use cmake with the pkg-config module to build my application. When I build the Project on another machine with gcc-4.9 there is no Problem. I install protobuf and grpc with gcc-5.2. I am running the project on Ubuntu 14.10 I reinstalled protobuf and grpc after cleaning up the old installation but the issue remains ", "code": [], "labels": ["c++", "bug"]}
{"project": "wordpress-mobile_WordPress-Android", "title": "Reader: Logged out reader shows text field to follow site/tag", "description": "Nexus 4, OS 5.1.1 While logged out, view the reader's menu.\nTry to add a site or tag via the text field.\nFollowing a site will fail, but following a tag will appear to succeed, even though the tag does not show up in the list. Interestingly an added tag will be the current topic when you dismiss the menu. Maybe don't show the text field while logged out? ", "code": [], "labels": ["Reader"]}
{"project": "golang_go", "title": "debug/goobj: decide whether it goes into Go 1.3", "description": "<CODE> ", "code": ["New package debug/goobj supports the new cmd/nm and eventually the new cmd/ld. But\nshould it be in the standard tree? The argument in favor is that debug/elf, debug/macho,\ndebug/pe are all there, and it keeps the prereq for these commands in the tree. The\nargument against is that I probably wouldn't put any of them in the standard library if\nI were doing it again today.\n\nPerhaps debug/goobj can be put somewhere else in the main repo that is not the standard\ntree, or maybe it should be in a subrepo, or it is fine where it is. Decide."], "labels": ["FrozenDueToAge", "fixed"]}
{"project": "vibe-d_vibe.d", "title": "High CPU usage when using FileDescriptorEvent", "description": "See the related forum thread for a full description. ", "code": [], "labels": ["bug"]}
{"project": "wechaty_wechaty", "title": "How about add a new kind of name called `Display` in the room", "description": "@zixia  I think maybe we should keep three kind of name in the room.\nbesides name and alias, we should also add display We had 2 kinds of roomMap now: <CODE> <CODE> nameMap can identify the contact by bot version.\naliasMap as your request, should return roomAlias\uff0cif not set, it should return '' Then, what if other contact's vision in a room? I think we should consider this. For example,  when I @\u821e\u54e9\u5ba2\u670d\uff0c whose alias is  50fb16c0-ff09-11e6-9fe5-dda97284d25b  set by the bot. but I cannot find the contact by any kind of map, sometimes, it real confused the developer. Then we can find the contact by name, alias, and display. What's your concern? BTW, About the Display Order, I have talked in #173 Related Issues : #173 #217 ", "code": ["\"nameMap\": {\n            \"@4c32c97337cbb325442c304d6a44e374\": \"22acb030-ff09-11e6-8a73-cff62d9268c5\", \n            \"@cd7d467d7464e8ff6b0acd29364654f3666df5d04551f6082bfc875f90a6afd2\": \"\u5c0f\u6854\u540c\u5b66\", \n            \"@36d55130f6a91bae4a2ed2cc5f19c56a9258c65ce3db9777f74f607223ef0855\": \"50fb16c0-ff09-11e6-9fe5-dda97284d25b\"\n        }, \n", "\"aliasMap\": {\n            \"@4c32c97337cbb325442c304d6a44e374\": \"\", \n            \"@cd7d467d7464e8ff6b0acd29364654f3666df5d04551f6082bfc875f90a6afd2\": \"\", \n            \"@36d55130f6a91bae4a2ed2cc5f19c56a9258c65ce3db9777f74f607223ef0855\": \"\"\n        }\n"], "labels": ["duplicate"]}
{"project": "laurent22_joplin", "title": "AppImage for 1.0.67 not available", "description": "In latest release 1.0.67 there isn't AppImage package <URL> ", "code": [], "labels": ["bug"]}
{"project": "golang_go", "title": "x/net/http2: Transport is leaking streams on broken Body", "description": "Please answer these questions before submitting your issue. Thanks! go version go1.10.3 linux/amd64 Yes linux, amd64 Client fails the request and resets the stream. Client fails the request and leaks the stream (on both client and server sides). ", "code": [], "labels": ["NeedsInvestigation", "FrozenDueToAge"]}
{"project": "openshift_origin", "title": "flake: ExternalID should not be able to resolve \"mesos3.internal.company.com\"", "description": "<URL> <CODE> ", "code": ["In suite \"github.com/openshift/origin/vendor/k8s.io/kubernetes/pkg/cloudprovider/providers/mesos\", test case \"Test_ExternalID\" failed:\n=== RUN   Test_ExternalID\n--- FAIL: Test_ExternalID (0.25s)\n\tmesos_test.go:274: ExternalID should not be able to resolve \"mesos3.internal.company.com\"\nFAIL\n"], "labels": ["kind/test-flake"]}
{"project": "hashicorp_terraform", "title": "RDS support for Secrets Manager", "description": "In the AWS console, Secrets Manager can be linked to an RDS instance to set the credentials. It would be great if Terraform supported this, to allow using Secrets Manager to configure and rotate RDS's credentials. ", "code": [], "labels": ["provider/aws"]}
{"project": "dotnet_corefx", "title": "Remove synchronization on SecureString.Length", "description": "Contention on this getter showed up in profiles of a cloud service that was reading the length several times in one method running on multiple threads (as one might expect for eg a password). It doesn't need to be synchronized. From discussion with @stephentoub : removing the Synchronized/lock on Length would mean the disposed check and accessing the length would no longer be atomic, but you don\u2019t lose anything from that, because it could be disposed after accessing the length and before the caller gets back the value and acts on it.  Removing it would also means that _length isn\u2019t synchronized with other operations that change it, but again, the length could change immediately after using it, so it doesn\u2019t really save anything. To minimise the staleness of the read we can replace the lock on Length with Volatile.Read(ref _length) The same could be done for IsReadOnly and MakeReadOnly, I think. @maryamariyan one for you. ", "code": [], "labels": ["area-System.Security"]}
{"project": "spring-projects_spring-boot", "title": "spring-boot-maven-plugin - renaming artifact with finalName fails", "description": "Using the spring-boot-maven plugin (org.springframework.boot:spring-boot-maven-plugin:1.2.3.RELEASE), I'm trying to change the name of the repackaged final artifact like so: <CODE> When running mvn package, however, execution fails: <CODE> It does seem as though the artifacts are being created as target/ contains both bar.jar and foo-1.0.0-SNAPSHOT.jar, but the build fails with an error: <CODE> mvn package -X output: <URL> ", "code": ["            <executions>\n                <execution>\n                    <goals>\n                        <goal>repackage</goal>\n                    </goals>\n                    <configuration>\n                        <finalName>bar</finalName>\n                    </configuration>\n                </execution>\n            </executions>\n", "[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.2.3.RELEASE:repackage (default) on project foo: Execution default of goal org.springframework.boot:spring-boot-maven-plugin:1.2.3.RELEASE:repackage failed: For artifact mvn pa{foo:foo:1.0.0-SNAPSHOT:jar}: An attached artifact must have a different ID than its corresponding main artifact. -> [Help 1]\n", "[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.2.3.RELEASE:repackage (default) on project foo: Execution default of goal org.springframework.boot:spring-boot-maven-plugin:1.2.3.RELEASE:repackage failed: For artifact {foo:foo:1.0.0-SNAPSHOT:jar}: An attached artifact must have a different ID than its corresponding main artifact. -> [Help 1]\n"], "labels": ["type: bug"]}
{"project": "flutter_flutter", "title": "Autofill on iPhone not working as expected", "description": "Result: Password is put into the email field instead of the username/email and nothing goes into the password field.\nExpected Result: username goes into email field and password goes into password field Here is a link to a video that shows the issue: <URL> Here is a reproduction case: related to #13015 <CODE> <CODE> <CODE> ", "code": ["", "Analyzing issue...                                                      \nNo issues found! (ran in 5.6s)\n", "[\u2713] Flutter (Channel beta, v1.5.4-hotfix.1, on Mac OS X 10.14.4 18E226, locale en-US)\n    \u2022 Flutter version 1.5.4-hotfix.1 at /Users/natalieflores/flutter\n    \u2022 Framework revision 09cbc34a0b (7 days ago), 2019-04-30 15:44:27 -0700\n    \u2022 Engine revision 52c7a1e849\n    \u2022 Dart version 2.3.0 (build 2.3.0-dev.0.5 a1668566e5)\n\n \n[\u2713] Android toolchain - develop for Android devices (Android SDK version 28.0.3)\n    \u2022 Android SDK at /Users/natalieflores/Library/Android/sdk\n    \u2022 Android NDK location not configured (optional; useful for native profiling support)\n    \u2022 Platform android-28, build-tools 28.0.3\n    \u2022 ANDROID_HOME = /Users/natalieflores/Library/Android/sdk\n    \u2022 Java binary at: /Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/bin/java\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1136-b06)\n    \u2022 All Android licenses accepted.\n\n[\u2713] iOS toolchain - develop for iOS devices (Xcode 10.2.1)\n    \u2022 Xcode at /Applications/Xcode.app/Contents/Developer\n    \u2022 Xcode 10.2.1, Build version 10E1001\n    \u2022 ios-deploy 1.9.4\n    \u2022 CocoaPods version 1.5.3\n\n[\u2713] Android Studio (version 3.2)\n    \u2022 Android Studio at /Applications/Android Studio.app/Contents\n    \u2022 Flutter plugin version 31.2.1\n    \u2022 Dart plugin version 181.5656\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1136-b06)\n\n[\u2713] VS Code (version 1.33.1)\n    \u2022 VS Code at /Applications/Visual Studio Code.app/Contents\n    \u2022 Flutter extension version 2.25.1\n\n[\u2713] Connected device (1 available)\n    \u2022 iPhone X \u2022 90F6DD03-448B-4B6C-B03F-6FD7345B224D \u2022 ios \u2022 com.apple.CoreSimulator.SimRuntime.iOS-12-2 (simulator)\n\n\u2022 No issues found!\n"], "labels": ["a: text input", "\u233a\u202c platform-ios", "engine"]}
{"project": "bwssytems_ha-bridge", "title": "Where do install the nssm before installing it?", "description": "Do I download and install this file in the java folder before I install it through CMD? ", "code": [], "labels": ["question"]}
{"project": "bulletphysics_bullet3", "title": "Complete the Bullet C-API (was googlecode  Issue 43)", "description": "See <URL> ", "code": [], "labels": ["new feature"]}
{"project": "IdentityServer_IdentityServer4", "title": "I'm missing a refresh token", "description": "Hi, I have defined the following client in an implementation of an openid connect authentication server using the Indentityserver 4. The grant type is set to hybrid and from the client definition I would have expected to receive a refresh token.\nnew Client\n{\nClientId = \"xxxx.app\",\nClientName = \"xxxxx app\",\nRequireClientSecret = false, <CODE> but I'm getting the following from the authentication server Claims:\nsid: 4acaba7433226f97ce7947fec435f3b0\nsub: 818727\nidp: local\namr: pwd\nname: Alice Smith\ngiven_name: Alice\nfamily_name: Smith\nwebsite: <URL> identity token: eyJhbGciOiJSUzI1NiIsImtpZCI6IjUxNDBlNGE4MjM3ODM2ZjNhZGIxMDgxODk1ZjA5ZGIwIiwidHlwIjoiSldUIn0.eyJuYmYiOjE1NDkyNzI4NDAsImV4cCI6MTU0OTI3MzE0MCwiaXNzIjoiaHR0cHM6Ly9sb2NhbGhvc3Q6NDQzMzQiLCJhdWQiOiJ4eHh4LmFwcCIsIm5vbmNlIjoiYzk5ZmU4MmZjMWUyNTkyNTIxZWM1ZmI4MDhkZTdjZTIiLCJpYXQiOjE1NDkyNzI4NDAsImF0X2hhc2giOiJBclFSVS1zU1hQX19ncVpkQUNNSmRRIiwic2lkIjoiNGFjYWJhNzQzMzIyNmY5N2NlNzk0N2ZlYzQzNWYzYjAiLCJzdWIiOiI4MTg3MjciLCJhdXRoX3RpbWUiOjE1NDkyNzE4MDUsImlkcCI6ImxvY2FsIiwiYW1yIjpbInB3ZCJdfQ.hCbXKQTYYcx2jpF-uua3FIbi73jpNi0E1nB5S7XgXrgtiwqWSCToVNSG0x6Lu1tTwa8K8UFtEL9lLJlhaztsqBEdEkPKIqgPbv-BFOxWypfRrhCiMm3L74zD4kH6eZIRN4rkvb4uDfEN7tDBK96J4fRLJ3xSLMr-x0kCu0xf1Fpm9HkjJqkTtfnE6gpzKt4_RgGY-fhBZI-70mRVgyqVWhck7rjcMkdcXKsi_G6GZU-aovvbQ311_XpL5oGlTau4LaXgNRBwc0xS6IxGlRUxPGVj100-abBjZ14fUPt57dhaA_B6lMSGbdQy1ZrarfHgOEnKND-ovDKrYvNBvYtq1w\naccess token:   eyJhbGciOiJSUzI1NiIsImtpZCI6IjUxNDBlNGE4MjM3ODM2ZjNhZGIxMDgxODk1ZjA5ZGIwIiwidHlwIjoiSldUIn0.eyJuYmYiOjE1NDkyNzI4NDAsImV4cCI6MTU0OTI3MjkxNSwiaXNzIjoiaHR0cHM6Ly9sb2NhbGhvc3Q6NDQzMzQiLCJhdWQiOlsiaHR0cHM6Ly9sb2NhbGhvc3Q6NDQzMzQvcmVzb3VyY2VzIiwiaHlwb3NhZmV3ZWJhcGkiXSwiY2xpZW50X2lkIjoieHh4eC5hcHAiLCJzdWIiOiI4MTg3MjciLCJhdXRoX3RpbWUiOjE1NDkyNzE4MDUsImlkcCI6ImxvY2FsIiwic2NvcGUiOlsib3BlbmlkIiwicHJvZmlsZSIsImh5cG9zYWZld2ViYXBpLmZ1bGxfYWNjZXNzIl0sImFtciI6WyJwd2QiXX0.PS0I13MfXCrbpkBwn6hLxk8vE1npBElNlf8XpGw4lLYpAs79eNjKNlO1BmdkXUAAnTFdgIrVkO9QVTSCc5HzTBvUqtrN7GT7DNjRuQfPVJQjLkdA12V05czTqGK7tp24dLl4FdfEWdAXTiK1kI-t6CsIsGEq9WVbPMfcMryGXUTiwHEOk4D8ABfoW9eepVG4-vqgb3kS6vArl-vbigQQ_o54r_O-Q4mt3q1DdJV9fmChamb8Q8giix9PAAHI7a0wJPkmiIwnZRkiIjG0eU5HJ8-meYx_2Mk-Vq78IJgbjYXu61D4wtMFLCmz9_bCQuc4HRXq4JbsdbhR8sW1ywygRg\nrefresh token:  none That is no refresh token? Have I missed a setting of somehow? br\nJakob ", "code": ["                AllowedGrantTypes = GrantTypes.Hybrid,\n                AccessTokenLifetime = 75,\n                RequirePkce = true,\n                RedirectUris = { \"http://127.0.0.1:7890/\", \"https://oidcdebugger.com/debug\" },\n                PostLogoutRedirectUris = { \"https://notused\" },\n                AllowOfflineAccess = true,\n                AllowAccessTokensViaBrowser = true,\n                AllowedScopes =\n                {\n                    IdentityServerConstants.StandardScopes.OpenId,\n                    IdentityServerConstants.StandardScopes.Profile,\n                    IdentityServerConstants.StandardScopes.Email,\n                    \"api.full_access\"\n                },\n                SlidingRefreshTokenLifetime = 12960,\n                RefreshTokenUsage = TokenUsage.OneTimeOnly,\n                RefreshTokenExpiration = TokenExpiration.Sliding,\n               \n            },\n"], "labels": ["question"]}
{"project": "webpack_webpack", "title": "\"Cannot find module\" error though build is successful", "description": "We are using Papaparse from Bower with WebPack and TypeScript 1.5. And though the build is successful (e.g. app is working), we are getting this error in stats.toString(): <CODE> WebPack config: Import: TS files are loaded through ts-loader: Papaparse:\nbower.json: <URL>\nmain file to which points bower.json: <URL> How this can be solved? ", "code": ["ERROR in /app/shared/services/papa.service.ts\n./app/shared/services/papa.service.ts\n  /app/shared/services/papa.service.ts (1,23): Cannot find module 'papaparse'.\n"], "labels": ["question"]}
{"project": "qgis_QGIS", "title": "PDOK Service en Python Console in QGIS 2.18.2 werken niet na installatie QGIS op MacBook Pro", "description": "Author Name: Bert Mast (Bert Mast)\nOriginal Redmine Issue: 16547\nAffected QGIS version: 2.18.2\nRedmine category:plugin_manager\nAssignee: Borys Jurgiel Ik heb QGIS versie 2.18.2 vorige week ge\u00efnstalleerd op mijn MacBook Pro. Vervolgens heb ik diverse plugins ge\u00efnstalleerd waar onder ook de PDOK Service. QGIS werkt op zich correct, echter de plugin PDOK Service werkt na installatie helaas niet. Zodra ik een adres in de plugin heb ingevoerd, komt de foutmelding terug: \"Niets gevonden. Probeer een andere spelling of gebruik alleen postcode/huisnummer\". Ook de Python Console werkt niet in het me nu Plugin. Ik zou graag advies willen hebben welke oorzaak hieraan ten grondslag ligt en hoe ik dit kan oplossen. iemand een idee? ", "code": [], "labels": ["Bug", "Plugins"]}
{"project": "ossrs_srs", "title": "FLV: \u5c06http_remux\u4eceon\u8bbe\u7f6e\u4e3aoff\uff0creload\u4e4b\u540e\uff0c\u53ea\u4f1adisable\u6700\u540e\u4e00\u6761stream", "description": "\u5c06http_remux\u4eceon\u8bbe\u7f6e\u4e3aoff\uff0creload\u4e4b\u540e\uff0c\u53ea\u4f1adisable\u6700\u540e\u4e00\u6761stream\uff0c\u524d\u9762\u7684\u82e5\u5e72stream\u4ecd\u80fd\u6b63\u5e38\u64ad\u653e\u3002\nSrsHttpStreamServer -> tflvs[] \u7684SrsLiveEntry template \u4e3a\u4f55\u53ea\u8bb0\u5f55\u6700\u8fd1\u7684\u4e00\u4e2astream\u800c\u4e0d\u662f\u6240\u6709\u7684stream\u5462 ", "code": [], "labels": ["bug"]}
{"project": "magento_magento2", "title": "PHP Less Compiler doesn't properly compile nested selectors within conditions", "description": "The issue we are running into is within the PHP less compiler.  When nesting selectors inside of conditional statements the php less compile ignores the conditioanls and doesn't render properly.  See example: <CODE> Expected CSS Output:\nSee codepen with working example using LESS js compiler\n(view compiled code) <CODE> Actual results compiled from Less PHP Compiler: <CODE> Notice the PHP Compiler ignores the .svg-view-slider-left;' and '.svg-view-slider-left-dims; selectors while nested in the & when (@fileName = \"slider-left\") { conditional statement which is native LESS behavior. This is native LESS behavior which doesn't work on production environments due to the choice of leveraging the php LESS compiler. ", "code": [".svg-view() {\n  background: url(\"../images/sprites.view.svg\") no-repeat;\n}\n\n.svg-view {\n.svg-view();\n}\n\n.svg-view-slider-left {\n    background-position: 0 0;\n}\n\n.svg-view-slider-left-dims {\n    width: 43px;\n    height: 43px;\n}\n\n.svg-icon(@fileName) when(isstring(@fileName)) {\n.svg-view();\n\n  & when (@fileName = \"slider-left\") {\n      .svg-view-slider-left;\n      .svg-view-slider-left-dims;\n  }\n}\n\nbody {\n    .svg-icon('slider-left');\n}\n", "body {\n  background: url(\"../images/sprites.view.svg\") no-repeat;\n  background-position: 0 0;\n  width: 43px;\n  height: 43px;\n}\n", "body {\n  background: url(\"http://images/sprites.view.svg\") no-repeat;\n}\n"], "labels": ["Issue: Ready for Work", "Issue: Confirmed", "Reproduced on 2.1.x", "Fixed in 2.3.x", "Issue: Format is valid", "Issue: Clear Description", "Reproduced on 2.2.x"]}
{"project": "apache_pulsar", "title": "Failed to build Golang client.", "description": "Describe the bug\nFailed to build Golang client, returning an error. To Reproduce\nSteps to reproduce the behavior: Expected behavior\nBuilding my program should work without error Screenshots Desktop (please complete the following information): Additional context\nThe output of the build: <CODE> ", "code": ["In file included from ../../../../../go/pkg/mod/github.com/apache/incubator-pulsar@v2.2.1+incompatible/pulsar-client-go/pulsar/c_client.go:24:\n./c_go_pulsar.h:22:10: fatal error: 'pulsar/c/client.h' file not found\n#include <pulsar/c/client.h>\n         ^~~~~~~~~~~~~~~~~~~\n1 error generated.\n"], "labels": ["type/bug"]}
{"project": "bridgedotnet_Bridge", "title": "Derived classes share parents member variable lists", "description": "<URL> ", "code": [], "labels": ["defect"]}
{"project": "symless_synergy-core", "title": "Auto detect server button", "description": "Imported issue: Problem: Users have to go through the \"IP or name\" problem, then find their IP (usually IPs are DHCP assigned) which is straight forward but a bit of an unnecesary hudle for new users. Solution: Allow the client to maybe scan their subnet for Synergy servers in \"auto-accept connections\" mode. ", "code": [], "labels": ["obsolete"]}
{"project": "ng-select_ng-select", "title": "Event toggling ng-select", "description": "Is your feature request related to a problem? Please describe.\nI'm working with aplication on Angular 6 and Electron.\nThe event in charge of expand/close ng-select is mousedown. While testing the aplication with Spectron there is no possibility to toggle the ng-select. Click events in this API simulates click not mousedown. Is there any reason why we are using mousedown event type instead of click? Describe the solution you'd like\nChange event listener from mousedown to click. Describe alternatives you've considered\nMake event listener configurable. ", "code": [], "labels": ["stale"]}
{"project": "atom_atom", "title": "Editor Failing to Open", "description": "Atom background processes starting, but then ending without the editor opening Expected behavior: Editor Opening Actual behavior: Editor does not open Reproduces how often: 100% 1.30.0 Unknown what additional information would be needed ", "code": [], "labels": ["stale"]}
{"project": "neovim_neovim", "title": "The `$VIMRUNTIME/vimrc_example.vim` file does not exists", "description": "nvim version v0.2.2 installed by homebrew on macOS. Help docs (e.g. usr_01.txt, usr_05.txt) refer $VIMRUNTIME/vimrc_example.vim as the example vimrc file, yet it does not exist inside neovim installation. ", "code": [], "labels": ["documentation"]}
{"project": "DynamoRIO_drmemory", "title": "Can't build Debug DrMemory on Windows with VS2008", "description": "From timurrrr@google.com on April 12, 2011 12:38:47 As of r249 ,\n(cygwin under VS2008 cmd)\ntimurrrr:drmemory/build$ cmake -DDEBUG=ON .. && devenv.com DrMemory.sln /Build Debug /Project drmemorylib\n...\n...\n1>cl : Command line error D8016 : '/O2' and '/RTC1' command-line options are incompatible\n... Original issue: <URL> ", "code": [], "labels": ["Type-Bug", "OpSys-Windows", "Status-Fixed", "Migrated", "Priority-Medium"]}
{"project": "apache_incubator-echarts", "title": "echar3\u5728\u79fb\u52a8\u7aef\u7684\u5404\u79cd\u624b\u673a\u4e2d\u6587\u5b57\u5927\u5c0f\u7684\u9002\u5e94BUG", "description": "echar3\u5728\u79fb\u52a8\u7aef\u7684\u5404\u79cd\u624b\u673a\u4e2d\u6587\u5b57\u5927\u5c0f\u7684\u9002\u5e94BUG 1.\u5b89\u5353\uff0c\u82f9\u679c\n2.   series: [\n{\nlabel: {\nnormal: {\nshow: true,\nposition: 'top',\ntextStyle:{\nfontSize:30,                 //BUG\u4f4d\u7f6e\n},\n},\n},\ntype:'line',\nsymbolSize:20,                       //BUG\u4f4d\u7f6e\n//                          connectNulls:true,\nlineStyle:{\nnormal:{\ncolor:'#f2ac2d',\n}\n},\nitemStyle:{\nnormal:{\ncolor:'#f2ac2d',\n}\n},\ndata:[seven.income1,seven.income2,seven.income3,seven.income4,seven.income5,seven.income6,seven.income7]\n}\n],\ntextStyle:{\ncolor:'#f2ac2d',\nfontSize:30,\n} \u8c03\u6574\u6587\u5b57\u5728\u79fb\u52a8\u7aef\u7684\u9002\u5e94 \u4ee5\u4e0b\u56fe\u7247\u4e3a\u4e0d\u540c\u79fb\u52a8\u7aef\u7684\u663e\u793a\u60c5\u51b5\n\n\n ", "code": [], "labels": ["stale"]}
{"project": "rafalp_Misago", "title": "Enforce user blocks.", "description": "If I'm blocking user, I don't want to receive notifications from him, get pulled into his private threads nor see his posts and threads. ", "code": [], "labels": ["backend"]}
{"project": "nopSolutions_nopCommerce", "title": "Browser language isn't detected properly", "description": "nopCommerce version: 4.10 Steps to reproduce the problem: Install 2 language EU and IT. Language display order doesn't matter here for me. Our website server is in Italy so they are using Italian culture on server. In previous version(nop 3.90) it was working fine. But in this version it works like below This issue only happen when customer open site & didn't login yet. After login it's showing site as per customer's choice language Under GetLanguageFromRequest()  method while debugging using logger\nvar requestCulture = _httpContextAccessor.HttpContext.Features.Get<IRequestCultureFeature>()?.RequestCulture; it gives culture = it-IT & UI culture = en-US which might be wrong for me if I m visiting site from India with en-US culture set in Browser(chrome). so I follow up this link <URL>\n& they suggested to use this & it works fine now with our site. customers form Italy can see site in Italian by default and customer outside Italy can see site in English var requestCulture = _httpContextAccessor.HttpContext.Request.GetTypedHeaders() .AcceptLanguage .OrderByDescending(x => x.Quality ?? 1) // Quality defines priority from 0 to 1, where 1 is the highest. .Select(x => x.Value.ToString()) .FirstOrDefault(); instead of this (your code)\nvar requestCulture = _httpContextAccessor.HttpContext.Features.Get<IRequestCultureFeature>()?.RequestCulture; ", "code": [], "labels": ["bug"]}
{"project": "dotnet_corefx", "title": "Allows JsonStringEnumConverter.CreateConverter to specify a default enum value", "description": "that allows parsing unrecognized strings/numbers into a specified default enum value. Currently if unrecognized strings/numbers are encountered an exception is thrown. ", "code": [], "labels": ["area-System.Text.Json", "enhancement"]}
{"project": "dotnet_cli", "title": "3.0 SDK is copying runtimes folders and assets to desktop TF", "description": "Found during dotnet/roslyn#34093 Repro Steps Notice that after build every net472 directory has a runtimes folder under it with the assets you'd expect from .NET Core TF. Example: <CODE> ", "code": ["E:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win\\lib\\net461\\System.Text.Encoding.CodePages.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win\\native\\Microsoft.DiaSymReader.Native.amd64.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win\\native\\Microsoft.DiaSymReader.Native.arm.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win\\native\\Microsoft.DiaSymReader.Native.x86.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win-x64\\native\\Microsoft.DiaSymReader.Native.amd64.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win-x86\\native\\Microsoft.DiaSymReader.Native.x86.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win7-x64\\native\\e_sqlite3.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win7-x86\\native\\e_sqlite3.dll\nE:\\code\\roslyn\\artifacts\\bin\\Roslyn.VisualStudio.Next.UnitTests\\Debug\\net472\\runtimes\\win8-arm\\native\\Microsoft.DiaSymReader.Native.arm.dll\n"], "labels": ["Bug"]}
{"project": "hyperledger_composer", "title": "How transaction are signed in composer?", "description": "", "code": [], "labels": ["stale"]}
{"project": "highcharts_highcharts", "title": "Scatter 3d points are misplaced", "description": "Points in scatter3d are incorrectly placed on a chart. <URL>\ny values  are 99.8, but the points are placed under 99.5. Also, the line exceeds the plot area. ", "code": [], "labels": ["Type: Regression"]}
{"project": "arduino_Arduino", "title": "Please add \"TheTroll\" library to the manager", "description": "Please add \"TheTroll\" library to the library manager - thank you\n<URL> ", "code": [], "labels": ["Component: Board/Lib Manager"]}
{"project": "getgauge_gauge", "title": "Logs directory should be created only when running gauge commands in a gauge project", "description": "Eg:\nIf you run gauge --install java\nA logs directory is created in the working directory despite it not being a gauge project ", "code": [], "labels": ["bug"]}
{"project": "quasarframework_quasar", "title": "Version mismatch when upgrading quasar", "description": "Describe the bug\n Additional info\nMay have happened because of failed commit.\n Can be reproduced by upgrading quasar\n What is required\nA way to make sure libraries use same version in node_modules/quasar/package.json\n ", "code": [], "labels": ["bug"]}
{"project": "ionic-team_ionic", "title": "ionItemReorder fires the click event of the list item", "description": "Ionic version: [x] 4.0.0 Current behavior: When reordering the items on a list, the click event fires as soon as an item is moved down on a list. But if the item was moved to up , it works as expected. Expected behavior: An item on a list should be able to move without triggering the click event. (Same as how it works when moving an item up to reorder) Steps to reproduce: Related code: <CODE> <CODE> Other information: Ionic info: <CODE> ", "code": ["<ion-list >\n     <ion-reorder-group [disabled]=\"isReorderDisabled\" (ionItemReorder)=\"reorderItem($event)\">\n     <ion-item [routerLink]=\"'/item/item-detail/' + mItem.itemId\" routerDirection=\"forward\"  *ngFor=\"let mItem of itemList\"  >\n           <ion-label>\n                {{mItem.title}}\n           </ion-label>\n        <ion-reorder slot=\"end\"></ion-reorder>\n      </ion-item>\n      </ion-reorder-group>\n</ion-list>\n", "reorderItem(event) {\n        const itemToMove = this.itemList.splice(event.detail.from, 1)[0];\n        this.itemList.splice(event.detail.to, 0, itemToMove);\n        event.detail.complete();\n    }\n", "Ionic:\n\n   ionic (Ionic CLI)             : 4.6.0 (/usr/lib/node_modules/ionic)\n   Ionic Framework               : @ionic/angular 4.0.0\n   @angular-devkit/build-angular : 0.12.1\n   @angular-devkit/schematics    : 7.2.1\n   @angular/cli                  : 7.2.1\n   @ionic/angular-toolkit        : 1.2.2\n\nCapacitor:\n\n   capacitor (Capacitor CLI) : 1.0.0-beta.13\n   @capacitor/core           : 1.0.0-beta.13\n\nSystem:\n\n   NodeJS : v8.15.0 (/usr/bin/node)\n   npm    : 6.6.0\n   OS     : Linux 4.15\n\n"], "labels": ["triage"]}
{"project": "rook_rook", "title": "jenkins: consider removing the intermediate build-runner", "description": "I dont think we need it and it makes getting to the console output a lot easier. ", "code": [], "labels": ["build"]}
{"project": "NationalSecurityAgency_ghidra", "title": "Negative Structure Ordinal produces positive value field", "description": "Describe the bug\nAccessing a structure with a negative value will produce the same results as if the value was positive. To Reproduce\nSteps to reproduce the behavior: <CODE> Expected behavior\nUnsure. Screenshots\n Environment (please complete the following information): ", "code": ["int getValue(int* a_ptr) {\n    return a_ptr[-1];\n}\n\ntypedef struct A {\n    int a_data;\n};\n\ntypedef struct B {\n    int b_data; /* buffer for protection */\n    struct A a;\n};\n\nint main() {\n    struct B b;\n    b.b_data = 5;\n    printf(\"%d\\n\", getValue(&b.a));\n    return 0;\n}\n"], "labels": ["Type: Bug"]}
{"project": "kubernetes-sigs_kubespray", "title": "win_nodes/kubernetes_patch : Check current nodeselector for kube-proxy daemonset]", "description": "Environment: Cloud provider: AWS\nOS : centos LINUX 7\nVersion of Ansible: 2.7.10\nKubespray version: Master Tag: 2.9.0 Copy of your inventory file: master-1 ansible_host=ip-10-1-x-x.eu-west-3.compute.internal ip=10.1.x.x\nmaster-2 ansible_host=ip-10-1-x-x.eu-west-3.compute.internal ip=10.1.x.x\nworker-1 ansible_host=ip-10-1-x-x.eu-west-3.compute.internal ip=10.1.x.x\nworker-2 ansible_host=ip-10-1-x-x.eu-west-3.compute.internal ip=10.1.x.x\nworker-3 ansible_host=ip-10-1-x-x.eu-west-3.compute.internal ip=10.1.x.x\nworker-4 ansible_host=ip-10-1-x-x.eu-west-3.compute.internal ip=10.1.x.x [kube-master]\nmaster-1\nmaster-2 [etcd]\nmaster-1\nmaster-2\nworker-1 [kube-node]\nworker-1\nworker-2\nworker-3\nworker-4 [k8s-cluster:children]\nkube-master\nkube-node Command used to invoke ansible: ansible-playbook -i inventory/moneydev-jordan/inventory.ini cluster.yml -b -v --flush-cache --private-key=~/.ssh/k8s-key.pem --user=centos --extra-vars bootstrap_os=centos TASK [win_nodes/kubernetes_patch : Check current nodeselector for kube-proxy daemonset] ***************************************************************************************************************************\nTuesday 30 April 2019 09:43:32 +0000 (0:00:00.515) 0:05:54.369 *********\nfatal: [master-1]: FAILED! => {\"changed\": true, \"cmd\": \"/usr/local/bin/kubectl --kubeconfig /etc/kubernetes/admin.conf get ds kube-proxy --namespace=kube-system -o jsonpath='{.spec.template.spec.nodeSelector.beta.kubernetes.io/os}'\", \"delta\": \"0:00:00.125781\", \"end\": \"2019-04-30 09:43:32.386948\", \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2019-04-30 09:43:32.261167\", \"stderr\": \"Error from server (NotFound): daemonsets.extensions \"kube-proxy\" not found\", \"stderr_lines\": [\"Error from server (NotFound): daemonsets.extensions \"kube-proxy\" not found\"], \"stdout\": \"\", \"stdout_lines\": []} Copy of your inventory file: Command used to invoke ansible: Output of ansible run: Anything else do we need to know: ", "code": [], "labels": ["kind/bug", "lifecycle/rotten"]}
{"project": "prestodb_presto", "title": "Implement HIVE ACID table support", "description": "HIVE 0.14 introduce ACID table. Info in HIVE wiki : Hive Transactions These tables are not compatible with existing code because directory layout is different.\nThese tables will have subdirectories for different versions (bases) and addendum of the data. For example for a table foo : (command in HIVE) <CODE> If I add some values OR modify it with UPDATE or DELETE, I have that addendum directories : <CODE> A quick fix could be to only use the last \"base\" of the table. <CODE> ", "code": ["0: jdbc:hive2://nc-h04:10000/casino> dfs -ls hdfs://nc-h04/user/hive/warehouse/casino.db/foo;\n+----------------------------------------------------------------------------------------------------------------------------+--+\n|                                                         DFS Output                                                         |\n+----------------------------------------------------------------------------------------------------------------------------+--+\n| Found 1 items                                                                                                              |\n| drwxr-xr-x   - hduser supergroup          0 2014-11-12 14:53 hdfs://nc-h04/user/hive/warehouse/casino.db/foo/base_0000077  |\n+----------------------------------------------------------------------------------------------------------------------------+--+\n2 rows selected (0.065 seconds)\n", "0: jdbc:hive2://nc-h04:10000/casino> dfs -ls hdfs://nc-h04/user/hive/warehouse/casino.db/foo;\n+-------------------------------------------------------------------------------------------------------------------------------------+--+\n|                                                             DFS Output                                                              |\n+-------------------------------------------------------------------------------------------------------------------------------------+--+\n| Found 4 items                                                                                                                       |\n| drwxr-xr-x   - hduser supergroup          0 2014-11-12 14:53 hdfs://nc-h04/user/hive/warehouse/casino.db/foo/base_0000077           |\n| drwxr-xr-x   - hduser supergroup          0 2014-11-14 11:58 hdfs://nc-h04/user/hive/warehouse/casino.db/foo/delta_0000079_0000079  |\n| drwxr-xr-x   - hduser supergroup          0 2014-11-14 11:58 hdfs://nc-h04/user/hive/warehouse/casino.db/foo/delta_0000081_0000081  |\n| drwxr-xr-x   - hduser supergroup          0 2014-11-14 11:58 hdfs://nc-h04/user/hive/warehouse/casino.db/foo/delta_0000082_0000082  |\n+-------------------------------------------------------------------------------------------------------------------------------------+--+\n5 rows selected (0.017 seconds)\n", "if (table have `transactional` property set to true)\n{\n  1. get list of directories like \"base_???????\" (7 digits)\n  2. Only consider the last one instead of the root directory\n}\n"], "labels": ["enhancement"]}
{"project": "kubernetes_test-infra", "title": "Refactor prow/plugins/label/label.go", "description": "What would you like to be added:\nWe should add a return type to this function instead of passing in a pointer to mutate for: See conversation in here. Why is this needed:\nLower function arity makes the function easier to use and maintain. ", "code": [], "labels": ["kind/feature"]}
{"project": "spring-projects_spring-security", "title": "Update to htmlunit-driver 2.33.0", "description": "Update to htmlunit-driver 2.33.0 ", "code": [], "labels": ["type: enhancement", "in: build"]}
{"project": "nodejs_node", "title": "doc: Stability 2 (stable) listed as \"unstable\" in fs docs", "description": "<URL> indicates that Stability 2 = Stable but there are three places in the doc/fs.md where Stability 2 is marked Unstable. Not sure if the doc about stability index needs clarification, or if the fs doc needs to update those indices to different values, or ... ? ", "code": [], "labels": ["doc"]}
{"project": "appium_appium", "title": "Appium v1.8.0: With uiautomator2, Error \"ProxyRequestError: Could not proxy command to remote server\" displays when it use app_strings", "description": "\"\\Error, \"ProxyRequestError: Could not proxy command to remote server\", displayed when it tried to use uiautomator2. I installed 3 apps:\n1st app with minSDK = 16. It works well\n2nd apps: Google Drive. Don't use uiautomator2 for app strings.\n3rd app: minSDK = 21 (changed from 19 to 21): Error happens. Please, see the logs for more details\nDesire Capability for 3rd app is:\n\"app\": cfg.get(\"APP\", \"aio-package\"),\n\"appWaitActivity\": AIO_ACTIVITY.WAIT_ACTIVITY,\n'appPackage': PACKAGE.AIO_PACKAGE,\n'appActivity': AIO_ACTIVITY.LAUNCH_ACTIVITY,\n'fullReset': \"true\",\n'unicodeKeyboard': \"true\",\n'resetKeyboard': \"true\",\n'setWebContentsDebuggingEnabled': \"true\",\n'automationName': 'uiautomator2'\nLanguage: Python It works well on appium v1.7.2. logs.txt Create a GIST which is a paste of your full Appium logs, and link them here.\nDo NOT paste your full Appium logs here, as it will make this issue very long and hard to read!\nIf you are reporting a bug, always include Appium logs! Please remember that with sample code it's easier to reproduce the bug and it's much faster to fix it. Please git clone <URL> and use one of your favourite languages and sample apps to reproduce the issue. In case a similar scenario is missing in sample-code, please submit a PR with one of the sample apps provided. ", "code": [], "labels": ["NeedsInfo"]}
{"project": "flutter_flutter", "title": "Flutter Doc License", "description": "Hello, I am a student majoring in computer engineering in Korea. I am a student at Handong Global University and I would like to produce an online lecture course on developing mobile apps using Flutter and Firebase. I'd like to ask if it's okay to use the following for making training material. The lecture I'm going to produce is an open-type lecture that anyone can see, not for profit.\nI will look forward to the response from flutter team. ", "code": [], "labels": ["waiting for customer response"]}
{"project": "mozilla_geckodriver", "title": "When I open a new tab in firefox, driver.get(url) sometimes does not return results.", "description": "Code (for example):\nActionChains(driver).key_down(Keys.CONTROL).send_keys(\"t\").key_up(Keys.CONTROL).perform()\ndriver.switch_to_window(driver.window_handles[-1])\ndriver.get(url) Sometimes, Firefox can open new tab, but it stops and can not further navigate to the targeted website. In rest cases, Firefox can perform the task successfully.\nWhat is the problem? Can anyone help? ", "code": [], "labels": ["duplicate"]}
{"project": "gitextensions_gitextensions", "title": "[NBug] Overflow error.", "description": "Attempting to display a diff of an UTF16LE-BOM file causes crash. Expect no crash and that file is displayed as text initially without forcing it. Select a UTF16LE-BOM file from a commit to display diff (will not as claims is binary)\nRight click and select \"Treat all files as text\"\nSee Unicode text (with double byte chars)\nChange encoding dropdown to \"Unicode\"\nGet error. <CODE> ", "code": ["System.OverflowException: Overflow error.\n   at System.Drawing.Graphics.CheckErrorStatus(Int32 status)\n   at System.Drawing.Graphics.FillRectangle(Brush brush, Single x, Single y, Single width, Single height)\n   at System.Drawing.Graphics.FillRectangle(Brush brush, RectangleF rect)\n   at ICSharpCode.TextEditor.TextView.DrawDocumentWord(Graphics g, String word, Point position, Font font, Color foreColor, Brush backBrush)\n   at ICSharpCode.TextEditor.TextView.PaintLinePart(Graphics g, Int32 lineNumber, Int32 startColumn, Int32 endColumn, Rectangle lineRectangle, Int32 physicalXPos)\n   at ICSharpCode.TextEditor.TextView.PaintDocumentLine(Graphics g, Int32 lineNumber, Rectangle lineRectangle)\n   at ICSharpCode.TextEditor.TextView.Paint(Graphics g, Rectangle rect)\n   at ICSharpCode.TextEditor.TextArea.OnPaint(PaintEventArgs e)\n   at System.Windows.Forms.Control.PaintWithErrorHandling(PaintEventArgs e, Int16 layer)\n   at System.Windows.Forms.Control.WmPaint(Message& m)\n   at System.Windows.Forms.Control.WndProc(Message& m)\n   at System.Windows.Forms.NativeWindow.Callback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)\n"], "labels": [" type: bug"]}
{"project": "phpmyadmin_phpmyadmin", "title": "RTL languages not fully supported", "description": "RTL languages have broken display in database \ndropdown\ndisplays:\n&quot;(test (10&quot;\ninstead of\n&quot;(10) test&quot; Confirmed for Arabic and Hebrew. - Original URL: <URL>\n- Original author: robbat2\n- Found in version: Latest_Git ", "code": [], "labels": ["bug"]}
{"project": "caddyserver_caddy", "title": "Reverse proxy on ASP.NET sites using NTLM authentication is not working", "description": "Caddy 0.8.2 I'm trying to use Caddy as reverse proxy for MS Dynamics CRM installation to get more robust and balance loading, better performance (maybe) by applying HTTP/2 on context served by MS CRM. <CODE> Just typed caddy in cmd.exe\nI'm using Windows 8 / 64;\nI'm tested scenario in whole zoo of browsers: FF, IE, Chrome most recent version available;\nMS CRM hosted on Azure.\nMS CRM requires authentication, and normally uses simple Windows NTML.\nNo IFD (Internet Facing Deployment) is used (it's more or less cookie-based auth mechanism); I expected Caddy to be completely transparent, like Fiddler2, for example, normally does. Instead I get never ending sequence of requests asking to enter my credentials. Replying with 401 is normal behavior for NTLM auth, but as soon as browser supplies correct credentials, token is issued and these 401 re-directions stop. But not in this case. I suppose that Caddy misses to transfer some important header or any other information is not substituted correctly. As result, transparency of proxy literally becomes opaque. I don't think that information in Caddy's access log is valuable here, since information about headers there is not present, as I can see \u00ad\u2014 but I looked through it briefly, and URL used are 100% correct. But. I can provide RAW output from fiddler for investigation. For privacy reasons I will replace actual urls and authorization tokens (and yes, I have treble checked my password, I'm entering it without spelling errors). Request: <CODE> Response: <CODE> ", "code": ["localhost:2020\ngzip\nlog access.log\nproxy / https://azure.based.installation.of/mscrm/\n", "GET http://localhost:2020/[removed]/_common/styles/global.css.aspx?lcid=1053&ver=-2039462857 HTTP/1.1\nAccept: text/css, */*\nReferer: http://localhost:2020/\nAccept-Language: en-US,en;q=0.7,ru;q=0.3\nUser-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko\nAccept-Encoding: gzip, deflate\nConnection: Keep-Alive\nDNT: 1\nHost: localhost:2020\nAuthorization: Negotiate [removed]\n", "HTTP/1.1 401 Unauthorized\nContent-Length: 341\nContent-Type: text/html; charset=us-ascii\nDate: Tue, 08 Mar 2016 11:57:39 GMT\nServer: Caddy\nServer: Microsoft-HTTPAPI/2.0\nWww-Authenticate: Negotiate [removed]\nProxy-Support: Session-Based-Authentication\n\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\"http://www.w3.org/TR/html4/strict.dtd\">\n<HTML><HEAD><TITLE>Not Authorized</TITLE>\n<META HTTP-EQUIV=\"Content-Type\" Content=\"text/html; charset=us-ascii\"></HEAD>\n<BODY><h2>Not Authorized</h2>\n<hr><p>HTTP Error 401. The requested resource requires user authentication.</p>\n</BODY></HTML>\n"], "labels": ["feature request"]}
{"project": "vmware_clarity", "title": "Modal is missing fade-out animation on close", "description": "Our modal is missing fade-out animation on close. It was originally an issue due to Angular's issue specified in the following issue report: angular/angular#15798 It's visible on our doc site. The modal component should run fade-out animation on close. App Device: Add any other notes about the problem here. ", "code": [], "labels": ["resolution: duplicate", "type: bug"]}
{"project": "JuliaLang_julia", "title": "misplaced quote in documentation on new type system", "description": "The material on the new type system in the developer documentation, that is <URL> has a misplaced quote somewhere so that much of the quoted text is mistakenly unquoted and vice versa. ", "code": [], "labels": ["doc"]}
{"project": "tidusjar_Ombi", "title": "I\u00b4m probably an idiot...", "description": "But i can\u00b4t get the new version to start. I followed the guide (install as service) Everything goes smoothly, but the service does not start. Also, i cannot find the plexrequests,exe anywhere. P.S. I unblocked the zip file before unzipping. What am i doing wrong here? ", "code": [], "labels": ["support"]}
{"project": "golang_go", "title": "x/build/cmd/gopherbot: created multiple backport issues (and now offline)", "description": "@gopherbot created multiple backport issues at #23920 (comment). While some lag is expected for the \"done\" comment to reach the corpus, it should not have created duplicated issues anyway. gopherbot is offline while this is being fixed. ", "code": [], "labels": ["Builders", "FrozenDueToAge"]}
{"project": "Koenkk_zigbee2mqtt", "title": "flash cc2530", "description": "Hi whats should be the steps flashing cc2530 with this board link:\n<URL> thanks ", "code": [], "labels": ["stale"]}
{"project": "networkx_networkx", "title": "Doc missing for Similarity Algorithm", "description": "I'm using the similarity algorithm graph_edit_distance method 'as-is', but it would be most helpful to have it included in the official documentation.  A lingering question I have is if I can get a floating point from the graph_edit_distance calculation instead of an int (higher precision would be optimum). ", "code": [], "labels": ["Documentation"]}
{"project": "opencv_opencv", "title": "CMAKE using wrong path for TBB libraries", "description": "Intel Parallel Studio XE 2016 Update 2 install creates a shortcut named \"vc14\" in the tbb/lib folder, but this shortcut apparently only works from Windows Explorer. Apps opening the shortcut get an empty directory. CMake files should be updated to search for lib files below tbb/lib folder. ", "code": [], "labels": ["priority: low", "feature"]}
{"project": "timgrossmann_InstaPy", "title": "Not unfollowing all the users.", "description": "The count of users to unfollow shows up as: 300 but after 20-30 it stops. Windows 10 Machine local\nINFO [2018-04-15 17:26:02] ### Logged in successfully!\nINFO [2018-04-15 17:26:06] ###  Number of users available to unfollow: 336 INFO [2018-04-15 17:38:23] ### --> Total people unfollowed : 24\nINFO [2018-04-15 17:38:26] ###  Session ended - 2018-04-15 17:38:26\nINFO [2018-04-15 17:38:26] ###  -------------------- ", "code": [], "labels": ["wontfix"]}
{"project": "googleapis_google-cloud-node", "title": "Add GCS bucket labels feature", "description": "\nNo description provided.\n ", "code": [], "labels": ["api: storage", "priority: p1", "type: enhancement"]}
{"project": "firefly-iii_firefly-iii", "title": "Add transaction page fails to show first time", "description": "Bug description\nI am running Firefly III version 4.8.1.6, and when clicking on \"Create new transaction\", or \"New withdrawal\", \"New deposit\", \"New transfer\" in sidebar (opened with +). Error page is shown with \"Whoops! An error occurred. Unfortunately, this error was not recoverable. Firefly III broke. The error is: Undefined index: path\". Error is in $previousUri initializing from $parts, where path is not available. Refreshing the same page is successful. I can send you logs if necessary privately. Steps to reproduce Stacktrace <CODE> Extra info\nDebug information generated at 2019-10-26 08:47:49 Europe/Tallinn for Firefly III version 4.8.1.6. ", "code": ["#0 /var/www/firefly-iii/app/Http/Controllers/Transaction/CreateController.php(81): Illuminate\\Foundation\\Bootstrap\\HandleExceptions->handleError(8, 'Undefined index...', '/var/www/firefl...', 81, Array)\n#1 [internal function]: FireflyIII\\Http\\Controllers\\Transaction\\CreateController->create('withdrawal')\n#2 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Controller.php(54): call_user_func_array(Array, Array)\n#3 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/ControllerDispatcher.php(45): Illuminate\\Routing\\Controller->callAction('create', Array)\n#4 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Route.php(219): Illuminate\\Routing\\ControllerDispatcher->dispatch(Object(Illuminate\\Routing\\Route), Object(FireflyIII\\Http\\Controllers\\Transaction\\CreateController), 'create')\n#5 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Route.php(176): Illuminate\\Routing\\Route->runController()\n#6 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Router.php(680): Illuminate\\Routing\\Route->run()\n#7 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(30): Illuminate\\Routing\\Router->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#8 /var/www/firefly-iii/app/Http/Controllers/Transaction/CreateController.php(53): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#9 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(145): FireflyIII\\Http\\Controllers\\Transaction\\CreateController::FireflyIII\\Http\\Controllers\\Transaction\\{closure}(Object(Illuminate\\Http\\Request), Object(Closure))\n#10 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#11 /var/www/firefly-iii/app/Http/Controllers/Controller.php(82): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#12 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(145): FireflyIII\\Http\\Controllers\\Controller->FireflyIII\\Http\\Controllers\\{closure}(Object(Illuminate\\Http\\Request), Object(Closure))\n#13 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#14 /var/www/firefly-iii/app/Http/Middleware/InterestingMessage.php(59): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#15 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): FireflyIII\\Http\\Middleware\\InterestingMessage->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#16 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#17 /var/www/firefly-iii/app/Http/Middleware/Binder.php(78): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#18 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): FireflyIII\\Http\\Middleware\\Binder->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#19 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#20 /var/www/firefly-iii/app/Http/Middleware/Range.php(58): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#21 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): FireflyIII\\Http\\Middleware\\Range->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#22 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#23 /var/www/firefly-iii/vendor/pragmarx/google2fa-laravel/src/Middleware.php(15): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#24 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): PragmaRX\\Google2FALaravel\\Middleware->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#25 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#26 /var/www/firefly-iii/app/Http/Middleware/Authenticate.php(73): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#27 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): FireflyIII\\Http\\Middleware\\Authenticate->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#28 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#29 /var/www/firefly-iii/vendor/laravel/passport/src/Http/Middleware/CreateFreshApiToken.php(50): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#30 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Laravel\\Passport\\Http\\Middleware\\CreateFreshApiToken->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#31 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#32 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Middleware/VerifyCsrfToken.php(75): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#33 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Foundation\\Http\\Middleware\\VerifyCsrfToken->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#34 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#35 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/View/Middleware/ShareErrorsFromSession.php(49): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#36 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\View\\Middleware\\ShareErrorsFromSession->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#37 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#38 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Session/Middleware/StartSession.php(56): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#39 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Session\\Middleware\\StartSession->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#40 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#41 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Cookie/Middleware/AddQueuedCookiesToResponse.php(37): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#42 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Cookie\\Middleware\\AddQueuedCookiesToResponse->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#43 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#44 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Cookie/Middleware/EncryptCookies.php(66): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#45 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Cookie\\Middleware\\EncryptCookies->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#46 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#47 /var/www/firefly-iii/app/Http/Middleware/Sandstorm.php(54): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#48 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): FireflyIII\\Http\\Middleware\\Sandstorm->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#49 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#50 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(104): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#51 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Router.php(682): Illuminate\\Pipeline\\Pipeline->then(Object(Closure))\n#52 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Router.php(657): Illuminate\\Routing\\Router->runRouteWithinStack(Object(Illuminate\\Routing\\Route), Object(Illuminate\\Http\\Request))\n#53 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Router.php(623): Illuminate\\Routing\\Router->runRoute(Object(Illuminate\\Http\\Request), Object(Illuminate\\Routing\\Route))\n#54 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Router.php(612): Illuminate\\Routing\\Router->dispatchToRoute(Object(Illuminate\\Http\\Request))\n#55 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Kernel.php(176): Illuminate\\Routing\\Router->dispatch(Object(Illuminate\\Http\\Request))\n#56 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(30): Illuminate\\Foundation\\Http\\Kernel->Illuminate\\Foundation\\Http\\{closure}(Object(Illuminate\\Http\\Request))\n#57 /var/www/firefly-iii/vendor/fideloper/proxy/src/TrustProxies.php(57): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#58 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Fideloper\\Proxy\\TrustProxies->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#59 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#60 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Middleware/TransformsRequest.php(21): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#61 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Foundation\\Http\\Middleware\\TransformsRequest->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#62 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#63 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Middleware/TransformsRequest.php(21): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#64 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Foundation\\Http\\Middleware\\TransformsRequest->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#65 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#66 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Middleware/ValidatePostSize.php(27): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#67 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Foundation\\Http\\Middleware\\ValidatePostSize->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#68 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#69 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Middleware/CheckForMaintenanceMode.php(62): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#70 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): Illuminate\\Foundation\\Http\\Middleware\\CheckForMaintenanceMode->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#71 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#72 /var/www/firefly-iii/app/Http/Middleware/SecureHeaders.php(45): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#73 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(163): FireflyIII\\Http\\Middleware\\SecureHeaders->handle(Object(Illuminate\\Http\\Request), Object(Closure))\n#74 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Routing/Pipeline.php(53): Illuminate\\Pipeline\\Pipeline->Illuminate\\Pipeline\\{closure}(Object(Illuminate\\Http\\Request))\n#75 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Pipeline/Pipeline.php(104): Illuminate\\Routing\\Pipeline->Illuminate\\Routing\\{closure}(Object(Illuminate\\Http\\Request))\n#76 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Kernel.php(151): Illuminate\\Pipeline\\Pipeline->then(Object(Closure))\n#77 /var/www/firefly-iii/vendor/laravel/framework/src/Illuminate/Foundation/Http/Kernel.php(116): Illuminate\\Foundation\\Http\\Kernel->sendRequestThroughRouter(Object(Illuminate\\Http\\Request))\n#78 /var/www/firefly-iii/public/index.php(76): Illuminate\\Foundation\\Http\\Kernel->handle(Object(Illuminate\\Http\\Request))\n#79 {main} \n"], "labels": ["bug", "fixed"]}
{"project": "joomla_joomla-cms", "title": "[/libraries/cms/application/cms.php] has non-optimal code", "description": "<CODE> IMHO that will be better this way: <CODE> Joomla! 3.6.2 ", "code": ["            $authorisations = $authenticate->authorise($response, $options);\n\n            foreach ($authorisations as $authorisation)\n            {\n                $denied_states = array(JAuthentication::STATUS_EXPIRED, JAuthentication::STATUS_DENIED);\n\n                if (in_array($authorisation->status, $denied_states))\n                {\n", "            $authorisations = $authenticate->authorise($response, $options);\n            $denied_states = JAuthentication::STATUS_EXPIRED | JAuthentication::STATUS_DENIED;\n\n            foreach ($authorisations as $authorisation)\n            {\n                if ((int) $authorisation->status & $denied_states)\n                {\n"], "labels": ["No Code Attached Yet"]}
{"project": "rancher_rancher", "title": "Mapping two host ports to the same container port not working", "description": "Rancher versions:\nrancher/server: 1.5.8 / 1.6.0\nscheduler: cattle\nDocker 1.12.6 Steps to Reproduce: Results: \n ", "code": [], "labels": ["internal", "kind/bug", "area/networking", "status/resolved"]}
{"project": "iview_iview", "title": "[Feature Request]\u80fd\u5426\u6dfb\u52a0 select\u7ec4\u4ef6 \u652f\u6301\u591a\u4e2a\u5173\u952e\u8bcd\u641c\u7d22", "description": "What problem does this feature solve?\nselect\u7ec4\u4ef6\u591a\u4e2a\u5173\u952e\u8bcd\u641c\u7d22\nWhat does the proposed API look like?\n\u6dfb\u52a0\u5c5e\u6027 filterValues: [\u5b57\u6bb5\u540d1\uff0c \u5b57\u6bb5\u540d2 ...] \u5982\u9009\u62e9\u5730\u5740\uff0c\u5373\u652f\u6301\u4e2d\u6587\u6c49\u5b57\u641c\u7d22\u4e5f\u652f\u6301\u7b80\u62fc\u641c\u7d22\uff0c\u641c\u7d22\u7ed3\u679c\u663e\u793alable\u7684\u503c ", "code": [], "labels": ["invalid"]}
{"project": "Snipaste_feedback", "title": "\u5e0c\u671b\u80fd\u591f\u589e\u52a0\u622a\u957f\u56fe\u7684\u529f\u80fd", "description": "\u5982\u9898\uff0c\u751f\u6d3b\u4e2d\u4f1a\u6709\u4e00\u4e9b\u622a\u957f\u56fe\u7684\u5e94\u7528\u3002\u6700\u5e7f\u6cdb\u7684\u6bd4\u5982\u8bf4\u628a\u4e00\u4e2a\u7f51\u9875\u622a\u5c4f\uff0c\u622a\u56fe\u81ea\u5df1\u5b89\u88c5\u7684\u6240\u6709\u8f6f\u4ef6\uff0c\u6216\u8005\u622a\u56fe\u4e00\u4e2a\u6587\u4ef6\u5939\u4e0b\u9762\u7684\u6240\u6709\u6587\u4ef6\uff0c\u6b64\u65f6\u622a\u957f\u56fe\u5c31\u975e\u5e38\u6709\u5fc5\u8981\u3002 ", "code": [], "labels": ["duplicate"]}
{"project": "platformio_platformio-core", "title": "Home: Could not install platform", "description": "PIO Core Call Error: PlatformManager: Installing linux_arm\nDownloading...\nUnpacking...\nlinux_arm @ 1.4.6 has been successfully installed!\nPackageManager: Installing toolchain-gccarmlinuxgnueabi @ ~1.40802.0 Error: Could not find a version that satisfies the requirement '~1.40802.0' for your system 'linux_x86_64' ", "code": [], "labels": ["duplicate"]}
{"project": "aspnet_Mvc", "title": "old style DataAnnotations Localization Attributes not working RC2", "description": "The old style of DataAnnotations Localization Attributes do not work in RC2. These should be removed or fixed. Problem 2: how can you specify the Resource to use for the DataAnnotations? These models can be used in n controllers etc, so it should be possible to define the Resource. Not working <CODE> working <CODE> Greetings Damien ", "code": ["[Required(ErrorMessageResourceName = \"BoxLengthRequired\", ErrorMessageResourceType = typeof(SharedResource))]\n[Range(1.0, 100.0, ErrorMessageResourceName = \"BoxLengthRange\", ErrorMessageResourceType = typeof(SharedResource))]\n", "[Required(ErrorMessage = \"BoxLengthRequired\")]\n[Range(1.0, 100.0, ErrorMessage = \"BoxLengthRange\")]\n"], "labels": ["investigate"]}
{"project": "inorichi_tachiyomi", "title": "[Feature Request] Reverse volume key function", "description": "I have a large phone and it would make browsing chaptets easier if I could set the volume up key as page down and volume  down key as page up. So i can hold it like a camera. Im finding the volume keys to be a faster and easier page navigation method than the touch controls. ", "code": [], "labels": ["enhancement"]}
{"project": "magento_magento2", "title": "REST API: Message: No region found within the locale 'en", "description": "1.No error found ", "code": [], "labels": ["CS"]}
{"project": "qgis_QGIS", "title": "[postgres] Slow parsing of arrays", "description": "Describe the bug It is a performance issue, not really a bug. Lists of values returned from a PostgreSQL layer are very slow to extract. How to Reproduce 1/ create a database with the 3 following tables: <CODE> 2/ Load them in QGIS and run: <CODE> I have the following results (in seconds): <CODE> QGIS and OS versions 3.11-master 7f415ca ", "code": ["create table t_array as select 1 as id, array_agg(random()) as values from generate_series(1,100000);\ncreate table t_string as select 1 as id, array_to_string(array_agg(random()),',') as values from generate_series(1,100000);\n-- simulate a bytea of 100000 8-bytes floating point numbers\ncreate table t_bytea as select 1 as id, decode(repeat('0102030405060708', 100000), 'hex') as values;\n", "import time\nimport array\n\nl_array = QgsProject.instance().mapLayersByName(\"t_array\")[0]\nl_string = QgsProject.instance().mapLayersByName(\"t_string\")[0]\nl_bytea = QgsProject.instance().mapLayersByName(\"t_bytea\")[0]\nstart = time.time()\nfor f in l_array.getFeatures():\n    assert len(f[\"values\"])==100000\nprint(\"array\", time.time() - start)\nstart = time.time()\nfor f in l_string.getFeatures():\n    tt = [None if x == 'NULL' else float(x) for x in f[\"values\"].split(\",\")]\n    assert len(tt) == 100000\nprint(\"string\", time.time() - start)\nstart = time.time()\nfor f in l_bytea.getFeatures():\n    tt = array.array(\"d\", f[\"values\"].data())\n    assert len(tt) == 100000\nprint(\"bytea\", time.time() - start)\n", "array 9.508360624313354\nstring 0.04486846923828125\nbytea 0.0058481693267822266\n"], "labels": ["Bug", "Data Provider"]}
{"project": "AllenFang_react-bootstrap-table", "title": "deleteRow confirmation dialog can suppress future deletions", "description": "When deleting a row (which I am doing through calling handleDropRow), a confirmation dialog appears.  If I check 'Prevent this page from creating additional dialogs', then on subsequent calls to handleDropRow, the row does not get deleted and there is no indication that a delete was attempted, even after reload of the page. I have fixed this by using handleConfirmDeleteRow and calling next() to skip the confirmation, which works just fine, but I do not think the ability to prevent row deletions with that checkbox should be the default behavior. This is using Chrome Version 51.0.2704.103. Thanks for all the work on this great package! ", "code": [], "labels": ["enhancement"]}
{"project": "angular-ui_angular-google-maps", "title": "Update all src - Examples to use ui-gmap", "description": "\nNo description provided.\n ", "code": [], "labels": ["in-progress", "enhancement"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Call to undefined function PMA_DBI_try_query()", "description": "Fatal error: Call to undefined function\nPMA_DBI_try_query() in F:\\Program Files\\Apache\nGroup\\Apache2\\htdocs\\SQL2\\libraries\\check_user_privileges.lib.php\non line 16 To get this I was adding a unique index on InnoDB table\nwhich had dublicate entries, I got an error with browse\nbutton, clicked on it and was presented with two resuls\nthat were dublicate of each other and preventing UNIQUE\nindex to be added. When I clicked on [delete] icon next\nto one of them and agreed with promt dialog this php\nerror was shown. - Original URL: <URL>\n- Original author: mdonatas\n- Found in version: 2.7.0 ", "code": [], "labels": ["bug"]}
{"project": "WP-API_WP-API", "title": "Version bump", "description": "52a8028 was a significant change, and prevents the plugin from fatal erroring when a user updates to latest WordPress trunk now that the REST API infrastructure is in core. A new version of the REST API plugin should be tagged and released so that a user can update the plugin before they update core. One of my sites fataled and it took me a while to realise what the problem was, considering the plugin was up to date according to its version number. ", "code": [], "labels": ["Bug"]}
{"project": "home-assistant_home-assistant", "title": "Error System", "description": "We need to get better about our error reporting. Currently we report most errors to the log and in some cases we will also make a persistent notification. I think that the first thing that we should do is route all errors through a class that is in control. This class can then decide where and how these things should get reported: As part of this, we should also start generalizing our errors. Things like ERR_INVALID_CONFIG, ERR_LOGIN_ATTEMPT, ERR_INVALID_CREDENTIALS (for cloud services), ERR_CONNECTION_LOST (but only if a couple of retries didn't work it out) What do people think about this? ", "code": [], "labels": ["enhancement", "stale"]}
{"project": "helm_helm", "title": "using helm with kube-solo or kube-cluster on mac", "description": "Hi, Did anybody succeed using helm with a kubernetes install on a mac? I used kube-cluster for this but keep getting errors using \"helm init\". I think the config file is not in $HOME/.kube but in $HOME/kube-cluster/kube am I correct? So I'm setting $KUBECONFIG to that folder. Unfortunately I get following error: Error: error installing: Get http://localhost:8080/api: dial tcp [::1]:8080: getsockopt: connection refused Can anybody help me out here? Kind regards,\nPeter ", "code": [], "labels": ["support"]}
{"project": "vitessio_vitess", "title": "StreamExecute doesn't support offsets with limits", "description": "Filing this as a bug instead of a feature request because Execute does support limits with offsets. It's not immediately clear that there's any specific reason why StreamExecute shouldn't also. Probably just an inconsistency in the code? ", "code": [], "labels": ["Type: Bug"]}
{"project": "ziglang_zig", "title": "T.name instead of @typeName(T)", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement"]}
{"project": "WordPress_gutenberg", "title": "Author Option Box", "description": "I run a blog with 12-15 writers at any given time and I sometimes have to change who the author is. I do this currently by using the drop-down box called 'Authors'. I can't seem to find this in the new editor. How do I do this now? ", "code": [], "labels": ["[Type] Help Request"]}
{"project": "GothenburgBitFactory_taskwarrior", "title": "[TW-305] Need a mechanism to set annotation timestamp from the command line", "description": "Paul Beckingham on 2013-04-09T02:50:33Z says: Annotation time stamps are generated from the clock, and are not overridable.  It would be useful to be able to specify the time, although not by default, as the annotations are used for \"logging\". ", "code": [], "labels": ["enhancement"]}
{"project": "webyog_sqlyog-community", "title": "Double click is not working to edit field", "description": "Original issue 170 created by webyog on 2007-03-29T06:04:09.000Z: If  I double click on field to edit , cursor is not pointing to edit that\nfield.\nReproduceable: ", "code": [], "labels": ["Priority-Medium", "Type-Defect"]}
{"project": "orientechnologies_orientdb", "title": "Object Saving Issue in 2.0.11", "description": "Issue:   When saving a entity with a composite entity the composite entity's 'rid'  is not map to parent object correctly which breaks the relationship. Version: 2.0.11\nOperation Mode: Embedded Orient DB in webapp using the OObjectDatabaseTx Example: Example use: To persist: Results:\nselect attributeCodePk from AttributeCode returns <CODE> Trying to query the AttributeCode now fails because the RID is not correct.\nAttributeCodePk is RID is stored fine just the relationship is stored incorrectly. Expected Results: should be: <CODE> 1.7.10 puts in the rid in the relationship on save and works great. ", "code": ["\\#  | @CLASS | attributeCodePk\n1233|null  |com.orientechnologies.orient.core.record.impl.ODocument|QXR0cmlidXRlQ29kZVBrQGF0dHJpYnV0ZVR5cGU6IlRFU1QtQ0FT\nRS1UTVAiLGF0dHJpYnV0ZUNvZGU6IkEi  (This looks like a toString of the created entity?)\n", "\\#   | @CLASS | attributeCodePk\n1233|null  |#14:1504  (RID)\n"], "labels": ["bug"]}
{"project": "nopSolutions_nopCommerce", "title": "Print Packaging Slip with Manufacturer Codes", "description": "Currently when you print a packaging slip, it defaults to the product SKU. It would be nice if there was either a second option or a setting that could be changed to print the order using the manufacturer code's instead. This would be very beneficial for people doing drop shipping. Source: <URL> ", "code": [], "labels": ["on hold / maybe wont"]}
{"project": "facebook_create-react-app", "title": "Enable Babel syntax support for the dynamic import specification within `node_modules` such that webpack can handle the statements", "description": "Yes (Write your answer here.) <CODE> experimental syntax 'dynamicImport' <CODE> But this is what is relevant: <CODE> No error <CODE> As far as I understand this happens due to #3776. Related issue styleguidist/react-styleguidist#987 ", "code": ["yarn -v\n1.5.1\n", "npx create-react-app --info .\nPlease specify the project directory:\n  create-react-app <project-directory>\n", "node -v\nv8.6.0\nyarn -v\n1.5.1\n\"react-scripts\": \"2.0.0-next.b2fd8db8\",\n\"react-styleguidist\": \"7.0.14\"\nMacOS X\n", "styleguidist server\n./node_modules/react-styleguidist/lib/rsg-components/Editor/EditorLoader.js\nSyntax error: async-precious/node_modules/react-styleguidist/lib/rsg-components/Editor/EditorLoader.js: Support for the experimental syntax 'dynamicImport' isn't currently enabled (36:4):\n\n  34 | \t\t\tvar _this2 = this;\n  35 |\n> 36 | \t\t\timport('rsg-components/Editor/Editor').then(function (module) {\n     | \t\t\t^\n  37 | \t\t\t\t_this2.setState({ editor: module.default });\n  38 | \t\t\t});\n  39 | \t\t}\n\nAdd @babel/plugin-syntax-dynamic-import (https://git.io/vb4Sv) to the 'plugins' section of your Babel config to enable parsing.\n\tfrom thread-loader (worker 0)\n"], "labels": ["issue: proposal"]}
{"project": "getredash_redash", "title": "Shared dashboard crashes if one of the queries has no results yet", "description": "When loading a shared dashboard, if one of the queries doesn't have results yet, the dashboard won't load. ", "code": [], "labels": ["Bug"]}
{"project": "matomo-org_matomo", "title": "umlauts in sitesearch keywords", "description": "I love the new features of 1.9, you are great guys. Good work.\nI've only a small problem with tracked keywords from sitesearch. Umlauts wont be displayed correctly. I saw that all urls with umlaut  keywords are also not displayed correctly in the page urls view.\nhow does piwik detect the charset of a page?\nKeywords: piwik charset sitesearch ", "code": [], "labels": ["T: Bug"]}
{"project": "saltstack_salt", "title": "Error in Master log and salt-minions fail to shutdown", "description": "The salt-master has warnings in the logs of duplicate minions.  A minion can return query more than once.  Minion fails to shutdown with the service salt-minion restart or stop command.    A Kill -9 needed to stop the \"rogue\" minion. (Please provide relevant configs and/or SLS files (Be sure to remove sensitive info).) (Include debug logs if possible and relevant.) (Provided by running salt --versions-report. Please also mention any differences in master/minion versions.) -bash-4.1# salt --versions-report\nSalt Version:\nSalt: 2016.11.3 Dependency Versions:\ncffi: Not Installed\ncherrypy: Not Installed\ndateutil: 1.4.1\ngitdb: Not Installed\ngitpython: Not Installed\nioflo: Not Installed\nJinja2: 2.8.1\nlibgit2: Not Installed\nlibnacl: Not Installed\nM2Crypto: 0.20.2\nMako: 0.3.4\nmsgpack-pure: Not Installed\nmsgpack-python: 0.4.6\nmysql-python: Not Installed\npycparser: Not Installed\npycrypto: 2.6.1\npygit2: Not Installed\nPython: 2.6.6 (r266:84292, Aug  9 2016, 06:11:56)\npython-gnupg: Not Installed\nPyYAML: 3.11\nPyZMQ: 14.5.0\nRAET: Not Installed\nsmmap: Not Installed\ntimelib: Not Installed\nTornado: 4.2.1\nZMQ: 4.0.5 System Versions:\ndist: redhat 6.8 Santiago\nmachine: x86_64\nrelease: 2.6.32-642.15.1.el6.x86_64\nsystem: Linux\nversion: Red Hat Enterprise Linux Server 6.8 Santiago ", "code": [], "labels": ["Info Needed", "Duplicate"]}
{"project": "MISP_MISP", "title": "Error 500 while connecting to web interface", "description": "I newly installed MISP following the guide INSTALL.ubuntu1604.txt on a brand new linode but unable to connect to the interface over ssl. Keep getting the following error: This page isn\u2019t working\nmisp_server is currently unable to handle this request.\nHTTP ERROR 500 misp.local_error.log shows the following: [Tue Nov 07 10:22:27.055998 2017] [:error] [pid 11565] [client 97.105.241.94:58180] PHP Fatal error:  Uncaught InternalErrorException: Internal Server Error in /var/www/MISP/app/Lib/cakephp/lib/Cake/Error/ErrorHandler.php:261\\nStack trace:\\n#0 /var/www/MISP/app/Lib/cakephp/lib/Cake/Error/ErrorHandler.php(212): ErrorHandler::handleFatalError(256, '[MissingPluginE...', '/var/www/MISP/a...', 138)\\n#1 [internal function]: ErrorHandler::handleError(256, '[MissingPluginE...', '/var/www/MISP/a...', 138, Array)\\n#2 /var/www/MISP/app/Lib/cakephp/lib/Cake/Error/ErrorHandler.php(138): trigger_error('[MissingPluginE...', 256)\\n#3 /var/www/MISP/app/Lib/cakephp/lib/Cake/Error/ErrorHandler.php(269): ErrorHandler::handleException(Object(InternalErrorException))\\n#4 /var/www/MISP/app/Lib/cakephp/lib/Cake/Error/ErrorHandler.php(212): ErrorHandler::handleFatalError(1, 'Uncaught Intern...', '/var/www/MISP/a...', 261)\\n#5 /var/www/MISP/app/Lib/cakephp/lib/Cake/Core/App.php(970): ErrorHandler::handleError(1, 'Uncaught Intern...', '/var/www/MISP/a...', 261, Array)\\n#6 /var/www/MISP/app/Lib/cakephp/lib/Cake/Core/App.php(943): App::_checkFat in /var/www/MISP/app/Lib/cakephp/lib/Cake/Error/ErrorHandler.php on line 261 Please help. I saw a similar issue raised but there was no resolution posted. OS version (server) \tUbuntu 16.04.3 LTS\nOS version (client)         Macbook Sierra\nPHP version                    7.0.22\nMISP version                  2.4.81\nBrowser                          Chrome/ Firefox/ Safari Should be able to see login page This page isn\u2019t working\nmisp_server is currently unable to handle this request.\nHTTP ERROR 500 ", "code": [], "labels": ["support"]}
{"project": "godotengine_godot", "title": "direct space state intersect_ray function doesn't seem to take excludes into account", "description": "Here's my function: This function basically cast a ray from the center of the screen (like a common fps) and here is the call self is a rigidbody node and camera is a children camera node. The problem is: the result of this function always return the \"self\" node which shouldn't since I gave \"self\" as an exclude for the raycast. This bug is present in the latest sources but not in the 1.1 official release. ", "code": [], "labels": ["topic:core", "enhancement", "topic:gdscript"]}
{"project": "grails_grails-core", "title": "GRAILS-3442: Static type service cannot be reloaded", "description": "Original Reporter: mingfai\nEnvironment: Not Specified\nVersion: 1.0.3\nMigrated From: <URL> services defined with \u2018def myService\u2019 could be reloaded, but not \u2018MyService myService\u2019 refer to the following discussion:\n<URL> the following two issues may be related:\n<URL>\n<URL> ", "code": [], "labels": ["Major", "Duplicate", "Bug"]}
{"project": "dart-lang_sdk", "title": "Lots of JS compilation errors with SDK 6215 (win64)", "description": "This issue was originally filed by pru...@gmail.com What steps will reproduce the problem? class testing { \u00a0\u00a0testing() {\n\u00a0\u00a0} \u00a0\u00a0void run() {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0write(\"Hello World!\");\n\u00a0\u00a0}\n\u00a0\u00a0 \u00a0\u00a0void write(String message) {\n\u00a0\u00a0\u00a0\u00a0// the HTML library defines a global \"document\" variable\n\u00a0\u00a0\u00a0\u00a0document.query('#status').innerHTML = message;\n\u00a0\u00a0}\n} void main() {\n\u00a0\u00a0new testing().run();\n} Gives these errors on JS compilation:\nGenerating JavaScript...\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32036:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Float64Array(int length) => _F64(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32037:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Float64Array.fromList(List<num> list) => _F64(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32038:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Float64Array.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32044:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Int8Array(int length) => _I8(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32045:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Int8Array.fromList(List<num> list) => _I8(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32046:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Int8Array.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32052:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Int16Array(int length) => _I16(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32053:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Int16Array.fromList(List<num> list) => _I16(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32054:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Int16Array.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32060:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Int32Array(int length) => _I32(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32061:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Int32Array.fromList(List<num> list) => _I32(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32062:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Int32Array.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32068:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Uint8Array(int length) => _U8(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32069:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Uint8Array.fromList(List<num> list) => _U8(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32070:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Uint8Array.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32076:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Uint16Array(int length) => _U16(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32077:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Uint16Array.fromList(List<num> list) => _U16(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32078:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Uint16Array.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32084:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Uint32Array(int length) => _U32(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32085:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Uint32Array.fromList(List<num> list) => _U32(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32086:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Uint32Array.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32092:3: error: duplicate method definition of \"\"\n\u00a0\u00a0factory Uint8ClampedArray(int length) => _U8C(length);\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32093:3: error: duplicate method definition of \"fromList\"\n\u00a0\u00a0factory Uint8ClampedArray.fromList(List<num> list) => _U8C(ensureNative(list));\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:32094:3: error: duplicate method definition of \"fromBuffer\"\n\u00a0\u00a0factory Uint8ClampedArray.fromBuffer(ArrayBuffer buffer,\n\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:10522:23: error: no matching constructor for html_Element\n\u00a0\u00a0\u00a0\u00a0final container = new Element.tag(\"div\");\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:5059:15: error: no matching constructor for html_Element\n\u00a0\u00a0\u00a0\u00a0final e = new Element.tag(\"div\");\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:5063:18: error: no matching constructor for List\n\u00a0\u00a0\u00a0\u00a0List nodes = new List.from(e.nodes);\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^\nD:/Development/dart/editor_latest/dart/dart-sdk/lib/html/html_frog.dart:4911:5: error: no matching constructor for List\n\u00a0\u00a0\u00a0\u00a0new List.from(_childNodes.filter((n) => n is Element));\n\u00a0\u00a0\u00a0\u00a0^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ncompilation failed with 28 errors\nCompilation failed Dartium launch runs ok. ", "code": [], "labels": ["Type-Defect", "closed-duplicate"]}
{"project": "dart-lang_sdk", "title": "Provide better, shorter syntax for simple loops", "description": "This issue was originally filed by @mdakin It would be nice to have a shorthand syntax for writing simple and very common single increment loops. So instead of for (int i = 0; i < len; i++) { we could have: for int i = 0..len { or Ruby like for int i in 5..len { or something similar. In dart sdk (a few month old),\n$egrep -R \"for ([int|var|num) [a-z]+ = .; i < .; [a-z]++)\" . | wc -l\n273 I know it is only 11 chars shorter per loop, and does not cover all possibilities of classical C style for loops. but IMHO could be still worth the it because it is more readable and less scary for beginners, I remember the fear and dread when I first introduced for loop to beginners in a beginner Java lesson I taught for 1-2 semester. ", "code": [], "labels": ["area-language", "closed-not-planned", "Type-Defect"]}
{"project": "Semantic-Org_Semantic-UI-React", "title": "Add your support for React Json Schema Form", "description": "No problem just a suggestion Would you be interested in supporting React JSON Schema Form, to include your library as well? They currently support Material UI, I could include your library but would you continue to maintain it? ", "code": [], "labels": ["triage"]}
{"project": "technomancy_leiningen", "title": "Wrong delimiter for classpath on MingW", "description": "With leininigen 2.5.1, lein repl will fail under MingW/bash with a \"Could not find or load main class clojure.main\" error. The culprit seems to be that the delimiter used when compiling the classpath is set to ';' in add_path. MingW is treated similarly to Cygwin or msys here, but ':' is actually the correct delimiter to use. I'm not sure whether the bug applies to cygwin, too. This post on the MingW mailing list covers a similar case: <URL> I can verify that escaping the semicolon doesn't work, but using ':' works -- apparently, MingW/bash translates the ':' into the correct syntax itself, but is unable to hand over ';' or ';' correctly. ", "code": [], "labels": ["Windows", "bug"]}
{"project": "ytdl-org_youtube-dl", "title": "Crackle.com single video \"MPD 403 Forbidden\" and downloads 1GB non-HD video", "description": "<CODE> Every episode of this series allowed the MPD to download and resulted in around a 150mb file as this is a 90s show that was not HD to the best of my research tells me. So the fact that this episode randomly downloads almost a 1GB file is unknown. The resulting file does play and look right, but specs wise is not HD but 640x480 just like it's sister files. ", "code": ["youtube-dl -v https://www.sonycrackle.com/watch/972/2498714\n[debug] System config: []\n[debug] User config: []\n[debug] Custom config: []\n[debug] Command-line args: [u'-v', u'https://www.sonycrackle.com/watch/972/2498714']\n[debug] Encodings: locale UTF-8, fs UTF-8, out UTF-8, pref UTF-8\n[debug] youtube-dl version 2019.09.28\n[debug] Python version 2.7.15+ (CPython) - Linux-4.15.0-64-generic-x86_64-with-Ubuntu-18.04-bionic\n[debug] exe versions: ffmpeg 3.4.6, ffprobe 3.4.6, rtmpdump 2.4\n[debug] Proxy map: {}\n[Crackle] 2498714: Downloading media JSON as US\n[Crackle] 2498714: Downloading m3u8 information\n[Crackle] 2498714: Downloading MPD manifest\nWARNING: Failed to download MPD manifest: HTTP Error 403: Forbidden\n[debug] Default format spec: bestvideo+bestaudio/best\n[debug] Invoking downloader on u'http://content-ausw3.uplynk.com/4d55bdb9330e422cbd796ef413b2f1d2/h.m3u8?expand=117c&ad=crackle_resp_web_live&ad.locationDesc=crackle_responsive_web_up_us_shows&ad.bumper=&ad.preroll=1&extsid=1&ad.metr=7&euid=&exp=1570311637&ct=a&cid=4d55bdb9330e422cbd796ef413b2f1d2&sig=7341c1cf7fd5ddc4b86b24cfffd8a49e6db5c02af94191ffaa3cbdbda84f99b8&pbs=e9dac3ec981b4c2d8928a7ed49c931ee'\n[hlsnative] Downloading m3u8 manifest\n[hlsnative] Total fragments: 330 (not including 161 ad)\n[download] Destination: A Police Officer And A Gentleman-2498714.mp4\n[download]   0.4% of ~964.35MiB at  5.57MiB/s ETA 06:35\n"], "labels": ["invalid"]}
{"project": "moby_moby", "title": "Port not properly forwarded?", "description": "I have some problems getting ports forwarded with my stack. I have my  compose file, which defines movim service. Deploying the service on one node swarm starts everything OK, and the healthcheck passes the movim service as healthy. Curling from host does not return desired webpage though. Curling from within container (localhost, 127.0.0.1, IP of container) works like it should. docker service ls shows the ports as being forwarded. <CODE> Guys on IRC helped me find informations I listed above, and sent me here. Output of docker version: <CODE> Output of docker info: <CODE> ", "code": ["ID                  NAME                 MODE                REPLICAS            IMAGE                                   PORTS\nfy5q7tjms9s0        movim_movim          replicated          1/1                 movim:latest                            *:80->80/tcp,*:8171->8171/tcp\np3jcpvm0mxit        movim_etcd           replicated          1/1                 elcolio/etcd:latest                     \nyafw996qt9ia        movim_mysql-galera   replicated          3/3                 perconalab/percona-xtradb-cluster:5.6   \n", "Docker version 17.06.0-ce, build 3dfb8343\n", "Containers: 12\n Running: 5\n Paused: 0\n Stopped: 7\nImages: 399\nServer Version: 17.06.0-ce\nStorage Driver: overlay2\n Backing Filesystem: extfs\n Supports d_type: true\n Native Overlay Diff: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins: \n Volume: local\n Network: bridge host macvlan null overlay\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\nSwarm: active\n NodeID: ktx4aq4jy4l8q9pqaj99e68ox\n Is Manager: true\n ClusterID: 6isugvgre7fct81a0w2fcuppp\n Managers: 1\n Nodes: 1\n Orchestration:\n  Task History Retention Limit: 5\n Raft:\n  Snapshot Interval: 10000\n  Number of Old Snapshots to Retain: 0\n  Heartbeat Tick: 1\n  Election Tick: 3\n Dispatcher:\n  Heartbeat Period: 5 seconds\n CA Configuration:\n  Expiry Duration: 3 months\n  Force Rotate: 0\n Root Rotation In Progress: false\n Node Address: fda7:113b:e3e1::aa3\n Manager Addresses:\n  [fda7:113b:e3e1::aa3]:2377\nRuntimes: runc\nDefault Runtime: runc\nInit Binary: docker-init\ncontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088a\nrunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4\ninit version: 949e6fa\nSecurity Options:\n seccomp\n  Profile: default\nKernel Version: 4.11.9-1-ARCH\nOperating System: Arch Linux\nOSType: linux\nArchitecture: x86_64\nCPUs: 4\nTotal Memory: 7.747GiB\nName: hummer\nID: DFLX:2SMT:THGN:HD66:PL3N:5CVM:4CMI:KCID:LANE:LQBR:MGBM:GSPK\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nExperimental: false\nInsecure Registries:\n 89.36.221.90:5000\n 127.0.0.0/8\nLive Restore Enabled: false\n"], "labels": ["area/swarm", "status/more-info-needed"]}
{"project": "Automattic_wp-calypso", "title": "Safari OSX console errors 'Sandbox access violation: Blocked a frame at...' Media Gallery", "description": "No console errors A plethora of console errors Sandbox access violation: Blocked a frame at \"<URL>\" from accessing a frame at \"<URL>\".  The frame being accessed is sandboxed and lacks the \"allow-same-origin\" flag. Safari OSX Version 9.1.2 (11601.7.7)  ", "code": [], "labels": ["[Type] Bug", "Editor", "Media"]}
{"project": "godotengine_godot", "title": "Editing an auto-tile doesn't show scrollbars until you change the zoom", "description": "Godot version: 3.0.6 OS/device including version: Windows 10 Issue description: When editing the tileset on a tilemap, even if the tileset is huge and the window is small, it doesn't show scrollbars.  In this screenshot, the red arrow shows the tiles are truncated but the scrollbars are missing.  Steps to reproduce: Expected: the tilemap is large and extends beyond the window dimensions, so you see scrollbars.\nActual: You don't see scrollbars. Work-around: click (1) or zoom in/out and the scollbars appear. Minimal reproduction project: N/A. I think this bug is easy to reproduce. But if you want, you can use any commit from my current game. (If so: open up Scenes > Maps > AutoTileTilesets.tscn and edit any tileset. ", "code": [], "labels": ["usability", "topic:editor", "bug"]}
{"project": "syuilo_misskey", "title": "Misskey\u30e2\u30d0\u30a4\u30eb\u306b\u30ea\u30ed\u30fc\u30c9(\u518d\u8aad\u307f\u8fbc\u307f)\u306e\u305f\u3081\u306e\u30dc\u30bf\u30f3\u304c\u6b32\u3057\u3044", "description": "\u30bf\u30a4\u30c8\u30eb\u306e\u901a\u308a\u3001Misskey\u304c\u30e2\u30d0\u30a4\u30eb\u8868\u793a\u306e\u5834\u5408\u306b\u518d\u8aad\u307f\u8fbc\u307f\u3092\u3059\u308b\u305f\u3081\u306e\u30dc\u30bf\u30f3\u304c\u6b32\u3057\u3044\u3002\u305d\u306e\u307e\u307e\u30da\u30fc\u30b8\u306e\u518d\u8aad\u307f\u8fbc\u307f\u3092\u3059\u308b\u305f\u3081\u306e\u3082\u306e\u306a\u306e\u3067 location.reload(); \u304c\u3067\u304d\u308b\u7684\u306a\u30dc\u30bf\u30f3\u3002\u5834\u6240\u306f\u4eca\u601d\u3044\u3064\u304f\u3068\u3053\u308d\u3067\u306f\u30e1\u30cb\u30e5\u30fc\u4e00\u89a7\u306b\u51fa\u3066\u304f\u308b\u3068\u304b\u306b\u306a\u308b\u3068\u601d\u308f\u308c\u308b ", "code": [], "labels": ["Feature"]}
{"project": "MrKepzie_Natron", "title": "Transform application broken", "description": "Plugins that can apply a transform (CanTransform prop on srcClip) but do not provide a transform (getTransform returns false, or no cantransform property on the plugin) get a black image on imput. Here are two simple test cases. The last plugin always gets a null source image.\nReader <- Transform(rotate 10) <- NoOp with \"force copy\" checked Reader <- Transform(rotate 10) <- TransformMasked(rotate -10) Or amore complicated one:\nReader <- Transform <- STMap (see #551) ", "code": [], "labels": ["type:bug"]}
{"project": "mapbox_mapbox-gl-native", "title": "Inject MapboxMap with NativeMapView", "description": "To limit the overhead associated with a method call on Android. We should inject MapboxMap with a NativeMapView dependency. This will result in the removal of many, package hidden, facade methods we are currently exposing in MapView. Since this hasn't have an impact on public API. Going to wait with this until 4.0.0 is released. ", "code": [], "labels": ["refactor", "Android"]}
{"project": "arduino_Arduino", "title": "certification question error", "description": "I have just run the demo test for arduino certification. Not sure if this is being actively worked on but it does seem like a nice idea. Question regarding which of three buttons will turn on the LED.\nCode is something like (psuedocode ish)\nB1 on and B3 off  OR B2 on and B2 off\nthe second component seems difficult to obtain unless you have a third state...?\nperhaps I read it wrong, I am a teacher so I am of course tired always. :) Also.. same question and being a little pedantic.\nThe buttons on the image are labelled B1, B2, B3  the code says Bot1, Bot2, Bot3.\nperhaps align the question with the image. (Yes, i Know people should be able to work it out for themselves but if it is a test question, it may need to be adjusted a bit) Thanks\nDJV ", "code": [], "labels": ["Type: Bug"]}
{"project": "hluk_CopyQ", "title": "Scheduled Backup", "description": "Is your feature request related to a problem? Please describe.\nI lost contents of one of my tabs. No way to restore it. Describe the solution you'd like\nI'd like a way to perform scheduled backup of settings and tab contents ", "code": [], "labels": ["feature"]}
{"project": "elastic_beats", "title": "metrics.period has no effect", "description": "<CODE> Doesn't appear to be working on 5.1.1 <CODE> ", "code": ["#================================ Logging =====================================\n\n# Sets log level. The default log level is info.\n# Available log levels are: critical, error, warning, info, debug\n#logging.level: debug\nmetrics.period: 1m\n", "2016/12/30 23:28:40.984382 logp.go:230: INFO Non-zero metrics in the last 30s: publish.events=3 libbeat.publisher.published_events=1 registar.states.current=1 filebeat.harvester.running=1 registrar.states.update=3 registrar.writes=2 filebeat.harvester.open_files=1 filebeat.harvester.started=1\n2016/12/30 23:29:10.984312 logp.go:230: INFO Non-zero metrics in the last 30s: registrar.writes=1 registrar.states.update=1 libbeat.publisher.published_events=1 publish.events=1\n"], "labels": ["question", "libbeat"]}
{"project": "rust-lang_rust", "title": "Trailing `+` in bounds are allowed", "description": "Current parser allows ty/lt bounds have extra +. However, the comments on the parser suggest they shouldn't be allowed. grammar.md also suggests they shouldn't. Both the first and second lines should lead to parse error. The current stable and nightly compilers allow the above code. Tested on Rust Playground. stable <CODE> nightly <CODE> ", "code": ["rustc 1.16.0 (30cf806ef 2017-03-10)\n", "rustc 1.18.0-nightly (50c186419 2017-04-06)\n"], "labels": ["E-easy", "T-doc"]}
{"project": "mhammond_pywin32", "title": "Install problem XP", "description": "When I try to install\npywin32-214.win32-py3.1.exe\non a system with Windows XP SP3 the installation finish with this message: Copied pythoncom31.dll to C:\\WINDOWS\\system32\\pythoncom31.dll\nCopied pywintypes31.dll to C:\\WINDOWS\\system32\\pywintypes31.dll\nRegistered: Python.Interpreter\nRegistered: Python.Dictionary\nRegistered: Python\n-> Software\\Python\\PythonCore\\3.1\\Help[None]=None\n-> Software\\Python\\PythonCore\\3.1\\Help\\Pythonwin Reference[None]='C:\\\\Python31\\\\Lib\\\\site-packages\\\\PyWin32.chm'\nFailed to register pythonwin as editor\n'utf8' codec can't decode bytes in position 39-43: unsupported Unicode code range\nThe pywin32 extensions were successfully installed.\nTraceback (most recent call last):\nFile \"<string>\", line 398, in install\nFile \"<string>\", line 208, in RegisterPythonwin\nWindowsError: [Error 5] Acceso denegado The user has admin rights.\nThanks in advance. Reported by: trancos7 Original Ticket: pywin32/bugs/437 ", "code": [], "labels": ["sourceforge", "bug", "auto-migrated"]}
{"project": "numenta_nupic", "title": "Investigate why swarms pick up constant fields", "description": "Investigate constant field contribution in swarms. Why are they selected, and what can be done for them not to be selected. Check whether 0.2% improvement is sufficient to include a field. This issue was plucked from the backlog of Grok issues after the swarming process was open-sourced. It included some propriety data sets from previous customers that could not be included publicly. To reproduce this but, the assignee will likely need to test different data sets by swarming over them and find one where swarming selects a constant field. ", "code": [], "labels": ["triage", "P3"]}
{"project": "kubernetes_kubernetes", "title": "#19242 breaks compatibility of command line args on kube-controller-manager", "description": "Not specifying --service-cluster-ip-range added in #19242 causes a panic in nodecontroller which causes controller-manager to crash loop. This feels like a v1.3 blocker. Ref #19242 @bgrant0607 @mhrgoog @mqliang @wojtek-t @gmarek @lavalamp @goltermann @davidopp ", "code": [], "labels": ["kind/bug", "team/control-plane", "priority/critical-urgent"]}
{"project": "gwtproject_gwt", "title": "Heterogeneous serializable data containers cause serialization warning", "description": "Originally reported on Google Code with ID 2666 <CODE> Reported by plitwak on 2008-07-15 14:04:07 ", "code": ["Found in GWT Release:\n1.5 RC1\n\nDetailed description:\n\nLet say there is a following class:\n\npublic class DataRow implements Serializable\n{\n    public <T extends Serializable> void addValue( T o ) {\n        values.add( o );\n    }\n\n    public <T extends Serializable> T getValue( int idx ) {\n        return (T)values.get( idx );\n    }\n\n    private List<Serializable> values = new ArrayList<Serializable>();\n}\n\n\nAnd here is the service:\n\npublic interface TestService extends RemoteService {\n    // Sample interface method of remote interface\n    DataRow getDataRow();\n}\n\npublic class TestServiceImpl extends RemoteServiceServlet implements\nTestService {\n    // Implementation of sample interface method\n    public DataRow getDataRow()\n    {\n        DataRow dr = new DataRow();\n        dr.addValue( \"xxx\" );\n        dr.addValue( new Date() );\n\n        return dr;\n    }\n}\n\nI'm getting serialization warnings when I call the service from my code.\nIt is different from time to time but it goes somewhat like this:\n\n...\nAnalyzing the fields of type 'lient.DataRow' that qualify for serialization\nprivate java.util.List<java.io.Serializable> values\njava.util.List<java.io.Serializable>\nChecking type argument 0 of type 'java.util.List<E>' because it is directly\nexposed in this type or in one of its subtypes\njava.io.Serializable\nAnalyzing subclasses:\njava.util.LinkedHashSet<E> <-- THIS IS SOMETIMES DIFFERENT\nChecking parameters of 'java.util.LinkedHashSet<E>'\nChecking param 'E'\nChecking type argument 0 of type 'java.util.LinkedHashSet<E>' because it is\ndirectly exposed in this type or in one of its subtypes\njava.lang.Object\nIn order to produce smaller client-side code, 'Object' is not allowed;\nconsider using a more specific type\n\nWorkaround if you have one:\nnone\n"], "labels": ["Priority-Medium", "Type-Defect"]}
{"project": "signalapp_Signal-Desktop", "title": "de-sync between desktop and android clients when contact reinstalled on their android device", "description": "This is not the first time I've seen this behavior. I don't have time to describe the issue in my customary detail, so I'm leaving logs in the hope that they will be helpful along with what I do have time for. This is my contact for whom message delivery is very often delayed, if that makes any difference. Phone number ends in 08. Anyway last night I'd sent some messages to this contact and they were not delivered (never got the double checkmark) which has become normal behavior - the delivery bug comes and goes for periods of days to weeks - so I didn't think too much of it. This morning they messaged me with a new safety number, telling me they had reinstalled the app last night. The conversation proceeded from there, on and off over a few hours, all on my Android device. Fairly recently toward the end of these logs, they messaged me while I was near my desktop and I wanted to use the desktop client for convenience. I noticed no messages had gotten through after their reinstall, except the session reset, disappearing messages reset, and their first message. Nothing else between then and the time I sat down at the computer - neither their messages nor my replies - had made it to the desktop client. I typed a \"test\" and got a couple of the last messages they'd sent. I then tried resetting secure session on both desktop and phone, to no avail. First I wasn't getting double checkmarks and went out of band to ask them to perform a secure session reset, then they said \"my messages won't send\" on the out of band channel. Eventually with enough mashing the reset button on all three involved devices, things started working as expected again. Signal version: My desktop: 1.2.0 on Linux x86_64\nMy Android: 4.15.5 on Android 7.1.2 My desktop: <URL>\nMy Android: <URL> ", "code": [], "labels": ["Need Information"]}
{"project": "grails_grails-core", "title": "GRAILS-11966: Grails 3.0 HibernateException: No Session found for current thread", "description": "Original Reporter: ekamenev\nEnvironment: Ubuntu 14.04, Grails 3.0 M1, Groovy 2.4.0, JDK 1.8.0_31-b13\nVersion: 3.0-M1\nMigrated From: <URL> I am trying to use Grails 3.0 M1 just to play with it and got an error which I cant resolve myself. class Town {\nString title\nCountry country <CODE> } class Country {\nString title\nSet towns = new LinkedHashSet<>() <CODE> } Then I generated controllers for classes, and when I am trying to create new Town record, I am getting this Exception: ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[grailsDispatcherServlet] - Servlet.service() for servlet [grailsDispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.grails.gsp.GroovyPagesException: Error processing GroovyPageView: [views/town/create.gsp:36] Error executing tag <g:form>: [views/town/create.gsp:31] Error executing tag <f:all>: Could not obtain current Hibernate Session; nested exception is org.hibernate.HibernateException: No Session found for current thread] with root cause\norg.hibernate.HibernateException: No Session found for current thread\nat grails.plugin.formfields.FormFieldsTagLib.renderAssociationInput(FormFieldsTagLib.groovy:478) ~[fields-2.0.0.M1.jar:na]\nat grails.plugin.formfields.FormFieldsTagLib.renderDefaultInput(FormFieldsTagLib.groovy:393) ~[fields-2.0.0.M1.jar:na]\nat grails.plugin.formfields.FormFieldsTagLib.renderWidget(FormFieldsTagLib.groovy:252) ~[fields-2.0.0.M1.jar:na]\nat grails.plugin.formfields.FormFieldsTagLib$_closure3.doCall(FormFieldsTagLib.groovy:126) ~[fields-2.0.0.M1.jar:na]\nat grails.plugin.formfields.FormFieldsTagLib$_closure2.doCall(FormFieldsTagLib.groovy:79) ~[fields-2.0.0.M1.jar:na] I am running app with grails> run-app command Thanks. ", "code": ["static belongsTo = [country: Country]\n\nstatic mapping = {\n}\n", "static hasMany = [towns: Town]\n\nstatic mappedBy = [towns: 'country']\n\nstatic mapping = {\n}\n"], "labels": ["Blocker", "Bug", "Fixed"]}
{"project": "microsoft_vscode", "title": "debugging a process which creates a daemon child process, the deamon is killed when stop debugging", "description": "Debugging a App with a daemon child process\uff0cbut when I stop debug\uff0cthe daemon is killed\u3002 So I guess vscode find child processes and send SIGKILL to child. How can I do sth to prevent kill the daemon? code: <CODE> ", "code": ["    process.title = \"main-process\"\n    if (fs.existsSync(sockPath)) {\n        client = new Client({sockPath: sockPath});\n        handleClientEvent(client);\n    } else {\n        let sp = exec.spawn('node', [path.join(__dirname, './child.js')], {\n            detached: true,\n            execArgv: []\n        });\n        sp.unref();\n        detectionServer()\n    }\n"], "labels": ["*question", "debug"]}
{"project": "CartoDB_cartodb", "title": "Widget's bin color input is not representing the correct colors", "description": "Right now the COLOR input field in the widgets settings is not representing the correct colors when you switch between widget types or when you change the color of the bins and change types.  ", "code": [], "labels": ["Frontend", "bug"]}
{"project": "rails_rails", "title": "ActiveRecord associations not correctly cleared after transaction rollback", "description": "Rails 4.2 introduced a regression in transaction rollbacks that continues to exist in master.  When an associated record is created inside a transaction and then the transaction is rolled back, some shell of the associated data sticks around making the original record unsavable.  I thought it might be possible that this was an  intentional change but the data that sticks around is clearly glitchy: it is void of any data and in most real apps will result in constraint violations when activerecord attempts to perform the insert.  I also believe this behavior can't be intentional since it makes composing ActiveRecord transactions with OO design basically impossible: code can't be expected to know if a record it is going to operate on has been poisoned by a rolled-back transaction. The post has been \"poisoned\" by the rolled back transaction and cannot be saved.\nWhen calling post.save! ActiveRecord first attempts to insert (using DEFAULT VALUES) an empty-shell version of the associated comment record that was previously created and then discarded in the transaction.  In any nontrivial app with not-null constraints this empty insert will fail with an adapter-dependent exception.  In sqlite the exception raised is <CODE> Here is a reproduction test case.  This succeeds in rails 4-1-stable and fails in all subsequent versions, including master.  I used git bisect to determine that the first commit in which this test fails is 9ddb955.  This is the same commit that caused #32847 and that issue may indeed be related to this one. output: <CODE> Rails version master Ruby version 2.5.1 ", "code": ["ActiveRecord::StatementInvalid: SQLite3::ConstraintException: NOT NULL constraint failed: comments.message: INSERT INTO \"comments\" DEFAULT VALUES\n", "E\n\nError:\nBugTest#test_nested_bug:\nActiveRecord::NotNullViolation: SQLite3::ConstraintException: NOT NULL constraint failed: comments.message: INSERT INTO \"comments\" DEFAULT VALUES\n\n\n\nbin/rails test nested_bug.rb:47\n"], "labels": ["stale"]}
{"project": "conan-io_conan", "title": "conan_server (as prepackaged with pip) per default runs on \"0.0.0.0:9300\" instead of \"localhost:9300\" or as specified in server.conf", "description": "To help us debug your issue please explain: I am using Conan 1.0.4 on a Windows Operating system.\nI am currently evaluating to use Conan In-House, and wanted to get started using the prepackaged conan_server, that comes with the pip installation. When I run the conan server after a clean installation, it runs on \"0.0.0.0:9300\" instead of (as expected) localhost or whatever is specified in the server.conf file.  In the server_launcher.py this address seems to be hardcoded:\n This results in the problem, that I cannot upload anything to that \"testserver\"\n Calling launcher.launch() in server_launcher.py without any arguments launches the server on localhost, but I guess it should still take whatever is provieded by the server.conf file. ", "code": [], "labels": ["type: question"]}
{"project": "telegramdesktop_tdesktop", "title": "Edit icon instead of text", "description": "It would be nice if instead of \"edited\" text it would display an icon to not take space from the message.\nIt could practically have an icon permanently. It would be e.g. half transparent or something when message wasn't edited and clicking on it would allow to quick edit. After editing it would be full colored/filled. Thanks to that it would take always the same amount of space regardless the message was edited or not. ", "code": [], "labels": ["auto closed"]}
{"project": "olifolkerd_tabulator", "title": "Error in select_row.js", "description": "Line 175:\nrowMatch = self.table.rowManager.findRow(rows); Should be:\nrowMatch = this.table.rowManager.findRow(rows); self is not defined. ", "code": [], "labels": ["Bug"]}
{"project": "iview_iview", "title": "\u7b5b\u9009\u529f\u80fd\uff0c\u7b5b\u9009\u5217\u8868\u5e95\u90e8\u7684\u201d\u7b5b\u9009\u548c\u91cd\u7f6e\u201c\u6309\u94ae\u5982\u4f55\u6539\u4e3a\u7e41\u4f53\u5b57\uff1f", "description": " ", "code": [], "labels": ["invalid"]}
{"project": "EFForg_https-everywhere", "title": "Add new ruleset for ti.com", "description": "Type: new ruleset\nDomain: <URL> ", "code": [], "labels": ["new-ruleset"]}
{"project": "joomla_joomla-cms", "title": "[4.0] 4.0.0-alpha7-dev to 4.0.0-alpha8-dev: XMLs not updated with the new version", "description": "Joomla 4.0 NightlyBuilds download link (found on <URL>\nis  <URL>\nits version is 4.0.0-alpha8-dev.\nHowever next major list XML contains old version - 4.0.0-alpha7-dev. <URL> <URL>\n4.0.0-alpha8-dev <URL>\n4.0.0-alpha7-dev ", "code": [], "labels": ["No Code Attached Yet", "J4 Issue"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Not listing 4th column in table 'dos'", "description": "List all of those columns with expected values. It doesn't list the forth column time. it's not important what the name is. It just gives NULL for all of the values of that column. It works as expected in mysql console. (probably it's a phpmyadmin bug) Operating system:\nWindows 7\nWeb server:\nWamp3 x64/Apache2.4.17\nDatabase:\nMySQL / name: event-prediction\nPHP version:\n5.6.16\nphpMyAdmin version:\n4.5.2 Browser:\nFirefox\nOperating system:\nWindows 7 ", "code": [], "labels": ["question"]}
{"project": "firefly-iii_firefly-iii", "title": "Firefly III Ansible", "description": "<URL> In this tutorial I will be showing you how to deploy Firefly III via Ansible with Docker behind a containerised Nginx reverse proxy (so you can securely access Firefly III publically). I use Cloudflare as my DNS provider, so I will be showing you how to get hold of a certificate from letsencrypt via a Cloudflare DNS challenge. If you have any comments/suggestions/questions, please do post them below and I will be happy to answer, embrace change, or help :) You can either follow the folder structure I use, or merge all the tasks, vars, etc., however, I prefer to separate roles, tasks, vars, and templates, as it makes writing and using playbooks easier to understand and makes the experience much more modular. You will most likely need to refer to the folder structure as you go through each file. <CODE> NOTHING TO MODIFY - In this task we are installing certbot and setting up letsencrypt on the host machine. I prefer to do it this way, so that I can use the certificate for other instances if I so choose. Alternatively, you can have a look at creating/using a docker certbot container. There's a method to get hold of the certificate natively in ansible, however, I chose to use the command module, as this task creates a monthly certbot cron job to renew the certificates and did not want to confuse the directory locations of the generated/obtained certificates. <CODE> NOTHING TO MODIFY - This template is used in creating your wildcard certificate in the letsencrypt - Letsencrypt Certificate play. It is also used in future for when the cron job runs to renew your certificate monthly. <CODE> NOTHING TO MODIFY - In this task we do the bulk of the work. The (official) Postgres DB, (official) firefly application, and (official) Nginx proxy containers are deployed to your host. Nginx is also configured and the container restarted to reflect on the changes (you could just docker exec -it firefly_iii_nginx nginx -s reload on the host, or I could have just used the command ansible module, but whatever). <CODE> NOTHING TO MODFIY - This is basically a direct copy and paste from the official .env file. I just modified it to make use of the Jinja2 templating. <CODE> NOTHING TO MODIFY - This file is a Jinja2 templated Nginx virtual host file that gets copied to your server. This will allow you to use HTTPS to connect to your firefly instance. Note that this is copied directly from #2109 (comment) (thank you!). <CODE> NOTHING TO MODIFY - This is the nginx server configuration. Note that this is copied directly from #2109 (comment) (thank you!). <CODE> MODIFY ME! - This var file is used for the cloudflare.ini file for generating/renewing certificates. <CODE> MODIFY ME! - This var file is used for the docker container deployments.\nCHANGE - pretty much everything - see official documentation.\nI deployed this to a Raspberry Pi 3B running Ubuntu 18 Server, so I had to use the arm image. If you are deploying to a normal server, change the image to jc5x/firefly-iii:latest. <CODE> MODIFY ME! - This file contains all your hosts that ansible will therefore know about. Note that we are using ssh keys to connect to our host.\nCHANGE - x.x.x.x to your host's IP Address and ansible_ssh_private_key_file to the name and location of your ssh key. <CODE> NOTHING TO MODIFY - This is the playbook that will tell ansible to connect to your server, reference the vars and run the plays/roles. <CODE> ", "code": ["ansible\n |__roles\n |   |__letsencrypt\n |   |   |__tasks\n |   |   |   |__main.yml\n |   |   |__templates\n |   |       |__cloudflare.ini.j2\n |   |__docker-firefly\n |   |    |__tasks\n |   |    |   |__main.yml\n |   |    |__templates\n |   |        |__.env.j2\n |   |        |__firefly.conf.j2\n |   |        |__nginx.conf\n |   |__docker-install\n |       |__tasks\n |           |__main.yml\n |__vars\n |    |__letsencrypt\n |    |   |__cloudflare.yml\n |    |__docker-firefly\n |        |__firefly.yml\n |__firefly-ansible.yml\n |__hosts.yml\n", "---\n- name: Add Certbot Repository\n  apt_repository:\n    repo: ppa:certbot/certbot\n    state: present\n\n- name: Apt Update\n  apt:\n    update_cache: yes\n    force_apt_get: yes\n\n- name: Install Required System Packages\n  apt:\n    name: \"{{ packages }}\"\n    update_cache: yes\n    state: latest\n  vars:\n    packages:\n    - certbot\n    - python3-certbot-dns-cloudflare\n\n- name: Copy cloudflare.ini\n  template:\n    src: templates/cloudflare.ini.j2\n    dest: /etc/letsencrypt/cloudflare.ini\n    mode: '0400'\n\n- name: Letsencrypt Certificate\n  command: /usr/bin/certbot certonly --dns-cloudflare --dns-cloudflare-credentials /etc/letsencrypt/cloudflare.ini -d {{ DOMAIN }},*.{{ DOMAIN }} --preferred-challenges dns-01\n  register: res\n  failed_when: false\n  changed_when: false\n\n- name: Cert Renewal Cron Job\n  cron:\n    name: \"Cert Renewal\"\n    minute: \"0\"\n    hour: \"0\"\n    day: \"1\"\n    month: \"*\"\n    weekday: \"*\"\n    job: /usr/bin/certbot renew --quiet --post-hook \"/usr/bin/docker exec firefly_iii_nginx nginx -s reload\" > /dev/null 2>&1\n...\n", "dns_cloudflare_email = \"{{ CF_EMAIL }}\"\ndns_cloudflare_api_key = \"{{ CF_TOKEN }}\"\n", "---\n- name: Copy .env file for firefly_iii_app\n  template:\n    src: templates/.env.j2\n    dest: /tmp/.env\n\n- name: Create Docker Network\n  docker_network:\n    name: firefly_iii_net\n\n- name: Create firefly_iii_db container\n  docker_container:\n    name: firefly_iii_db\n    image: \"{{ DOCKER_IMAGE_POSTGRES }}\"\n    networks:\n      - name: \"{{ DOCKER_NETWORK_NAME }}\"\n    purge_networks: yes\n    networks_cli_compatible: no\n    volumes:\n      - firefly_iii_db:/var/lib/postgresql/data\n    env:\n      POSTGRES_PASSWORD: \"{{ DB_PASSWORD }}\"\n      POSTGRES_USER: \"firefly\"\n\n- name: Create firefly_iii_app container\n  docker_container:\n    name: firefly_iii_app\n    image: \"{{ DOCKER_IMAGE_FIREFLY }}\"\n    published_ports: \"81:80\"\n    networks:\n      - name: \"{{ DOCKER_NETWORK_NAME }}\"\n    purge_networks: yes\n    networks_cli_compatible: no\n    volumes:\n      - firefly_iii_export:/var/www/firefly-iii/storage/export\n      - firefly_iii_upload:/var/www/firefly-iii/storage/upload\n    env_file: /tmp/.env\n\n- name: Create firefly_iii_nginx container\n  docker_container:\n    name: firefly_iii_nginx\n    image: \"{{ DOCKER_IMAGE_NGINX }}\"\n    published_ports: \"443:443\"\n    networks:\n      - name: \"{{ DOCKER_NETWORK_NAME }}\"\n    purge_networks: yes\n    networks_cli_compatible: no\n    volumes:\n      - firefly_iii_nginx:/etc/nginx\n      - /etc/letsencrypt:/etc/letsencrypt\n    env:\n      VIRTUAL_HOST: \"{{ FQDN }}\"\n\n- name: Create sites-enabled Directory\n  file:\n    path: /var/lib/docker/volumes/firefly_iii_nginx/_data/sites-enabled\n    state: directory\n\n- name: Copy Nginx Config\n  synchronize:\n    src: templates/nginx.conf\n    dest: /var/lib/docker/volumes/firefly_iii_nginx/_data/nginx.conf\n\n- name: Copy Nginx VHOST Config\n  template:\n    src: templates/firefly.conf.j2\n    dest: /var/lib/docker/volumes/firefly_iii_nginx/_data/sites-enabled/firefly.conf\n\n- name: Restart Nginx Container\n  docker_container:\n    name: firefly_iii_nginx\n    state: started\n    restart: yes\n...\n", "# You can leave this on \"local\". If you change it to production most console commands will ask for extra confirmation.\n# Never set it to \"testing\".\nAPP_ENV=local\n\n# Set to true if you want to see debug information in error screens.\nAPP_DEBUG=false\n\n# This should be your email address\nSITE_OWNER={{ EMAIL }}\n\n# The encryption key for your sessions. Keep this very secure.\n# If you generate a new one existing data must be considered LOST.\n# Change it to a string of exactly 32 chars or use command `php artisan key:generate` to generate it\nAPP_KEY={{ APP_KEY }}\n\n# Change this value to your preferred time zone.\n# Example: Europe/Amsterdam\nTZ={{ TIMEZONE }}\n\n# This variable must match your installation's external address but keep in mind that\n# it's only used on the command line as a fallback value.\nAPP_URL={{ APP_URL }}\n\n# TRUSTED_PROXIES is a useful variable when using Docker and/or a reverse proxy.\n# Set it to ** and reverse proxies work just fine.\nTRUSTED_PROXIES=**\n\n# The log channel defines where your log entries go to.\n# - If you use DOCKER, use 'docker_out'\n# - For everything else, use 'daily'\n\n# Several other options exist. You can use 'single' for one big fat error log (not recommended).\n# Also available are 'syslog', 'errorlog' and 'stdout' which will log to the system itself.\nLOG_CHANNEL={{ LOG_CHANNEL }}\n\n# Log level. You can set this from least severe to most severe:\n# debug, info, notice, warning, error, critical, alert, emergency\n# If you set it to debug your logs will grow large, and fast. If you set it to emergency probably\n# nothing will get logged, ever.\nAPP_LOG_LEVEL=notice\n\n# Database credentials. Make sure the database exists. I recommend a dedicated user for Firefly III\n# For other database types, please see the FAQ: https://docs.firefly-iii.org/support/faq\nDB_CONNECTION=pgsql\nDB_HOST=firefly_iii_db\nDB_PORT=5432\nDB_DATABASE=firefly\nDB_USERNAME=firefly\nDB_PASSWORD={{ DB_PASSWORD }}\n\n# PostgreSQL supports SSL. You can configure it here.\nPGSQL_SSL_MODE=prefer\nPGSQL_SSL_ROOT_CERT=null\nPGSQL_SSL_CERT=null\nPGSQL_SSL_KEY=null\nPGSQL_SSL_CRL_FILE=null\n\n# If you're looking for performance improvements, you could install memcached.\nCACHE_DRIVER=file\nSESSION_DRIVER=file\n\n# You can configure another file storage backend if you cannot use the local storage option.\n# To set this up, fill in the following variables. The upload path is used to store uploaded\n# files and the export path is to store exported data (before download).\nSFTP_HOST=\nSFTP_PORT=\nSFTP_UPLOAD_PATH=\nSFTP_EXPORT_PATH=\n\n# SFTP uses either the username/password combination or the private key to authenticate.\nSFTP_USERNAME=\nSFTP_PASSWORD=\nSFTP_PRIV_KEY=\n\n# Cookie settings. Should not be necessary to change these.\nCOOKIE_PATH=\"/\"\nCOOKIE_DOMAIN=\nCOOKIE_SECURE=false\n\n# If you want Firefly III to mail you, update these settings\n# For instructions, see: https://docs.firefly-iii.org/advanced-installation/email\nMAIL_DRIVER={{ MAIL_DRIVER }}\nMAIL_HOST=smtp.mailtrap.io\nMAIL_PORT=2525\nMAIL_FROM=changeme@example.com\nMAIL_USERNAME=null\nMAIL_PASSWORD=null\nMAIL_ENCRYPTION=null\n\n# Other mail drivers:\nMAILGUN_DOMAIN=\nMAILGUN_SECRET=\n# If you are on EU region in mailgun, use api.eu.mailgun.net, otherwise use api.mailgun.net\nMAILGUN_ENDPOINT=api.mailgun.net\nMANDRILL_SECRET=\nSPARKPOST_SECRET=\n\n# Firefly III can send you the following messages\nSEND_REGISTRATION_MAIL=true\nSEND_ERROR_MESSAGE=true\n\n# These messages contain (sensitive) transaction information:\nSEND_REPORT_JOURNALS=true\n\n# Set a Mapbox API key here (see mapbox.com) so there might be a map available at various places.\nMAPBOX_API_KEY=\n\n# Firefly III currently supports two provider for live Currency Exchange Rates:\n# \"fixer\", and \"ratesapi\".\n# RatesApi.IO (see https://ratesapi.io) is a FREE and OPEN SOURCE live currency exchange rates,\n# built compatible with Fixer.IO, based on data published by European Central Bank, and doesn't require API key.\nCER_PROVIDER=ratesapi\n\n# If you have select \"fixer\" as default currency exchange rates,\n# set a Fixer IO API key here (see https://fixer.io) to enable live currency exchange rates.\n# Please note that this WILL ONLY WORK FOR PAID fixer.io accounts because they severely limited\n# the free API up to the point where you might as well offer nothing.\nFIXER_API_KEY=\n\n# If you wish to track your own behavior over Firefly III, set a valid analytics tracker ID here.\nANALYTICS_ID=\n\n# Firefly III has two options for user authentication. \"eloquent\" is the default,\n# and \"ldap\" for LDAP servers.\n# For full instructions on these settings please visit:\n# https://docs.firefly-iii.org/advanced-installation/authentication\nLOGIN_PROVIDER=eloquent\n\n# LDAP connection configuration\n# OpenLDAP, FreeIPA or ActiveDirectory\nADLDAP_CONNECTION_SCHEME=OpenLDAP\nADLDAP_AUTO_CONNECT=true\n\n# LDAP connection settings\nADLDAP_CONTROLLERS=\nADLDAP_PORT=389\nADLDAP_TIMEOUT=5\nADLDAP_BASEDN=\"\"\nADLDAP_FOLLOW_REFFERALS=false\nADLDAP_USE_SSL=false\nADLDAP_USE_TLS=false\n\nADLDAP_ADMIN_USERNAME=\nADLDAP_ADMIN_PASSWORD=\n\nADLDAP_ACCOUNT_PREFIX=\nADLDAP_ACCOUNT_SUFFIX=\n\n# LDAP authentication settings.\nADLDAP_PASSWORD_SYNC=false\nADLDAP_LOGIN_FALLBACK=false\n\nADLDAP_DISCOVER_FIELD=distinguishedname\nADLDAP_AUTH_FIELD=distinguishedname\n\n# Will allow SSO if your server provides an AUTH_USER field.\nWINDOWS_SSO_DISCOVER=samaccountname\nWINDOWS_SSO_KEY=AUTH_USER\n\n# field to sync as local username.\nADLDAP_SYNC_FIELD=userprincipalname\n\n# You can disable the X-Frame-Options header if it interfears with tools like\n# Organizr. This is at your own risk.\nDISABLE_FRAME_HEADER=false\n\n# Leave the following configuration vars as is.\n# Unless you like to tinker and know what you're doing.\nAPP_NAME=FireflyIII\nADLDAP_CONNECTION=default\nBROADCAST_DRIVER=log\nQUEUE_DRIVER=sync\nREDIS_HOST=127.0.0.1\nREDIS_PASSWORD=null\nREDIS_PORT=6379\nCACHE_PREFIX=firefly\nSEARCH_RESULT_LIMIT=50\nPUSHER_KEY=\nPUSHER_SECRET=\nPUSHER_ID=\nDEMO_USERNAME=\nDEMO_PASSWORD=\nUSE_ENCRYPTION=false\nIS_SANDSTORM=false\nIS_DOCKER=false\nIS_HEROKU=false\nBUNQ_USE_SANDBOX=false\nFFIII_LAYOUT=v1\n", "server {\n    server_name {{ FQDN }};\n    add_header Referrer-Policy \"no-referrer\";\n\n    location / {\n        proxy_pass http://{{ HOST_IP }}:81/;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_buffering off;\n    }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/{{ DOMAIN }}/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/{{ DOMAIN }}/privkey.pem; # managed by Certbot\n#    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n#    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\n\nserver {\n    if ($host = {{ FQDN }}) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    listen 80;\n    server_name {{ FQDN }};\n    return 404; # managed by Certbot\n}\n", "user www-data;\nworker_processes auto;\npid /run/nginx.pid;\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n        worker_connections 768;\n        # multi_accept on;\n}\n\nhttp {\n\n        ##\n        # Basic Settings\n        ##\n        server_tokens off;\n        sendfile on;\n        tcp_nopush on;\n        tcp_nodelay on;\n        keepalive_timeout 65;\n        types_hash_max_size 2048;\n        # server_tokens off;\n\n        # server_names_hash_bucket_size 64;\n        # server_name_in_redirect off;\n\n        include /etc/nginx/mime.types;\n        default_type application/octet-stream;\n\n        ##\n        # SSL Settings\n        ##\n        ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE\n        ssl_prefer_server_ciphers on;\n\n        ##\n        # Logging Settings\n        ##\n        access_log /var/log/nginx/access.log;\n        error_log /var/log/nginx/error.log;\n\n        ##\n        # Gzip Settings\n        ##\n        gzip on;\n\n        ##\n        # Virtual Host Configs\n        ##\n\n        include /etc/nginx/conf.d/*.conf;\n        include /etc/nginx/sites-enabled/*;\n}\n", "CF_EMAIL: mycloudflareemail@example.com\nCF_TOKEN: mycloudflareapikey\n", "---\n# Changeable .env variables\nHOST: firefly\nFQDN: firefly.example.com\nDOMAIN: example.com\nEMAIL: myemail@example.com\nAPP_KEY: R@nd0m32Chars\nTIMEZONE: Africa/Johannesburg\nAPP_URL: http://firefly\nMAIL_DRIVER: sendmail\nLOG_CHANNEL: stdout\nHOST_IP: x.x.x.x\n\n# Docker & related\nDOCKER_IMAGE_FIREFLY: jc5x/firefly-iii:latest-arm\nDOCKER_IMAGE_POSTGRES: postgres:10\nDOCKER_IMAGE_NGINX: nginx:latest\nDOCKER_NETWORK_NAME: firefly_iii_net\nDB_PASSWORD: firefly\n...\n", "[firefly]\nx.x.x.x\n\n[linux_servers:children]\nfirefly\n\n[linux_servers:vars]\nansible_python_interpreter=/usr/bin/python3\nansible_ssh_user=ubuntu\nansible_ssh_private_key_file=~/.ssh/firefly\n", "---\n- hosts: firefly\n  become: yes\n  become_method: sudo\n  vars_files:\n  - vars/letsencrypt/cloudflare.yml\n  - vars/docker-firefly/firefly.yml\n  roles:\n    - docker-install\n    - letsencrypt\n    - docker-firefly\n...\n"], "labels": ["stale", "question"]}
{"project": "helm_charts", "title": "string compare of version number may lead to unexpected behavior", "description": "When I build Kubernetes, I added a suffix to the version string such as v1.8.3-xxx which leads the versionInfo Minor is 8+. (I already export KUBE_GIT_MINOR=8 before compiling Kubernetes, but the Minor version is still 8+) I checked some of the charts, they are using string compare of the versionInfo, like following: <CODE> But when Kubernetes version is upgraded to v1.10.1, so the string compare may lead to unexpected behavior. Is there a way to handle such case? ", "code": ["{{- if and (eq .Capabilities.KubeVersion.Major \"1\") (gt .Capabilities.KubeVersion.Minor \"7\") }}\n"], "labels": ["kind/bug", "lifecycle/frozen"]}
{"project": "yarnpkg_yarn", "title": "Installation Problem: [title]", "description": "Which operating system are you using: Please describe the steps you took when trying to install Yarn and what went wrong: ", "code": [], "labels": ["triaged"]}
{"project": "signalapp_Signal-iOS", "title": "Cant send SMS to invite non-user from iPad/iPod touch", "description": "Signal app works fine on iPad/iPod touch; but when attempting to dial non-user it offers to send invitation via SMS. Then a \"New message\" window is displayed momentarily, with message pre-filled, to immediately disappear (due to crash, presumably since iPad does not have default SMS app or numerical identity). This is accompanied with MessagesViewService EXC_CRASH dump in Diagnostic&Usage Data... I can provide more details about the crash dump if needed. --igor ", "code": [], "labels": ["bug"]}
{"project": "angular_angular", "title": "tutorial: Instructed to link styles.css despite it being included in styles.bundle.js", "description": "<CODE> Tutorial in routing <URL> instructs to create a styles.css and then <link> it in the index.html. This issue is that the styles.css is already included in the \"styles\" of .angular-cli.json using ng new , and are compiled into dist/styles.bundle.js. The \"styles.css\" is not in the \"assets\": [] of .angular-cli.json so it will not be included in the build and people going through the tutorial will get a 404 in their console when requesting the stylesheet on pageload. Remove the instructions stating to <link> the stylesheet, as it is unnecessary because it is included in styles.bundle.js and causes 404s ng new <project>\ncd <project>\nng serve\nAdd to head contents of src/index.html <link rel=\"stylesheet\" href=\"styles.css\">\nProceed to get 404s at localhost:4200 because styles.css isn't copied as an asset but is compiled into styles.bundle.js Remove conflicting advice from tutorial. <CODE> ", "code": ["\n[ ] Regression (behavior that used to work and stopped working in a new release)\n[ ] Bug report \n[ ] Feature request\n[X] Documentation issue or request\n[ ] Support request => Please do not submit support request here, instead see https://github.com/angular/angular/blob/master/CONTRIBUTING.md#question\n", "\nAngular: 4.2.5\nangular-cli v 1.2.0\n\n\nBrowser:\n- [X] Chrome (desktop) version XX\n- [ ] Chrome (Android) version XX\n- [ ] Chrome (iOS) version XX\n- [ ] Firefox version XX\n- [ ] Safari (desktop) version XX\n- [ ] Safari (iOS) version XX\n- [ ] IE version XX\n- [ ] Edge version XX\n \nFor Tooling issues:\n- Node version: XX \n- Platform: \n\nOthers:\nN/A\n"], "labels": ["comp: docs"]}
{"project": "nefarius_ScpToolkit", "title": "DS3 Controller No Wireless", "description": "I installed the latest SCP-toolkit drivers and the output message was that the installation was successful  (it also restarted the SCP service). I installed the bluetooth PS3 and DS3 drivers. The controller works when plugged in to the USB but not via bluetooth. I have the Intel chipset, VID_8087&PID_07DA. The DS3 used to work on the old SCP service. Help please ", "code": [], "labels": ["help wanted"]}
{"project": "flutter_flutter", "title": "BorderRadius.only or .symmetric for circularRadius", "description": "is there any way to apply circular border radius to one side? ", "code": [], "labels": ["d: stackoverflow", "framework"]}
{"project": "arduino_Arduino", "title": "[Library Manager] Please add this iLib library", "description": "<URL> thanks ", "code": [], "labels": ["Component: Board/Lib Manager"]}
{"project": "ccrisan_motioneyeos", "title": "Which .gz to download for Pi Zero W?", "description": "Sorry for a n00b question, but which image should I download for the Pi Zero W?  ", "code": [], "labels": ["question"]}
{"project": "x64dbg_x64dbg", "title": "Crash on certain input files", "description": "ping @Mattiwatti Some time ago I got a sample that will crash when loading it into x64dbg. The reason appears to be that RtlImageDirectoryEntryToData returns a garbage pointer. Probably the best solution is to rewrite those functions, or perform the same check as the loader does in order to reject the result. ", "code": [], "labels": ["bug"]}
{"project": "go-gitea_gitea", "title": "Allow sendmail options in SENDMAIL_PATH", "description": "Please allow to set sendmail options like \"-t -i -f webmaster@domain.tld\" in option SENDMAIL_PATH. The reason is simple: Without options sendmail will use username@mailserver (e.g. git@mail.domain.tld, username = username, Gitea runs on the server) as a Return-Path in the outgoing mail. This can produce various problems. ", "code": [], "labels": ["kind/enhancement"]}
{"project": "microsoft_vscode", "title": "Revisit need for node/electron-browser in workbench/contrib/tasks", "description": "Refs #68302 I am not sure why src/vs/workbench/contrib/tasks has to have most of its files in electron-browser land. Please consider lifting this to browser if possible. If there is something blocking this task, speak up and we need to think about introducing new services as needed. //cc @dbaeumer ", "code": [], "labels": ["debt", "web"]}
{"project": "jquery-validation_jquery-validation", "title": "Latest Nuget package is 1.16.0", "description": "Just wondering if you could update the package to use 1.17.0. Thanks in advance! ", "code": [], "labels": ["Invalid"]}
{"project": "shadowsocks_shadowsocks-libev", "title": "ubuntu 17.10 error using shadowsocks-libev", "description": "3.0.8 ubuntu 17.10 apt install shadowsocks-libev It works. Oct 30 12:14:04 vultr systemd[1]: Started Shadowsocks-libev Default Server Service.\nOct 30 12:14:04 vultr ss-server[31081]: /usr/bin/ss-server: symbol lookup error: /usr/bin/ss-server: undefined symbol: crypto_aead_xchacha20poly1305_ietf_encrypt\nOct 30 12:14:04 vultr systemd[1]: shadowsocks-libev.service: Main process exited, code=exited, status=127/n/a\nOct 30 12:14:04 vultr systemd[1]: shadowsocks-libev.service: Unit entered failed state.\nOct 30 12:14:04 vultr systemd[1]: shadowsocks-libev.service: Failed with result 'exit-code'. ", "code": [], "labels": ["question"]}
{"project": "gperftools_gperftools", "title": "config.h.in is autotools product and is not needed in source repository", "description": "Originally reported on Google Code with ID 550 <CODE> Reported by alkondratenko on 2013-07-14 04:17:58 ", "code": ["What steps will reproduce the problem?\n1. observe how it's regenerated even if you remove it\n\nWhat is the expected output? What do you see instead?\n\n\nPlease use labels and text to provide additional information.\n\n\n"], "labels": ["Priority-Medium", "Status-Fixed", "Type-Defect"]}
{"project": "expressjs_express", "title": "Promises (async/await) in Express 4 vs 5", "description": "I see that Promises are on the roadmap for Express 5, at which point async/await will work out of the box with Babel. I thought it wouldn't work before Express 5, but I read this article <URL> that shows it can be done already! Are there any drawbacks to starting to use Promises and async/await in Express 4 (for example, error messages or stack traces)? Apart from having to create that 1-line wrap function as described in the article and wrapping all route functions within that wrap function, is there anything to be aware of or anything else that needs to be done? When it comes time to switch to Express 5, will it be as simple as just removing all occurrences of wrap throughout the code (as far as async/await is concerned)? ", "code": [], "labels": ["question", "4.x"]}
{"project": "signalapp_Signal-iOS", "title": "Not showing correct thread after receiving a notification (Beta 2.0.7)", "description": "Both with locked and unlocked iphone, when I sweep or select a notificacion of a new message, the app doesn't open in the correct thread but on the last seen one. ", "code": [], "labels": ["needs reproduction", "bug"]}
{"project": "traccar_traccar", "title": "How to use Postgresql in Traccar ?", "description": "Hello, I am a beginner in using Traccar, I want to use Postgresql to store data. How can I do that ? ", "code": [], "labels": ["question"]}
{"project": "pyrocms_pyrocms", "title": "[streams-platform] Locale hint messes up asset root", "description": "\nNo description provided.\n ", "code": [], "labels": ["Bug"]}
{"project": "prisma_prisma", "title": "make version command available at --version", "description": " Issue by timsuchanek\nSunday Sep 24, 2017 at 19:50 GMT\nOriginally opened as <URL> ", "code": [], "labels": ["area/cli"]}
{"project": "OpenTTD_OpenTTD", "title": "Crash when playing on server", "description": "Qwerty_asd opened the ticket and wrote: Attachments Reported version: 1.7.1\nOperating system: Mac OS X ", "code": [], "labels": ["needs triage", "stale", "flyspray", "bug"]}
{"project": "desktop_desktop", "title": "Re-add the 'View on GitHub' menu item/shortcut", "description": "I sure do miss this fella:  As I'm moving between repos in the app but don't necessarily have them open in browser. Any chance getting it re-added? ", "code": [], "labels": ["enhancement"]}
{"project": "remy_nodemon", "title": "Uncaught exception in Nodemon when application throws an exception", "description": "During developing, I throw an exception (a bit dirty I know, but the purpose is to halt my server if this happened, so I can address the issue). <CODE> Circumstantially, after my app throws this, it seems that nodemon crashes as well:\nClearly coming from this nodemon source file <CODE> I think nodemon shouldn't crash though.. but rather emit it's standard [nodemon] app crashed - waiting for file changes before starting... message and wait for app changes. If it does crash, can it produce some more context about the crash, so I can consider making a pull request? ", "code": ["    throw \"stop my app\";\n    ^\nstop my app\n", "exception in nodemon killing node\nError: read ECONNRESET\n    at errnoException (net.js:901:11)\n    at Pipe.onread (net.js:556:19)\n\nIf appropriate, please file an error: http://github.com/remy/nodemon/issues/new\n"], "labels": ["stale"]}
{"project": "rook_rook", "title": "VolumeSnapshots never go into Ready-To-Use state if using old CRDs", "description": "Is this a bug report or feature request? Deviation from expected behaviour: We experimented with the CephCSI drivers back in Rook v1.0 so our cluster had some old CRDs. Specifically: Upon running through an upgrade to Rook v1.1 and switching to using the CephCSI drivers for RBD, those CRDs don't get updated. Trying to take a volume snapshot produces this error in the csi-snapshotter logs: E1015 20:47:13.057258       1 goroutinemap.go:150] Operation for \"create-wordpress/mysql-csi-pvc[b1bc1c9d-ef8c-11e9-bdcd-901b0e6be2b4]\" failed. No retries permitted until 2019-10-15 20:47:15.057225226 +0000 UTC m=+3214.959239580 (durationBeforeRetry 2s). Error: \"snapshot controller failed to update wordpress/mysql-csi-pvc on API server: the server could not find the requested resource (put volumesnapshots.snapshot.storage.k8s.io mysql-csi-pvc)\" Describing the VolumeSnapshot also show that the Ready To Use is false. Expected behaviour: The Volumesnapshot should be created successfully without errors in the logs and the \"Ready To Use\" status should be set to true. The root cause was determined to be the old CRDs, as discussed here: kubernetes-csi/external-snapshotter#147 (comment) Upon deleting the old CRDs and restarting the csi-rbd-provisioner-0 pod, those CRDs were recreated with the new versions and the snapshots were successful. How to reproduce it (minimal and precise): This issue was only reproducible due to the fact that we tested CephCSI functionality in v1.0. I reviewed the upgrade docs again and the upgrade-from-v1.0-crds.yaml but there's no mention of deleting the CRDs. ", "code": [], "labels": ["bug"]}
{"project": "assimp_assimp", "title": "Feature request: DropXXXProcess to control JoinVerticesProcess behaviour.", "description": "Assimp removes duplicate vertices only after comparing not only position but also comparing normals, uvs, tangents and bitangents.\nThis is intended behaviour. I would like to import a File without it's normals(etc..) so the merging process removes as many vertices as possible. ", "code": [], "labels": ["feature request"]}
{"project": "inspec_inspec", "title": "etc_group not implemented for centos", "description": "you can test it with \"kitchen verify default-centos-64\" in chef-os-hardening project ", "code": [], "labels": ["Type: Bug"]}
{"project": "OptimalBits_bull", "title": "Higher CPU usage with Bull 3.x (over Bull 1.x)", "description": "We're noticing significantly higher CPU across the board with Bull 3.0. The upgrade was about halfway through the charts below. Job throughput remained constant. Redis CPU:\n Node process CPU\n We're using all the default settings for Bull 3.0. ", "code": [], "labels": ["enhancement"]}
{"project": "ArduPilot_ardupilot", "title": "Copter: MAV_ROI_WPNEXT with no WP causes uncontrolled yaw", "description": "I had a problem that kept me busy for a week, it may not be a bug but I'm due to inform it. I had no WP and I enabled (accidentally) MAV_ROI_WPNEXT flag/parameter, this caused the Quad to revolve (yaw) out of control on it's Z axis, would be nice to add a check to avoid this behavior, I don't have the skills to do it, but I know it's trivial to someone who has it. I use 3DR APM v2.6 with FW v3.2.1 cheers! ", "code": [], "labels": ["Copter", "BUG"]}
{"project": "RasaHQ_rasa", "title": "Import specific subskills", "description": "In a naive multi skill setup, all training data / domains of subdirectories get imported and are used for the training of the bot. <CODE> As part of this issue, we want to add the capability to use only certain subdirectories / sub bots (e.g. only include Bot A and Bot B1). Where to specify the imports: ", "code": ["multi\\ domain\\ example\n\u251c\u2500\u2500 Bot\\ A\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 domain.yml\n\u251c\u2500\u2500 Bot\\ B\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Bot\\ B1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 config.yml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 domain.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 domain.yml\n\u251c\u2500\u2500 config.yml\n\u251c\u2500\u2500 data\n\u2514\u2500\u2500 domain.yml\n"], "labels": ["enhancement"]}
{"project": "golang_go", "title": "x/tools/go/packages: IgnoreFuncBodies implementation and comment mismatch", "description": "<URL> The comment and the given example is self-contradictory. The implementation is actually type-check bodies of functions only in initial packages. For my use case, I would appreciate if IgnoreFuncBodies could be somehow controlled by packages.Config. I have a script (invoked by go generate) parsing source code, harvesting struct definition and generating serialization-related code for those structs. Due to lack of serialization-related code, the type-checking for function bodies always fail because those structs does not implement my serialization interface yet. I don't have any assertions like var _ MySerializationInterface = MyStruct{}. So as long as I can turn IgnoreFuncBodies on, everything works for me. ", "code": [], "labels": ["NeedsInvestigation", "Tools"]}
{"project": "intljusticemission_react-big-calendar", "title": "dayWrapper is broken in the new RBC", "description": "Bug Nothing gets returned in dayWrapper. ", "code": [], "labels": ["wontfix"]}
{"project": "roundcube_roundcubemail", "title": "Addressbook and configuration doesn't work", "description": "Reported by xkill on 24 Sep 2008 09:04 UTC as Trac ticket #1485406 I upgrade Roundcube to the latest subversion snap, but the links to addressbook and config doesn't work. I check the error log, but no errors. Keywords: Addressbook config configuration\nMigrated-From: <URL> ", "code": [], "labels": ["worksforme", "bug", "C: User Interface"]}
{"project": "neo4j_neo4j", "title": "weird ghost node", "description": "I don't think I have ever created any node with a label named \"ghost\". But today I found there were many nodes with no properties at all in production evironment. But unfortunately I couldn't reproduce it in my local environment. Is it kind of some historical version upgrade problem? Could I just delete them? Is there any concern? Any suggestion would be appreciated! production:\nNeo4j version: 2.1-2.3\nOperating system: Linux local:\nNeo4j version: 2.3.2\nOperating system: Mac ", "code": [], "labels": ["question"]}
{"project": "bokeh_bokeh", "title": "examples/plotting/server/slider.py throws an error", "description": "/Bokeh/examples/plotting/server  [master] $ python slider.py\nUsing plot server at http://localhost:5006/bokeh; Docname: slider.py example\nTraceback (most recent call last):\nFile \"slider.py\", line 28, in \nplot.tools.append(slider_x)\nAttributeError: 'NoneType' object has no attribute 'tools' ", "code": [], "labels": ["type: bug"]}
{"project": "ansible_ansible", "title": "ec2 module exact_count output should list deleted instances", "description": "lib/ansible/modules/cloud/amazon/ec2.py <CODE> When using the exact_count option with the ec2 module, there's no simple way to programmatically see what was changed. If an instance is added or removed, it shows up in the \"instances\" attribute of the result object, but there's no indication about whether the instance was added or removed. It would be great either use a separate attribute (added_instances, deleted_instances) for each \"operation\", or some other method of getting to this information easily. ", "code": ["2.4.0\n"], "labels": ["feature", "support:core", "affects_2.4", "module", "aws", "cloud"]}
{"project": "OfficeDev_office-ui-fabric-react", "title": "Dropdown: unnecessary margin-bottom: 10px", "description": "Are you willing to submit a PR to fix? (Yes) Requested priority: (Normal) Products/sites affected: (if applicable) Dropdown component has been assigned margin-botttom: 10px by default. A fabric component shouldn't assign external margins. If dropdown is put in a table column it breaks layout for other column elements. <URL> ", "code": [], "labels": ["Type: Bug "]}
{"project": "moby_moby", "title": "Windows support for Swarm", "description": "Tracker issue for Swarm on Windows Please let me know if we're missing other pieces. /cc @friism @mgoelzer @vsaraswat ", "code": [], "labels": ["area/swarm", "platform/windows"]}
{"project": "the-control-group_voyager", "title": "Getting the tumbnail image in the Vue InstantSearch and Agolia", "description": "Hi everyone, I'm trying to add an instant search in my front end app with Agolia and Vue InstantSearch, but I have no skill whit vue so I'm having a hard time to find a way to get the thumbnail image made by voyager in my search results. Here my search box and results code : I can display the original image with : 'storage/' + result.image\" I don't know if it's possible but i would like to find a way to have the same result as :\n{{ Voyager::image($post->thumbnail('cropped')) }} Thanks in advance for your help ! ", "code": [], "labels": ["question"]}
{"project": "xceedsoftware_wpftoolkit", "title": "Feature Request: PropertyGrid - OnPropertyValueChanged", "description": "xaviergonz[CodePlex] It would be nice if the control could ha ve a OnPropertyValueChanged event like the MS counterpart\nnbsp\n<URL>\nnbsp\nThis is because I'm trying to port a project that uses the WinForms property grid to use this one and I do some quotspecialquot code within that event (actually what it does is quotwhenever the property changed, send it to a serverquot) and adding that\nkind of code to the model of every editable class all the time would be weird (and probably not possible, since the quotsend to serverquot code is not related to the datamodel assembly).\nnbsp\nIf adding that event is not possible, is there a way to emulate it?\nnbsp\nThanks ", "code": [], "labels": ["CodePlex"]}
{"project": "phan_phan", "title": "signature mismatches caused by func_get_args() can look confusing", "description": "<CODE> This produces the rather confusing:\nPhanParamSignatureMismatch Declaration of function fn() should be compatible with function fn() ", "code": ["<?php\nclass C {\n    function fn() { func_get_args(); }\n}\n\nclass D extends C{\n    function fn() { }\n}\n"], "labels": ["help wanted", "enhancement"]}
{"project": "firasdib_Regex101", "title": "Tooltip for  {0,2}? quantifier", "description": "The tooltip for the expression {0,2}? shows: Quantifier. Repeat previous token 0 to 2? times, as few times as possible Should the ? appear within the tooltip? ", "code": [], "labels": ["bug"]}
{"project": "nolimits4web_swiper", "title": "Swipe not working in mobile opera mini browser", "description": "Swhip not working in mobile opera mini browser ", "code": [], "labels": ["outdated"]}
{"project": "dart-lang_sdk", "title": "Args Package: Inconsistent spacing in getUsage() string.", "description": "This issue was originally filed by @butlermatt void main() {\n\u00a0\u00a0var parser = new ArgParser();\n\u00a0\u00a0\n\u00a0\u00a0parser.addOption('test', help: 'A short help line. Only one line');\n\u00a0\u00a0parser.addOption('test2', help: 'Another short help line. Still one.\\n\\n');\n\u00a0\u00a0parser.addOption('works', help: 'This is multiline help\\nNext should work');\n\u00a0\u00a0parser.addOption('fails', help: 'Theres a proper space before this');\n\u00a0\u00a0\n\u00a0\u00a0print(parser.getUsage());\n} If you notice when running the above code, any single line comments only have one new line after them in the usage. Even when I manually specify two. However once I have a multi-line help content it provides two new lines after the option in the string. Personally I would like to see all help followed by two new lines to prevent clumping of commands when there is a one-line help vs multi-line. ", "code": [], "labels": ["Type-Defect", "area-pkg"]}
{"project": "Semantic-Org_Semantic-UI", "title": "\"$().dropdown('set selected', value)\" no effect after update \u201cselect option\u201d\u2019", "description": "In my project, need update 'select option' and select one option.\nWhy the update is no longer work later.\nJSFiddle example: <URL> ", "code": [], "labels": ["Usage Question"]}
{"project": "nwjs_nw.js", "title": "Losing the NW object on window.location", "description": "I was unsing the 0.12.3 version, and it was working until i needed native pdf viewer, so i decided to use the new version instead of using PDF js, but for some reason, i get the following error: <CODE> It was because i have an index.html with a js, that loads some things that i need, and then, i redirect to the login page, after i redirect, that's where i have the error. Then i decided to put the js in the login page, and in the console i can open the nw object, but if i made a window.location to another file, the nw object is not defined. Any ideas? ", "code": ["require is note defined\n"], "labels": ["needinfo"]}
{"project": "angular_angular", "title": "Not able to open menu in iPad device", "description": "<CODE> Trying to open menu by using sandwich icon but not able to open it. Nothing happened while clicking on menu icon. Menu should open. <CODE> ", "code": ["\n[ ] Regression (a behavior that used to work and stopped working in a new release)\n[ ] Bug report  \n[ ] Feature request\n[x] Documentation issue or request\n[ ] Support request => Please do not submit support request here, instead see https://github.com/angular/angular/blob/master/CONTRIBUTING.md#question\n", "\nAngular version: X.Y.Z\n\n\nBrowser:\n- [ ] Chrome (desktop) version XX\n- [ ] Chrome (Android) version XX\n- [ ] Chrome (iOS) version XX\n- [ ] Firefox version XX\n- [ ] Safari (desktop) version XX\n- [ ] Safari (iOS) version XX\n- [ ] IE version XX\n- [ ] Edge version XX\n \nFor Tooling issues:\n- Node version: XX  \n- Platform:  \n\nOthers:\n\n"], "labels": ["comp: docs-infra"]}
{"project": "roundcube_roundcubemail", "title": "Automatic new message check shouldn't display feedback", "description": "Reported by ksteinhoff on 15 Aug 2008 20:27 UTC as Trac ticket #1485276 When checking for new messages RoundCube displays a loading message. This feedback is useful when the user has click the \"Check for new message\" button, but it is also displayed when RoundCube automatically checks for new mail. RoundCube should only display the message when the user has manually initiated a check. Migrated-From: <URL> ", "code": [], "labels": ["enhancement", "C: User Interface"]}
{"project": "IdentityServer_IdentityServer4", "title": "Single sign out with hybrid flow", "description": "I'm trying to implement single sign out with hybrid flow, however can't figure out how to use sid which is passed via frontchannellogouturl I have 2 Clients(Client A and Client B) with single sign on in my Identity Server.\nIn login callback i got id_token, code, reference_token, and session_state.\nNow i want to logout Client B when ClientA is logged out.\nI configured frontchannellogouturl for both clients and IdentityServer via iframe calls the configured urls.\nHowever it passes session id which i can't connect with reference_token or id_token and identify the user to logout.\nWhat is the correct way to approach single sign out ? ", "code": [], "labels": ["question"]}
{"project": "sindresorhus_refined-github", "title": "Username in comment thread messed up possibly because of accented character", "description": "The thread in question: w3c/webdriver#385 (comment) How it looks like without refined-github:\n How it looks like with refined-github\n This seems to have occurred because the username had an accented character (\u00e4) ", "code": [], "labels": ["good first issue", "help wanted", "bug"]}
{"project": "doctrine_orm", "title": "DDC-767: Updating many-to-many relations", "description": "Jira issue originally created by user ambis: I have an entity with a many-to-many relation. When I delete all relations and then flush, add new relations and then flush, all inside one transaction, I get Fatal error: Call to a member function update() on a non-object in Doctrine/ORM/UnitOfWork.php on line 312 <CODE> <CODE> <CODE> <CODE> If this is not a bug, I'd like to know which is the most efficient and elegant way to update many-to-many relationships. ", "code": ["        // Delete old categories\n        foreach ($revision->getCategories() as $category) {\n            $revision->removeCategory($category);\n        }\n\n        $this->entityManager->flush();\n\n        // Add new\n        foreach ($categories as $categoryId) {\n            $category = $this->entityManager->find('Category', $categoryId);\n\n            if ($category instanceof Category) {\n                $revision->addCategory($category);\n            }\n        }\n\n        $this->entityManager->flush();\n", "    /****\n     * @return ArrayCollection\n     */\n    public function getCategories()\n    {\n        return $this->categories;\n    }\n", "    /****\n     * @param Category $category\n     * @return Revision\n     */\n    public function addCategory(Category $category)\n    {\n        $this->categories->add($category);\n        return $this;\n    }\n", "    /****\n     * @param Category $category\n     * @return Revision\n     */\n    public function removeCategory(Category $category)\n    {\n        $this->categories->removeElement($category);\n        return $this;\n    }\n"], "labels": ["Bug"]}
{"project": "magento_magento2", "title": "Newsletter issue on Magento 2.2.3", "description": "Tested on Magento 2.2.3\nThe issue is, can't disable or enable newsletter popup on magento home page.\nIn admin panel,\nGo to Codazon->fastest Options->General options->Theme options->Newsletter Pop-up I have enabled newsletter option and gave corresponding static block ID too. but the worst thing is newsletter pop-up close icon alone displaying instead of the form information.\nWhat should i do to load newsletter information fully.. Kindly, let me know the possible option to enable newsletter form on Home page.\nThanks in advance. ", "code": [], "labels": ["Issue: Format is not valid"]}
{"project": "swagger-api_swagger-core", "title": "Superclass annotation for method prevails in swagger", "description": "I have the below code. The method getDetails is over-ridden in Class B and thus is not available as a web-service. But Swagger still documents it as a valid service. Any idea why does this happen and how to avoid this behavior in Class B? Note: I cannot hide the operation in class A as this would be needed by other sub-classes. Class A{ @path(\"/details\")\nString getDetails(){....}\n} @path(\"/path1\")\nClass B extends A{ @override\nString getDetails(){....}\n} ", "code": [], "labels": ["Bug"]}
{"project": "godotengine_godot", "title": "Parity between iOS and Android 9dof sensors", "description": "I'm hoping someone who has got both an Android phone and Apple phone can diagnose this further then I can at this moment. Now that we have accelerometer, gyroscope and magnetometer data working on both iOS and Android in both Godot 2.1 and 3.0 it looks like the coordinate systems do not line up and the devices have a different idea of what \"down\" is. If there is someone who has both devices it would be good if they could put the devices side by side and compare the output of these sensors in different orientations of the device.\nThis project outputs raw data to screen (amongst others) and could be used to test this:\n<URL> If I get my hands on a suitable android phone I will certainly do this myself.\nNote that PR #8100 contains a small fix to make the magnetometer give output for iOS. ", "code": [], "labels": ["usability", "enhancement", "platform:ios", "platform:android"]}
{"project": "kubernetes_kubernetes", "title": "Retries for kubelet plugin registration should be at a lower layer", "description": "What would you like to be added:\nThe kubelet registration mechanism should be more robust (e.g. have a full controller that maintains desired/actual and reconciles that state periodically). The CSI layer is not right layer to implement retries. Retries should not be implemented by every consumer. Why is this needed: For a more robust kubelet registration mechanism Related issue: #71487 /cc @saad-ali\n/sig storage\n/assign ", "code": [], "labels": ["sig/storage", "sig/node", "kind/feature"]}
{"project": "doctrine_orm", "title": "DDC-483: DiscriminatorMap misbehaves when key are Integer", "description": "Jira issue originally created by user ulf.thomas: When in a Class-Inheritance Scenario @DiscriminatorMap is set like \"@DiscriminatorMap({2=\"Class1\", 4=\"Class2\"})\" (DiscriminatorColumn is of type Integer) then EntityManager->find('Class2', 'key)->will return an object of type Class1. I hunted down the bug to Doctrine/Common/Annotations/Parser.php (Line: 412): if (is_string($key)) {\n$array[$key] = $value[$key];\n} else {\n$array[] = $value[$key];\n} should be: if (is_string($key) || is_int($key)) {\n$array[$key] = $value[$key];\n} else {\n$array[] = $value[$key];\n} ", "code": [], "labels": ["Bug"]}
{"project": "microsoft_vscode-cpptools", "title": "step over work unexpectedly.", "description": "Type: Debugger\nInput information below Please review existing issues and our documentation at <URL> prior to filing an issue. Describe the bug To Reproduce\nPlease include a code sample and launch.json configuration.\nSteps to reproduce the behavior: <CODE> <CODE> <CODE> \n Additional context\nIf applicable, please include logging by adding \"logging\": { \"engineLogging\": true, \"trace\": true, \"traceResponse\": true } in your launch.json\nAdd any other context about the problem here including log or error messages in your Debug Console or Output windows. ", "code": ["{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"(gdb) Launch\",\n            \"preLaunchTask\": \"build\",\n            \"type\": \"cppdbg\",\n            \"request\": \"launch\",\n            \"program\": \"${fileDirname}/${fileBasenameNoExtension}.exe\",\n            \"args\": [],\n            \"stopAtEntry\": false,\n            \"cwd\": \"${workspaceFolder}\",\n            \"environment\": [],\n            \"externalConsole\": true,\n            \"MIMode\": \"gdb\",\n            \"logging\": { \"engineLogging\": true, \"trace\": true, \"traceResponse\": true },\n            \"miDebuggerPath\": \"D:/Program Files/TDM-GCC-64/bin/gdb64.exe\", \n            \"setupCommands\": [\n                {\n                    \"description\": \"Enable pretty-printing for gdb\",\n                    \"text\": \"-enable-pretty-printing\",\n                    \"ignoreFailures\": true\n                }\n            ]\n        }]\n}\n", "{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"build\",\n            \"type\": \"shell\",\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            },\n            \"presentation\": {\n                \"echo\": true,\n                \"reveal\": \"always\",\n                \"focus\": false,\n                \"panel\": \"shared\"\n            },\n            \"windows\": {\n                \"command\": \"g++\",\n                \"args\": [\n                    \"-ggdb\",\n                    \"\\\"${file}\\\"\",\n                    \"--std=c++11\",\n                    \"-o\",\n                    \"\\\"${fileDirname}\\\\${fileBasenameNoExtension}.exe\\\"\"\n                ]\n            }\n        }\n    ]\n}\n", "Using built-in specs.\nCOLLECT_GCC=gcc\nCOLLECT_LTO_WRAPPER=D:/Program\\ Files/TDM-GCC-64/bin/../libexec/gcc/x86_64-w64-mingw32/5.1.0/lto-wrapper.exe\nTarget: x86_64-w64-mingw32\nConfigured with: ../../../src/gcc-5.1.0/configure --build=x86_64-w64-mingw32 --enable-targets=all --enable-languages=ada,c,c++,fortran,lto,objc,obj-c++ --enable-libgomp --enable-lto --enable-graphite --enable-cxx-flags=-DWINPTHREAD_STATIC --disable-build-with-cxx --disable-build-poststage1-with-cxx --enable-libstdcxx-debug --enable-threads=posix --enable-version-specific-runtime-libs --enable-fully-dynamic-string --enable-libstdcxx-threads --enable-libstdcxx-time --with-gnu-ld --disable-werror --disable-nls --disable-win32-registry --prefix=/mingw64tdm --with-local-prefix=/mingw64tdm --with-pkgversion=tdm64-1 --with-bugurl=http://tdm-gcc.tdragon.net/bugs\nThread model: posix\ngcc version 5.1.0 (tdm64-1)\n"], "labels": ["debugger", "external"]}
{"project": "hashicorp_terraform", "title": "proposal: don't run state migration by default during init", "description": "The init command will currently always attempt to migrate the saved state when it detects a change in the backend config. This was originally put into place to aid users when changing converting from the legacy remote state system, as well as for new users moving from local state to remote state. Here we propose to change the default to not prompt for migration, removing the -reconfigure flag and adding something akin to -migrate-state. The default migration presents problems for many users. Terraform must have access to resources defined in the previous backend configuration, but the backend may be reconfigured because those resources no longer exist, are incorrect, or because Terraform no longer has access to them. Also there may be other values in the backend config or credentials that are changing (parameterized, or otherwise), but the remote state is staying in place, and migration is not technically required. We try to avoid the latter in most cases, but for various reasons the user may still be prompted to migrate the state even when it's not intended. This confusion is brought up in numerous issues like #18007, #17980, #17382, #16177, #13589, #17975, and #17803 just to name a few. Since init is a required part of the workflow, the majority of time that init is executed, migration is not expected. In the cases where it is desired, the user should already be aware of the change because there was a change in the configuration. This would also match the behavior of running terraform in a clean environment every time, as it usually is in automation. The only place where migration is \"protecting\" users to any degree, is when there is an unintended change to the backend. If the unintended change happened before plan or apply, then the user would be notified of a change to the backend config and can take appropriate action. If the unintended change were because of a difference in environment causing a parameterized backend config change during init, then the user may be faced with an incorrect or missing remote state. Only this last point could be a problem, but in general it's not a safety issue, because plan no longer writes to the state, so any mismatch between the expected state and config would be displayed with no changes made. ", "code": [], "labels": ["cli", "enhancement"]}
{"project": "ytdl-org_youtube-dl", "title": "[Minor] Formatting bug of manpage", "description": "Hi. Debian maintainer here. I'm just forwarding the bug that I received at: <URL> Thanks, Rog\u00e9rio. ", "code": [], "labels": ["cant-reproduce"]}
{"project": "PapirusDevelopmentTeam_papirus-icon-theme", "title": "[Question] How to modify folder color? (Color that is not given with default Papirus)", "description": "I can change folder color with the color folder script. However, I would like to have pink color. The closest thing was magenta, but still not to my liking.\nI have found that I can change color by modifying folder color directly and use  tools/work to copy the modification.\nHowever, I would like to know if there are easier way to do it? Like simply giving the color code and then run some script. Annnnddd BAM!. All folder color change. ", "code": [], "labels": ["completed", "enhancement"]}
{"project": "vuetifyjs_vuetify", "title": "Button (router link) in bottom nav doesn't get the active class", "description": "Open the codepen - dashboard button on the top of the page is active, corresponding button in bottom nav is not\nClick the home button (any of them) - now home button is active both at the top of the page and in the buttom nav 0.15.7 When opening the page both dashboard buttons should be active Dashboard button in bottom nav is not active. <URL> ", "code": [], "labels": ["T: bug"]}
{"project": "betaflight_betaflight", "title": "Documentation for INFLIGHT_ACC_CAL", "description": "Hi,\nThis is more of a documentation issue i'd like to raise (and potentially rectify). I can't seem to find any documentation for this feature. Does any documentation exist? I've had a look in the code, specifically sensors/acceleration.c at the method performInflightAccelerationCalibration() and i'm not really sure what's going on. Can someone either point me in the direction of the documentation or give me abit of info so I can document it?\nMany thanks\nLee ", "code": [], "labels": ["Inactive"]}
{"project": "matomo-org_matomo", "title": "Restricting token_auth access", "description": "Issue Background is here: <URL>,129194,129409 I assume that the reason currently, for giving token_auth access to anything beyond viewing the dashboard/widgets instead of using only regular session management for that is, e.g., bulk tracking, which requires token_auth of an administrator/super-user. The currently unlimited access with a token_auth has a security impact, as token_auth can be compromised even with HTTPS. E.g., HTTPS, generally, has many known attack scenarios. (Requiring continuous vigilance on server side of the latest known issues, both cryptographic (e.g. TLS version used and cypher suite choices) and bugs in the library used. And implementation of the latest and greatest HTTPS extensions (e.g. HSTS and HPKP). And similar on the client side.) The issue is made worse by the fact that token_auth, unlike a password, is continuously exchanged between the browser and the server. Neither does it expire like a session. Solutions Discussion There could be following solutions: A) A \"bolt-on\" solution, not ideal: If the token_auth mechanism is absolutely necessary to the extent it is currently used, following could be done to limit the damage in case of a token_auth compromise: That could be done, e.g., via a JS overlay to enter the password. But, for CSRF protection, it should clearly state what the password is being required for. Requiring password confirmation on significant changes seems to be widely used (in case the user is temporarily away from the PC, to prevent changes by others, and against session hijacks). And it seems to be crucial (and that on far less important changes) with the use of such an unlimited access token as token_auth, which allows for a complete bypass of application session management. B) Ideally, an authentication token should not be allowed unlimited access.\nExample: Tokens for external tools (e.g. Git) on Github. That token, once generated, is a secret that is never sent to the client (including browser). And is not needed for website functionality, which is covered by regular session management. If a token gets lost, a new one can be generated, including a choice what can be done with it. In Piwik, such a token could be generated (with a random value) if, e.g., bulk tracking is used. With the token limited to that. Or if widget inclusion into other websites is needed - again with access limited to that only and a specific site. So, there could be an unlimited number of token_auth, all generated for a specific purpose when needed, like on Github. One can even imagine different token_auth with exact same access, just to share them with different recipients, and later be able to revoke the access of one recipient without affecting others. Note: On inclusion of Piwik widgets/dashboard into other websites, different tokens could be used for different access levels. I.e. it could be defined which widgets on which site can be viewed with a specific token. (Kind of like in #5703, but possibly without a need for a different token name - it could still be the token_auth.) In which case the \"anonymous\" user would not need to be activated. The \"anonymous\" user would be there only for an unauthenticated dashboard view access without a token, if needed - like on <URL> Additional Resources #4171\n#6348\n#7202\n#1568\n#5728 (comment)\n#5703\n#1419 Disclaimer: I'm not a professional in any field this issue report touches, including web development. So, feel free to take it apart. Also, this could be an old and worn-out topic. I'm sorry if it is. ", "code": [], "labels": ["answered", "duplicate"]}
{"project": "OrchardCMS_Orchard", "title": "Fail to access gallery themes [5409 (4743bb7dc463)]", "description": "Yinhaixia created:\n<URL> Access \"~/Packaging/Gallery/Themes\",the site crashed as follows: Server Error in '/' Application.\nParser Error\nDescription: An error occurred during the parsing of a resource required to service this request. Please review the following specific parse error details and modify your source file appropriately. Parser Error Message: Encountered end tag \"li\" with no matching start tag.  Are your start/end tags properly balanced? Source Error: Line 99:                     \nLine 100:                \nLine 101:            }\nLine 102:        \nLine 103:    } else { Source File: /Modules/Orchard.Packaging/Views/Gallery/Themes.cshtml    Line: 101 ", "code": [], "labels": ["high"]}
{"project": "OpenRA_OpenRA", "title": "Cloak effects lacks visual transition", "description": "In the original games, ", "code": [], "labels": ["Polish"]}
{"project": "brave_browser-laptop", "title": "tab opens and never finishes loading on payments saveRecoveryFile", "description": "tab opens and never finishes loading on payments saveRecoveryFile. Its URL is chrome-extension://mnojpmjdmbbfmejpflffifhffcmidifd/about-blank.html and it contains: Actual result: New tab with infinite progress spinner is irritating and brave consumes a lot of CPU resources. Expected result: No tab unless it contains info and finishes loading Reproduces how often: 100% <CODE> ", "code": ["Brave: 0.19.105 \nrev: 51f8ba56ca1c1409ddd0620b12650bb7f81c2f79 \nMuon: 4.5.16 \nlibchromiumcontent: 62.0.3202.94 \nV8: 6.2.414.42 \nNode.js: 7.9.0 \nUpdate Channel: Release \nOS Platform: Linux \nOS Release: 4.4.0-102-generic \nOS Architecture: x64\n"], "labels": ["priority/P3", "feature/rewards", "duplicate"]}
{"project": "Alamofire_Alamofire", "title": "Normalize Response Types", "description": "While separate response types may be useful for separating API, the Default* versions of these responses are quite awkward. We should reevaluate these APIs and try to normalize down to a simple inheritance tree. ", "code": [], "labels": ["enhancement"]}
{"project": "flynn_flynn", "title": "docker login failure with private docker registry", "description": "Hi, I am unable to deploy with docker to my private docker registry. Is this currently supported? Here are the commands I run. Is there a way to pass in the username and password when I login? Thanks for all the help flyn v20161017.1\nDocker version 1.12.1, build 6f9534c <CODE> ", "code": ["$ flynn docker set-push-url dockerhub.myprivatereg.com\n$ flynn docker login\n\nerror running `docker login`: exit status 1 - output: {\"Flag --email has been deprecated, will be removed in 1.13.\nError response from daemon: Get https://dockerhub.myprivatereg.com/v2/: unauthorized: incorrect username or password\\n\" '\\x00' \"\\x00\\x00\\x00\\x00\" \n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0\n0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0\n0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" '\\x00'}\n"], "labels": ["kind/question"]}
{"project": "appium_appium", "title": "Unable to launch WebDriverAgent because of xcodebuild failure: \"Carthage binary is not found.", "description": "This issue is always happening when I try to start desktop Appium server with iOS capabilities. The app is getting installed properly but once it has to be started, the above-mentioned error message appears. Whenever I try to run Appium with android capabilities everything is working as expected, but every time I try to run Appium with iOS capabilities I am getting above mentioned error message. <URL> {\n\"platformName\": \"iOS\",\n\"deviceName\": \"iPhone X\",\n\"app\": \"path/to/my/App.app\",\n\"platformVersion\": \"11.2\",\n\"automationName\": \"XCUITest\",\n\"xcodeOrgId\": \"myXcodeOrgId\",\n\"bundleId\": \"bundleIdOfMyApp\"\n} ", "code": [], "labels": ["NeedsInfo", "NotABug"]}
{"project": "rubocop-hq_rubocop", "title": "rubocop's rubocop config is missing a cop", "description": "My PR #3365 was checked by the cop, but there seems to be missing a config for\nmethods that require a newline above/below. ie. <CODE> ", "code": ["HTTP_METHODS = [:get, :post, :put, :patch, :delete, :head].freeze\ndef on_send(node)\n   do something\nend\n\n"], "labels": ["feature request"]}
{"project": "deis_deis", "title": "Run Deis Etcd cluster inside of K8S", "description": "Instead of using the K8S etcd instance to store Deis data (a workflow frowned upon in k8s), we will instead use a 3+ node etcd cluster running inside of k8s, and namespaced to Deis. ", "code": [], "labels": ["v2"]}
{"project": "Sylius_Sylius", "title": "Deleting taxon with children deletes also taxons that aren't children of the deleted one", "description": "It is not wise to have an entity that uses Softdeleteable and Tree at the one time, the whole tree structure gets messed up. This happens when we try to remove taxonomy \"Category\" (with its root taxon). <CODE> ", "code": ["PRE DELETE\n\nmysql> select * from sylius_taxon;\n+-----+-------------+-----------+------+-----------+------------+------------+------------+------+\n| id  | taxonomy_id | parent_id | code | tree_left | tree_right | tree_level | deleted_at | path |\n+-----+-------------+-----------+------+-----------+------------+------------+------------+------+\n| 211 |          43 |      NULL | RTX1 |         1 |         18 |          0 | NULL       | NULL | <-- Category\n| 212 |          44 |      NULL | RTX2 |        19 |         20 |          0 | NULL       | NULL | <-- Brand\n| 213 |          43 |       211 | TX1  |         2 |         11 |          1 | NULL       | NULL |\n| 214 |          43 |       213 | TX3  |         3 |          4 |          2 | NULL       | NULL |\n| 215 |          43 |       213 | TX4  |         5 |         10 |          2 | NULL       | NULL |\n| 216 |          43 |       215 | TX5  |         6 |          7 |          3 | NULL       | NULL |\n| 217 |          43 |       215 | TX6  |         8 |          9 |          3 | NULL       | NULL |\n| 218 |          43 |       211 | TX2  |        12 |         17 |          1 | NULL       | NULL |\n| 219 |          43 |       218 | TX7  |        13 |         14 |          2 | NULL       | NULL |\n| 220 |          43 |       218 | TX8  |        15 |         16 |          2 | NULL       | NULL |\n+-----+-------------+-----------+------+-----------+------------+------------+------------+------+\n10 rows in set (0.00 sec)\n\nDELETE\n\nmysql> select * from sylius_taxon;\n+-----+-------------+-----------+------+-----------+------------+------------+------------+------+\n| id  | taxonomy_id | parent_id | code | tree_left | tree_right | tree_level | deleted_at | path |\n+-----+-------------+-----------+------+-----------+------------+------------+------------+------+\n| 211 |          43 |      NULL | RTX1 |         1 |          6 |          0 | NULL       | NULL | <-- Category\n| 212 |          44 |      NULL | RTX2 |         7 |          8 |          0 | NULL       | NULL | <-- Brand\n| 213 |          43 |       211 | TX1  |         2 |          7 |          1 | NULL       | NULL |\n| 214 |          43 |       213 | TX3  |         3 |          4 |          2 | NULL       | NULL |\n| 215 |          43 |       213 | TX4  |         3 |          6 |          2 | NULL       | NULL |\n| 216 |          43 |       215 | TX5  |         4 |          5 |          3 | NULL       | NULL |\n| 217 |          43 |       215 | TX6  |         6 |          7 |          3 | NULL       | NULL |\n| 218 |          43 |       211 | TX2  |         8 |          5 |          1 | NULL       | NULL |\n| 219 |          43 |       218 | TX7  |         9 |          8 |          2 | NULL       | NULL |\n| 220 |          43 |       218 | TX8  |         9 |         10 |          2 | NULL       | NULL |\n+-----+-------------+-----------+------+-----------+------------+------------+------------+------+\n10 rows in set (0.00 sec)\n\nQuery that gets children elements to be deleted:\n\nSELECT node FROM Sylius\\Component\\Core\\Model\\Taxon node WHERE node.left BETWEEN ?1 AND ?2\n\nSELECT s0_.code AS code0, s0_.tree_left AS tree_left1, s0_.tree_right AS tree_right2, s0_.tree_level AS tree_level3, s0_.deleted_at AS deleted_at4, s0_.id AS id5, s0_.path AS path6, s0_.taxonomy_id AS taxonomy_id7, s0_.parent_id AS parent_id8 FROM sylius_taxon s0_ WHERE (s0_.tree_left BETWEEN ? AND ?) AND (s0_.deleted_at IS NULL)\n\n?1 = 2\n?2 = 11\n\nPOST DELETE\n\nmysql> select * from sylius_taxon;\n+-----+-------------+-----------+------+-----------+------------+------------+---------------------+------+\n| id  | taxonomy_id | parent_id | code | tree_left | tree_right | tree_level | deleted_at          | path |\n+-----+-------------+-----------+------+-----------+------------+------------+---------------------+------+\n| 211 |        NULL |      NULL | RTX1 |         1 |          6 |          0 | 2016-01-12 14:59:17 | NULL | <-- Category\n| 212 |          44 |      NULL | RTX2 |         7 |          8 |          0 | 2016-01-12 14:59:17 | NULL | <-- Brand\n| 213 |        NULL |       211 | TX1  |         2 |          7 |          1 | 2016-01-12 14:59:17 | NULL |\n| 214 |        NULL |       213 | TX3  |         3 |          4 |          2 | 2016-01-12 14:59:17 | NULL |\n| 215 |        NULL |       213 | TX4  |         3 |          6 |          2 | 2016-01-12 14:59:17 | NULL |\n| 216 |        NULL |       215 | TX5  |         4 |          5 |          3 | 2016-01-12 14:59:17 | NULL |\n| 217 |        NULL |       215 | TX6  |         6 |          7 |          3 | 2016-01-12 14:59:18 | NULL |\n| 218 |        NULL |       211 | TX2  |         8 |          5 |          1 | 2016-01-12 14:59:18 | NULL |\n| 219 |        NULL |       218 | TX7  |         9 |          8 |          2 | 2016-01-12 14:59:18 | NULL |\n| 220 |        NULL |       218 | TX8  |         9 |         10 |          2 | 2016-01-12 14:59:18 | NULL |\n+-----+-------------+-----------+------+-----------+------------+------------+---------------------+------+\n10 rows in set (0.00 sec)\n"], "labels": ["Bug"]}
{"project": "mui-org_material-ui", "title": "Internet Explorer 11 (IE 11) and MS Edge - Text input shows large reset x", "description": "If there is already an issue concerning this topic, feel free to close. When inserting text into the text input component, the IE11 and Edge show a (very large) reset X. Other browsers don't show the x. The size of the x is also not appropriate to the rest of the text(input). It just looks weird.   <URL> ", "code": [], "labels": ["duplicate"]}
{"project": "facebook_react-native", "title": "toLocaleString is only working on ios not android.", "description": "toLocaleString is only working on ios and not android. When will this be supported? ", "code": [], "labels": ["Resolution: Locked"]}
{"project": "endless-sky_endless-sky", "title": "Bug: Malformed data causes really weird behavior", "description": "While playing around with different outfit parameters, I accidentally wrote \"shield generation\": 100 instead of \"shield generation\" 100, and that colon somehow caused hostile ships to stop acting entirely. For example, I demanded tribute from a planet, and the planet released its defense fleet, but the ships were all yellow on my radar and all simply drifted outward from the planet - they didn't move, fire, or even turn. Other hostile ships entering the system did the same thing - they hyperjumped in, and then simply drifted across the system and away into the void. Side note: it might be nice if the data parser complained when it found data it didn't know how to parse, instead of silently failing. ", "code": [], "labels": ["bug"]}
{"project": "mapbox_mapbox-gl-js", "title": "Configurable tile cache size", "description": "Recently a tilecache has been added to Mapbox GL JS using Cache API (#8363) The size seems to be set at 50MB, but a larger cache would improve performance on machines with more storage available.\n Can this be piped through to a property in mapboxgl.Map like:\nnew mapboxgl.Map({ cacheSize: 10010241024 }) ? ", "code": [], "labels": ["feature "]}
{"project": "PowerShell_PowerShell", "title": "Raspbian ARM64 is missing on README", "description": "On README.md, I don't find a link to download \"powershell-6.2.0-linux-arm64.tar.gz\" ( Raspbian (Stretch) Experimental ) ", "code": [], "labels": ["Resolution-Fixed", "Issue-Question"]}
{"project": "spring-projects_spring-boot", "title": "`/actuator/health` returns 404 if no indicator is present", "description": "An application with no custom HealthIndicator and management.health.defaults.enabled=false will return a 404. It used to be a 200 in 2.1.x: <CODE> ", "code": ["HTTP/1.1 200\nContent-Type: application/vnd.spring-boot.actuator.v2+json;charset=UTF-8\nDate: Sat, 02 Nov 2019 07:06:31 GMT\nTransfer-Encoding: chunked\n\n{\n    \"details\": {\n        \"application\": {\n            \"status\": \"UP\"\n        }\n    },\n    \"status\": \"UP\"\n}\n"], "labels": ["type: regression", "status: duplicate"]}
{"project": "Automattic_wp-calypso", "title": "Editor: Gutenberg image size dropdown is not functioning", "description": "Changing the size of the image via the \u201cImage Size\u201d dropdown does nothing. <URL> Can we confirm if this is a Gutenberg regression or something specific to WordPress.com? ", "code": [], "labels": ["[Type] Bug", "Editor", "[Pri] High"]}
{"project": "readthedocs_readthedocs.org", "title": "Missing i18n for footer and warning banner", "description": "The text displayed on the warning banner (when using an old version of the documentation) right now is hard coded on the js code. <URL> Also the footer response from the API <URL> Related comment #3547 (comment) Warning message and footer are translated according to the current language of the docs. The warning message and footer always display English text. ", "code": [], "labels": ["Improvement", "Good First Issue", "Accepted"]}
{"project": "jessesquires_JSQMessagesViewController", "title": "Tapping InputToolbar causes Keyboard to resign", "description": "@jessesquires I couldnt find a related issue despite all the keyboard/toolbar issues. My problem is that while fast typing, you are hitting all over the inputToolBar and many times this causes it to resign the keyboard. I noticed the sample app doesnt have this behaviour so is there maybe a way to turn it off? ", "code": [], "labels": ["questions & help"]}
{"project": "joomla_joomla-cms", "title": "Tagged Items ugly Joomla Bug", "description": "Menu Title > Drop number Details\nMenu Item Type > Tagged Items\nTag > Drop number\nContent Type > Article Menu > Main menu\nParent Item > SMALL\nOrdering > Drop number /small/drop-number/brin-te /?view=article&id=54:brin-te&catid=12 Joomla 3.8.13\nPHP 7.1\nMySQL 5.7 How to fix this? ", "code": [], "labels": ["No Code Attached Yet", "J3 Issue"]}
{"project": "shadowsocks_shadowsocks-android", "title": "Android Q (10) \u65ad\u6d41", "description": "Please read contributing guidelines. Thanks. Describe the bug\n\u6b63\u5e38\u4f7f\u7528\u4e00\u6bb5\u65f6\u95f4\u540e\u65ad\u6d41\uff08\u6709\u53ef\u80fd\u662f\u51e0\u5206\u949f\uff0c\u4e5f\u53ef\u80fd\u662f\u51e0\u5341\u5206\u949f\uff09\uff0c\u4e00\u6bb5\u65f6\u95f4\u540e\u4f1a\u6062\u590d\u3002 To Reproduce\n\u6b63\u5e38\u4f7f\u7528\u4e00\u6bb5\u65f6\u95f4\u3002 Expected behavior\n\u4e0d\u65ad\u6d41\u3002 Screenshots\nIf applicable, add screenshots to help explain your problem. Smartphone (please complete the following information): Configuration\nPut an x inside the [ ] that applies. Additional context\nAdd any other context about the problem here. ", "code": [], "labels": ["cannot reproduce"]}
{"project": "vector-im_riot-web", "title": "Concept of 'urgent' messages, intended to break through 'night mode' DND", "description": "Created by @ matthew:matrix.org. ", "code": [], "labels": ["p3", "feature"]}
{"project": "tensorpack_tensorpack", "title": "DoReFa Net paper question", "description": "Hi, Thank you for your help. Now I got a question about the data type in dorefa net.\n\nIn this paragraph, you said Ro is a k-bit fixed point integer, however, I print out the value and from the print out result, I think it should be the floating point value. I could get something wrong here, could you help me to understand this? Best regards, Tong Wu ", "code": [], "labels": ["examples"]}
{"project": "dart-lang_sdk", "title": "Pub Update/Install does not work on XP-SP3", "description": "This issue was originally filed by arete.wor...@gmail.com What steps will reproduce the problem? What is the expected output? What do you see instead? Should run in a browser window. It fails. After trying the documented workaround for Pub, pub install seems to be install the unittest and vector_math packages, but the vector_math package folder is empty. What version of the product are you using? On what operating system? Latest version (12/10/2012) on Windows XP-SP3. Please provide any additional information below. I've tried the documented workaround for Pub per links below. <URL>\n<URL> ", "code": [], "labels": ["Type-Defect", "closed-duplicate"]}
{"project": "travis-ci_travis-ci", "title": "Appium can't start Instruments when run in Travis", "description": "When running appium on travis, appium can't start Instruments. I'm getting this error: warn: Instruments socket client never checked in; timing out (global) (see log) I've tried using osx_image xcode6.4, beta xcode6.3, and the default, with iphonesimulator 8.4, 8.3, and 8.1. This seems identical to this issue within appium: appium/appium#3328, but I can only reproduce the issue in travis. Also, for one build, I attempted to use the globally installed appium (from #2348), but it was not there, instead I got a appium: command not found (see log). This might be a separate problem. Let me know if I should create a separate issue for it. ", "code": [], "labels": ["stale", "mac"]}
{"project": "TrinityCore_TrinityCore", "title": "[Bug/Visual]Ornolf the Scarred's Throw spell", "description": "Whenever i see Ornolf the Scarred use his \"Throw(38557)\" ability, the weapon that he throws appears as a white-blue cube. I've tested the same spell with Kvaldir Berserker whom use or should use the same spell according to wowhead and instead of a box he threw a big weapon. Ornolf the Scarred - <URL>\nKvaldir Berserker - <URL> Picture of Ornolf the Scarred throwing a cube - <URL> Core revision: Trinity Core 92d32ab+\nDatabase revision: TDB 335.11.43\nAddons: Anticheat1 ", "code": [], "labels": ["Comp-Core"]}
{"project": "Automattic_mongoose", "title": "Run getters through virtuals even on nested property get() queries", "description": "It seems that when doing a get on a model which involves indexing into nested objects, virtuals are not executed unless it's a direct match.  It'd be nice if sub-properties would be evaluated against result from the parent virtual. Further, providing the selector to the virtual would make for even more interesting behavior possibilities. Is this possible already and I missed something?  Terrible idea? ", "code": [], "labels": ["enhancement"]}
{"project": "dbeaver_dbeaver", "title": "DBeaver icon appears twice when running on ElementaryOS", "description": "When the app is running on elementary os, a second icon appears between open apps, not the icon used as launcher.  ", "code": [], "labels": ["can't reproduce", "bug"]}
{"project": "elementor_elementor", "title": "[Request] Include Alt tag value for each image insertion", "description": "Including Alt tags on every image of the site is considered one of the most basic SEO best practices. Another best practice is to reuse the same images whenever possible so that pages can use cached images for faster page load times. Although the \"alt\" value can be set in the Media Library, that is often not sufficient. While that is okay for setting a default value, the alt tag often needs to be unique for each instance of the image being used. The alt tag issue is especially significant because the site I am converting to Wordpress already has unique alt tags assigned and has Google rankings impacted by the values of those alt tags. Switching to Elementor will result in losing some of our unique alt tag values, which may have an adverse impact on search engine rankings, thereby reducing visibility, traffic, sales, market share, revenues, and profits. Alt tag reference: <URL> ", "code": [], "labels": ["request/feature", "request/enhancement"]}
{"project": "palantir_tslint", "title": "Using tags \"existence\" property in completed-docs rule causing TypeError for correct documentation containing other tags", "description": "I want to add rule to tslint that when I add tag @privateApi to comment documentation is not required. with tslint.json configuration: Causes TypeError: <CODE> This configuration works fine when I actually add `@privateApi' tag to comment, the following code works correctly no error or rule violation caused: Setting tslint.json configuration to following value: seems seems to fix the problem however I am forced to use unnecessary empty object or I am wrong and this is required? Such error should not be thrown since function is correctly documented ", "code": ["TypeError: Cannot read property 'returns' of undefined\n    at TagExclusion.excludes (C:\\test\\node_modules\\tslint\\lib\\rules\\completed-docs\\tagExclusion.js:42:47)\n    at CompletedDocsWalker.checkNode (C:\\test\\node_modules\\tslint\\lib\\rules\\completedDocsRule.js:295:27)\n    at CompletedDocsWalker.visitFunctionDeclaration (C:\\test\\node_modules\\tslint\\lib\\rules\\completedDocsRule.js:256:14)\n    at CompletedDocsWalker.SyntaxWalker.visitNode (C:\\test\\node_modules\\tslint\\lib\\language\\walker\\syntaxWalker.js:374:22)\n    at C:\\test\\node_modules\\tslint\\lib\\language\\walker\\syntaxWalker.js:535:63\n    at visitEachNode (C:\\test\\node_modules\\typescript\\lib\\typescript.js:15956:30)\n    at Object.forEachChild (C:\\test\\node_modules\\typescript\\lib\\typescript.js:16136:24)\n    at CompletedDocsWalker.SyntaxWalker.walkChildren (C:\\test\\node_modules\\tslint\\lib\\language\\walker\\syntaxWalker.js:535:12)\n    at CompletedDocsWalker.SyntaxWalker.visitSourceFile (C:\\test\\node_modules\\tslint\\lib\\language\\walker\\syntaxWalker.js:228:14)\n    at CompletedDocsWalker.SyntaxWalker.visitNode (C:\\test\\node_modules\\tslint\\lib\\language\\walker\\syntaxWalker.js:482:22)\n"], "labels": ["Status: Accepting PRs", "Type: Bug"]}
{"project": "syncthing_syncthing", "title": "\"Uncomplicated FireWall\" (UFW) Integration", "description": "It would be a nice to have an application preset for ufw in the etc folder of the releases (like for the startup scripts).\nThe file could look like this: So (after copying it to /etc/ufw/applications.d/) opening the needed ports is as simple as <CODE> The file could also be automatically added when installing with a package manager I guess. ", "code": ["sudo ufw allow syncthing\n"], "labels": ["help-wanted", "enhancement", "frozen-due-to-age"]}
{"project": "AntennaPod_AntennaPod", "title": "Loudness normalization (compressor/limiter)", "description": "Some podcasts have wildly varying audio levels. It can be quite unpleasant to listen to them via headphones -- either you don't understand what's being said, or your ears start to hurt. This is also a health risk. In technical terms, this is an issue of missing normalization during postproduction of the podcasts, or postproduction for a different target: Attentive listeners with a Hifi rack and speakers can appreciate voices talking softly and shouting alternately, while people with headphones, sitting on a train, jogging, or listening on car audio while driving can not. A basic audio effect can go a long way to fix this: We need a compressor, to push up the soft parts, and a limiter, to keep the loud parts within bounds. There are some quite sophisticated solutions for this, e.g. auphonic. A good introduction in their blog: <URL> For Android, this opensource app seems to offer a normalization feature:\n<URL> I have also found this free compressor which focuses on PD apps:\n<URL> and this one, which is only \"free as in beer\" for use in apps:\n<URL> ", "code": [], "labels": ["feature request"]}
{"project": "osquery_osquery", "title": "make sync is failing on CentOS 7", "description": "Trying to make sync causes cmake to fail compiler tests. <CODE> ", "code": ["osquery-centos-7] osquery $ make sync\n-- Welcome to osquery's build -- thank you for your patience! :)\n-- For a brief tutorial see: http://osquery.readthedocs.io/en/stable/development/building/\n-- If at first you dont succeed, perhaps: make distclean; make depsclean\n-- Building for platform CentOS (centos, centos7)\n-- Building osquery version  3.2.4 sdk 3.2.4\n-- Cannot find fpm executable in path\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/fmanco/osquery/build/centos7\n[ 25%] Built target osquery_extensions\n[ 75%] Built target osquery_amalgamation\n[100%] Generating sdk sync: /home/fmanco/osquery/build/centos7/sync\n-- The C compiler identification is Clang 5.0.1\n-- The CXX compiler identification is Clang 5.0.1\n-- Check for working C compiler: /usr/local/osquery/bin/clang\n-- Check for working C compiler: /usr/local/osquery/bin/clang -- broken\nCMake Error at /usr/local/osquery/Cellar/cmake/3.10.1_200/share/cmake/Modules/CMakeTestCCompiler.cmake:52 (message):\n  The C compiler\n\n    \"/usr/local/osquery/bin/clang\"\n\n  is not able to compile a simple test program.\n\n  It fails with the following output:\n\n    Change Dir: /home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeTmp\n\n    Run Build Command:\"/usr/bin/gmake\" \"cmTC_4e9e6/fast\"\n    gmake[5]: Entering directory `/home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeTmp'\n    /usr/bin/gmake -f CMakeFiles/cmTC_4e9e6.dir/build.make CMakeFiles/cmTC_4e9e6.dir/build\n    gmake[6]: Entering directory `/home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeTmp'\n    Building C object CMakeFiles/cmTC_4e9e6.dir/testCCompiler.c.o\n    /usr/local/osquery/bin/clang    -o CMakeFiles/cmTC_4e9e6.dir/testCCompiler.c.o   -c /home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeTmp/testCCompiler.c\n    Linking C executable cmTC_4e9e6\n    /usr/local/osquery/Cellar/cmake/3.10.1_200/bin/cmake -E cmake_link_script CMakeFiles/cmTC_4e9e6.dir/link.txt --verbose=1\n    /usr/local/osquery/bin/clang      -rdynamic CMakeFiles/cmTC_4e9e6.dir/testCCompiler.c.o  -o cmTC_4e9e6\n    /usr/bin/ld: /usr/local/osquery/opt/gcc/lib64/gcc/x86_64-unknown-linux-gnu/5.4.0/crtbegin.o: unrecognized relocation (0x2a) in section `.text'\n    /usr/bin/ld: final link failed: Bad value\n    clang-5.0: error: linker command failed with exit code 1 (use -v to see invocation)\n    gmake[6]: *** [cmTC_4e9e6] Error 1\n    gmake[6]: Leaving directory `/home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeTmp'\n    gmake[5]: *** [cmTC_4e9e6/fast] Error 2\n    gmake[5]: Leaving directory `/home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeTmp'\n\n\n\n\n  CMake will not be able to correctly generate this project.\nCall Stack (most recent call first):\n  CMakeLists.txt:394 (project)\n\n\n-- Configuring incomplete, errors occurred!\nSee also \"/home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeOutput.log\".\nSee also \"/home/fmanco/osquery/build/centos7/sync/code-analysis/CMakeFiles/CMakeError.log\".\nmake[4]: *** [CMakeFiles/sync] Error 1\nmake[3]: *** [CMakeFiles/sync.dir/all] Error 2\nmake[2]: *** [CMakeFiles/sync.dir/rule] Error 2\nmake[1]: *** [sync] Error 2\nmake: *** [sync] Error 2\n"], "labels": ["good-first-issue", "bug", "Linux"]}
{"project": "spyder-ide_spyder", "title": "Automatically show code completion widget", "description": "From abhinav....@gmail.com on 2014-07-30T02:35:01Z Spyder Version:  2.2.5\nPython Version:  2.7.8\nQt Version    :  4.8.6, PyQt4 (API v2) 4.11.1 on Linux\npyflakes >=0.5.0:  0.8.1 (OK)\npep8 >=0.6      :  1.5.7 (OK)\nIPython >=0.13  :  2.1.0 (OK)\nrope >=0.9.2    :  0.9.4 (OK)\nsphinx >=0.6.6  :  1.2.2 (OK)\nmatplotlib >=1.0:  1.3.1 (OK)\nsympy >=0.7.0   :  0.7.5 (OK)\npylint >=0.25   :  1.3.0 (OK) Hello,\nThis is not a bug but a feature request. I would like to see some autocompletion features similar to that of Kate and KDevelop, where pressing a default number of characters triggers off options to complete the word automatically. This is useful in projects where there are a lot of variables, and where having long variable names makes the code easier to read. Thanks,\nAbhinav Original issue: <URL> ", "code": [], "labels": ["type:Enhancement", "2\u20135 stars", "component:Editor"]}
{"project": "hazelcast_hazelcast", "title": "Entry still returned when querying on an Indexed field which is an Enum", "description": "If I add an Index to a Map which has an Enum type, and I delete an entry from the Map, then if I do a map.values(new SqlPredicate(\"myEnumField = ''ENUM_VALUES\")) it will still return the deleted item.\nI think the reason for this is that during adding the Index the Enum value will be converted to String, and during delete in com.hazelcast.query.impl.UnsortedIndexStore#removeIndex the oldValue parameter will be an Enum value, but com.hazelcast.query.impl.UnsortedIndexStore#mapRecords will store a String, so mapRecords.get(oldValue) won't work.\nHazelcast version: 3.2.3 ", "code": [], "labels": ["Team: Core", "Type: Defect"]}
{"project": "gcushen_hugo-academic", "title": "Improve section pager links", "description": "I noticed that when a publication page has links to both the prior and the next item, the two links come out with no margin between them. I think the layout would look nicer with a bit of space added, if both .PrevInSection and .NextInSection are present. Of course this isn't an important issue, but it might also be an easy enhancement. Thanks as always for your work on this theme. ", "code": [], "labels": ["enhancement"]}
{"project": "yihui_knitr", "title": "`format_sci`: `\\cdot` instead of `\\times`", "description": "The function format_sci_one in R/utils.R uses \\times as a sign for multiplication: <CODE> Is there a reason, why the \\times (\"\u00d7\")sign is preferred over the (as far as I know more commonly used) dot (\"\u00b7\", typeset by LaTeX's \\cdot macro)? If not, it would be great, if the call to sci_notation could be changed to <CODE> Maybe adding an option would be helpful, so that users could choose between these two different notations. ", "code": ["sci_notation('%s%s10^{%s}', b, '\\\\times ', lx)    # line 199\n", "sci_notation('%s%s10^{%s}', b, '\\\\cdot ', lx)    # line 199 changed\n"], "labels": ["Feature"]}
{"project": "ant-design_ant-design", "title": "create-react-app + antd\u65b0\u7684\u6d41\u7a0b\u6709\u6ca1\u6709\u95ee\u9898\uff1f", "description": "\u67e5\u4e86\u4e00\u4e0b\u4ee3\u7801\uff0c\u6309\u5b98\u7f51\u7684\u914d\u7f6e\uff0c\u6700\u7ec8\u662f\u6267\u884c\u7684react-scripts\u5305\u4e2d\u7684start.js\u7b49 \u7814\u7a76\u4e86\u4e0b\uff0c\u4f3c\u4e4e\u53ef\u4ee5\u6309\u5982\u4e0b\u6b65\u9aa4\u64cd\u4f5c\uff0c\u4e0d\u77e5\u9053\u6709\u6ca1\u6709\u4ec0\u4e48\u95ee\u9898\uff1f \u57fa\u4e8ecreate-react-app\u7684antd\u9879\u76ee\n1\u3001\u521b\u5efa\u9879\u76ee\ncreate-react-app demo\ncd demo\n2\u3001\u5c55\u5f00\u914d\u7f6e\nnpm run eject\n3\u3001\u5b89\u88c5\u4f9d\u8d56\ncnpm i  babel-plugin-import --save-dev\ncnpm i antd --save\ncnpm i 3\u3001\u6dfb\u52a0bable\u914d\u7f6e\n\u6839\u76ee\u5f55\u4e0b\u521b\u5efa.babelrc\u6587\u4ef6\uff0c\u5185\u5bb9\u4e3a\n{\n\"presets\": [\"react-app\"],\n\"plugins\": [\n[\"import\", { \"libraryName\": \"antd\", \"libraryDirectory\": \"es\", \"style\": \"css\" }]\n]\n} 4\u3001\uff08\u53ef\u9009\uff09\u6dfb\u52a0eslint\u914d\u7f6e\n\u6839\u76ee\u5f55\u521b\u5efa  .eslintrc \u6587\u4ef6\uff0c\u5185\u5bb9\u4e3a\n{\n\"extends\": \"react-app\",\n\"rules\": {\n\"no-console\":\"warn\"\n//\u81ea\u884c\u8bbe\u7f6eeslint\u89c4\u5219\n}\n} ", "code": [], "labels": ["Invalid"]}
{"project": "MarlinFirmware_Marlin", "title": "Babystepping not working", "description": "On current bugfix-1.1.x (last commit 5e0dffd) i'm having big issues with babystepping. No matter which way I rotate the dial, the Z axis moves in one direction. Sometimes it's up, sometimes it's down, but it's not related to how I rotate the encoder. It looks like it moves on the same direction UBL is compensating, but i'm not completely sure about that. The value in the LCD changes correctly based on how I move the encoder (up or down), so it's not an issue with the encoder. I have UBL compiled and active Tried both with BABYSTEP_ZPROBE_OFFSET enabled or disabled, same behavior. Expected behavior: [What you expect to happen]\nThe Z axis moves both up and down based on which way I turn the encoder Actual behavior: [What actually happens]\nThe Z axis moves the same direction regardless of which way I turn the encoder Configuration ZIP file ", "code": [], "labels": ["T: Question"]}
{"project": "mui-org_material-ui", "title": "[bug?] withStyles not working as a regular function in TypeScript.", "description": "Seems like this was supposed to be fixed back in #8178, but I'm on @material-ui/core 3.9.0 and typescript 3.1.6 and it isn't working. F.e. gives the error  <CODE> ", "code": ["error TS2345: Argument of type 'typeof LayerManager' is not assignable to parameter of type 'ComponentType<never>'.\n[1]   Type 'typeof LayerManager' is not assignable to type 'ComponentClass<never, any>'.\n[1]     Type 'LayerManager' is not assignable to type 'Component<never, any, any>'.\n[1]       Types of property 'props' are incompatible.\n[1]         Type 'Readonly<{ children?: ReactNode; }> & Readonly<ILayerManagerProperties>' is not assignable to type 'never'.\n"], "labels": ["incomplete", "typescript"]}
{"project": "matomo-org_matomo", "title": "Charts does not work", "description": "looking here <URL> you should probably see that the charts for visitors per day and visitors per hour are not working ", "code": [], "labels": ["T: Bug"]}
{"project": "SDWebImage_SDWebImage", "title": "Non-public API usage", "description": "Since the release of watchOS 6 beta, I am receiving an invalid binary message every time I upload my app with the following description: It appears that the official docs no longer reference iOS as a supported platform for WKInterfaceDevice. ", "code": [], "labels": ["stale"]}
{"project": "openseadragon_openseadragon", "title": "Openseadragon preview mode ?", "description": "Is there some kind of preview mode for the openseadragon? I need it to stop handling events, stop moving, stop anything just like a simple image in img tag ? The main goal is to block the current openseadragon event system so I can write and use my own event handlers ? ", "code": [], "labels": ["question"]}
{"project": "TrinityCore_TrinityCore", "title": "[3.3.5]Southsea Freebooter does not use ranged attack", "description": "Description:\nSouthsea Freebooter (Creature ID 7856) does not use ranged attack. Current behaviour: Tell us what happens\nThis creature does not attempt to attack at range; instead, if you attack it at range, the creature will stand still and will not attack back. It will only attack with a melee weapon if you get within melee range. Expected behaviour: Tell us what should happen instead\nThis creature is supposed to fire a musket at range and melee attack when a player gets within melee range. This issue was reported in May of 2011 but does not appear to have been fixed. See #1318. Though a PvP video, the following shows a Southsea Freebooter shooting the player with a musket at range at the 1:20 mark: <URL> Steps to reproduce the problem: Branch(es): 3.3.5 / 6.x (Select the branch(es) affected by this issue)\n3.3.5 TC hash/commit:\n8835607 TDB version:\n335.61 Operating system:\nUbuntu Server 16.04 64-bit ", "code": [], "labels": ["Branch-3.3.5a", "Comp-Database"]}
{"project": "timgrossmann_InstaPy", "title": "Getting 0 possible posts with tags like follow follow4follow etc..", "description": "Everything else is working fine...\n Any ideas ? Workarounds... ", "code": [], "labels": ["wontfix"]}
{"project": "google_shaka-player", "title": "Questions about segment fetch behaviour which may return 404", "description": "I've been asked by our content infrastructure team to provide some insight on Shaka's behaviour when fetching segments for a live stream. They tell me that they're seeing an unusual number of requests which return 404, under the following circumstances: At the moment I don't have a reproducible test case, or network logs showing the requests. As our investigation progresses I may be able to provide this. I'm hoping you can provide some insight into whether Shaka could or would make any of the above requests for segments. We're also following up with ExoPlayer, since the issue is seen with DASH content generally. Let me know if I can provide any more information. Thanks! ", "code": [], "labels": ["archived", "question"]}
{"project": "nodejs_node", "title": "\u6709\u4e2d\u56fd\u670b\u53cb\u5417\uff1f", "description": "\u6ed1\u7a3d ", "code": [], "labels": ["invalid"]}
{"project": "cloud-custodian_cloud-custodian", "title": "How to find buckets with no bucket policy", "description": "Hi, I am still getting my head around how to write Cloud Custodian policies. Could someone please help me write the policy for filtering all S3 buckets which have no (or an empty) bucket policy? I don't need any actions run, as I can report the filtered buckets using the 'report' subcommand. All I need is to capture buckets with an inexistent policy. I have a feeling I can use the 'missing-policy-statement' filter... Also, is it possible to find S3 buckets with policies which provide access to the bucket from any source on the Internet? I.e. policies which give public-read/write to the bucket? Thank you in advance! ", "code": [], "labels": ["kind/question"]}
{"project": "dotnet_roslyn", "title": "SemanticModel.Compilation.References returns empty list on Deployment Server", "description": "Version Used: 1.3.1 Steps to Reproduce: <CODE> <CODE> Please let me know what am i missing on the Server Machine? ", "code": ["var semanticModel = document.GetSemanticModelAsync().Result //Where document is Microsoft.CodeAnalysis.Document;\n\nISymbol symbolInformation = semanticModel.GetSymbolInfo(node).Symbol\n                                        ?? semanticModel.GetDeclaredSymbol(node);\n\nvar allReferences = sementicModel.Compilation.References;\n", "var semanticModel = document.GetSemanticModelAsync().Result //Where document is Microsoft.CodeAnalysis.Document;\n\nISymbol symbolInformation = semanticModel.GetSymbolInfo(node).Symbol\n                                        ?? semanticModel.GetDeclaredSymbol(node);\n\nvar allReferences = sementicModel.Compilation.References;\n"], "labels": ["Resolution-Answered", "Area-IDE", "Concept-API", "Question"]}
{"project": "QuantConnect_Lean", "title": "Options Support", "description": "Support for options trading. Broadly speaking this will have several pieces. Lets scope out the depth of the changes needed here: PHASE 1:\nLEAN Proposed User Facing ToolBox: PHASE 2:\nBrokerage and live trading support. TBD. ", "code": [], "labels": ["feature", "up for grabs"]}
{"project": "tootsuite_mastodon", "title": "Featured hashtags URLs conflicting with media tab", "description": "Media tab URL ends with /media. If you feature the hashtag #media, the URL ends with /tagged/media. The media tab URL only checks the ending so it takes precedence. ", "code": [], "labels": ["bug"]}
{"project": "espressif_arduino-esp32", "title": "EEPROM, and WiFiClient issues with updated library .", "description": "Using the libraries from the middle of 2018 I was able to successfully use the EEPROM and WiFiClientSecure libraries.  After updating the libraries to the current versions. 1 ) The EEPROM library only reads zeros as the current data state, where previously the unprogrammed state was all \"ones\" as in 0xFF's with data being present that I previously programmed. 2 ) When operating in Access Point mode directly to a PC's web browser, the WiFiClientSecure was able to send messages that got posted on the web page using the println function.  Now with the new libraries nothing gets posted but the println function return the number of bytes \"supposedly\" sent. What do I need to change in my software to get both of these libraries working again?  Or are these \"bugs\" in the updated libraries? Tom ", "code": [], "labels": ["stale"]}
{"project": "doctrine_orm", "title": "DDC-1297: Only one index creates when they are haven't predefined names", "description": "Jira issue originally created by user koc: <CODE> As you see, I haven't specified indes name. And doctrine:schema:create created only one (last) index. I think that problem in AnnotationDriver <CODE> And maybe it affects uniqueConstraints also ", "code": ["/****\n * @Orm\\Entity\n * @Orm\\Table(name=\"newsfeed_event\",\n *   indexes={\n *     @Orm\\index(columns={\"class\"}),\n *     @Orm\\index(columns={\"class\", \"message\"})\n *   }\n * )\n * @Orm\\HasLifecycleCallbacks\n */\nclass Event\n", "<?php\n                foreach ($tableAnnot->indexes as $indexAnnot) {\n                    $primaryTable['indexes'][$indexAnnot->name] = array(\n                        'columns' => $indexAnnot->columns\n                    );\n                }\n"], "labels": ["Bug"]}
{"project": "microsoft_vscode", "title": "HTML auto formatting using spaces instead of tabs", "description": "Steps to Reproduce:   I would expect that tabs are using instead of spaced. Does this issue occur when all extensions are disabled?: Yes ", "code": [], "labels": ["html", "needs more info"]}
{"project": "grails_grails-core", "title": "GRAILS-11129: Integration tests not possible from within IntelliJ", "description": "Original Reporter: bodiam\nEnvironment: Not Specified\nVersion: 2.3.5\nMigrated From: <URL> Whenever I run a integration test in IntelliJ, I get the following error: {noformat}\n/Library/Java/JavaVirtualMachines/jdk1.7.0_45.jdk/Contents/Home/bin/java -Dgrails.home=/Users/erikp/.gvm/grails/2.3.5 -Dbase.dir=/Users/erikp/Userfiles/projects/conference/web -Dtools.jar=/Library/Java/JavaVirtualMachines/jdk1.7.0_45.jdk/Contents/Home/lib/tools.jar -Dgroovy.starter.conf=/Users/erikp/.gvm/grails/2.3.5/conf/groovy-starter.conf -Xmx768M -Xms768M -XX:MaxPermSize=256m -XX:PermSize=256m -Dgrails.build.listeners=org.jetbrains.groovy.grails.rt.GrailsIdeaTestListener -Didea.launcher.port=7538 \"-Didea.launcher.bin.path=/Applications/IntelliJ IDEA 13.app/bin\" -Dfile.encoding=UTF-8 -classpath \"/Users/erikp/.gvm/grails/2.3.5/lib/org.codehaus.groovy/groovy-all/jars/groovy-all-2.1.9.jar:/Users/erikp/.gvm/grails/2.3.5/dist/grails-bootstrap-2.3.5.jar:/Applications/IntelliJ IDEA 13.app/lib/idea_rt.jar\" com.intellij.rt.execution.application.AppMain org.codehaus.groovy.grails.cli.support.GrailsStarter --classpath \"/Applications/IntelliJ IDEA 13.app/plugins/Grails/lib/grails-rt.jar\" --main org.codehaus.groovy.grails.cli.GrailsScriptRunner --conf /Users/erikp/.gvm/grails/2.3.5/conf/groovy-starter.conf \"test-app integration: \"conference.rest.RestConferenceControllerSpec.test basic rest information\" -echoOut --stacktrace\"\nTesting started at 23:14 ...\n| Loading Grails 2.3.5\n| Configuring classpath\n| Configuring classpath.\n| Environment set to test\n| Environment set to test.\n| Environment set to test..\n| Environment set to test...\n| Environment set to test....\n| Environment set to test.....\n| Running without daemon...\nobjc[7550]: Class JavaLaunchHelper is implemented in both /Library/Java/JavaVirtualMachines/jdk1.7.0_45.jdk/Contents/Home/bin/java and /Library/Java/JavaVirtualMachines/jdk1.7.0_45.jdk/Contents/Home/jre/lib/libinstrument.dylib. One of the two will be used. Which one is undefined.\n| Error Error running forked test-app: Could not load grails build listener class (NOTE: Stack trace has been filtered. Use --verbose to see entire trace.)\njava.lang.RuntimeException: Could not load grails build listener class\nCaused by: java.lang.ClassNotFoundException: org.jetbrains.groovy.grails.rt.GrailsIdeaTestListener\n| Error Error running forked test-app: Could not load grails build listener class\n| Error Forked Grails VM exited with error Process finished with exit code 1\n{noformat} ", "code": [], "labels": ["Blocker", "Bug", "Fixed"]}
{"project": "dotnet_coreclr", "title": "[Perf][Release/2.1] Investigate Perf benchmark failures on Ubuntu 16.04", "description": "The following perf benchmarks are failing in Release/2.1 Ubuntu 16.04: <CODE> <CODE> <CODE> <CODE> <CODE> <CODE> <CODE> <CODE> <CODE> ", "code": ["14:28:18 [./tests/scripts/run-xunit-perf.py]: --------\n14:28:18 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off PacketTracer\n14:28:18 [./tests/scripts/run-xunit-perf.py]: --------\n14:28:18 [./tests/scripts/run-xunit-perf.py]: \n14:28:18 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/PacketTracer.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/PacketTracer --perf:runid Perf-Off --perf:collect stopwatch\n14:28:18 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:28:18 [10/6/18 2:26:40 PM][ERR] Could not find constructor for 'Xunit.Sdk.CollectionPerClassTestCollectionFactory' with arguments type(s): Xunit.Sdk.TestAssembly\n14:28:18 \n[ERROR] Benchmark execution failed.\n14:28:18   System.IO.FileNotFoundException: Could not load file or assembly 'System.Runtime.Intrinsics, Version=4.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51'. The system cannot find the file specified.\n14:28:18 \n14:28:18 File name: 'System.Runtime.Intrinsics, Version=4.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51'\n14:28:18    at System.Reflection.RuntimeAssembly.GetExportedTypes(RuntimeAssembly assembly, ObjectHandleOnStack retTypes)\n14:28:18    at System.Reflection.RuntimeAssembly.GetExportedTypes()\n14:28:18    at Xunit.Sdk.ReflectionAssemblyInfo.GetTypes(Boolean includePrivateTypes)\n14:28:18    at Xunit.Sdk.TestCollectionFactoryHelper.GetTestCollectionDefinitions(IAssemblyInfo assemblyInfo, IMessageSink diagnosticMessageSink)\n14:28:18    at Xunit.Sdk.CollectionPerClassTestCollectionFactory..ctor(ITestAssembly testAssembly, IMessageSink diagnosticMessageSink)\n14:28:18    at Xunit.Sdk.ExtensibilityPointFactory.GetXunitTestCollectionFactory(IMessageSink diagnosticMessageSink, IAttributeInfo collectionBehaviorAttribute, ITestAssembly testAssembly)\n14:28:18    at Xunit.Sdk.XunitTestFrameworkDiscoverer..ctor(IAssemblyInfo assemblyInfo, ISourceInformationProvider sourceProvider, IMessageSink diagnosticMessageSink, IXunitTestCollectionFactory collectionFactory)\n14:28:18    at Xunit.Sdk.XunitTestFramework.CreateDiscoverer(IAssemblyInfo assemblyInfo)\n14:28:18    at Xunit.Sdk.TestFramework.GetDiscoverer(IAssemblyInfo assemblyInfo)\n14:28:18    at Xunit.Xunit2Discoverer..ctor(AppDomainSupport appDomainSupport, ISourceInformationProvider sourceInformationProvider, IAssemblyInfo assemblyInfo, String assemblyFileName, String xunitExecutionAssemblyPath, String configFileName, Boolean shadowCopy, String shadowCopyFolder, IMessageSink diagnosticMessageSink, Boolean verifyAssembliesOnDisk)\n14:28:18    at Xunit.Xunit2..ctor(AppDomainSupport appDomainSupport, ISourceInformationProvider sourceInformationProvider, String assemblyFileName, String configFileName, Boolean shadowCopy, String shadowCopyFolder, IMessageSink diagnosticMessageSink, Boolean verifyTestAssemblyExists)\n14:28:18    at Xunit.XunitFrontController.CreateInnerController()\n14:28:18    at Xunit.XunitFrontController.get_InnerController()\n14:28:18    at Microsoft.Xunit.Performance.Api.XunitBenchmark.GetMetadata(String assemblyFileName, IEnumerable`1 performanceMetricInfos, Boolean collectDefaultMetrics)\n14:28:18    at Microsoft.Xunit.Performance.Api.XunitPerformanceHarness.RunBenchmarks(String assemblyFileName)\n14:28:18    at PerfHarness.Main(String[] args) in /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/tests/src/Common/PerfHarness/PerfHarness.cs:line 11\n", "14:43:13 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:13 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off k-nucleotide-1\n14:43:13 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:13 [./tests/scripts/run-xunit-perf.py]: \n14:43:13 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/k-nucleotide-1.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/k-nucleotide-1 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:13 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:13 [10/6/18 2:42:42 PM][INF] Running 1 [Benchmark]s\n14:43:13 [10/6/18 2:42:42 PM][INF]   BenchmarksGame.KNucleotide_1.RunBench\n14:43:13 [10/6/18 2:42:42 PM][ERR] BenchmarksGame.KNucleotide_1.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:13 [10/6/18 2:42:42 PM][INF] Finished 1 tests in 0.105s (1 failed, 0 skipped)\n", "14:43:13 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:13 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off k-nucleotide-9\n14:43:13 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:13 [./tests/scripts/run-xunit-perf.py]: \n14:43:13 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/k-nucleotide-9.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/k-nucleotide-9 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:13 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:13 [10/6/18 2:42:42 PM][INF] Running 1 [Benchmark]s\n14:43:13 [10/6/18 2:42:42 PM][INF]   BenchmarksGame.KNucleotide_9.RunBench\n14:43:13 [10/6/18 2:42:43 PM][ERR] BenchmarksGame.KNucleotide_9.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:13 [10/6/18 2:42:43 PM][INF] Finished 1 tests in 0.104s (1 failed, 0 skipped)\n", "14:43:13 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:13 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off regex-redux-1\n14:43:13 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:13 [./tests/scripts/run-xunit-perf.py]: \n14:43:13 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/regex-redux-1.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/regex-redux-1 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:13 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:13 [10/6/18 2:42:43 PM][INF] Running 1 [Benchmark]s\n14:43:13 [10/6/18 2:42:43 PM][INF]   BenchmarksGame.RegexRedux_1.RunBench\n14:43:13 Using input file regexdna-input25000.txt\n14:43:13 [10/6/18 2:42:43 PM][ERR] BenchmarksGame.RegexRedux_1.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:13 [10/6/18 2:42:43 PM][ERR]    at BenchmarksGame.RegexRedux_1.<>c__DisplayClass1_0.<RunBench>b__0()\n14:43:13    at Microsoft.Xunit.Performance.Benchmark.Iterate(Action measuredOperation)\n14:43:13 [10/6/18 2:42:43 PM][INF] Finished 1 tests in 0.144s (1 failed, 0 skipped)\n", "14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off regex-redux-5\n14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: \n14:43:16 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/regex-redux-5.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/regex-redux-5 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:16 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:16 [10/6/18 2:42:44 PM][INF] Running 1 [Benchmark]s\n14:43:16 [10/6/18 2:42:44 PM][INF]   BenchmarksGame.RegexRedux_5.RunBench\n14:43:16 Using input file regexdna-input25000.txt\n14:43:16 [10/6/18 2:42:44 PM][ERR] BenchmarksGame.RegexRedux_5.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:16 [10/6/18 2:42:44 PM][ERR]    at BenchmarksGame.RegexRedux_5.<>c__DisplayClass3_0.<RunBench>b__0()\n14:43:16    at Microsoft.Xunit.Performance.Benchmark.Iterate(Action measuredOperation)\n14:43:16 [10/6/18 2:42:44 PM][INF] Finished 1 tests in 0.143s (1 failed, 0 skipped)\n", "14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off spectralnorm-3\n14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: \n14:43:16 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/spectralnorm-3.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/spectralnorm-3 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:16 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:16 [10/6/18 2:42:44 PM][INF] Running 1 [Benchmark]s\n14:43:16 [10/6/18 2:42:44 PM][INF]   BenchmarksGame.SpectralNorm_3.RunBench\n14:43:16 [10/6/18 2:42:44 PM][ERR] BenchmarksGame.SpectralNorm_3.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:16 [10/6/18 2:42:44 PM][INF] Finished 1 tests in 0.106s (1 failed, 0 skipped)\n", "14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off spectralnorm-1\n14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: \n14:43:16 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/spectralnorm-1.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/spectralnorm-1 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:16 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:16 [10/6/18 2:42:45 PM][INF] Running 1 [Benchmark]s\n14:43:16 [10/6/18 2:42:45 PM][INF]   BenchmarksGame.SpectralNorm_1.RunBench\n14:43:16 [10/6/18 2:42:45 PM][ERR] BenchmarksGame.SpectralNorm_1.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:16 [10/6/18 2:42:45 PM][INF] Finished 1 tests in 0.105s (1 failed, 0 skipped)\n", "14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off reverse-complement-1\n14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: \n14:43:16 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/reverse-complement-1.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/reverse-complement-1 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:16 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:16 [10/6/18 2:42:46 PM][INF] Running 1 [Benchmark]s\n14:43:16 [10/6/18 2:42:46 PM][INF]   BenchmarksGame.ReverseComplement_1.RunBench\n14:43:16 [10/6/18 2:42:46 PM][ERR] BenchmarksGame.ReverseComplement_1.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:16 [10/6/18 2:42:46 PM][INF] Finished 1 tests in 0.104s (1 failed, 0 skipped)\n", "14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: Running Perf-Off reverse-complement-6\n14:43:16 [./tests/scripts/run-xunit-perf.py]: --------\n14:43:16 [./tests/scripts/run-xunit-perf.py]: \n14:43:16 [./tests/scripts/run-xunit-perf.py]: taskset 0x00000002 nice --adjustment=-10 /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/corerun PerfHarness.dll /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox/reverse-complement-6.exe --perf:outputdir /home/administrator/jenkins/w/dotnet_coreclr/perf/release_2.1/perf_Ubuntu16.04/bin/sandbox_logs/Microbenchmarks/Off/reverse-complement-6 --perf:runid Perf-Off --perf:collect stopwatch\n14:43:16 [./tests/scripts/run-xunit-perf.py]: CoreRun.exe exited with 1 code\n14:43:16 [10/6/18 2:42:46 PM][INF] Running 1 [Benchmark]s\n14:43:16 [10/6/18 2:42:46 PM][INF]   BenchmarksGame.ReverseComplement_6.RunBench\n14:43:16 [10/6/18 2:42:46 PM][ERR] BenchmarksGame.ReverseComplement_6.RunBench: Could not load file or assembly 'xunit.assert, Version=2.4.0.4010, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n14:43:16 [10/6/18 2:42:46 PM][INF] Finished 1 tests in 0.104s (1 failed, 0 skipped)\n"], "labels": ["area-Infrastructure-coreclr"]}
{"project": "rstudio_rstudio", "title": "Feature Request: Provide Session-level control over Themes or Background Colors", "description": "<CODE> Feature Request for ability to set session-specific background colors or themes.  I am frequently working on several related or completely unrelated projects, and the ability to color-code the sessions in either the Windows R-Gui or the MacOS/Linux console makes \u201cvisual grepping\u201d much easier and faster (\u201cvisual grepping\u201d a term is from the description of the file-icons package for the Atom editor). Themes are great, but when I change it for one session it changes for all sessions. Please excuse any oversights on my part, and thanks! ", "code": ["RStudio Edition : <!-- Desktop or Server -->\nRStudio Version : \nOS Version      : \nR Version       : \n"], "labels": ["themes", "enhancement"]}
{"project": "cockroachdb_cockroach", "title": "testutils/buildutil: (unknown) failed under stress", "description": "SHA: <URL> Parameters: <CODE> To repro, try: <CODE> Failed test: <URL> <CODE> ", "code": ["TAGS=\nGOFLAGS=\n", "# Don't forget to check out a clean suitable branch and experiment with the\n# stress invocation until the desired results present themselves. For example,\n# using stressrace instead of stress and passing the '-p' stressflag which\n# controls concurrency.\n./scripts/gceworker.sh start && ./scripts/gceworker.sh mosh\ncd ~/go/src/github.com/cockroachdb/cockroach && \\\nmake stress TESTS=(unknown) PKG=github.com/cockroachdb/cockroach/pkg/testutils/buildutil TESTTIMEOUT=5m STRESSFLAGS='-stderr=false -maxtime 20m -timeout 10m'\n", "\n"], "labels": ["O-robot", "C-test-failure"]}
{"project": "containous_traefik", "title": "Add PassHostHeader in frontends configuration", "description": "We need to add PassHostHeader option in frontend configuration. ", "code": [], "labels": ["kind/enhancement", "status/5-frozen-due-to-age"]}
{"project": "NativeScript_NativeScript", "title": "Question: is this an okey way to...", "description": "Hello, Recently started using nativescript with firebase. I want to redirect user to dashboard, if he is alredy logged in. Here is how i am doing it right now: <CODE> I wanted to ask, is this okey way to do it ? What could be improved ? ", "code": ["  2 import {Component} from \"@angular/core\";\n  3 import {NS_ROUTER_DIRECTIVES} from \"nativescript-angular/router\";\n  4 import firebase = require(\"nativescript-plugin-firebase\");\n  5 \n  6 @Component({\n  7   selector: \"main\",\n  8   directives: [NS_ROUTER_DIRECTIVES],\n  9   template: \"<page-router-outlet></page-router-outlet>\"\n 10 })\n 11 export class AppComponent {\n 12 \n 13   constructor(private _router: Router) {\n 14     var thisAppComponent = this;\n 15 \n 16     firebase.getCurrentUser().then(function(data) {\n 17       if(data.uid != \"\") {\n 18         thisAppComponent._router.navigate([\"/dashboard\"])\n 19       }\n 20 \n 21       console.log(data.uid);\n 22     }, function(error) {\n 23       console.log(\"userNotLoggedIn\")\n 24     });\n 25 \n 26   }\n 27 }\n\n"], "labels": ["question"]}
{"project": "bridgedotnet_Bridge", "title": "Equals for Tuple includes reference check", "description": "Reported on the forum <URL> MSDN Tuple.Equals Method (Object)  True False Sample:\nBridge Live\n.Net Fiddle ", "code": [], "labels": ["defect"]}
{"project": "ampproject_amphtml", "title": "Support AdWords tracking URLs in viewerless AMP", "description": "Request: ", "code": [], "labels": ["WG: analytics", "Type: Feature Request", "WG: ads", "P2: Soon"]}
{"project": "monero-project_monero", "title": "Monerod crashing when trying to resize db on Windows10", "description": "Monerod is crashing when trying to resize db. find detailed log below: 2017-12-13 09:43:14.253\t7564\tINFO \tglobal\tsrc/daemon/main.cpp:279\tMonero 'Helium Hydra' (v0.11.1.0-release)\n2017-12-13 09:43:14.253\t7564\tINFO \tglobal\tsrc/daemon/protocol.h:55\tInitializing cryptonote protocol...\n2017-12-13 09:43:14.253\t7564\tINFO \tglobal\tsrc/daemon/protocol.h:60\tCryptonote protocol initialized OK\n2017-12-13 09:43:14.268\t7564\tINFO \tglobal\tsrc/daemon/p2p.h:63\tInitializing p2p server...\n2017-12-13 09:43:25.402\t7564\tINFO \tglobal\tsrc/daemon/p2p.h:68\tP2p server initialized OK\n2017-12-13 09:43:25.402\t7564\tINFO \tglobal\tsrc/daemon/rpc.h:58\tInitializing core rpc server...\n2017-12-13 09:43:25.418\t7564\tINFO \tglobal\tcontrib/epee/include/net/http_server_impl_base.h:70\tBinding on 127.0.0.1:18081\n2017-12-13 09:43:25.418\t7564\tINFO \tglobal\tsrc/daemon/rpc.h:63\tCore rpc server initialized OK on port: 18081\n2017-12-13 09:43:25.418\t7564\tINFO \tglobal\tsrc/daemon/core.h:73\tInitializing core...\n2017-12-13 09:43:25.418\t7564\tINFO \tglobal\tsrc/cryptonote_core/cryptonote_core.cpp:323\tLoading blockchain from folder C:\\ProgramData\\bitmonero\\lmdb ...\n2017-12-13 09:44:51.153\t5728\tINFO \tlogging\tcontrib/epee/src/mlog.cpp:148\tNew log categories: *:WARNING,net:FATAL,net.p2p:FATAL,net.cn:FATAL,global:INFO,verify:FATAL,stacktrace:INFO,logging:INFO,msgwriter:INFO\n2017-12-13 09:44:51.153\t5728\tINFO \tlogging\tcontrib/epee/src/mlog.cpp:156\tNew log categories: *:TRACE\n2017-12-13 09:44:51.153\t5728\tINFO \tglobal\tsrc/daemon/main.cpp:279\tMonero 'Helium Hydra' (v0.11.1.0-release)\n2017-12-13 09:44:51.169\t5728\tINFO \tdaemon\tsrc/daemon/main.cpp:281\tMoving from main() into the daemonize now.\n2017-12-13 09:44:51.169\t5728\tINFO \tglobal\tsrc/daemon/protocol.h:55\tInitializing cryptonote protocol...\n2017-12-13 09:44:51.169\t5728\tINFO \tglobal\tsrc/daemon/protocol.h:60\tCryptonote protocol initialized OK\n2017-12-13 09:44:51.169\t5728\tTRACE\tblockchain\tsrc/cryptonote_core/blockchain.cpp:136\tBlockchain::Blockchain\n2017-12-13 09:44:51.169\t5728\tINFO \tglobal\tsrc/daemon/p2p.h:63\tInitializing p2p server...\n2017-12-13 09:44:51.169\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:489\tdns_threads created, now waiting for completion or timeout of 20000ms\n2017-12-13 09:44:51.169\t6456\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[1] created for: seeds.moneroseeds.ae.org\n2017-12-13 09:44:51.169\t9976\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[2] created for: seeds.moneroseeds.ch\n2017-12-13 09:44:51.169\t6604\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[0] created for: seeds.moneroseeds.se\n2017-12-13 09:44:51.169\t1108\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[3] created for: seeds.moneroseeds.li\n2017-12-13 09:44:51.669\t6456\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[1] DNS resolve done\n2017-12-13 09:44:51.669\t6456\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[1] addr_str: seeds.moneroseeds.ae.org  number of results: 0\n2017-12-13 09:44:51.685\t1108\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[3] DNS resolve done\n2017-12-13 09:44:51.685\t1108\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[3] addr_str: seeds.moneroseeds.li  number of results: 0\n2017-12-13 09:44:51.685\t6604\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[0] DNS resolve done\n2017-12-13 09:44:51.685\t6604\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[0] addr_str: seeds.moneroseeds.se  number of results: 0\n2017-12-13 09:44:51.685\t9976\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[2] DNS resolve done\n2017-12-13 09:44:51.685\t9976\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[2] addr_str: seeds.moneroseeds.ch  number of results: 0\n2017-12-13 09:44:51.685\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.se: 0 results\n2017-12-13 09:44:51.700\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.ae.org: 0 results\n2017-12-13 09:44:51.700\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.ch: 0 results\n2017-12-13 09:44:51.700\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.li: 0 results\n2017-12-13 09:44:51.700\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:519\tDNS seed node lookup either timed out or failed, falling back to defaults\n2017-12-13 09:44:51.700\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 107.152.130.98:18080\n2017-12-13 09:44:51.700\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 107.152.130.98:18080\n2017-12-13 09:44:51.700\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 161.67.132.39:18080\n2017-12-13 09:44:51.700\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 161.67.132.39:18080\n2017-12-13 09:44:51.700\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 163.172.182.165:18080\n2017-12-13 09:44:51.716\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 163.172.182.165:18080\n2017-12-13 09:44:51.716\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 195.154.123.123:28080\n2017-12-13 09:44:51.716\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 195.154.123.123:28080\n2017-12-13 09:44:51.716\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 198.74.231.92:18080\n2017-12-13 09:44:51.716\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 198.74.231.92:18080\n2017-12-13 09:44:51.716\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 212.83.172.165:28080\n2017-12-13 09:44:51.716\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 212.83.172.165:28080\n2017-12-13 09:44:51.716\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 212.83.175.67:18080\n2017-12-13 09:44:51.716\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 212.83.175.67:18080\n2017-12-13 09:44:51.732\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 5.9.100.248:18080\n2017-12-13 09:44:51.732\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 5.9.100.248:18080\n2017-12-13 09:44:51.732\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:533\tNumber of seed nodes: 8\n2017-12-13 09:44:51.732\t5728\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 4.40402e+006 kbps\n2017-12-13 09:44:51.732\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1883\tSet limit-up to 2048 kB/s\n2017-12-13 09:44:51.732\t5728\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:44:51.747\t5728\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:44:51.747\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1897\tSet limit-down to 8192 kB/s\n2017-12-13 09:44:51.747\t5728\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 4.40402e+006 kbps\n2017-12-13 09:44:51.747\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1919\tSet limit-up to 2048 kB/s\n2017-12-13 09:44:51.747\t5728\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:44:51.747\t5728\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:44:51.747\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1923\tSet limit-down to 8192 kB/s\n2017-12-13 09:44:51.778\t5728\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:795\tSet server type to: 2 from name: P2P, prefix_name = P2P\n2017-12-13 09:44:51.794\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:572\tBinding on 0.0.0.0:18080\n2017-12-13 09:44:51.794\t5728\tDEBUG\tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:734\tstart accept\n2017-12-13 09:44:51.794\t5728\tINFO \tnet.p2p\tsrc/p2p/connection_basic.cpp:164\tSpawned connection p2p#0 to 0.0.0.0 currently we have sockets count:1\n2017-12-13 09:44:51.810\t5728\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:85\ttest, connection constructor set m_connection_type=2\n2017-12-13 09:44:51.810\t5728\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:577\t\ufffd[1;32mNet service bound to 0.0.0.0:18080\ufffd[0m\n2017-12-13 09:44:51.825\t5728\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:583\tAttempting to add IGD port mapping.\n2017-12-13 09:44:54.017\t5728\tWARN \tnet.p2p\tsrc/p2p/net_node.inl:615\tUPnP device was found but not recognized as IGD.\n2017-12-13 09:44:54.017\t5728\tINFO \tglobal\tsrc/daemon/p2p.h:68\tP2p server initialized OK\n2017-12-13 09:44:54.017\t5728\tINFO \tglobal\tsrc/daemon/rpc.h:58\tInitializing core rpc server...\n2017-12-13 09:44:54.017\t5728\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:795\tSet server type to: 1 from name: RPC, prefix_name = RPC\n2017-12-13 09:44:54.032\t5728\tINFO \tglobal\tcontrib/epee/include/net/http_server_impl_base.h:70\tBinding on 127.0.0.1:18081\n2017-12-13 09:44:54.032\t5728\tDEBUG\tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:734\tstart accept\n2017-12-13 09:44:54.032\t5728\tINFO \tnet.p2p\tsrc/p2p/connection_basic.cpp:164\tSpawned connection p2p#0 to 0.0.0.0 currently we have sockets count:1\n2017-12-13 09:44:54.032\t5728\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:85\ttest, connection constructor set m_connection_type=1\n2017-12-13 09:44:54.032\t5728\tINFO \tglobal\tsrc/daemon/rpc.h:63\tCore rpc server initialized OK on port: 18081\n2017-12-13 09:44:54.032\t5728\tINFO \tglobal\tsrc/daemon/core.h:73\tInitializing core...\n2017-12-13 09:44:54.048\t5728\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1070\tBlockchainLMDB::BlockchainLMDB\n2017-12-13 09:44:54.048\t5728\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1388\tBlockchainLMDB::get_db_name\n2017-12-13 09:44:54.048\t5728\tINFO \tglobal\tsrc/cryptonote_core/cryptonote_core.cpp:323\tLoading blockchain from folder C:\\ProgramData\\bitmonero\\lmdb ...\n2017-12-13 09:44:54.048\t5728\tDEBUG\tcn\tsrc/cryptonote_core/cryptonote_core.cpp:339\toption: fast\n2017-12-13 09:44:54.048\t5728\tDEBUG\tcn\tsrc/cryptonote_core/cryptonote_core.cpp:339\toption: async\n2017-12-13 09:44:54.063\t5728\tDEBUG\tcn\tsrc/cryptonote_core/cryptonote_core.cpp:339\toption: 1000\n2017-12-13 09:44:54.063\t5728\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1091\tBlockchainLMDB::open\n2017-12-13 09:44:54.079\t5728\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:502\tBlockchainLMDB::need_resize\n2017-12-13 09:44:54.095\t5728\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:518\tDB map size:     36676089856\n2017-12-13 09:44:54.095\t5728\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:519\tSpace used:      28924506112\n2017-12-13 09:44:54.095\t5728\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:520\tSpace remaining: 7751583744\n2017-12-13 09:44:54.095\t5728\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:521\tSize threshold:  0\n2017-12-13 09:44:54.110\t5728\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:523\tPercent used: 0.7886  Percent threshold: 0.8000\n2017-12-13 09:44:54.110\t5728\tDEBUG\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1219\tSetting m_height to: 1398908\n2017-12-13 09:48:20.413\t13652\tINFO \tlogging\tcontrib/epee/src/mlog.cpp:148\tNew log categories: *:WARNING,net:FATAL,net.p2p:FATAL,net.cn:FATAL,global:INFO,verify:FATAL,stacktrace:INFO,logging:INFO,msgwriter:INFO\n2017-12-13 09:48:20.413\t13652\tINFO \tlogging\tcontrib/epee/src/mlog.cpp:156\tNew log categories: *:TRACE\n2017-12-13 09:48:20.429\t13652\tINFO \tglobal\tsrc/daemon/main.cpp:279\tMonero 'Helium Hydra' (v0.11.1.0-release)\n2017-12-13 09:48:20.429\t13652\tINFO \tdaemon\tsrc/daemon/main.cpp:281\tMoving from main() into the daemonize now.\n2017-12-13 09:48:20.429\t13652\tINFO \tglobal\tsrc/daemon/protocol.h:55\tInitializing cryptonote protocol...\n2017-12-13 09:48:20.429\t13652\tINFO \tglobal\tsrc/daemon/protocol.h:60\tCryptonote protocol initialized OK\n2017-12-13 09:48:20.429\t13652\tTRACE\tblockchain\tsrc/cryptonote_core/blockchain.cpp:136\tBlockchain::Blockchain\n2017-12-13 09:48:20.429\t13652\tINFO \tglobal\tsrc/daemon/p2p.h:63\tInitializing p2p server...\n2017-12-13 09:48:20.429\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:489\tdns_threads created, now waiting for completion or timeout of 20000ms\n2017-12-13 09:48:20.429\t1568\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[1] created for: seeds.moneroseeds.ae.org\n2017-12-13 09:48:20.429\t13360\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[2] created for: seeds.moneroseeds.ch\n2017-12-13 09:48:20.429\t2664\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[0] created for: seeds.moneroseeds.se\n2017-12-13 09:48:20.429\t14024\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:461\tdns_threads[3] created for: seeds.moneroseeds.li\n2017-12-13 09:48:26.323\t13360\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[2] DNS resolve done\n2017-12-13 09:48:26.323\t13360\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[2] addr_str: seeds.moneroseeds.ch  number of results: 0\n2017-12-13 09:48:26.338\t14024\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[3] DNS resolve done\n2017-12-13 09:48:26.338\t14024\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[3] addr_str: seeds.moneroseeds.li  number of results: 0\n2017-12-13 09:48:28.823\t1568\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[1] DNS resolve done\n2017-12-13 09:48:28.823\t1568\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[1] addr_str: seeds.moneroseeds.ae.org  number of results: 0\n2017-12-13 09:48:28.839\t2664\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:469\tdns_threads[0] DNS resolve done\n2017-12-13 09:48:28.839\t2664\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:481\tdns_threads[0] addr_str: seeds.moneroseeds.se  number of results: 0\n2017-12-13 09:48:28.839\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.se: 0 results\n2017-12-13 09:48:28.839\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.ae.org: 0 results\n2017-12-13 09:48:28.854\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.ch: 0 results\n2017-12-13 09:48:28.854\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:505\tDNS lookup for seeds.moneroseeds.li: 0 results\n2017-12-13 09:48:28.854\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:519\tDNS seed node lookup either timed out or failed, falling back to defaults\n2017-12-13 09:48:28.854\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 107.152.130.98:18080\n2017-12-13 09:48:28.870\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 107.152.130.98:18080\n2017-12-13 09:48:28.870\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 161.67.132.39:18080\n2017-12-13 09:48:28.870\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 161.67.132.39:18080\n2017-12-13 09:48:28.870\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 163.172.182.165:18080\n2017-12-13 09:48:28.870\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 163.172.182.165:18080\n2017-12-13 09:48:28.870\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 195.154.123.123:28080\n2017-12-13 09:48:28.870\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 195.154.123.123:28080\n2017-12-13 09:48:28.886\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 198.74.231.92:18080\n2017-12-13 09:48:28.886\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 198.74.231.92:18080\n2017-12-13 09:48:28.886\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 212.83.172.165:28080\n2017-12-13 09:48:28.886\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 212.83.172.165:28080\n2017-12-13 09:48:28.886\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 212.83.175.67:18080\n2017-12-13 09:48:28.886\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 212.83.175.67:18080\n2017-12-13 09:48:28.886\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:530\tSeed node: 5.9.100.248:18080\n2017-12-13 09:48:28.886\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:395\tAdded seed node: 5.9.100.248:18080\n2017-12-13 09:48:28.886\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:533\tNumber of seed nodes: 8\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 4.40402e+006 kbps\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1883\tSet limit-up to 2048 kB/s\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1897\tSet limit-down to 8192 kB/s\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 4.40402e+006 kbps\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1919\tSet limit-up to 2048 kB/s\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.throttle\tsrc/p2p/network_throttle-detail.cpp:162\tSetting LIMIT: 8.38861e+006 kbps\n2017-12-13 09:48:28.901\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:1923\tSet limit-down to 8192 kB/s\n2017-12-13 09:48:28.933\t13652\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:795\tSet server type to: 2 from name: P2P, prefix_name = P2P\n2017-12-13 09:48:28.933\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:572\tBinding on 0.0.0.0:18080\n2017-12-13 09:48:28.933\t13652\tDEBUG\tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:734\tstart accept\n2017-12-13 09:48:28.933\t13652\tINFO \tnet.p2p\tsrc/p2p/connection_basic.cpp:164\tSpawned connection p2p#0 to 0.0.0.0 currently we have sockets count:1\n2017-12-13 09:48:28.933\t13652\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:85\ttest, connection constructor set m_connection_type=2\n2017-12-13 09:48:28.933\t13652\tINFO \tnet.p2p\tsrc/p2p/net_node.inl:577\t\ufffd[1;32mNet service bound to 0.0.0.0:18080\ufffd[0m\n2017-12-13 09:48:28.933\t13652\tDEBUG\tnet.p2p\tsrc/p2p/net_node.inl:583\tAttempting to add IGD port mapping.\n2017-12-13 09:48:31.064\t13652\tWARN \tnet.p2p\tsrc/p2p/net_node.inl:615\tUPnP device was found but not recognized as IGD.\n2017-12-13 09:48:31.064\t13652\tINFO \tglobal\tsrc/daemon/p2p.h:68\tP2p server initialized OK\n2017-12-13 09:48:31.064\t13652\tINFO \tglobal\tsrc/daemon/rpc.h:58\tInitializing core rpc server...\n2017-12-13 09:48:31.064\t13652\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:795\tSet server type to: 1 from name: RPC, prefix_name = RPC\n2017-12-13 09:48:31.080\t13652\tINFO \tglobal\tcontrib/epee/include/net/http_server_impl_base.h:70\tBinding on 127.0.0.1:18081\n2017-12-13 09:48:31.080\t13652\tDEBUG\tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:734\tstart accept\n2017-12-13 09:48:31.080\t13652\tINFO \tnet.p2p\tsrc/p2p/connection_basic.cpp:164\tSpawned connection p2p#0 to 0.0.0.0 currently we have sockets count:1\n2017-12-13 09:48:31.096\t13652\tINFO \tnet\tcontrib/epee/include/net/abstract_tcp_server2.inl:85\ttest, connection constructor set m_connection_type=1\n2017-12-13 09:48:31.096\t13652\tINFO \tglobal\tsrc/daemon/rpc.h:63\tCore rpc server initialized OK on port: 18081\n2017-12-13 09:48:31.096\t13652\tINFO \tglobal\tsrc/daemon/core.h:73\tInitializing core...\n2017-12-13 09:48:31.096\t13652\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1070\tBlockchainLMDB::BlockchainLMDB\n2017-12-13 09:48:31.096\t13652\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1388\tBlockchainLMDB::get_db_name\n2017-12-13 09:48:31.096\t13652\tINFO \tglobal\tsrc/cryptonote_core/cryptonote_core.cpp:323\tLoading blockchain from folder C:\\ProgramData\\bitmonero\\lmdb ...\n2017-12-13 09:48:31.096\t13652\tDEBUG\tcn\tsrc/cryptonote_core/cryptonote_core.cpp:339\toption: fast\n2017-12-13 09:48:31.111\t13652\tDEBUG\tcn\tsrc/cryptonote_core/cryptonote_core.cpp:339\toption: async\n2017-12-13 09:48:31.111\t13652\tDEBUG\tcn\tsrc/cryptonote_core/cryptonote_core.cpp:339\toption: 1000\n2017-12-13 09:48:31.111\t13652\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1091\tBlockchainLMDB::open\n2017-12-13 09:48:31.127\t13652\tTRACE\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:502\tBlockchainLMDB::need_resize\n2017-12-13 09:48:31.127\t13652\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:518\tDB map size:     36676089856\n2017-12-13 09:48:31.127\t13652\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:519\tSpace used:      28924506112\n2017-12-13 09:48:31.127\t13652\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:520\tSpace remaining: 7751583744\n2017-12-13 09:48:31.127\t13652\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:521\tSize threshold:  0\n2017-12-13 09:48:31.127\t13652\tINFO \tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:523\tPercent used: 0.7886  Percent threshold: 0.8000\n2017-12-13 09:48:31.142\t13652\tDEBUG\tblockchain.db.lmdb\tsrc/blockchain_db/lmdb/db_lmdb.cpp:1219\tSetting m_height to: 1398908 ", "code": [], "labels": ["resolved"]}
{"project": "RocketMap_RocketMap", "title": "[Feature Request]", "description": "Search (through a search bar) scanned area for pokemon (by name) that has spawned. List of current appearances on a side bar will show where the pokemon has currently spawned User can navigate between the instances by clicking through the list which then jumps around the map to the location of the selected instance. ", "code": [], "labels": ["new feature"]}
{"project": "dotnet_roslyn", "title": "Completion list spans cannot be set by \"exclusive\" CompletionProviders", "description": "In the GetCompletionsAsync() method of CompletionServiceWithProviders, the CompletionList is always created with the span that is returned from GetDefaultCompletionListSpan(). If one of the service's CompletionProviders tries to specify a span on the CompletionContext it is passed, that value will always be ignored in favor of the default span. That makes sense when there are multiple CompletionProviders returning results, but in the case where one of the CompletionProviders returns a CompletionContext where IsExclusive is set to true (indicating that only its completions are to be displayed in the list), should the CompletionServiceWithProviders instead use the span on the CompletionContext rather than the default span? Currently, that is not the behavior. I discussed this earlier with @CyrusNajmabadi and he suggested I open an issue. Version Used:\nmaster Expected Behavior:\n\"Exclusive\" CompletionProviders can specify their own completion spans on the CompletionContext Actual Behavior:\nAll completion list spans in CompletionServiceWithProviders are determined by  GetDefaultCompletionListSpan(). ", "code": [], "labels": ["Feature Request", "Area-IDE"]}
{"project": "spree_spree", "title": "Not setting master price for product gives obscure error 'invalid value for BigDecimal(): \"\"'", "description": "When creating or updating a product if you don't set a master price you get taken to the rails error page showing invalid value for BigDecimal(): \"\". Because this affects the user side of things there should be a simple flash showing that the product needs to have a master price before being saved. ", "code": [], "labels": ["Bug"]}
{"project": "pmmp_PocketMine-MP", "title": "Server crashed", "description": "Error: \"Call to a member function broadcastPacketToViewers() on null\" (EXCEPTION) in \"src/pocketmine/entity/Entity\" at line 1267\n[15:35:01] [Server thread/DEBUG]: #0 src/pocketmine/entity/Entity(1235): pocketmine\\entity\\Entity->broadcastMotion()\n[15:35:01] [Server thread/DEBUG]: #1 src/pocketmine/entity/Entity(1942): pocketmine\\entity\\Entity->updateMovement()\n[15:35:01] [Server thread/DEBUG]: #2 plugins/PiggyCustomEnchants-dcf887f84b78e79b0d6d0456abe3a71aba6ba4d3/src/DaPigGuy/PiggyCustomEnchants/Tasks/GoeyTask(41): pocketmine\\entity\\Entity->setMotion(object pocketmine\\math\\Vector3)\n[15:35:01] [Server thread/DEBUG]: #3 src/pocketmine/scheduler/TaskHandler(159): DaPigGuy\\PiggyCustomEnchants\\Tasks\\GoeyTask->onRun(integer 55692)\n[15:35:01] [Server thread/DEBUG]: #4 src/pocketmine/scheduler/TaskScheduler(199): pocketmine\\scheduler\\TaskHandler->run(integer 55692)\n[15:35:01] [Server thread/DEBUG]: #5 src/pocketmine/plugin/PluginManager(689): pocketmine\\scheduler\\TaskScheduler->mainThreadHeartbeat(integer 55692)\n[15:35:01] [Server thread/DEBUG]: #6 src/pocketmine/Server(2569): pocketmine\\plugin\\PluginManager->tickSchedulers(integer 55692)\n[15:35:01] [Server thread/DEBUG]: #7 src/pocketmine/Server(2345): pocketmine\\Server->tick()\n[15:35:01] [Server thread/DEBUG]: #8 src/pocketmine/Server(2205): pocketmine\\Server->tickProcessor()[15:35:01] [Server thread/DEBUG]: #9 src/pocketmine/Server(1784): pocketmine\\Server->start()\n[15:35:01] [Server thread/DEBUG]: #10 src/pocketmine/PocketMine(275): pocketmine\\Server->__construct(object BaseClassLoader, object pocketmine\\utils\\MainLogger, string[63] C:\\Users\\Nam Tran\\Desktop\\FOXNETWORK\\SkyBlockVersion2\\SkyBlock, string[71] C:\\Users\\Nam Tran\\Desktop\\FOXNETWORK\\SkyBlockVersion2\\SkyBlock\\plugins)\n[15:35:01] [Server thread/DEBUG]: #11 src/pocketmine/PocketMine(299): pocketmine\\server()\n[15:35:01] [Server thread/EMERGENCY]: An unrecoverable error has occurred and the server has crashed. Creating a crash dump\n[15:35:01] [Server thread/EMERGENCY]: Please upload the \"C:\\Users\\Nam Tran\\Desktop\\FOXNETWORK\\SkyBlockVersion2\\SkyBlock\\crashdumps/Thu_Aug_1-15.35.01-WIB_2019.log\" file to the Crash Archive and submit the link to the Bug Reporting page. Give as much info as you can. ", "code": [], "labels": ["Resolution: Invalid"]}
{"project": "grails_grails-core", "title": "GRAILS-2807: Obtain the whole model passed to the view in the view", "description": "Original Reporter: elvanor\nEnvironment: All\nVersion: 1.0.2\nMigrated From: <URL> It would be nice to be able to obtain the whole model passed from the controller to a view / template. This would for example allow it to be passed further down to a render template tag. Even nicer would be to automatically pass the current model in a view to a template if no model is explicitly specified. If the second option is retained, this bug is quite linked to: <URL> The only difference being that in bug 2805, the controller\u2019s properties would be used by default (when no model is explicitely passed), and in this bug, the current model of the view / template would be used by default. ", "code": [], "labels": ["Improvement", "Major", "Duplicate"]}
{"project": "GoogleChrome_lighthouse", "title": "DevTools Error: PROTOCOL_TIMEOUT", "description": "Initial URL: <URL>\nChrome Version: 73.0.3683.86\nError Message: PROTOCOL_TIMEOUT\nStack Trace: <CODE> ", "code": ["LHError: PROTOCOL_TIMEOUT\n    at eval (chrome-devtools://devtools/remote/serve_file/@f9b0bec6063ea50ce2b71f5b9abbae7beee319a6/audits2_worker/audits2_worker_module.js:1027:210)\n"], "labels": ["duplicate"]}
{"project": "yarnpkg_yarn", "title": "--frozen-lockfile is not failing as expected when a change is required from within a workspace", "description": "Do you want to request a feature or report a bug? Bug What is the current behavior? When running yarn install --frozen-lockfile from a project using Yarn workspaces, the command will complete successfully without throwing an error, even if an update to the lockfile is required due to a dependency within a workspace. If the current behavior is a bug, please provide the steps to reproduce. @devrelm has created a repository to reproduce the problem: <URL> What is the expected behavior? yarn install --frozen-lockfile should throw an error if an update to the lockfile is required. Please mention your node.js, yarn and operating system version. Yarn v1.9.4 (also tested with v1.0.0)\nNode.js v8.1.11.3\nWindows 10 build 17134.228 ", "code": [], "labels": ["triaged"]}
{"project": "angular_components", "title": "tree.treeControl.expandAll() has an error", "description": "Dear team!\nI has an error when I want to expand all node of Mat nested tree <CODE> Angular 6.1.0\nMaterial 6.4.1 ", "code": ["ERROR TypeError: Cannot read property 'reduce' of undefined\n    at NestedTreeControl.push../node_modules/@angular/cdk/esm5/tree.es5.js.NestedTreeControl.expandAll (tree.es5.js:287)\n    at Object.eval [as handleEvent] (FilterViewComponent.html:18)\n    at handleEvent (core.js:10050)\n    at callWithDebugContext (core.js:11143)\n    at Object.debugHandleEvent [as handleEvent] (core.js:10846)\n    at dispatchEvent (core.js:7509)\n    at core.js:7953\n    at HTMLButtonElement.<anonymous> (platform-browser.js:1140)\n    at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask (zone.js:421)\n    at Object.onInvokeTask (core.js:3748)\n"], "labels": ["discussion", "P3"]}
{"project": "dotnet_roslyn", "title": "TypeScript and JavaScript are read-only when debugging", "description": "Note: I already discussed this with @tmat and he asked me to log the issue here for tracking. Version Used: Git commit e74d9fa (Oct 3rd) Steps to Reproduce: Expected Behavior:\n4. The file is still editable in the editor. Actual Behavior:\n5. The file is marked as readonly (same goes for TypeScript files) It seems to me the root cause is that TypeScript/JavaScript documents belong to a different project than the project being debugged, but the EditAndContinue code only tracks one project launched by the debugger, and thus doesn\u2019t find the documents project to answer certain questions. The whole class \"VsENCRebuildableProjectImpl\" is initialized with one AbstractProject (the project being debugged): In this class, in EnterBreakStateOnPE, it creates the edit session with that one project: So when VSReadOnlyDocumentTracker::SetReadOnly asks: When it runs: The editSession.Projects doesn't contain the TypeScript project, and falls through to the MetadataNotAvailable code path. This simple hack in VsReadOnlyDocumentTracker::SetReadOnly to skip all those checks for documents belonging to the TypeScript project type... ..worked around the issue (as shown below). Maybe this is an OK temporary workaround if a proper fix is too invasive at this point. ", "code": [], "labels": ["Area-Interactive", "Resolution-Fixed"]}
{"project": "spring-projects_spring-boot", "title": "Create canonical place in the documentation for WAR deployments", "description": "Currently the documentation of how to get a WAR deployment up and running with Boot is spread between multiple places. It would be cool to have a canonical place to be able to point user to that need WAR deployments. ", "code": [], "labels": ["type: documentation"]}
{"project": "sphinx-doc_sphinx", "title": "Latexpdf broken on", "description": "With texlive-latex-base 2013.20130530-1 make latexpdf with the following command ALLSPHINXOPTS   = -d $(BUILDDIR)/doctrees/$$lang $(PAPEROPT_$(PAPER)) $(SPHINXOPTS)\n-Dlanguage=$$lang latexpdf:\nFalse lang in $(LANGUAGES);\ndo \nmkdir -p $(BUILDDIR)/latex/$(SOURCE)/$$lang $(BUILDDIR)/doctrees/$(SOURCE)/$$lang;\necho \"$(SPHINXBUILD) -b latex $(ALLSPHINXOPTS) $(SOURCE)\n$(BUILDDIR)/latex/$(SOURCE)/$$lang\";\n$(SPHINXBUILD) -b latex $(ALLSPHINXOPTS) $(SOURCE) $(BUILDDIR)/latex/$(SOURCE)/$$lang;\necho \"Running LaTeX files through pdflatex...\";\n$(MAKE) -C $(BUILDDIR)/latex/$(SOURCE)/$$lang all-pdf;\ndone\nFalse\nFalse \"pdflatex finished; the PDF files are in $(BUILDDIR)/latex/.\";\\ throws an error: ! Package babel Error: You haven't specified a language option. Same source, same conf.py, with Version: 2012.20120611-5 works fine. ", "code": [], "labels": ["bug", "wontfix"]}
{"project": "toggl-open-source_toggldesktop", "title": "Hibernation causing black window", "description": "A user has reported that the app shows entirely black for them when waking Windows from hibernation and has to be quit using task manager. ", "code": [], "labels": ["windows", "bug"]}
{"project": "dotnet_corefx", "title": "[HttpListener] [Porting] HttpListener.GetContext on Windows throws an NRE for NTLM and Negotiate authentication", "description": "The following test gives an example of this (I'm currently writing tests for HttpListener authentication): This does not fail on desktop. The netcoreapp stack trace is: <CODE> HttpListener... the gift that keeps on giving ", "code": ["System.Net.Tests.AuthenticationTests.NtlmAuthentication_NoRequestHeaders_ReturnsForbiddenStatusCode [FAIL]\n        System.NullReferenceException : Object reference not set to an instance of an object.\n        Stack Trace:\n           C:\\Users\\hugh\\Documents\\GitHub\\corefx\\src\\System.Net.HttpListener\\src\\System\\Net\\Windows\\HttpListener.Window\n  s.cs(1918,0): at System.Net.HttpListener.DisconnectAsyncResult..ctor(HttpListener httpListener, UInt64 connectionId)\n           C:\\Users\\hugh\\Documents\\GitHub\\corefx\\src\\System.Net.HttpListener\\src\\System\\Net\\Windows\\HttpListener.Window\n  s.cs(1645,0): at System.Net.HttpListener.RegisterForDisconnectNotification(UInt64 connectionId, DisconnectAsyncResult\n  & disconnectResult)\n           C:\\Users\\hugh\\Documents\\GitHub\\corefx\\src\\System.Net.HttpListener\\src\\System\\Net\\Windows\\HttpListener.Window\n  s.cs(1306,0): at System.Net.HttpListener.HandleAuthentication(RequestContextBase memoryBlob, Boolean& stoleBlob)\n           C:\\Users\\hugh\\Documents\\GitHub\\corefx\\src\\System.Net.HttpListener\\src\\System\\Net\\Windows\\HttpListener.Window\n  s.cs(655,0): at System.Net.HttpListener.GetContext()\n           C:\\Users\\hugh\\Documents\\GitHub\\corefx\\src\\System.Net.HttpListener\\tests\\AuthenticationTests.cs(310,0): at Sy\n  stem.Net.Tests.AuthenticationTests.<AuthenticationFailure>b__30_0()\n              at System.Threading.Tasks.Task`1.InnerInvoke()\n              at System.Threading.Tasks.Task.<>c.<.cctor>b__276_1(Object obj)\n              at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Obj\n  ect state)\n              at System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot)\n           --- End of stack trace from previous location where exception was thrown ---\n              at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n              at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n           C:\\Users\\hugh\\Documents\\GitHub\\corefx\\src\\System.Net.HttpListener\\tests\\AuthenticationTests.cs(317,0): at Sy\n  stem.Net.Tests.AuthenticationTests.<AuthenticationFailure>d__30.MoveNext()\n           --- End of stack trace from previous location where exception was thrown ---\n              at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n              at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n           C:\\Users\\hugh\\Documents\\GitHub\\corefx\\src\\System.Net.HttpListener\\tests\\AuthenticationTests.cs(127,0): at Sy\n  stem.Net.Tests.AuthenticationTests.<NtlmAuthentication_NoRequestHeaders_ReturnsForbiddenStatusCode>d__14.MoveNext()\n           --- End of stack trace from previous location where exception was thrown ---\n              at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n              at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.GetResult()\n           --- End of stack trace from previous location where exception was thrown ---\n              at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n              at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.GetResult()\n           --- End of stack trace from previous location where exception was thrown ---\n              at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\n              at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task)\n              at System.Runtime.CompilerServices.TaskAwaiter.GetResult()\n"], "labels": ["os-windows", "test bug", "area-System.Net.Http"]}
{"project": "influxdata_chronograf", "title": "Chronograf (1.7.7) o is not a function", "description": "What browser are you using (name and version)? Firefox 64.0.2 (64 bit) What operating system are you using? MAC OS Mojave 10.14.2 Please describe what you were trying to do when you encountered this error:\nI was setting up the Chronograf for the very first time and tried the default system template. When I got to the Kapacitor question I got a little confused and pressed the back button a couple of times and then I ended up here..... <CODE> ", "code": ["l/i.onChangeInput/</<@http://10.101.1.101:8888/src.216c1ae9.js:4691:3998\npl@http://10.101.1.101:8888/src.216c1ae9.js:716:45570\ndl@http://10.101.1.101:8888/src.216c1ae9.js:716:45322\nxi@http://10.101.1.101:8888/src.216c1ae9.js:716:84392\nwi@http://10.101.1.101:8888/src.216c1ae9.js:716:79945\nki@http://10.101.1.101:8888/src.216c1ae9.js:716:79561\nLe@http://10.101.1.101:8888/src.216c1ae9.js:716:90853\nWe@http://10.101.1.101:8888/src.216c1ae9.js:716:10444\nFn@http://10.101.1.101:8888/src.216c1ae9.js:716:30800\nSi@http://10.101.1.101:8888/src.216c1ae9.js:716:85578\nRn@http://10.101.1.101:8888/src.216c1ae9.js:716:30543\n\n"], "labels": ["kind/bug"]}
{"project": "spring-projects_spring-boot", "title": "Incorrect jms health status when using UserCredentialsConnectionFactoryAdapter", "description": "In our setup we are getting the QueueConnectionFactory from the Context by JNDI name look up. Then we inject it as the targetConnectionFactory into UserCredentialsConnectionFactoryAdapter. The adapter provides the user credentials and makes the actual connection.\nThe problem is that the both are instances of the ConnectionFactory and 2  health checks are done for the both instances instead of only 1 for UserCredentialsConnectionFactoryAdapter. Obviously, the call for UserCredentialsConnectionFactoryAdapter is successful because it is made with the user credentials and the call for QueueConnectionFactory returns javax.jms.JMSSecurityException: Inauthentic Client:\n\"jms\":{\"status\":\"DOWN\", \"userCredentialsConnectionFactoryAdapter\":{\"status\":\"UP\",\"provider\":\"SonicMQ/Java\"}, \"connectionFactory\":{\"status\":\"DOWN\",\"error\":\"javax.jms.JMSSecurityException: Inauthentic Client\"}}\nThus, the final status is \"DOWN\" instead of \"UP\".\nIs there any solution/workaround for this problem? ", "code": [], "labels": ["status: invalid"]}
{"project": "EasyCorp_EasyAdminBundle", "title": "Unable to save entity when doctrine enum type is not changed.", "description": "BUG REPORT: ", "code": [], "labels": ["unconfirmed", "help wanted", "bug"]}
{"project": "PyCQA_pylint", "title": "Add option to ignore code in if TYPE_CHECKING", "description": "In typed code, this is common pattern: If some_type is defined in stub, it doesn't have to exist in runtime (e. g. wsgiref.types is only available in .pyi files). Pylint issues an error for this code, while it's perfectly valid.\nPylint isn't a type checker, so it should ignore all code in if TYPE_CHECKING:. Add option like to ignore all errors or, probably, only import-related errors in if TYPE_CHECKING: blocks. ", "code": [], "labels": ["enhancement"]}
{"project": "facebook_hhvm", "title": "date_create_immutable - incompatible with PHP on failure", "description": "I think I have found an incompatibility and inconsistency in the date_create_immutable function. If you use the  date_create or  date_create_immutable functions with a unparseable argument, the expected return value is false. But the actual output is: <CODE> This means that it is both incompatible with PHP and inconsistent with the \"sibling\" function date_create which seems to behave correctly. You can see a live example here: <URL> This could be caused when the DTI constructor is called straight away and the exception is not handled. It is actually stated in the documentation, that this should be alias of the constructor, which is not entirely true (although it is the same as in the PHP manual), because the difference is that the \"procedural\" API returns values indicating errors, where the \"OOP\" API throws exceptions. Found this while playing with Doctrine DBAL, so quite big impact libraries might be affected. Unfortunatelly Doctrine DBAL hhvm build is next to nonexistent so I can't even send a failing test/pull there. ", "code": ["bool(false)\n\nFatal error: Uncaught exception 'Exception' with message 'DateTime::__construct(): Failed to parse time string (foo) at position 0 (f): The timezone could not be found in the database' in :\nStack trace:\n#0 (): DateTime->__construct()\n#1 (): DateTimeImmutable->__construct()\n#2 /in/aXGmG(5): date_create_immutable()\n#3 {main}\n\nProcess exited with code 255.\n"], "labels": ["php5 incompatibility"]}
{"project": "ariya_phantomjs", "title": "Still have this problem now, someone is solved?", "description": "", "code": [], "labels": ["stale"]}
{"project": "phpmyadmin_phpmyadmin", "title": "(2.3.2) Javascript bug in setPointer() function", "description": "After porting your Javascript setPointer() function \n(from /libraries/functions.js) to an application of my own I \nfound a slight bug.  Though it will not likely affect the \nPhpMyAdmin application I thought you might want to \naddress it anyways. In the section (4.1) that sets the new row color the \nfollowing code should be changed: // 4. Defines the new color\n// 4.1 Current color is the default one\nif (currentColor == \u2018\u2019\n|| currentColor.toLowerCase() == \ntheDefaultColor.toLowerCase()) {\nif (theAction == \u2019over\u2019 &amp;&amp; thePointerColor != \u2018\u2019) {\nnewColor              = thePointerColor;\n}\nelse if (theAction == \u2019click\u2019 &amp;&amp; theMarkColor != \u2019\u2019) {\nnewColor              = theMarkColor;\n} \u2026 to \u2026 // 4. Defines the new color\n// 4.1 Current color is the default one\nif (currentColor == \u2018\u2019\n|| currentColor.toLowerCase() == \ntheDefaultColor.toLowerCase()) {\nif (theAction == \u2019over\u2019 &amp;&amp; thePointerColor != \u2018\u2019) {\nnewColor              = thePointerColor;\n}\nelse if (theAction == \u2019click\u2019 &amp;&amp; theMarkColor != \u2019\u2019) {\nnewColor              = theMarkColor;\n// NEW LINE \u2014v\nmarked_row[theRowNum] = true;\n} The reason is that if setPointer() is called from another \nfunction (i.e. to set default highlited rows using \ndocument.onLoad()) the marked_row array needs to be \nupdated in order to ensure that the row color is changed \nback properly.  Otherwise, the row will remain colored \nwith the value of thePointerColor variable despite \nrepeated calls to setPointer(). - Original URL: <URL>\n- Original author: xangelusx\n- Found in version: 2.3.2 ", "code": [], "labels": ["bug"]}
{"project": "matomo-org_matomo", "title": "Matomo shows IP of virtual machine host", "description": "Hey, I have a really strange problem with matomo. When I track users, every user \"has\" the ip address of the host which the virtual machine with matomo is running on. I really have no idea what could cause this kind of problem. I am very confused and appreciate every kind of help.\nThank you! ", "code": [], "labels": ["answered"]}
{"project": "ampproject_amphtml", "title": "amp-image-viewer: mutation inside measure phase", "description": "  This is done inside a measure phase! ", "code": [], "labels": ["Type: Bug", "P2: Soon", "Category: Presentation"]}
{"project": "realm_realm-java", "title": "io.realm.exceptions.RealmMigrationNeededException: Field count is less than expected - expected 9 but was 6", "description": "My Requirement was to add three new columns(One Boolean type , two new String type) to the existing database. Old Realm model contained of 6 fields and now after i add the 3 new fields i have 9 in total. I created a RealmMigration class and new Realm Configuration with schemaVersion to 1.(This is the first time i am migrating local database.) In the RealmMigration i add the new fields to the RealmObjectSchema  for my model class. When i try to initialise realm by using getInstance(newConfig) , the migration happened (i printed the new table columns and it showed the three new fields) but it crashed saying \"io.realm.exceptions.RealmMigrationNeededException: Field count is less than expected - expected 9 but was 6. Migration should have succeeded with the three new fields having default values. 07-19 22:30:22.413 2145-2145/au.com.* E/AndroidRuntime: FATAL EXCEPTION: main\nProcess: au.com., PID: 2145\njava.lang.RuntimeException: Unable to start activity ComponentInfo{ au.com.test.presentation.dashboard.DashboardActivity}: io.realm.exceptions.RealmMigrationNeededException: Field count is less than expected - expected 9 but was 6\nat android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2984)\nat android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3045)\nat android.app.ActivityThread.-wrap14(ActivityThread.java)\nat android.app.ActivityThread$H.handleMessage(ActivityThread.java:1642)\nat android.os.Handler.dispatchMessage(Handler.java:102)\nat android.os.Looper.loop(Looper.java:154)\nat android.app.ActivityThread.main(ActivityThread.java:6776)\nat java.lang.reflect.Method.invoke(Native Method)\nat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1520)\nat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1410)\nCaused by: io.realm.exceptions.RealmMigrationNeededException: Field count is less than expected - expected 9 but was 6\nat io.realm.CustomerDestinationRealmProxy.validateTable(CustomerDestinationRealmProxy.java:465)\nat io.realm.DefaultRealmModuleMediator.validateTable(DefaultRealmModuleMediator.java:87)\nat io.realm.Realm.initializeRealm(Realm.java:359)\nat io.realm.Realm.createAndValidate(Realm.java:317)\nat io.realm.Realm.createInstance(Realm.java:282)\nat io.realm.RealmCache.createRealmOrGetFromCache(RealmCache.java:145)\nat io.realm.Realm.getInstance(Realm.java:229)\nat au.com.test*.data.realm.RealmLocalStorage.open(RealmLocalStorage.java:48)\nat injection.modules.PersistenceModule$1.run(PersistenceModule.java:130)\nat io.reactivex.internal.operators.completable.CompletableFromAction.subscribeActual(CompletableFromAction.java:34)\nat io.reactivex.Completable.subscribe(Completable.java:1517)\nat io.reactivex.internal.operators.completable.CompletableSubscribeOn$SubscribeOnObserver.run(CompletableSubscribeOn.java:64)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:428)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)\nat java.lang.Thread.run(Thread.java:762)* Running the updated app on to the exisitng app cause the crash. Logs printed from the app migration class indicates that the migration happened because it was printing the new table columns. Below are the logs 07-23 16:51:30.369 28663-28914/ I/AppStateMigration: Opening Storage : app_state.realm\n07-23 16:51:30.369 28663-28914/ I/AppStateMigration: Opening Thread Name : realm\n07-23 16:51:30.382 28663-28914/ I/AppStateMigration: Old Version : 0\n07-23 16:51:30.382 28663-28914/ I/AppStateMigration: New Version : 1\n07-23 16:51:30.382 28663-28914/ I/AppStateMigration: Contains : true\n07-23 16:51:30.385 28663-28914/ I/AppStateMigration: =====Current Field Names======\n07-23 16:51:30.385 28663-28914/ I/AppStateMigration: field : destinationId\n07-23 16:51:30.385 28663-28914/ I/AppStateMigration: field : name\n07-23 16:51:30.385 28663-28914/ I/AppStateMigration: field : address\n07-23 16:51:30.385 28663-28914/ I/AppStateMigration: field : coordinates\n07-23 16:51:30.385 28663-28914/ I/AppStateMigration: field : deliveryInstructions\n07-23 16:51:30.385 28663-28914/ I/AppStateMigration: field : driverNotes\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: =====Migrated Field Names======\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : destinationId\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : name\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : address\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : coordinates\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : deliveryInstructions\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : driverNotes\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : isNewCustomer\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : packagingLabel\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: field : packagingCode\n07-23 16:51:30.393 28663-28914/ I/AppStateMigration: Migrating Thread Name : realm public class AppStateStorageRealmMigration implements RealmMigration { <CODE> } Realm version(s): ?  io.realm:realm-gradle-plugin:3.1.2 Realm sync feature enabled: NO Android Studio version: ? 3.0 Which Android version and device: ? Testing on Android 7.0 ", "code": ["private static final String TAG = \"AppStateMigration\";\nprivate static final String CUSTOMER_DESTINATION = \"CustomerDestination\";\nprivate static final String IS_NEW_CUSTOMER = \"isNewCustomer\";\nprivate static final String PACKAGING_LABEL = \"packagingLabel\";\nprivate static final String PACKAGING_CODE = \"packagingCode\";\nprivate final Logger logger;\n\npublic AppStateStorageRealmMigration(final Logger logger) {\n    this.logger = logger;\n}\n\n@Override\npublic void migrate(final DynamicRealm realm, final long oldVersion, final long newVersion) {\n\n    logger.i(TAG, \"Old Version : \" + oldVersion);\n    logger.i(TAG, \"New Version : \" + newVersion);\n\n    long currentVersion = oldVersion;\n    if (currentVersion == 0) {\n        RealmSchema schema = realm.getSchema();\n\n        RealmObjectSchema taskSchema = schema.get(CUSTOMER_DESTINATION);\n\n        Set<String> originalFieldNames = taskSchema.getFieldNames();\n\n        logger.i(TAG, \"Current Field Names \");\n        for (String fieldName : originalFieldNames) {\n            logger.i(TAG, \"field : \" + fieldName);\n        }\n\n        //Adding new fields 'isNewCustomer', 'packagingLabel', 'packagingCode'\n        taskSchema.addField(IS_NEW_CUSTOMER, Boolean.class)\n                .addField(PACKAGING_LABEL, String.class)\n                .addField(PACKAGING_CODE, String.class);\n                \n        Set<String> migratedfieldNames = taskSchema.getFieldNames();\n\n        logger.i(TAG, \"Migrated Field Names \");\n        for (String fieldName : migratedfieldNames) {\n            logger.i(TAG, \"field : \" + fieldName);\n        }\n        \n        currentVersion++;\n    }\n}\n"], "labels": ["T-Help", "O-Community"]}
{"project": "godotengine_godot", "title": "Subpixel Label rendering issues when Label within Node2D", "description": "Godot version:\n3.1.1 stable, but also tested on e802da4 OS/device including version:\nWindows 10 | RTX 2070 Super, 431.68 Issue description:\nWhen a Control Node using a Dynamic Font is contained withing a Node2D, which is in a subpixel position (in this case 0.5 pixels), each letter will be rendered on a different height.\n\n(Open in a new tab to see it more easily) Meaning the issue title is similar to #15124 but it is a different problem Steps to reproduce: Minimal reproduction project:\nBug Demo Wrong Text Rendering.zip I want to mention that the reproduction project I provided shows the problem, but in my project I am working on, the offset letters are even more visible. ", "code": [], "labels": ["bug", "topic:rendering"]}
{"project": "gephi_gephi", "title": "New feature: change label orientation/offset", "description": "Setting for label orientation or offset from node (above,below etc.) No way to specify Labels are clobbering each other when nodes are aligned vertically ", "code": [], "labels": ["Wishlist"]}
{"project": "ElemeFE_element", "title": "NavMenu \u8bbe\u7f6edefault-active\u65f6\uff0c\u5982\u679c\u4e3a\u5b50\u7ea7\u83dc\u5355\u5e94\u8be5\u81ea\u52a8\u5c55\u5f00\u7236\u7ea7\u83dc\u5355", "description": "\u5982\u9898\uff0c\u8fd9\u6837\u5904\u7406\u540e\uff0c\u6839\u636e\u8def\u7531\u6fc0\u6d3b\u9ed8\u8ba4\u83dc\u5355\u65f6\uff0c\u83dc\u5355\u5c31\u53ef\u4ee5\u81ea\u52a8\u5c55\u5f00\u5230\u5bf9\u5e94\u8282\u70b9\u3002 ", "code": [], "labels": ["type: feature request"]}
{"project": "mmistakes_minimal-mistakes", "title": "How to change lines for author bio", "description": "Hi, Thank you for this great theme! I am writing to ask how to change line in the author bio part. Instead of a sentence spanning the whole left side bar, I want to use a few words on different rows in the author bio part. I would appreciate your help. Thank you. ", "code": [], "labels": ["Type: Support", "Status: Stale"]}
{"project": "tensorflow_tensorflow", "title": "cant downlod tensorflow it shows could not find a versone", "description": "Please go to Stack Overflow for help and support: <URL> If you open a GitHub issue, here is our policy: Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow. You can collect some of this information using our environment capture script: <URL> You can obtain the TensorFlow version with python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\" Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem. ", "code": [], "labels": ["type:build/install", "stat:awaiting response"]}
{"project": "lucas-clemente_quic-go", "title": "Call OnCongestionEvent on RTO retransmission", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug"]}
{"project": "firefox-devtools_debugger", "title": "[Preview] 'Split console' overlays the debugger variable tooltip", "description": "STR: AR:\nThe variable tooltip is cropped:\n ER:\nDon't crop. Either have the tooltip above the Split console. Or: Take the opened console into consideration while calculation into which direction the tooltop should open (So in this case not to the bottom but to the top). ", "code": [], "labels": ["backlog", " bug"]}
{"project": "CityOfZion_neon-wallet", "title": "Return Clickable NEO/GAS/BLOCK/VERSION Values", "description": "In previous versions of Neon Wallet you used to be able to click the 'Block' etc and it'd return the page requested. It used to be a really quick way to get the current blocklist. Can the feature be restored? Clicking NEO/GAS returns neogas.io (or something else?)\nClicking Block returns neotracker.io/browse/block/1\nClicking Version returns neonwallet.com <URL> - Reference If there was a reason this was removed, apologies, please delete/close this issue/ticket. ", "code": [], "labels": ["enhancement"]}
{"project": "kubernetes_kubernetes", "title": "Remove deprecated alpha for volume provisioning, if we're happy with Beta", "description": "\nNo description provided.\n ", "code": [], "labels": ["team/cluster", "area/kubelet", "sig/storage"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Patch for broken pagination dropdown (Bug id: 3151925)", "description": "URL for the Get method was missing, most probably due to the changes done while AJAXifying the PMA. ", "code": [], "labels": ["patch"]}
{"project": "DynamoRIO_dynamorio", "title": "improved isolation of user32.dll: handle privlib loading user32 when app doesn't, etc.", "description": "From bruen...@google.com on October 23, 2013 14:54:22 I'm splitting this out from issue #235 , as that's really about ntdll\nredirection. From the original issue #157 , and from issue #235c#3: The biggest issue today is handling a dynamically loaded user32.dll, or a\nprivlib-loaded user32.dll when the app does not use user32.dll. We actually hit the latter with the minidump client from issue #1292 on\nhello.exe, which does not use user32: ** TODO CRASH running app w/o user32.dll when privlib loads gdi32.dll Running the minidump client from issue #1292 on hello.exe, which does not use user32: Private gdi32.dll pulls in user32.dll, which we do private-load when the\napp has not already loaded it.  The user32 entry invokes the gdi32 entry\nbefore the gdi32 imports are all set up: ASYNCH intercepted exception in thread 91236 at pc 0x000589bc Attempt to execute non-executable address 000589bc 0:000> kn\n*** Stack trace for last set context - .thread/.cxr resets it WARNING: Frame IP not in any known module. Following frames may be wrong.\n00 1778dc10 7547640b 0x589bc\n01 1778dd04 75476375 GDI32!ReadDisableMetaFilesRegKey+0x45\n02 1778dd10 761fb970 GDI32!GdiDllInitialize+0xd\n03 1778e3d0 6422e995 USER32!_UserClientDllInitialize+0x32f\n04 1778e440 641016b7 dynamorio!privload_call_entry+0x315 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 1146]\n05 1778e458 64100b27 dynamorio!privload_load_finalize+0x137 [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 655]\n06 1778e480 6422f90d dynamorio!privload_load+0x2c7 [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 539]\n07 1778e4a0 6422d949 dynamorio!privload_locate_and_load+0x21d [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 1396]\n08 1778e4c0 6422dc10 dynamorio!privload_lookup_locate_and_load+0xa9 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 844]\n09 1778e504 6410162d dynamorio!privload_process_imports+0x270 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 918]\n0a 1778e518 64100b27 dynamorio!privload_load_finalize+0xad [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 646]\n0b 1778e540 6422f90d dynamorio!privload_load+0x2c7 [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 539]\n0c 1778e560 6422d949 dynamorio!privload_locate_and_load+0x21d [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 1396]\n0d 1778e580 6422dc10 dynamorio!privload_lookup_locate_and_load+0xa9 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 844]\n0e 1778e5c4 6410162d dynamorio!privload_process_imports+0x270 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 918]\n0f 1778e5d8 64100b27 dynamorio!privload_load_finalize+0xad [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 646]\n10 1778e600 6422f90d dynamorio!privload_load+0x2c7 [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 539]\n11 1778e620 6422d949 dynamorio!privload_locate_and_load+0x21d [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 1396]\n12 1778e640 6422dc10 dynamorio!privload_lookup_locate_and_load+0xa9 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 844]\n13 1778e684 6410162d dynamorio!privload_process_imports+0x270 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 918]\n14 1778e698 64100b27 dynamorio!privload_load_finalize+0xad [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 646]\n15 1778e6c0 6422f90d dynamorio!privload_load+0x2c7 [c:\\src\\dr\\git\\src\\core\\loader_shared.c @ 539]\n16 1778e6e0 6422d949 dynamorio!privload_locate_and_load+0x21d [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 1396]\n17 1778e700 6422d86e dynamorio!privload_lookup_locate_and_load+0xa9 [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 844]\n18 1778e724 64233a51 dynamorio!privload_load_private_library+0x2e [c:\\src\\dr\\git\\src\\core\\win32\\loader.c @ 860]\n19 1778e73c 63e210f8 dynamorio!redirect_LoadLibraryA+0x51 [c:\\src\\dr\\git\\src\\core\\win32\\drwinapi\\kernel32_lib.c @ 139]\n1a 1778e74c 63e23fd4 dbghelp!Win32LiveSystemProvider::GetCpuPowerInfo+0x19\n1b 1778e778 63e1d69c dbghelp!NtWin32LiveSystemProvider::GetCpuPowerInfo+0x98\n1c 1778e7c0 63e1e9e1 dbghelp!GenAllocateProcessObject+0x1f0\n1d 1778ec10 63e1a976 dbghelp!GenGetProcessInfo+0x31\n1e 1778ed9c 63e1adbb dbghelp!MiniDumpProvideDump+0x175\n1f 1778ee18 740f125c dbghelp!MiniDumpWriteDump+0x1ce\n20 1778eeb4 1775109c minidump!snap_cb3+0x8c [c:\\src\\dr\\bugs\\minidump\\minidump.c @ 102] 754763f4 8b356c014775    mov     esi,dword ptr [GDI32!_imp__RtlInitUnicodeString (7547016c)]\n754763fa 8d8540ffffff    lea     eax,[ebp-0C0h]\n75476400 33ff            xor     edi,edi\n75476402 50              push    eax\n75476403 893d10014c75    mov     dword ptr [GDI32!gbDisableMetaFiles (754c0110)],edi\n75476409 ffd6            call    esi 0:000> dd GDI32!_imp__RtlInitUnicodeString\n7547016c  000589bc 000589d4 000589f0 00058a04 This is not a relocation issue b/c it's at preferred base: privload_load: loading C:\\Windows/system32/GDI32.dll\nnew dynamo vm area: 0x75460000-0x754f0000 map_file\nprivload_process_imports: GDI32.dll imports from API-MS-Win-Core-LocalRegistry-L1-1-0.dll The problem here, I believe, is that we have only processed\nsome of gdi32's imports when we hit user32 and load it.  It then invokes\nthe gdi32 entry before we've finished processing its imports, in particular\nits imports from ntdll! If the app itself used user32 this wouldn't happen. USER32!_UserClientDllInitialize+0x329:\n761fb96a ff158c021f76    call    dword ptr [USER32!_imp__GdiDllInitialize (761f028c)] Basically we're hitting this known issue which was under issue #235: <CODE> Original issue: <URL> ", "code": ["/* FIXME issue #235: loading a private user32.dll is problematic: it registers\n * callbacks that KiUserCallbackDispatcher invokes.  For now we do not\n * duplicate it.  If the app loads it dynamically later we will end up\n * duplicating but not worth checking for that.\n * If client private lib loads user32 when app does not statically depend\n * on it, we'll have a private copy and no app copy: this may cause\n * problems later but waiting to see.\n */\n"], "labels": ["OpSys-Windows", "Priority-Medium", "Migrated"]}
{"project": "iina_iina", "title": "add Collection featrue", "description": "like the Potplayer on Windows\uff0cthe videos can be sorted on this own folder or collection tab,  then next time I can locate easily. Thanks! ", "code": [], "labels": ["type: feature request"]}
{"project": "vnpy_vnpy", "title": "log4mongo\u4ee3\u66ffmainEngine\u7684dbLog\u529f\u80fd", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement"]}
{"project": "golang_go", "title": "runtime/pprof: does StartTrace belong?", "description": "Dmitriy's new tracing has API entry points in runtime/pprof because all the other runtime tracing does. But it's not consumed by pprof and probably belongs somewhere else. Decide. ", "code": [], "labels": ["FrozenDueToAge"]}
{"project": "google_traceur-compiler", "title": "Support `super` in object literals", "description": "code: SyntaxError: Unexpected reserved word... ", "code": [], "labels": ["bug"]}
{"project": "SAP_openui5", "title": "No wordwrap in IE for fragment with FeedListItem in Messagebox with custom layout", "description": "Replication instructions: My temporary fix in onAfterRendering: <CODE> ", "code": ["                        if (sap.ui.Device.browser.msie) {\n                            var my_css_class = {\n                                '-ms-word-break' : 'break-all',\n                                width : '290px'\n                            };\n                            $('.sapMFeedListItemTextText').css(my_css_class);\n                        }\n"], "labels": ["bug", "fixed"]}
{"project": "npm_npm", "title": "\"npm install\" executes \"npm pretest\"", "description": "I found a similar tickets described that \"prepublish\" are executed during \"npm install\" (like #3059). This behavior seems to be fixed (it's not executed anymore in 4.x+). But is there some documentation, discussion, plans what's with \"pretest\"? Currently \"npm install\" executes \"npm pretest\" and I don't found any information why this behavior exists. ", "code": [], "labels": ["support", "bug"]}
{"project": "kythe_kythe", "title": "Update third_party/src/google.golang.org packages [phab:D650]", "description": "Created by schroederc at 2015-12-15 17:15:17: ", "code": [], "labels": ["phabricator diff"]}
{"project": "apache_druid", "title": "KafkaIndexingService Load Spec not setting correctly", "description": "See discussion in <URL> Unclear if this is a bug or a misconfiguration, so I'm opening this ticket to track figuring that out. Patches to HdfsDataSegmentPusher since 0.9.1.1 that may be related: #3196, #3494, #3547, #3555. ", "code": [], "labels": ["Bug"]}
{"project": "ionic-team_ionic", "title": "No way to disable caching of tabs", "description": "After you run the tabs tutorial ionic starts projectName tabs --v2, there is no way to disable the cache in between the tabs.  What happens is when each tab is clicked, it is cached and added to the DOM.  This is problematic on tabs that dynamically request new data when clicked. If caching is disable between the tabs, the expectation is that the code would fire every time a tab is clicked. Steps to reproduce: Observe that when you click on the home button, and if you add logging on the constructor, there is no indication that the chats button ever loads again.  This is a problem if there is new data on the chats page. Which Ionic Version? 1.x or 2.x <CODE> Run ionic info from terminal/cmd prompt: (paste output below) <CODE> ", "code": ["v2\n", "Cordova CLI: 6.0.0\nIonic Version: 2.0.0-beta.2\nIonic CLI Version: 2.0.0-beta.19\nIonic App Lib Version: 2.0.0-beta.9\nOS: Distributor ID: Ubuntu Description: Ubuntu 14.04.3 LTS \nNode Version: v5.4.1\n"], "labels": ["v2"]}
{"project": "facebook_react-native", "title": "ERROR react-native link", "description": "Hi, im having problem with the installation. I can succesfully install native-base but encountered error after running \"dependencies\": {\n\"firebase\": \"^4.1.3\",\n\"native-base\": \"^2.2.0\",\n\"react\": \"16.0.0-alpha.3\",\n\"react-native\": \"0.44.2\",\n\"react-native-action-button\": \"^2.7.2\",\n\"react-native-drawer\": \"^2.3.0\",\n\"react-native-fbsdk\": \"^0.6.0\",\n\"react-native-google-signin\": \"^0.10.0\",\n\"react-native-icon-badge\": \"^1.1.1\",\n\"react-native-linear-gradient\": \"^2.0.0\",\n\"react-native-maps\": \"^0.15.2\",\n\"react-native-modal\": \"^2.5.0\",\n\"react-native-parallax-scroll-view\": \"^0.19.0\",\n\"react-native-router-flux\": \"3.38.0\",\n\"react-native-splash-screen\": \"^2.1.0\",\n\"react-native-swiper\": \"^1.5.4\",\n\"react-native-tab-view\": \"^0.0.66\",\n\"react-native-vector-icons\": \"^4.1.1\",\n\"react-redux\": \"5.0.4\",\n\"redux\": \"3.6.0\",\n\"redux-thunk\": \"^2.2.0\"\n}, \"react-native link\" successfully ", "code": [], "labels": ["Resolution: Locked"]}
{"project": "OnsenUI_OnsenUI", "title": "ons.slidescreen.ontoogle, ons.slidescreen.setAbovepage,  is stopped working.....", "description": "This is the error i am getting in console, please look at this, :: ----------   'webkitRequestAnimationFrame' is vendor-specific. Please use the standard 'requestAnimationFrame' instead. ", "code": [], "labels": ["outdated"]}
{"project": "CleverRaven_Cataclysm-DDA", "title": "Add an option to make the map square-fonted instead?", "description": "When I use the map, I really need to be able to calculate distances correctly, which is irritatingly difficult with rectangular tiles. Having an option to set the map in square-font would allow for much better proportions and awareness of space in general, while still leaving the die-hard fans of rectangular the possibility to stick with the current one. ", "code": [], "labels": ["<Suggestion / Discussion>"]}
{"project": "kubernetes_kubernetes", "title": "Simplify grace period related code in NodeController", "description": "The code is hard to understand and debug. Related issue: #14652. cc: @gmarek @davidopp @smarterclayton @fgrzadkowski @mikedanese ", "code": [], "labels": ["kind/cleanup", "team/control-plane", "priority/backlog", "sig/node", "lifecycle/stale"]}
{"project": "glpi-project_glpi", "title": "Task category translation problem when sending notifications", "description": "Dear all, There is a weird problem with task category translations when sending a task notification.\nLet's see the following configuration: Logged in GLPi as User Y (en_US) add a task in a ticket assigning User X as task technician. Define the task category for this task as Task Category TC. Then User X will receive a notification with task category being in en_US and not in fr_FR. Thank you,\nRegards,\nTomolimo PS: I'm going to provide a fix for this ", "code": [], "labels": ["bug"]}
{"project": "kubernetes_test-infra", "title": "Handling of vendor/.../OWNERS with rebases is annoying", "description": "I keep getting automated review requests when people bump their kubernetes dependency in various openshift subprojects just because I'm listed as a reviewer in a few parts of the kubernetes tree. eg, openshift/service-ca-operator#40, openshift/kubernetes-autoscaler#76, openshift/console-operator#163, openshift/image-registry#166, openshift/service-ca-operator#16, openshift/cluster-api-provider-aws#160. I don't even know what some of those projects do. They definitely don't want me reviewing their rebases. In previous discussions of vendor-vs-OWNERS (eg, #3694, #6404) it was pointed out that obeying vendored OWNERS files can be useful because the people listed there are likely to be the people you want reviewing the change. But that only applies to the case of cherry-picking a single fix or making a small local change. In the case of a rebase, the review request is basically just saying \"Hey, remember when we changed this code upstream a few months ago? Yeah, those were good times!\" So, ideas: ", "code": [], "labels": ["kind/feature"]}
{"project": "vaadin_framework", "title": "VaadinService.closeInactiveUIs does not set UI threadlocals", "description": "Originally by @jdahlstrom VaadinService.closeInactiveUIs should call UI.close() via UI.accessSynchronously() to ensure UI.getCurrent() is properly set in case UI.close() is overridden by user. removeClosedUIs already does this. Imported from <URL> issue #12186 ", "code": [], "labels": ["bug"]}
{"project": "woocommerce_woocommerce", "title": "Out of stock message stays visible", "description": "When viewing a product variation that is marked out of stock, the Out of Stock message appears and the add to cart button disappears.  When you select another variation and it is in stock, the add to cart button reappears, but the Out of Stock message stays visible. ", "code": [], "labels": ["status: needs feedback"]}
{"project": "Qiskit_qiskit-terra", "title": "NewConnectionError Errno 111 Connection refused", "description": "After I execute this code against the IBM backend : ibmqx4 or ibmq_16_melbourne job = execute(self.qc, self.backend, shots=args.shots, max_credits=3)  while not job.done: time.sleep(20) jobState=job.status  It crashes (randomly) after 2-4 minutes with the error below if I'm  connecting from the NERSC computing center , this is domain IP 2620:83:8000:108:0:0:1:244.  But sometimes I it runs through.\nWhen I run from home (using Comcast) I never have this problem - same laptop, even the same token. {'job_id': '5bad12a058af9e003e198e0f', 'status': <JobStatus.ERROR: 'job incurred error'>, 'status_msg': \"HTTPSConnectionPool(host='quantumexperience.ng.bluemix.net', \" 'port=443): Max retries exceeded with url: ' '/api/Jobs/5bad12a058af9e003e198e0f?access_token=4M7QJSFYAfU7EgV9qOUJLa2OWJDlzHE2OZWJo9pPNYkEriLJz5jv40pHd5J3byPH ' '(Caused by ' \"NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection \" 'object at 0x7fc01fe6f6d8>: Failed to establish a new ' \"connection: [Errno 111] Connection refused',))\"} The loop querying if job is done should continue until job.done=True.\nI have observed this pattern (works from home but not from NERSC) for many days, so it is not just one bad day. I also spoke to NERCS expert and they see not reason on our end for blocking connection.  I tried old token, new token - all combinations - it does not matter. ", "code": [], "labels": ["bug"]}
{"project": "frontendbr_forum", "title": "Compatibilidade ES6 para IE8  com polyfills, shim", "description": "Galera, estamos iniciando o desenvolvimento de um produto (especificamente integra\u00e7\u00e3o SCORM) que necessita de compatibilidade com browser antigos como IE8. A inten\u00e7\u00e3o era desenvolver em ES6 para viabilizar escalabilidade e organiza\u00e7\u00e3o do produto. Queria saber se voc\u00eas tem algum case e experi\u00eancia de o qu\u00e3o vi\u00e1vel est\u00e1 o uso do es5-shim e outros polyfills. ", "code": [], "labels": ["[D\u00favida]", "JavaScript"]}
{"project": "ovh_cds", "title": "Add a log action to plugin-kafka-publish", "description": "Goal: add logs visible on the CDS side during the waiting time (execution of something long over kafka)\nThe way it could be nice to be used:\nplugin-kafka-publish log  logs.txt logs.txt to be received by the plugin on CDS side and not to be considered as an ACK, only appending the steps logs (where [XXX seconds] Please wait... is usually written) At the end of the plugin-kafka step on CDS (ie proper ACK received), it could be a really nice to get all the successive logs as a single txt file (to be appended to artifact logging archive in my case) Note: with such a feature it would be nice to increase the delay between 2 \"[XXX seconds] Please wait...\" to avoid flooding the logs Thanks in advance =) ", "code": [], "labels": ["feature"]}
{"project": "gatsbyjs_gatsby", "title": "Hot reloading error: \"path\" argument must be of type string", "description": "Hot reloading in gatsby develop gives this error in my project. Hot reloading sometimes works despite the error (as in, I see the error in the console window where I ran gatsby develop, but the website in browser appears to hot reload and work just fine). This error appeared after I updated some (mainly Gatsby) npm dependencies. Stack trace is giving me no ideas on how to debug this. Is it a Gatsby bug? Note that this error only comes up on hot reload. So I can run gatsby develop just fine as long as I don't make any changes to any files. I can also build just fine. <CODE> ", "code": ["[ { TypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received type undefined\n      at assertPath (path.js:39:11)\n      at Object.resolve (path.js:1085:7)\n      at findLinkedFileNode (/.../node_modules/gatsby/dist/schema/resolvers.js:208:47)\n      at resolveValue (/.../node_modules/gatsby/dist/schema/resolvers.js:223:108)\n      at /.../node_modules/gatsby/dist/schema/resolvers.js:220:10\n      at process._tickCallback (internal/process/next_tick.js:68:7)\n    message:\n     'The \"path\" argument must be of type string. Received type undefined',\n    locations: [ [Object] ],\n    path:\n     [ 'allMarkdownRemark', 'edges', 0, 'node', 'frontmatter', 'cover' ] } ]\n\n"], "labels": ["stale?", "type: bug", "status: confirmed", "not stale"]}
{"project": "arendst_Tasmota", "title": "How to use Pulse on Sonoff 4CH", "description": "Hi to all!!! How do i have to use the \"Power On\" with a \"Pulse Time\" I've tried: http://IP:Port/cm?user=admin&password=pw&cmnd=PulseTime1%203000 -> RESULT = {\"PulseTime1\":3000}\nand then\nhttp://IP:Port/cm?user=admin&password=pw&cmnd=Power1%20On -> RESULT = {\"POWER1\":\"ON\"} POWER1 = ON but the Sonoff did not \"Turn off \"after 3000sec... Thx Tom ", "code": [], "labels": ["stale"]}
{"project": "ianstormtaylor_slate", "title": "Copy-paste of multiple blocks in a nested block fails", "description": "Hello @ianstormtaylor, I think I have found a bug in insertFragmentAtRange, when pasting a fragment of several blocks into a nested block. You can see it in action here GitbookIO/slate-edit-list#6 Pull Request that adds a fixture for this case. ", "code": [], "labels": ["bug"]}
{"project": "alacritty_alacritty", "title": "Weird carat behavior when scrolling", "description": "Using the latest Alacritty, on Gentoo, and under Sway I see this interesting behavior when scrolling. I think the best way to describe it is to show it:  P.S. Click on image for full video. ", "code": [], "labels": ["B - bug"]}
{"project": "strapi_strapi", "title": "mongoose connection config was changed between alpha.13 and alpha.14", "description": "Informations What is the current behavior?\nAfter upgrading to alpha.14.1, my panel's data was all gone. Turns out the format has changed. Steps to reproduce the problem Prior to 3.0.0-alpha.14.1 (and maybe 3.0.0-alpha.14, though I did not encounter this), in order to use srv, this is the database.json: <CODE> The new format is now as follows: <CODE> What is the expected behavior?\nIt should connect to the correct database. Suggested solutions\nUpdate your database.json in your /config/environments/**/\nProbably want to make sure this is also mentioned in the migration guide? ", "code": ["{\n  \"defaultConnection\": \"default\",\n  \"connections\": {\n    \"default\": {\n      \"connector\": \"strapi-hook-mongoose\",\n      \"settings\": {\n        \"client\": \"mongo\",\n        \"uri\": \"mongodb+srv://<user>:<pass>0@<host>/<database>\"\n      },\n      \"options\": {\n        \"ssl\": true\n      }\n    }\n  }\n}\n\n", "{\n  \"defaultConnection\": \"default\",\n  \"connections\": {\n    \"default\": {\n      \"connector\": \"strapi-hook-mongoose\",\n      \"settings\": {\n        \"client\": \"mongo\",\n        \"host\": \"<host>\",\n        \"srv\": true,\n        \"port\": 27017,\n        \"database\": \"<db>\",\n        \"username\": \"<user>\",\n        \"password\": \"<password>\"\n      },\n      \"options\": {\n        \"ssl\": true\n      }\n    }\n  }\n}\n"], "labels": ["type: help wanted "]}
{"project": "inorichi_tachiyomi", "title": "[Feature Request] Preload source migration", "description": "The current source migration is slow as hell a lot of waiting for all the sources to be searched for the manga.\nSo we need a better way to migrate all mangas from a specific source, for instance MangaRock. Which currently shut down. Preload all the searches for all the mangas in specific source, plus delete any results that don't find anything. So in the end you just get a list for you to select.\nAdditionall features would also be nice such as show number of chapters on the cover (in the search same way it's done while manga is in your libary) and last chapter added and time of added chapter as we dont get the option to check the manga(source) before migration/copying ", "code": [], "labels": ["feature"]}
{"project": "expo_expo", "title": "Downloading iOS code error", "description": "", "code": [], "labels": ["outdated"]}
{"project": "gwtproject_gwt", "title": "Class cast problem", "description": "Originally reported on Google Code with ID 743 <CODE> Reported by wangyonghester on 2007-03-02 03:14:43 ", "code": ["Found in GWT Release: GWT 1.3.3\n\nDetailed description:\nI have a object array who contains three NetworkElement(a class is created \nby me) instances, but a ClassCastException is threw when the below \nstatements is executed.\n\n//Only the objects contains NetworkElement instance.\nObject[] objects = getNetworkElements();\n\n//A ClassCastException is threw.\nNetworkElement[] elements = (NetworkElement[])objects;\n\n\nWorkaround if you have one:\n\n\nLinks to the relevant GWT Developer Forum posts:\n\n"], "labels": ["Priority-Medium", "Type-Defect"]}
{"project": "ansible_awx", "title": "Metrics endpoint squashes json data if multiple entries for data (e.g. awx_instance_info etc)", "description": "If the data metric has multiple entries like: <CODE> e.g. we are reporting the awx_instance_capacity for mutliple instances, then when we do a GET with ContentType as application/json we only get the last value: <CODE> Create a tower cluster w/ at least 2 nodes Expect that we get lists in json of awx_instance_capacity, awx_instance_cpu, awx_instance_memory, awx_instance_info, awx_instance_consumed_capacity, and awx_remaining_capacity Only get one value for each key Will need to do some kind of custom rendering when request asked for application/json\nCreated this bug as a defect for this feature: #5292 (comment) ", "code": ["awx_instance_capacity{hostname=\"some-domain-tower1.com.example.com\",instance_uuid=\"b5c9e65f-f75a-421f-8c14-23405d25fc41\"} 54.0\nawx_instance_capacity{hostname=\"some-domain-isolated1.com.example.com\",instance_uuid=\"48d53859-9d1c-431c-9c44-7d08322188e9\"} 55.0\nawx_instance_capacity{hostname=\"some-domain-tower2.com.example.com\",instance_uuid=\"066e3aa8-9e9b-4833-bfe6-ecaff4fd7d83\"} 54.0\nawx_instance_capacity{hostname=\"some-domain-tower3.com.example.com\",instance_uuid=\"16eacc57-f876-498a-885f-1c1fe193f2df\"} 54.0\nawx_instance_capacity{hostname=\"some-domain-tower4.com.example.com\",instance_uuid=\"6bf06e69-9cc2-49e9-bde0-a00648024f48\"} 54.0\n", "    \"awx_instance_capacity\": {\n        \"labels\": {\n            \"hostname\": \"some-domain-tower4.com.example.com\",\n            \"instance_uuid\": \"6bf06e69-9cc2-49e9-bde0-a00648024f48\"\n        },\n        \"value\": 54.0\n    },\n"], "labels": ["priority:medium", "state:needs_devel", "type:bug", "component:api"]}
{"project": "NativeScript_NativeScript", "title": "Android ActionBar.titleView throws with specific CSS attached to the top element", "description": "Duplicate of #1710 When we have ActionBar.titleView with the extended syntax and CSS is applied to its top element Android will crash with the following error : <CODE> Code to reproduce the issue : in main-page.xml <CODE> main-page.css <CODE> Will throw also with width, height, margin-top, margin-bottom, margin-right, margin-left ", "code": ["java.lang.ClassCastException: org.nativescript.widgets.CommonLayoutParams cannot be cast to android.support.v7.widget.Toolbar$LayoutParams\n", "  <Page.actionBar>\n      <ActionBar>\n          <ActionBar.titleView>\n              <Label text=\"TITLE\" class=\"logo\" />\n          </ActionBar.titleView>\n          <ActionBar.actionItems>\n              <ActionItem text=\"Left\"  />\n              <ActionItem text=\"Right\"  />\n          </ActionBar.actionItems> \n      </ActionBar>\n  </Page.actionBar>\n", ".logo {\n    margin:10;\n}\n\n"], "labels": ["done"]}
{"project": "tensorflow_tensorflow", "title": "Adding speech output for tensorflowlite apps", "description": "Hello, I am currently building a image recognizer using tensorflow lite. I also wanted to add speech output with the prediction of the model. For example, if the model predicts that a given image is a daisy flower, it will say out loud \"daisy\". System information Describe the feature and the current behavior/state. Will this change the current api? How? The api would be modified such that text to speech is involved. Who will benefit with this feature? Adding speech would greatly help people with visual impairments, and benefit other app users in general. Any Other info. ", "code": [], "labels": ["type:feature", "stat:awaiting tensorflower", "TF 2.0", "comp:lite"]}
{"project": "ledger_ledger", "title": "balance reports incorrect numbers when used with --monthly and/or --average (BZ#1087)", "description": "Note: the issue was created automatically with bugzilla2github Bugzilla bug ID: BZ#1087\nFrom: @c-14\nCC:   @aleksejrs, unknown user, @thdox ", "code": [], "labels": ["bug", "P3"]}
{"project": "ytdl-org_youtube-dl", "title": "removed", "description": "removed ", "code": [], "labels": ["incomplete"]}
{"project": "ionic-team_stencil", "title": "Internal typings for hyperscript nodes", "description": "I'm submitting a: [ ] bug report\n[x] feature request\n[ ] support request => Please do not submit support requests here, use one of these channels: <URL> or <URL> I'm creating a system that outputs a tree of hyperscript, to be consumed by Stencil's h utility. With the release of TypeScript 3.7, we can now model circular tuple types of unknown length. I've been using the following type: It's not urgent, but it'd be awesome if this was updated in the declarations, as to enable users to\u2013\u2013when manually constructing VNodes\u2013\u2013have added type-safety. I'm currently doing (h as any).apply(null, [...hypertext]) (as this is what's done in the Stencil documentation site). Using the internal type, instead of defining my own, would be sweet. Once again, not urgent. Kind regards, Harry ", "code": [], "labels": ["triage"]}
{"project": "home-assistant_home-assistant", "title": "Device Trackers Losing State Upon Restart", "description": "Home Assistant release with the issue: Last working Home Assistant release (if known):\nHome Assistant 0.67.0 Operating environment (Hass.io/Docker/Windows/etc.): Hass.io\nComponent/platform: device tracker Description of problem:\nWhen a restart of hass.io is performed, the state of the device tracker is lost.  Which results in issues when the Home Assistant finishes up its startup.  It used to keep the state info and a restart didn't result in the devices being set to \"not_home\" which is what is happening now. Problem-relevant configuration.yaml entries and (fill out even if it seems unimportant): Traceback (if applicable): <CODE> Additional information: ", "code": ["\n"], "labels": ["auto-closed", "waiting-for-reply"]}
{"project": "dotnet_aspnetcore", "title": "Does Blazor (via Mono) JIT code to \"native\" webassembly?", "description": "Or will, for example, my method bodies always be interpreted at a higher language layer inside the runtime during execution? ", "code": [], "labels": ["area-blazor"]}
{"project": "PowerShell_PowerShell", "title": "Powershell 6.0.0 AppImage crashes after a few seconds on CentOS Linux 7.4", "description": "<CODE> Application does not crash. <CODE> Backtrace:- <CODE> <CODE> ", "code": ["$ powershell\n", "$ powershell\n$XDG_DATA_DIRS is missing. Please run /tmp/.mount_f8fJ9u/usr/bin/pwsh.wrapper from within an AppImage.\nPowerShell v6.0.0\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nhttps://aka.ms/pscore6-docs\nType 'help' to get help.\n\nPS /tmp> Segmentation fault\n", "[Switching to Thread 0x7fffe9f91700 (LWP 17163)]\n0x00007fff562cb99f in __libc_res_nsend () from /lib64/libresolv.so.2\n(gdb) bt\n#0  0x00007fff562cb99f in __libc_res_nsend () from /lib64/libresolv.so.2\n#1  0x00007fff562c8c5e in __libc_res_nquery () from /lib64/libresolv.so.2\n#2  0x00007fff562c9840 in __libc_res_nsearch () from /lib64/libresolv.so.2\n#3  0x00007fff2f4eac2d in _nss_dns_gethostbyname4_r () from /tmp/.mount_IHLoIp/usr/lib/libnss_dns.so.2\n#4  0x00007ffff6eb9ed8 in gaih_inet () from /lib64/libc.so.6\n#5  0x00007ffff6ebd5cd in getaddrinfo () from /lib64/libc.so.6\n#6  0x00007fffe632feb4 in ?? () from /tmp/.mount_IHLoIp/usr/lib/libcurl.so.4\n#7  0x00007fffe633cd64 in ?? () from /tmp/.mount_IHLoIp/usr/lib/libcurl.so.4\n#8  0x00007fffe633a60b in ?? () from /tmp/.mount_IHLoIp/usr/lib/libcurl.so.4\n#9  0x00007ffff79c2e25 in start_thread () from /lib64/libpthread.so.0\n#10 0x00007ffff6ed434d in clone () from /lib64/libc.so.6\n", "$ uname -r\n3.10.0-693.11.6.el7.x86_64\n$ cat /etc/centos-release\nCentOS Linux release 7.4.1708 (Core)\n$ rpm -q glibc\nglibc-2.17-196.el7_4.2.x86_64\nglibc-2.17-196.el7_4.2.i686\n"], "labels": ["Area-Build"]}
{"project": "ytdl-org_youtube-dl", "title": "udemy.com download errors", "description": "Add the -v flag to your command line you run youtube-dl with (youtube-dl -v <your command line>), copy the whole output and insert it here. It should look similar to one below (replace it with your log inserted between triple ```): <CODE> Note that youtube-dl does not support sites dedicated to copyright infringement. In order for site support request to be accepted all provided example URLs should not violate any copyrights. it was working last week, I added a course, and updated my youtube-dl.... now i get the above... even on courses that worked last week ", "code": ["[debug] System config: []\n[debug] User config: []\n[debug] Custom config: []\n[debug] Command-line args: [u'-u', u'PRIVATE', u'-p', u'PRIVATE', u'-ciw', u'--verbose', u'-f', u'best', u'-o', u'/media/USBStorage/plex/YouTube_-_Make_Stuff/UDemy/%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s', u'https://www.udemy.com/complete-guitar-system-beginner-to-advanced/learn/v4/']\n[debug] Encodings: locale UTF-8, fs UTF-8, out UTF-8, pref UTF-8\n[debug] youtube-dl version 2018.04.25\n[debug] Python version 2.7.9 (CPython) - Linux-4.9.35-v7+-armv7l-with-debian-8.0\n[debug] exe versions: avconv 11.12-6, avprobe 11.12-6, rtmpdump 2.4\n[debug] Proxy map: {}\n[udemy:course] Downloading login popup\nERROR: Unable to download webpage: HTTP Error 403: Unauthorized (caused by HTTPError()); please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; type  youtube-dl -U  to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/common.py\", line 519, in _request_webpage\n    return self._downloader.urlopen(url_or_request)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 2203, in urlopen\n    return self._opener.open(req, timeout=self._socket_timeout)\n  File \"/usr/lib/python2.7/urllib2.py\", line 437, in open\n    response = meth(req, response)\n  File \"/usr/lib/python2.7/urllib2.py\", line 550, in http_response\n    'http', request, response, code, msg, hdrs)\n  File \"/usr/lib/python2.7/urllib2.py\", line 475, in error\n    return self._call_chain(*args)\n  File \"/usr/lib/python2.7/urllib2.py\", line 409, in _call_chain\n    result = func(*args)\n  File \"/usr/lib/python2.7/urllib2.py\", line 558, in http_error_default\n    raise HTTPError(req.get_full_url(), code, msg, hdrs, fp)\n\n\n...\n<end of log>\n"], "labels": ["duplicate"]}
{"project": "microsoft_TypeScript", "title": "Two equally defined mapped types are incompatible", "description": "TypeScript Version:  2.1.5 Code Expected behavior: Should compile. Actual behavior: Fails to compile at the initialization of x with the claim the types were incompatible: <CODE> (Maybe this is the expected behavior for some reason, but it seems off to me.) ", "code": ["app.ts(200,9): error TS2322: Type 'M<T>' is not assignable to type '{ [P in keyof T]: A<T[P]>; }'.\n  Type 'A<T[P]>' is not assignable to type 'A<T[P]>'. Two different types with this name exist, but they are unrelated.\n\n    Type 'T[P]' is not assignable to type 'T[P]'. Two different types with this name exist, but they are unrelated.\n"], "labels": ["Duplicate", "Fixed"]}
{"project": "ccrisan_motioneye", "title": "Custom hostname?", "description": "MotionEyeOS has this feature ref: ccrisan/motioneyeos#103 Just wondering if it's coming to the standalone? ", "code": [], "labels": ["wontfix"]}
{"project": "yiisoft_yii2", "title": "Pagination, no return it self", "description": "It will be more convenient if seters of Pagination return self\nNow I must write this: <CODE> But I'd like this ^^ : <CODE> ", "code": ["        $pgn = new Pagination(['totalCount' => $total]);\n        $pgn->setPage($page);\n        $links = $pgn->getLinks();\n", "        $links = (new Pagination(['totalCount' => $total]))\n                ->setPage($page)->getLinks();\n"], "labels": ["status:under discussion"]}
{"project": "appium_appium", "title": "Not able to change video recording parameters on iOS", "description": "I'm not able to change the video settings for iOS devices using the python function: the values are examples The appium server (1.12.1) is processing correctly the arguments and passing them to the wda but the wda is not updating its values. I had try to connect via a REST client to the wda session in order to POST myself  the new settings but the wda always returns a 200 with the same body and without any update. POST /session/:session_id/appium/settings <URL>\n<URL>\n<URL> ", "code": [], "labels": ["XCUITest", "Bug"]}
{"project": "MicrosoftDocs_azure-docs", "title": "Possible typo. \"Examples\" should be \"Example\".", "description": "In the following sentence from the first section of this page, \"examples\" should probably be \"example\". \"This article walks you through some examples SQL queries ...\", should probably be \"This article walks you through some example SQL queries ...\" \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["doc-bug", "cosmos-db/svc", "triaged", "cxp"]}
{"project": "artf_grapesjs", "title": "[Bug]: editor.runCommand('gjs-get-inlined-html') returns undefined (preset-webpage)", "description": "Hi, Artur I'm using grapesjs-preset-webpage v0.1.10, grapesjs v0.14.29 I'm trying to save templates with inline css rather than having classes.\nbut editor.runCommand('gjs-get-inlined-html') returns undefined. I've read your comments regarding this on other issue tickets but you said it's for newsletter. is it not available for preset webpage..? is there any way to save template with inline css instead of classes? Thank you! ", "code": [], "labels": ["outdated"]}
{"project": "netdata_netdata", "title": "tomcat or xmlstarlet?", "description": "", "code": [], "labels": ["question"]}
{"project": "dart-lang_sdk", "title": "create polymer/mirrors_used.dart", "description": "Similar to what we have in observe/mirrors_used.dart, we might want to create a similar library in case we need a fallback. If codegen don't work as expected, then users could write: import 'package:polymer/mirrors_used.dart'; // for smaller code\nimport 'package:polymer/polymer.dart';\nimport 'package:smoke/mirrors.dart'; main() {\n\u00a0\u00a0useMirrors();\n\u00a0\u00a0initPolymer().run(...);\n} ", "code": [], "labels": ["closed-not-planned", "Type-Defect", "area-pkg"]}
{"project": "orientechnologies_orientdb", "title": "OProperty Constraints are not enforced on OrientElement", "description": "I am trying to set property constraints on elements in the graph.  The constraints should throw an error when they are not followed. Property constraints are ignored, and elements can be created that do not follow the constraints. `\npublic class OrientPropertyTest { <CODE> }\n` ", "code": ["private String randomLocation() {\n    return \"memory:test\" + new Random().nextInt();\n}\n\n@Test(expected=OValidationException.class)\npublic void testPropertyMax() {\n    String location = randomLocation();\n    OrientGraphNoTx graphNoTx = new OrientGraphNoTx(location);\n    OrientVertexType testType = graphNoTx.createVertexType(\"Test\");\n    OProperty prop = testType.createProperty(\"name\", OType.STRING).setMax(\"3\");\n    graphNoTx.shutdown();\n\n    Assert.assertEquals(prop.getMax(), \"3\"); //this one passes\n\n    OrientGraph graph = new OrientGraph(location);\n    try {\n        graph.addVertex(\"class:Test\", \"name\", \"Sam\");\n        graph.addVertex(\"class:Test\", \"name\", \"Henry\"); //this should throw an exception\n        graph.commit();\n    } finally {\n        graph.drop();\n    }\n}\n\n@Test(expected=OValidationException.class)\npublic void testPropertyMin() {\n    String location = randomLocation();\n    OrientGraphNoTx graphNoTx = new OrientGraphNoTx(location);\n    OrientVertexType testType = graphNoTx.createVertexType(\"Test\");\n    OProperty prop = testType.createProperty(\"name\", OType.STRING).setMin(\"4\");\n    graphNoTx.shutdown();\n\n    Assert.assertEquals(prop.getMin(), \"4\"); //this one passes\n\n    OrientGraph graph = new OrientGraph(location);\n    try {\n        graph.addVertex(\"class:Test\", \"name\", \"Sam\"); //this should throw an exception\n        graph.addVertex(\"class:Test\", \"name\", \"Henry\");\n\n        graph.commit();\n\n    } finally {\n        graph.drop();\n    }\n}\n\n@Test(expected=OValidationException.class)\npublic void testPropertyRegexp() {\n    String location = randomLocation();\n    OrientGraphNoTx graphNoTx = new OrientGraphNoTx(location);\n    OrientVertexType testType = graphNoTx.createVertexType(\"Test\");\n    OProperty prop = testType.createProperty(\"gender\", OType.STRING).setRegexp(\"[M|F]\");\n    graphNoTx.shutdown();\n\n    Assert.assertEquals(prop.getRegexp(), \"[M|F]\"); //this one passes\n\n    OrientGraph graph = new OrientGraph(location);\n    try {\n        graph.addVertex(\"class:Test\", \"gender\", \"A\"); //this should throw an exception\n        graph.addVertex(\"class:Test\", \"gender\", \"M\");\n\n        graph.commit();\n\n    } finally {\n        graph.drop();\n    }\n}\n"], "labels": ["invalid"]}
{"project": "ampproject_amphtml", "title": "Layers: Change Resize rules to account for Layers", "description": "Elements inside Layers which are not in-viewport may be resized without issues, since they would only change the scroll size of the Layer. ", "code": [], "labels": ["WG: runtime", "P2: Soon"]}
{"project": "envoyproxy_envoy", "title": "Subset load balancer: Add a fallback policy that uses priority/locality weighting", "description": "Title: Subset load balancer: Add a fallback that uses priority/locality weighting Description:\nCurrently subset load balancing and priority/locality load balancing are mutually exclusive for a cluster. However, I have a use case where I would like to allow client either to select subsets via HTTP headers, or to elide the headers and follow priority and locality load balancing rules. Currently the closest I can get to that is to use the ANY_ENDPOINT fallback policy, but my understanding of the docs is that it will give all hosts in the cluster an equal weighting, which isn't what I want. I can get around this requirement by doubling the number of clusters I have and having one for subset load balancing and one for priority/locality load balancing, however I'd rather avoid that if possible. ", "code": [], "labels": ["help wanted", "enhancement"]}
{"project": "spring-projects_spring-framework", "title": "Actuator doesn't play nice with reactive WebFilters (HttpStatus == null) [SPR-16736]", "description": "Nicolas Portmann opened SPR-16736 and commented The reactive web stack allows configuration of a WebFilter with a beforeCommit handler. Requests handled by controllers returning Mono<ResponseEntity<?>>, will have the HTTP status code set in the beforeCommit handler. Other endpoints (such as actuator) have a HTTP status of null in the beforeCommit handler.\nThe same applies to controllers returning Mono<ServerResponse> (which actuator might do internally, I haven't checked) A consistant and documented behaviour would be much appreciated. A sample to reproduce the issue is attached as Reference URL. Affects: 5.0.5 Reference URL: <URL> ", "code": [], "labels": ["in: web"]}
{"project": "fsprojects_Paket", "title": "Paket pack: need a way to specify current nuget version as dependency", "description": "I'm interested in integrating the paket pack functionality in my projects, so I've started playing around with it in FsPickler. In FsPickler there are two projects, FsPickler and FsPickler.Json. FsPickler has no nuget dependencies and FsPickler.Json depends on 1) Json.Net and 2) FsPickler of precisely the same version number. I can rely on the Json.Net dependency being added automatically by paket pack, however I can't find a way to specify the latter dependency correctly. Is there any way I can achieve this through the paket.template syntax or FAKE? ", "code": [], "labels": ["enhancement"]}
{"project": "opencv_opencv", "title": "compiling with opencv_contrib and cmake fails with : fatal error sys/videoio.h: no such file or directory", "description": "cmake -D CMAKE_BUILD_TYPE=RELEASE  -D CMAKE_INSTALL_PREFIX=/usr/local     -D WITH_CUDA=OFF     -D INSTALL_PYTHON_EXAMPLES=ON     -D OPENCV_EXTRA_MODULES_PATH=/grundata/zhimo.bmz/download/opencv_contrib-3.3.1/modules     -D BUILD_EXAMPLES=ON -D INSTALL_C_EXAMPLES=OFF .. cmake command failed with below errors:\nAnd as suggested, these files are missing on my machine.\nAnd I google for a while and fail to find the name of the dependency package which i need to install to make it work. So, could you please help? <CODE> ", "code": ["Determining if the include file linux/videodev.h exists failed with the following output:\nChange Dir: /gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp\n\nRun Build Command:\"/usr/bin/gmake\" \"cmTC_670e7/fast\"\n/usr/bin/gmake -f CMakeFiles/cmTC_670e7.dir/build.make CMakeFiles/cmTC_670e7.dir/build\ngmake[1]: Entering directory `/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp'\nBuilding C object CMakeFiles/cmTC_670e7.dir/CheckIncludeFile.c.o\n/usr/bin/cc   -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-narrowing -Wno-comment -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections  -msse -msse2 -msse3 -fvisibility=hidden  -O3 -DNDEBUG   -o CMakeFiles/cmTC_670e7.dir/CheckIncludeFile.c.o   -c /gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c\n/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c:1:28: fatal error: linux/videodev.h: No such file or directory\n #include <linux/videodev.h>\n                            ^\ncompilation terminated.\ngmake[1]: *** [CMakeFiles/cmTC_670e7.dir/CheckIncludeFile.c.o] Error 1\ngmake[1]: Leaving directory `/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp'\ngmake: *** [cmTC_670e7/fast] Error 2\n\n\nDetermining if the include file linux/videodev2.h exists failed with the following output:\nChange Dir: /gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp\n\nRun Build Command:\"/usr/bin/gmake\" \"cmTC_00b02/fast\"\n/usr/bin/gmake -f CMakeFiles/cmTC_00b02.dir/build.make CMakeFiles/cmTC_00b02.dir/build\ngmake[1]: Entering directory `/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp'\nBuilding C object CMakeFiles/cmTC_00b02.dir/CheckIncludeFile.c.o\n/usr/bin/cc   -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-narrowing -Wno-comment -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections  -msse -msse2 -msse3 -fvisibility=hidden  -O3 -DNDEBUG   -o CMakeFiles/cmTC_00b02.dir/CheckIncludeFile.c.o   -c /gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c\nIn file included from /gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c:1:0:\n/usr/include/linux/videodev2.h:1763:20: error: field \u2018timestamp\u2019 has incomplete type\n  struct timespec   timestamp;\n                    ^\ngmake[1]: *** [CMakeFiles/cmTC_00b02.dir/CheckIncludeFile.c.o] Error 1\ngmake[1]: Leaving directory `/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp'\ngmake: *** [cmTC_00b02/fast] Error 2\n\n\nDetermining if the include file sys/videoio.h exists failed with the following output:\nChange Dir: /gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp\n\nRun Build Command:\"/usr/bin/gmake\" \"cmTC_dacfc/fast\"\n/usr/bin/gmake -f CMakeFiles/cmTC_dacfc.dir/build.make CMakeFiles/cmTC_dacfc.dir/build\ngmake[1]: Entering directory `/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp'\nBuilding C object CMakeFiles/cmTC_dacfc.dir/CheckIncludeFile.c.o\n/usr/bin/cc   -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-narrowing -Wno-comment -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections  -msse -msse2 -msse3 -fvisibility=hidden  -O3 -DNDEBUG   -o CMakeFiles/cmTC_dacfc.dir/CheckIncludeFile.c.o   -c /gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c\n/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp/CheckIncludeFile.c:1:25: fatal error: sys/videoio.h: No such file or directory\n #include <sys/videoio.h>\n                         ^\ncompilation terminated.\ngmake[1]: *** [CMakeFiles/cmTC_dacfc.dir/CheckIncludeFile.c.o] Error 1\ngmake[1]: Leaving directory `/gruntdata/zhimo.bmz/download/opencv-3.3.1/build/CMakeFiles/CMakeTmp'\ngmake: *** [cmTC_dacfc/fast] Error 2\n"], "labels": ["invalid", "duplicate", "question (invalid tracker)"]}
{"project": "aio-libs_aiohttp", "title": "Error: reserved fields must be empty", "description": "Not sure, if that a bug, but maybe my report will help you\nI was looking for async solution on python found you and decide to make some quick tests.\nBy quick googling if found that chat solution base on aiohttp <URL>\nLooks like pretty simple and good solution. Since past few years i was using nodejs i used 10 lines js script for generate 1000 users online in one char room, here is a script: <CODE> After 100 iteration i got bunch of errors. It looks like there is a bug somewhere in a system when aiohttp send not the correct information (but again i'm not sure) <CODE> For websocket i'm using protocolVersion: 13\nFor a few days i tried to resolve issue by myself but looks like problem somewhere deeper. ", "code": ["var WebSocket = require('ws' );\n\n\nfor(var i = 0; i < 1000; i ++) {\n    (function(i) {\n        var ws = new WebSocket('ws://localhost:2222/chat.ws');\n            ws.on('open', function open() {\n                    //this.send(JSON.stringify({ type: 'init', data: {back: 0, nick: 'Name' + i}}));\n                    //this.send(JSON.stringify({ type: 'message', data: \"hello \" + i}));\n            }).\n            on('message', function(data, flags) {\n                //console.log('new message ', data, flags);\n            }).\n            on('error', function(error, data) {\n                console.log('err ', error, data);\n            }).\n            on('close', function(err, d) {\n                console.log('close connection', err, d);\n            })\n    })(i);\n};\n", "Error: reserved fields must be empty\n    at Receiver.error (/Users/admin/projects/pchat/node_modules/ws/lib/Receiver.js:322:18)\n    at Receiver.processPacket (/Users/admin/projects/pchat/node_modules/ws/lib/Receiver.js:204:12)\n    at Receiver.add (/Users/admin/projects/pchat/node_modules/ws/lib/Receiver.js:103:24)\n    at realHandler (/Users/admin/projects/pchat/node_modules/ws/lib/WebSocket.js:825:20)\n    at firstHandler (/Users/admin/projects/pchat/node_modules/ws/lib/WebSocket.js:815:7)\n    at _combinedTickCallback (internal/process/next_tick.js:67:7)\n    at process._tickCallback (internal/process/next_tick.js:98:9) undefined\n"], "labels": ["outdated"]}
{"project": "sqlalchemy_sqlalchemy", "title": "deeper check for \"unique\" non-match when clauses have been adapted", "description": "Migrated issue, originally created by Michael Bayer (@zzzeek) quick demo: <CODE> here's the patch: <CODE> ", "code": ["from sqlalchemy import *\nfrom sqlalchemy.orm import *\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass Point(Base):\n   __tablename__ = 'point'\n   id = Column(Integer, primary_key=True)\n   flag = Column(Boolean, default=True)\n\n   coordinate_id = Column(Integer)\n\nclass Line(Base):\n   __tablename__ = 'line'\n   id = Column(Integer, primary_key=True)\n   start_point_id = Column(Integer, ForeignKey('point.id'))\n   start_point = relationship(\n       'Point',\n       primaryjoin=and_(\n            start_point_id==Point.id,\n            Point.flag == True\n       ))\n\nstarts_one = Line.start_point.has()\nstarts_other = Line.start_point.has()\n\nprint and_(\n    starts_one, starts_other\n)\n", "diff -r db69a48231754c4279b2ceb5ce7317a50ed839d2 lib/sqlalchemy/sql/compiler.py\n--- a/lib/sqlalchemy/sql/compiler.py\tThu Mar 08 00:51:49 2012 -0800\n+++ b/lib/sqlalchemy/sql/compiler.py\tThu Mar 08 14:35:35 2012 -0800\n@@ -655,7 +655,8 @@\n         if name in self.binds:\n             existing = self.binds[name](name)\n             if existing is not bindparam:\n-                if existing.unique or bindparam.unique:\n+                if (existing.unique or bindparam.unique) and \\\n+                    not existing.proxy_set.intersection(bindparam.proxy_set):\n                     raise exc.CompileError(\n                             \"Bind parameter '%s' conflicts with \"\n                             \"unique bind parameter of the same name\" %\n"], "labels": ["high priority", "bug", "sql"]}
{"project": "dart-lang_sdk", "title": "Failure of new test standalone_2/dwarf_stack_trace_obfuscate on vm-kernel-precomp-linux-product-x64", "description": "Relevant part of the logs: <CODE> Looks like we're seeing the _Closure.call and _AsyncAwaitCompleter.start calls on the stack in product mode when obfuscating, but we don't when it's not obfuscated? Have approved for now, and will make a quick CL tomorrow to weaken the test, as we don't actually need to look below the call to foo in main (and it's better not to do so to avoid changes in how main gets invoked causing issues with this test). ", "code": ["/===============================================================================================\\\n| standalone_2/dwarf_stack_trace_obfuscate_test is new and failed (RuntimeError, expected Pass) |\n\\===============================================================================================/\n\n...\n\n--- Command \"vm\" (took 96ms):\nDART_CONFIGURATION=ProductX64 out/ProductX64/dart_precompiled_runtime --dwarf-stack-traces --save-debugging-info=dwarf_obfuscate.so --obfuscate --ignore-unrecognized-flags --packages=/b/s/w/ir/.packages /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n\nexit code:\n255\n\nstdout:\nRaw stack trace:\nWarning: This VM has been configured to produce stack traces that violate the Dart standard.\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\npid: 12532, tid: 140553505732352, name DartWorker\nisolate_instructions: 7fd52a122000 vm_instructions: 0\n    #00 abs 00007fd52a188ec0 virt 000000000006bec0 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #01 abs 00007fd52a189072 virt 000000000006c072 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #02 abs 00007fd52a1e2b4f virt 00000000000c5b4f /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #03 abs 00007fd52a1bf344 virt 00000000000a2344 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #04 abs 00007fd52a188de4 virt 000000000006bde4 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #05 abs 00007fd52a188e6a virt 000000000006be6a /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #06 abs 00007fd52a1e2b4f virt 00000000000c5b4f /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #07 abs 00007fd52a18bc51 virt 000000000006ec51 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #08 abs 00007fd52a1e2a52 virt 00000000000c5a52 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #09 abs 00007fd52a1b8208 virt 000000000009b208 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n\n\nCall information for PC addresses:\nFor PC 0x6cec0:\n  Calls corresponding to user or library code:\n    bar (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:17)\n    foo (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:23)\n  All calls:\n    bar (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:17)\n    foo (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:23)\nFor PC 0x6d072:\n  Calls corresponding to user or library code:\n    main (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:29)\n  All calls:\n    main (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:29)\nFor PC 0xc6b4f:\n  Calls corresponding to user or library code:\n  All calls:\n    _Closure.call (dart:core-patch/function.dart:??)\nFor PC 0xa3344:\n  Calls corresponding to user or library code:\n    _AsyncAwaitCompleter.start (dart:async-patch/async_patch.dart:46)\n  All calls:\n    _AsyncAwaitCompleter.start (dart:async-patch/async_patch.dart:46)\nFor PC 0x6cde4:\n  Calls corresponding to user or library code:\n    main (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:26)\n  All calls:\n    main (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:26)\nFor PC 0x6ce6a:\n  Calls corresponding to user or library code:\n  All calls:\n    main (file:///b/s/w/ir/tests/standalone_2/dwarf_stack_trace_obfuscate_test.dart:??)\nFor PC 0xc6b4f:\n  Calls corresponding to user or library code:\n  All calls:\n    _Closure.call (dart:core-patch/function.dart:??)\nFor PC 0x6fc51:\n  Calls corresponding to user or library code:\n    _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:307)\n  All calls:\n    _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:307)\nFor PC 0xc6a52:\n  Calls corresponding to user or library code:\n  All calls:\n    _Closure.call (dart:core-patch/function.dart:??)\nFor PC 0x9c208:\n  Calls corresponding to user or library code:\n    _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:174)\n  All calls:\n    _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:174)\n\nstderr:\nUnhandled exception:\nExpected: 'main'\n  Actual: '_Closure.call'\n   Which: is different.\nExpected: main\n  Actual: _Closure.c ...\n          ^\n Differ at offset 0\n\nWarning: This VM has been configured to produce stack traces that violate the Dart standard.\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\npid: 12532, tid: 140553527523200, name Dart_Initialize\nisolate_instructions: 7fd52a122000 vm_instructions: 0\n    #00 abs 00007fd52a176c88 virt 0000000000059c88 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #01 abs 00007fd52a176c0e virt 0000000000059c0e /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #02 abs 00007fd52a176a3f virt 0000000000059a3f /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #03 abs 00007fd52a16d224 virt 0000000000050224 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #04 abs 00007fd52a187a5a virt 000000000006aa5a /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #05 abs 00007fd52a14ef04 virt 0000000000031f04 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #06 abs 00007fd52a1bc4bf virt 000000000009f4bf /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #07 abs 00007fd52a1bd3b1 virt 00000000000a03b1 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #08 abs 00007fd52a1bcf0a virt 000000000009ff0a /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #09 abs 00007fd52a1beaf2 virt 00000000000a1af2 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #10 abs 00007fd52a16f6dc virt 00000000000526dc /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #11 abs 00007fd52a14f39b virt 000000000003239b /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #12 abs 00007fd52a16e214 virt 0000000000051214 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #13 abs 00007fd52a14c229 virt 000000000002f229 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #14 abs 00007fd52a14cb80 virt 000000000002fb80 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #15 abs 00007fd52a16f31b virt 000000000005231b /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #16 abs 00007fd52a16ef3b virt 0000000000051f3b /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #17 abs 00007fd52a14fc0a virt 0000000000032c0a /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #18 abs 00007fd52a1500e8 virt 00000000000330e8 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #19 abs 00007fd52a14fa09 virt 0000000000032a09 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #20 abs 00007fd52a14f97b virt 000000000003297b /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #21 abs 00007fd52a14f39b virt 000000000003239b /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #22 abs 00007fd52a16e214 virt 0000000000051214 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #23 abs 00007fd52a14c229 virt 000000000002f229 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #24 abs 00007fd52a16e901 virt 0000000000051901 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #25 abs 00007fd52a16e67c virt 000000000005167c /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #26 abs 00007fd52a16e381 virt 0000000000051381 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #27 abs 00007fd52a134036 virt 0000000000017036 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #28 abs 00007fd52a133df8 virt 0000000000016df8 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #29 abs 00007fd52a133f4a virt 0000000000016f4a /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #30 abs 00007fd52a18b9c0 virt 000000000006e9c0 /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n    #31 abs 00007fd52a1b820f virt 000000000009b20f /b/s/w/ir/out/ProductX64/generated_compilations/dartkp/tests_standalone_2_dwarf_stack_trace_obfuscate_test/out.aotsnapshot\n\n--- Re-run this test:\npython tools/test.py -n dartkp-linux-product-x64 standalone_2/dwarf_stack_trace_obfuscate_test\n"], "labels": ["area-vm"]}
{"project": "helm_charts", "title": "[stable/etcd-operator] commandArgs documentation", "description": "Can someone point me to the documentation regarding etcdOperator.commandArgs, backupOperator.commandArgs and restoreOperator.commandArgs ", "code": [], "labels": ["lifecycle/stale"]}
{"project": "microsoft_TypeScript", "title": "No typecheck if classes have the same properties", "description": "I found this very subtle error only after some digging because the system then goes on by using valueA as valueB and the other way round. When I change the name of the value property it works as expected. I mean this bug defeats the whole purpose of having a value object in the first place. If I have a getter with the same name the problem persists, just removed them for simplicity. TypeScript Version:  1.8.10 Code Expected behavior: Compiler throws an error for parameter types being incorrect. Actual behavior: Compiles without any issues. <CODE> ", "code": ["ValueObjectA:  valueb\nValueObjectB:  valuea\n"], "labels": ["Duplicate"]}
{"project": "kubernetes_website", "title": "Issue with k8s.io/docs/concepts/overview/what-is-kubernetes/", "description": "This is a... Problem: Proposed Solution: Page to Update:\n<URL> ", "code": [], "labels": ["triage/needs-information"]}
{"project": "apache_incubator-echarts", "title": "\u96f7\u8fbe\u56fe radar rich \u65e0\u6548", "description": "\u96f7\u8fbe\u56fe radar rich \u65e0\u6548 <CODE>   ", "code": ["var myChart = echarts.init(document.querySelector('#main'), null, {renderer: 'svg'});\n"], "labels": ["enhancement"]}
{"project": "qgis_QGIS", "title": "Spatialite database file remains locked after layers removed.", "description": "Author Name: John Stevenson (John Stevenson)\nOriginal Redmine Issue: 13699\nAffected QGIS version: 2.10.1\nRedmine category:data_provider/spatialite When Spatialite layers are removed, the connection to the database remains open.  This prevents renaming or deleting of the file.  The lock remains in place for around 45 to 60 seconds, in most cases. Example:\n* Layer > Add Layer > Add Spatialite Layer\n* Select from database and add\n* Right click Layer > Remove\n* Database file is locked This behaviour also occurs with Python, which gives \u2018WindowsError\u2019 in Windows 7, or \u2018OSError\u2019 in Xubuntu 14.04.\nThe Linux terminal gets:\nmv: cannot move \u2018test.sqlite\u2019 to \u2018test2.sqlite\u2019: Text file busy Further information can be obtained from the following command in Linux:\nlsof -r5 +D /path/to/working/directory/ This shows open files every 5 seconds.  Opening a layer creates 2 connections to the file, both owned by qgis.bin.  One is read/write, the other is read only.  On removing the layers, the read only connection remains for around a minute, after which the file can be moved.  Sometimes (on Windows) the connection requires a restart of QGIS, or even a reboot, to be cleared. The behaviour seems similar to #21018, which affects the DB Manager and resulted in it adding extra layers to the registry when spatialite layers were previewed.  However, no extra layers are added in this case.  Running the DB Manager with lsof active shows that it also creates connections that are not closed. ", "code": [], "labels": ["Bug", "Data Provider"]}
{"project": "EasyCorp_EasyAdminBundle", "title": "Relationship OneToMany is not save correctly", "description": "I have a collection Type field, and inversed side of relationship is not saved. Following code: Config.yml: Entity/SplitterSaida: Entity/Splitter:  Look the column splitter_id is null. But i expected it has the id of splitter. ", "code": [], "labels": ["bug"]}
{"project": "gohugoio_hugo", "title": "Add FreeBSD release for extended version", "description": "Some hosting providers are using FreeBSD, and having an extended release of Hugo available for FreeBSD amd64 would be great. Is there anything preventing that? ", "code": [], "labels": ["Enhancement"]}
{"project": "spring-cloud_spring-cloud-netflix", "title": "Domumentation for sidecar", "description": "\nNo description provided.\n ", "code": [], "labels": ["documentation"]}
{"project": "microsoft_vscode", "title": "Aria attribute visible on menu bar buttons", "description": "Hello - after updating to newest version of Code Insiders I've noticed that all menu buttons have aria attribute visible if menuBarVisibility is set to toggle in the settings. The issue did not occur on stable version. Steps to Reproduce: <CODE> <CODE> Screenshot: <URL> Does this issue occur when all extensions are disabled?: Yes (also with all settings cleared except that one) ", "code": ["    \"window.menuBarVisibility\": \"toggle\",\n", "<u aria-hidden=\"true\">T</u>ips and Tricks\n"], "labels": ["insiders"]}
{"project": "joomla_joomla-cms", "title": "Updating to Joomla 3.5 through the administrator panel is unnecessarily complicated", "description": "Download the Joomla update package\nTry to update Joomla through the Administrator interface.\nExtension manager no longer allows Core updates (3.5 something made this change, Noted in #9430 )\nJoomla Update does not allow a file upload the way that the extensions manager does, only via the update channel or via a custom URL This leaves FTP file transfer as the only other option to update with a downloaded Core update package Three methods for Updates\nFile upload via Joomla Update ( as was done with the extension manager)\nUpdate via the update channel via Joomla Update\nUpdate via FTP upload Message in the Extention manager does not direct people to use the Joomla Update component if they tried to use the Extention manager for a core update as was done in #9430 Only able to update Update via the update channel or Update via FTP upload (file overwriting) Any system Although I understand the reasons for Joomla core updates through the extension manager being removed; because the Joomla updates component doesn't allow for updating via an uploaded package the way that the extensions manager does. This over complicates the update process. I feel being stuck with updates only through FTP file transfer or via the update channel, is an issue to consider fixing. There are likely many users are going to be reporting the issue noted in #9430 Additionally not having a message to explain the update method change to users is going to frustrate and annoy  people. ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "ionic-team_ionic", "title": "ion-textarea with ion-label breaks layout on resize", "description": "Ionic version:  (check one with \"x\")\n[ ] 1.x\n[ ] 2.x\n[x] 3.x I'm submitting a ...  (check one with \"x\")\n[x] bug report\n[ ] feature request\n[ ] support request => Please do not submit support requests here, use one of these channels: <URL> or <URL> Current behavior:\nWhen manually resizing a textarea within an ion-item and along with a ion-label, if the textarea is resized horizontally the label will disappear. Expected behavior:\nWe should only be able to resize vertically in that case, or no resize at all? Steps to reproduce:\n<URL> Related code: <CODE> Ionic info: (run ionic info from a terminal/cmd prompt and paste output below): <CODE> ", "code": ["<ion-list>\n  <ion-item>\n    <ion-label>Description</ion-label>\n    <ion-textarea></ion-textarea>\n  </ion-item>\n</ion-list>\n", "Cordova CLI: 6.4.0 \nIonic Framework Version: 3.1.0\nIonic CLI Version: 2.2.2\nIonic App Lib Version: 2.2.1\nIonic App Scripts Version: 1.3.0\nios-deploy version: 1.9.1 \nios-sim version: 5.0.13 \nOS: macOS Sierra\nNode Version: v7.4.0\nXcode version: Xcode 8.3.2 Build version 8E2002\n"], "labels": ["ionitron: stale issue", "v2"]}
{"project": "eclipse_che", "title": "Error: UPGRADE FAILED: error validating \"\": error validating data: found invalid field test for v1beta1.DeploymentSpec", "description": "Deploying with Helm\nMulti User Execute the command\nhelm upgrade --install  --namespace  -f ./values/multi-user.yaml --set global.ingressDomain= ./ Error message reported Error: UPGRADE FAILED: apiVersion \"rbac.authorization.k8s.io/v1\" in che/charts/che-keycloak/templates/endpoints-monitor-role.yaml is not available Let me change  rbac.authorization.k8s.io/v1 to  rbac.authorization.k8s.io/v1beta1 for endpoints-monitor-role.yaml Execute the command\nhelm upgrade --install  --namespace  -f ./values/multi-user.yaml --set global.ingressDomain= ./ Error message reported\uff1a\nError: UPGRADE FAILED: error validating \"\": error validating data: found invalid field test for v1beta1.DeploymentSpec OS and version:\nk8s version    1.6.11\neclipse che   6.7.0-SNAPSHOT\nDiagnostics:\nNo log information Could it be that the k8s cluster version is low or the configuration file is not the latest cause\uff1f ", "code": [], "labels": ["kind/question"]}
{"project": "xonsh_xonsh", "title": "prompt: error: on field 'curr_branch' on running xonsh", "description": "Hey, I wanted to try out xonsh and installed it using homebrew, but I see this error every time I get into a xonsh shell. It looks like something related to getting the current git branch. <CODE> Here are my xonfig and .xonshrc: <CODE> <CODE> Let me know if you need any other information and/or need help fixing this. Thanks! ", "code": ["~ \ue0b0 xonsh\nprompt: error: on field 'curr_branch'\nxonsh: To log full traceback to a file set: $XONSH_TRACEBACK_LOGFILE = <filename>\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/xonsh/0.5.8/libexec/lib/python3.6/site-packages/xonsh/prompt/__amalgam__.py\", line 671, in _get_field_value\n    value = field_value() if callable(field_value) else field_value\n  File \"/usr/local/Cellar/xonsh/0.5.8/libexec/lib/python3.6/site-packages/xonsh/prompt/__amalgam__.py\", line 486, in current_branch\n    has_git = bool(cmds.locate_binary('git', ignore_alias=True))\n  File \"/usr/local/Cellar/xonsh/0.5.8/libexec/lib/python3.6/site-packages/xonsh/__amalgam__.py\", line 7790, in locate_binary\n    _ = self.all_commands\n  File \"/usr/local/Cellar/xonsh/0.5.8/libexec/lib/python3.6/site-packages/xonsh/__amalgam__.py\", line 7733, in all_commands\n    for cmd in executables_in(path):\n  File \"/usr/local/Cellar/xonsh/0.5.8/libexec/lib/python3.6/site-packages/xonsh/__amalgam__.py\", line 5881, in executables_in\n    yield from func(path)\n  File \"/usr/local/Cellar/xonsh/0.5.8/libexec/lib/python3.6/site-packages/xonsh/__amalgam__.py\", line 5849, in _executables_in_posix\n    yield from _yield_accessible_unix_file_names(path)\n  File \"/usr/local/Cellar/xonsh/0.5.8/libexec/lib/python3.6/site-packages/xonsh/__amalgam__.py\", line 5829, in _yield_accessible_unix_file_names\n    for file_ in scandir(path):\nNotADirectoryError: [Errno 20] Not a directory: '/usr/local/bin/jamf'\n", "r@GOHG ~ (ERROR:curr_branch) $ xonfig\n+------------------+-----------------+\n| xonsh            | 0.5.8           |\n| Python           | 3.6.0           |\n| PLY              | 3.9             |\n| have readline    | True            |\n| prompt toolkit   | None            |\n| shell type       | readline        |\n| pygments         | None            |\n| on posix         | True            |\n| on linux         | False           |\n| on darwin        | True            |\n| on windows       | False           |\n| on cygwin        | False           |\n| is superuser     | False           |\n| default encoding | utf-8           |\n| xonsh encoding   | utf-8           |\n| encoding errors  | surrogateescape |\n+------------------+-----------------+\n", "$ cat ~/.xonshrc\n$XONSH_SHOW_TRACEBACK = True\n"], "labels": ["help wanted", "bug"]}
{"project": "grails_grails-core", "title": "GRAILS-7056: transaction issue when useing GORM ,HQL ,groovy sql in one service method", "description": "Original Reporter: grails-fun\nEnvironment: Not Specified\nVersion: 1.3.3\nMigrated From: <URL> {code}\nclass AbcService implements Serializable { def dataSource def savePerson(UserInfo user) {\nprintln \"before save person\"\nif(!user.save(flush:true)) {\nuser.errors.each {\nprintln it\n}\n}\ndef sql = new Sql(dataSource)\nsql.executeUpdate \"update inf_user t set t.details=='cc'\"//use a wrong sql syntax,to see whether it rollback automatically\n// println 1/0\n}\n}\n{code} I expect the savePerson transaction rollback automatically,while it throws a exception and does not rollback ,the user object is still persisted into database .I don't know why.\nWhen i replace the code\n{code}\ndef sql=new Sql(dataSource)\nsql.executeUpdate \"update inf_user t set t.details=='cc'\"//use a wrong sql syntax,to see whether it rollback automatically\n{code}\nwith\n{code}\nprintln 1/0\n{code}\nand it rollback as expected. My question is how to correctly injected a groovy SQL and control the transaction when useing GORM,HQL,direct SQL togother within  a method of service. Another question is about the tool,i am now using springsource tool suite,when in debug mode,at the first time i can debug nomally,but after I edit one controller file and save it,debug doesnot work,it shows souce not found,I don't know why. ", "code": [], "labels": ["Major", "Duplicate", "Bug"]}
{"project": "cocos2d_cocos2d-x", "title": "[Bug v3.6 Renderer Test] Culling effect is wrong", "description": "When moving the scene out of the screen, the children of scene would be culled unexpectely. I mean the children are not out of the boundary of screen, but the culling takes effect. ", "code": [], "labels": ["type:bug"]}
{"project": "angular-translate_angular-translate", "title": "Question: overriding values after REST Call", "description": "Hi, is there any way to change some values in a translation table that was previously loaded via static file loader? Specifically I need to load a \"default\" set of language tables at .config time (and this is working perfectly via above call), but then another call to a REST API may return some values I want to use to override values of these tables. This second call fires later than .config time, say at .run time or even later on. I tried to use a custom loader that returns the \"overriding values\" , but that does not seem to be used in conjunction with the static file loader (while the REST Call is running, I see no values at all, not even the placeholders). Thank you, ", "code": [], "labels": ["FAQ"]}
{"project": "agda_agda", "title": "Highlighting destructors everywhere", "description": "<CODE> Original issue reported on code.google.com by andreas....@gmail.com on 4 Oct 2010 at 8:50 ", "code": ["Since the signature now provides information whether a function is a record \nprojection, the highlighting module could make use of it and color projections \neverywhere, not only in the record definition.\n"], "labels": ["type: enhancement", "auto-migrated"]}
{"project": "ShareX_ShareX", "title": "Scrolling capture improvements", "description": "When I was using XP, I used an old program called FireShot. It's still up for download. It had perfectly executed scrolling capture and it even opens a cropper tool\u00b9 after the capture. Sadly, on the current version of ShareX cropper tool usually glitches out, miss some pieces or doesn't come up with satisfied capture. You're probably aware of this issue, and I hope this is in somewhere on your todo list. I'll be pleased to hear from your input on this issue. \u00b9 We'll be happy if you add a cropping feature in Output Scrolling Capture window. It's extremely useful, perhaps the most used feature and I always used this feature after scrolling capture. I fully understand that you can create a task to open an image editor to crop, but that's a little clunky experience. In my opinion, the ost valuable is proper scrolling capture and second valuable feature is a simple cropping tool. ", "code": [], "labels": ["Stale"]}
{"project": "YePpHa_YouTubeCenter", "title": "The player is not changed to flash on Chrome", "description": "I've just noticed that the methods that YouTube Center is using to change the player to the flash player does not work anymore. ", "code": [], "labels": ["bug"]}
{"project": "spring-projects_spring-boot", "title": "Upgrade to Ehcache3 3.5.0", "description": "\nNo description provided.\n ", "code": [], "labels": ["priority: normal", "type: dependency-upgrade"]}
{"project": "golang_go", "title": "sync: function passed by value cause unreasonable goroutine blocked(random)", "description": "Please answer these questions before submitting your issue. Thanks! go1.9.2 linux/386 |  go1.9.3 windows/amd64 yes linux and windows <CODE> after about 100 seconds later, the program should quit normally. with the finally output\nrecv 300 recv 296 recv 297 recv 298 2018/01/30 16:37:02 begin check 2018/01/30 16:37:02 1517301422 2018/01/30 16:37:02 end check 2018/01/30 16:37:17 begin check 2018/01/30 16:37:17 1517301437 2018/01/30 16:37:17 end check \nand never quit the result is random, normally all the goroutines should quit, but sometimes, one or two goroutines are just blocked, i did't check which line is blocked( t.RLock() or  t.RUnlock() I guess), but if I impl the code like this : (pass func argument by reference) <CODE> everything just work fine ", "code": ["package main\n\nimport (\n        \"time\"\n        \"sync\"\n        \"log\"\n)\ntype _time struct {\n        time.Time\n        sync.RWMutex\n}\n\nfunc (t _time) now() time.Time {\n        t.RLock()\n        n := t.Time\n        t.RUnlock()\n        return n\n}\n\n\nvar timen _time\nfunc f(j int, c chan struct{}) {\n        for i := 1; i<=1000;i++{\n                println(j, i, timen.now().Unix())\n                time.Sleep(time.Millisecond*100)\n        }\n        go func() {c<-struct{}{}}()\n}\nfunc main() {\n        t := time.Tick(time.Second)\n        go func() {\n                for _ = range t {\n                        timen.Lock()\n                        timen.Time = time.Now()\n                        timen.Unlock()\n                }\n        }()\n        t2 := time.NewTicker(time.Second * 15)\n        defer func() {\n                t2.Stop()\n        }()\n        go func() {\n                for {\n                        select {\n                        case <-t2.C:\n                                log.Println(\"begin check\")\n                                log.Println(timen.now().Unix())\n                                log.Println(\"end check\")\n                        }\n                }\n        }()\n\n        c := make(chan struct{})\n        n := 300\n        for i:=1; i<= n;i++ {\n                go f(i, c)\n        }\n        f(0, c)\n        for i := 0;i <=n;i++ {\n                <-c\n                println(\"recv\", i)\n        }\n}\n\n", "func (t *_time) now() time.Time {\n        t.RLock()\n        n := t.Time\n        t.RUnlock()\n        return n\n}\n\n\nvar timen *_time\nfunc f(j int, c chan struct{}) {\n        for i := 1; i<=1000;i++{\n                println(j, i, timen.now().Unix())\n                time.Sleep(time.Millisecond*100)\n        }\n        go func() {c<-struct{}{}}()\n}\nfunc main() {\n        timen = &_time{}\n...\n"], "labels": ["FrozenDueToAge"]}
{"project": "Windows-XAML_Template10", "title": "Occasional COM Exception E_FAIL when loading HumburgerMenu", "description": "Hi, just got an exception while loading HumburgerMenu. Don't know if it's a known one, but it's occasional. System.Runtime.InteropServices.COMException: Error HRESULT E_FAIL has been returned from a call to a COM component.\nat Windows.UI.Xaml.VisualStateChangedEventArgs.get_Control()\nat Template10.Controls.HamburgerMenu.NavButton_VisualStateChanged(Object sender, VisualStateChangedEventArgs e) ", "code": [], "labels": ["bug"]}
{"project": "qgis_QGIS", "title": "export layout output via terminal", "description": "Author Name: Basil Eric Rabi (@basilrabi)\nOriginal Redmine Issue: 18240 Redmine category:map_composer/printing A terminal command like below, to print layouts by batches without opening the gui, would be nice. qqis-layout -p project.qgs -l layoutName -o mymap.pdf see <URL> ", "code": [], "labels": ["Feature Request", "Print Layouts"]}
{"project": "microsoft_vscode", "title": "Can not sync files to VSTS anymore", "description": "Issue Type: Bug Hi there, i am no longer be able to sync my changes to VSTS anymore.\nI was able to save it and sync it 3 days ago.  I have recently updated the VSC to latest version. Once I click on sync icon its asks me to provide the username and password for Git:company.visualstudio.com (Press 'enter' to confirm or 'Escape to cancel'). This was never asked 3 days ago, and even if I enter the correct username and password, it throws error\nGit: Logon failed, use Ctrl+c to cancel credential prompt. `` I recently updated to below version, not sure if its related.\nVersion 1.24.1\nCommit 24f6262\nDate 2018-06-13T17:51:32.889Z\nShell 1.7.12\nRenderer 58.0.3029.110\nNode 7.9.0\nArchitecture x64 Please help.\n-Viral VS Code version: Code 1.24.1 (24f6262, 2018-06-13T17:51:32.889Z)\nOS version: Windows_NT x64 10.0.14393 ", "code": [], "labels": ["needs more info"]}
{"project": "RIOT-OS_RIOT", "title": "arduino-due SPI", "description": "The arduino-due SPI does not work as expected (or I am doing something wrong). Compare logic analyzer screenshots on arduino:\n\nand stm:\n Tested with tests/periph_spi. ", "code": [], "labels": ["Type: bug"]}
{"project": "angular_components", "title": "Installing Angular Material and Angular CDK (v. 5.2.4) is not working properly", "description": "The installation of Angular material as suggested in (<URL> via npm install --save @angular/material @angular/cdk installs version 6.3.1 of @angular/cdk and @angular/material which is not working with the following installed version of Angular, Angular CLI and Node: Angular CLI: 1.7.4\nNode: 6.11.0\nOS: win32 x64\nAngular: 5.2.11 The installation guide should have the right command to install the proper material version. A version is installed which breaks the app. Angular CLI: 1.7.4\nNode: 6.11.0\nOS: win32 x64\nAngular: 5.2.11 ", "code": [], "labels": ["P4", "docs"]}
{"project": "vuematerial_vue-material", "title": "[MdInput] doesn't put name attribute into inner input tag", "description": "Chrome put the name attribute so i can send my form form is sending empty ", "code": [], "labels": ["needs repro"]}
{"project": "microsoft_microsoft-ui-xaml", "title": "Can't use Narrator item navigation to leave the lower part of the CommandBarFlyout", "description": "(Copied from internal issue.) Core/Non Core Scenario: Unable to come out of lower part of sub context menu in both item/shift tab navigation, in a rich edit box Build Info: 18268 Pre-requisite: Repro steps: Expected result: With item navigation as well as with three finger back swipe focus should move from paste/select all menu item to \"see less\" button. Actual result: The focus gets trapped in the pop-up. Observation: Shift+tab from paste button to \"see less\" button works.In rs5_release three finger back swipe works but item mode navigation doesn't work. User Impact: Touch users will be affected as the focus is getting trapped and user cannot come out of pop-up ", "code": [], "labels": ["team-Controls"]}
{"project": "spring-projects_spring-framework", "title": "A lite configuration class's member classes are processed when it's imported but not when it's registered directly [SPR-16839]", "description": "Andy Wilkinson opened SPR-16839 and commented The problem's hopefully illustrated by the following two tests: thingIsAvailableWhenOuterConfigurationIsImported will pass but thingIsAvailableWhenOuterConfigurationIsRegisteredDirectly will fail. This appears to be because member classes of a lite configuration class are only processed when the lite configuration class has been imported. They are not processed when it's been registered directly with the application context. Affects: 5.0.6 Reference URL: spring-projects/spring-boot#13129 Issue Links: Referenced from: commits spring-projects/spring-boot@5cc1a83 0 votes, 5 watchers ", "code": [], "labels": ["type: enhancement"]}
{"project": "DynamoRIO_drmemory", "title": "indirected code object has two strlen* targets: drmem replaces only one", "description": "From derek.br...@gmail.com on December 10, 2010 17:58:24 PR 582202 xref issue #248/PR 510905 where ELF indirect code object support was added: I\nassume that there is only one routine to intercept.\nbut running tests/loader on my FC12 box I see two!\nI don't fully understand what's going on: is the exported func checking how\nmany args it got somehow?  need to analyze. from log:\nexport strlen indirected from 0x003ead50 to 0x003ead90\nreplacing strlen @0x003ead90 in libc.so.6 (base 0x00374000)\nyet code is at both and executed at ad50:\n(gdb) x/4i strlen\n0x3ead50 :      push   %ebx\n0x3ead51 :    call   0x38a9ef 0x3ead56 :    add    $0xfa29e,%ebx\n0x3ead5c :   cmpl   $0x0,0x354c(%ebx)\n(gdb) x/4i 0x003ead90\n0x3ead90 :       push   %esi\n0x3ead91 :     mov    0x8(%esp),%eax\n0x3ead95 :     mov    %eax,%ecx\n0x3ead97 :     pxor   %xmm0,%xmm0 Original issue: <URL> ", "code": [], "labels": ["Priority-Medium", "Migrated"]}
{"project": "hashicorp_vault", "title": "LDAP Support as Auth Backend", "description": "Are there any plans to support LDAP as an auth backend? This would have to be added in\n<URL>\nin a similar fashion to the existing auth backends. Right? By the way is there a roadmap for vault? ", "code": [], "labels": ["enhancement"]}
{"project": "dotnet_roslyn", "title": "GetOperation returns null for CatchFilterClauseSyntax and FinallyClauseSyntax", "description": "See unit tests TryCatch_GetOperationForCatchFilterClause and TryCatch_GetOperationForFinallyClause added in #22210 It seems the operation tree has nodes mapping to the underlying expression of the CatchFilterClauseSyntax  and block of the FinallyClauseSyntax, but I would except these two syntax nodes also to map the underlying catch filter expression and finally block respectively. ", "code": [], "labels": ["Bug", "New Feature - IOperation", "Area-Analyzers", "Resolution-By Design"]}
{"project": "gatsbyjs_gatsby", "title": "[gatsby-plugin-offline] Configure to cache all resources on first visit", "description": "Hey, Gatsby (and JAMstack in general) newcomer here. A customer is asking for an app to display showcase information on iPads. (These iPads will be in front of their products in the showcase room.) I'd like to use Gatsby for this since it is a rather small project to test things out. But there is one thing I am not sure Gatsby could handle. The client wants an app-like offline experience without bothering about app stores. I know that there are plugins for service workers and a manifest. But I don't know if it behaves like a native app. To my knowledge, I (as the user) must visit every single page to have the full site offline, right? Could I configure the service worker to load all pages including images and videos during the first page load so that the client does not have to manually visit all pages? Oh, and it should work with iOS Safari ... \ud83d\udc4e ", "code": [], "labels": ["stale?", "type: question or discussion"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Nav tree line alignment issue", "description": "If you zoom in you'll see that each item has an additional vertical line. ", "code": [], "labels": ["bug"]}
{"project": "WeblateOrg_weblate", "title": "Weblate 2.19-dev - Parts of the UI are in english", "description": "See screenshot : in this screen at least 3 parts of the UI which were available in french are now displayed in english ;-(.\n ", "code": [], "labels": ["bug"]}
{"project": "ant-design_ant-design-mobile", "title": "\u4f7f\u7528picker\u7ec4\u4ef6\uff0c\u65b0pull\u4e0b\u6765\u7684\u4ee3\u7801\u751f\u6210\u4f9d\u8d56\u5305\u62a5\u3010semver\u3011", "description": "\u9879\u76ee\u91cc\u9762\u5f15\u5165picker\u7ec4\u4ef6\uff0c\u81ea\u5df1\u672c\u5730\u7684\u9879\u76ee\u6ca1\u6709\u62a5\u9519\uff0c\u4f46\u662f\u91cdgit\u4e0a\u9762\u65b0pull\u4e0b\u6765\u7684\u4ee3\u7801\u751f\u6210\u4f9d\u8d56\u7684\u65f6\u5019\u90fd\u62a5\u4e86\u4f9d\u8d56\u3010semver\u3011\uff0c\u542f\u52a8\u9879\u76ee\u7684\u65f6\u5019\u62a5\u9519\uff0c\u627e\u4e0d\u5230rmc\u4e0b\u7684picker\u5305\n\u7136\u540e\u5c1d\u8bd5\u4fee\u6539\u5728package\u91cc\u7684dependencies\u5f15\u5165 \"rmc-picker\":\"3.0.7\"\u7136\u540e\u91cd\u65b0\u751f\u6210\u4f9d\u8d56\uff0c\u542f\u52a8\u6ca1\u6709\u62a5\u9519\uff0c\u4f46\u662fpicker\u5728antd-mobile\u5c01\u88c5\u7684\u4e00\u4e9b\u5c5e\u6027\u5c31\u4e0d\u80fd\u7528\u4e86\u3002 ", "code": [], "labels": ["invalid"]}
{"project": "dart-lang_sdk", "title": "Add a link to \"api.dartlang.org\" on \"try.dartlang.org\"", "description": "This issue was originally filed by JayYoung990...@gmail.com I just tried to verify something using the \"try.dartlang.org\" Dartboard and needed to consult the API docs and had to navigate to them manually.  I doubt this is an uncommon scenario, so having a link to the new API docs seems like a quick and easy plus. ", "code": [], "labels": ["closed-not-planned", "Type-Enhancement", "type-enhancement"]}
{"project": "eclipse_che", "title": "Upgraded to from 4.0.1 to 4.2.0: internal server error 500 when trying to access to workspaces", "description": "Hi everyone, For some months I use Che version 4.0.1 successfully. Really amazing!\nChe runs on an OpenSuse Leap 42.1 server.\nMy configuration is default with these few changes: <CODE> I've just upgraded my server to 4.2.0 and use same configuration as above.\nNow going to http://myserver:8080/api/workspace fires an internal server error 500.\nTrying to create a new workspace fires same error and displays Failed. Error during workspace creation message.\nNo trace in Tomcat logs (see below). And after downgrading to previous 4.0.1, same errors appear now.\nPlease, any ideas ? Thanks,\nJacques Tomcat logs: <CODE> ", "code": ["che.user.workspaces.storage=/home/myuser/workspaces\nche.conf.storage=/home/myuser/local-storage\n", "2016-05-15 16:01:19,978[main]             [INFO ] [o.a.c.s.VersionLoggerListener 89]    - Server version:        Apache Tomcat/8.0.32\n2016-05-15 16:01:19,983[main]             [INFO ] [o.a.c.s.VersionLoggerListener 91]    - Server built:          Feb 2 2016 19:34:53 UTC\n2016-05-15 16:01:19,983[main]             [INFO ] [o.a.c.s.VersionLoggerListener 93]    - Server number:         8.0.32.0\n2016-05-15 16:01:19,984[main]             [INFO ] [o.a.c.s.VersionLoggerListener 95]    - OS Name:               Linux\n2016-05-15 16:01:19,985[main]             [INFO ] [o.a.c.s.VersionLoggerListener 97]    - OS Version:            4.1.20-11-default\n2016-05-15 16:01:19,985[main]             [INFO ] [o.a.c.s.VersionLoggerListener 99]    - Architecture:          amd64\n2016-05-15 16:01:19,986[main]             [INFO ] [o.a.c.s.VersionLoggerListener 101]   - Java Home:             /usr/java/jdk1.8.0_73/jre\n2016-05-15 16:01:19,987[main]             [INFO ] [o.a.c.s.VersionLoggerListener 103]   - JVM Version:           1.8.0_73-b02\n2016-05-15 16:01:19,988[main]             [INFO ] [o.a.c.s.VersionLoggerListener 105]   - JVM Vendor:            Oracle Corporation\n2016-05-15 16:01:19,989[main]             [INFO ] [o.a.c.s.VersionLoggerListener 107]   - CATALINA_BASE:         /home/myuser/eclipse-che-4.2.0/tomcat\n2016-05-15 16:01:19,990[main]             [INFO ] [o.a.c.s.VersionLoggerListener 109]   - CATALINA_HOME:         /home/myuser/eclipse-che-4.2.0/tomcat\n2016-05-15 16:01:19,991[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Djava.util.logging.config.file=/home/myuser/eclipse-che-4.2.0/tomcat/conf/logging.properties\n2016-05-15 16:01:19,992[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager\n2016-05-15 16:01:19,992[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Xms256m\n2016-05-15 16:01:19,993[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Xmx1024m\n2016-05-15 16:01:19,994[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Djava.security.egd=file:/dev/./urandom\n2016-05-15 16:01:19,994[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dport.http=8080\n2016-05-15 16:01:19,995[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dche.home=/home/myuser/eclipse-che-4.2.0\n2016-05-15 16:01:19,995[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dche.logs.dir=/home/myuser/eclipse-che-4.2.0/tomcat/logs/\n2016-05-15 16:01:19,996[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dcom.sun.management.jmxremote\n2016-05-15 16:01:19,996[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dcom.sun.management.jmxremote.ssl=false\n2016-05-15 16:01:19,997[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dcom.sun.management.jmxremote.authenticate=false\n2016-05-15 16:01:19,997[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dche.local.conf.dir=/home/myuser/eclipse-che-4.2.0/conf/\n2016-05-15 16:01:19,998[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Djava.endorsed.dirs=/home/myuser/eclipse-che-4.2.0/tomcat/endorsed\n2016-05-15 16:01:19,998[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dcatalina.base=/home/myuser/eclipse-che-4.2.0/tomcat\n2016-05-15 16:01:19,999[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Dcatalina.home=/home/myuser/eclipse-che-4.2.0/tomcat\n2016-05-15 16:01:20,000[main]             [INFO ] [o.a.c.s.VersionLoggerListener 115]   - Command line argument: -Djava.io.tmpdir=/home/myuser/eclipse-che-4.2.0/tomcat/temp\n2016-05-15 16:01:20,454[main]             [INFO ] [o.a.c.http11.Http11NioProtocol 425]  - Initializing ProtocolHandler [\"http-nio-8080\"]\n2016-05-15 16:01:20,497[main]             [INFO ] [o.a.t.util.net.NioSelectorPool 72]   - Using a shared selector for servlet write/read\n2016-05-15 16:01:20,503[main]             [INFO ] [o.a.catalina.startup.Catalina 591]   - Initialization processed in 1255 ms\n2016-05-15 16:01:20,544[main]             [INFO ] [c.m.JmxRemoteLifecycleListener 332]  - L'\u00e9couteur distant JMX a configur\u00e9 le r\u00e9pertoire sur le port 32001 et le serveur sur le port 32101 pour le serveur Platform\n2016-05-15 16:01:20,545[main]             [INFO ] [o.a.c.core.StandardService 435]      - D\u00e9marrage du service Catalina\n2016-05-15 16:01:20,546[main]             [INFO ] [o.a.c.core.StandardEngine 259]       - Starting Servlet Engine: Apache Tomcat/8.0.32\n2016-05-15 16:01:20,716[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 910]        - D\u00e9ploiement de l'archive /home/myuser/eclipse-che-4.2.0/tomcat/webapps/swagger.war de l'application web\n2016-05-15 16:01:21,529[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 974]        - Deployment of web application archive /home/myuser/eclipse-che-4.2.0/tomcat/webapps/swagger.war has finished in 812 ms\n2016-05-15 16:01:21,534[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 910]        - D\u00e9ploiement de l'archive /home/myuser/eclipse-che-4.2.0/tomcat/webapps/dashboard.war de l'application web\n2016-05-15 16:01:21,783[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 974]        - Deployment of web application archive /home/myuser/eclipse-che-4.2.0/tomcat/webapps/dashboard.war has finished in 249 ms\n2016-05-15 16:01:21,788[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 910]        - D\u00e9ploiement de l'archive /home/myuser/eclipse-che-4.2.0/tomcat/webapps/ide.war de l'application web\n2016-05-15 16:01:30,652[ost-startStop-1]  [WARN ] [p.DockerExtConfBindingProvider 51]   - DockerExtConfBindingProvider\n2016-05-15 16:01:33,588[ost-startStop-1]  [INFO ] [.c.p.d.c.DockerRegistryChecker 43]   - Probing registry 'http://localhost:5000'\n2016-05-15 16:01:33,604[ost-startStop-1]  [WARN ] [.c.p.d.c.DockerRegistryChecker 50]   - Docker registry http://localhost:5000 is not available, which means that you won't be able to save snapshots of your workspaces.\nHow to configure registry?\n    Local registry  -> https://docs.docker.com/registry/\n    Remote registry -> set up 'docker.registry.auth.*' properties\n2016-05-15 16:01:34,124[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 974]        - Deployment of web application archive /home/myuser/eclipse-che-4.2.0/tomcat/webapps/ide.war has finished in 12\u00a0336 ms\n2016-05-15 16:01:34,126[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 1030]       - D\u00e9ploiement du r\u00e9pertoire /home/myuser/eclipse-che-4.2.0/tomcat/webapps/ROOT de l'application web\n2016-05-15 16:01:34,226[ost-startStop-1]  [INFO ] [o.a.c.startup.HostConfig 1142]       - Deployment of web application directory /home/myuser/eclipse-che-4.2.0/tomcat/webapps/ROOT has finished in 100 ms\n2016-05-15 16:01:34,237[main]             [INFO ] [o.a.c.http11.Http11NioProtocol 470]  - Starting ProtocolHandler [\"http-nio-8080\"]\n2016-05-15 16:01:34,257[main]             [INFO ] [o.a.catalina.startup.Catalina 642]   - Server startup in 13752 ms\n"], "labels": ["kind/question"]}
{"project": "angular_angular", "title": "[router] version 3.2.0 has a peer dependency on the @angular/upgrade", "description": "I'm submitting a ... <CODE> Current behavior\nWhen I updated angular to 2.2.0 and the router to 3.2.0, I had a warning saying that I had an unmet peer dependency because @angular/upgrade was missing. The router is running fine without it, but the warning prevents me from using npm shrinkwrap.\nThe dependency is defined here: <URL> Expected behavior\nIt shouldn't have a hard peer dependency on @angular/upgrade since this is only needed with ng1/ng2 hybrid applications. Minimal reproduction of the problem with instructions\nInstall any angular application with the router but without the upgrade package. What is the motivation / use case for changing the behavior?\nDon't force people to install libs that they don't use and that aren't required to make the router work. ", "code": ["[x] bug report => search github for a similar issue or PR before submitting\n"], "labels": ["comp: router"]}
{"project": "systemd_systemd", "title": "broken unicode while shutdown process", "description": "NOTE: Do not submit anything other than bug reports or RFEs via the issue tracker! NOTE: Do not submit bug reports about anything but the two most recently released systemd versions upstream! Hello,\nFollowing behaviour: Everytime when I execute systemctl poweroff I have weird systemd messages during the poweroff process. It looks like a mix of broken unicode with korean. When I look in the journald log it's fine. I can read it. But during poweroff I can't read whats happening. As far as i can see everything behave normal, just the display of the text seems broken. I will try to add a picture when I reboot/poweroff my machine next time. I am not sure if this is a systemd bug in general or if it has something todo with my locales or something else. <CODE> ", "code": ["# localectl\n   System Locale: LANG=en_US.UTF-8\n       VC Keymap: us\n      X11 Layout: us\n"], "labels": ["needs-reporter-feedback "]}
{"project": "ytti_oxidized", "title": "scriptlet does not exist!", "description": "hello when following the instruction for centos I have come across the following error. Is there any chance you might be able to help me resolve this issue? [root@srv01 ~]# scl enable rh-ruby23 bash\nwarning: /opt/rh/rh-ruby23//enable scriptlet does not exist! ", "code": [], "labels": ["triage"]}
{"project": "godotengine_godot", "title": "GDScript issue with re-initializaing of a variable when script used both as autoload and bound to a Node", "description": "Operating system or device, Godot version, GPU Model and driver (if graphics related):\nWindows 10, Godot 3.0 master at 10 dec 2017 Issue description:\nGDScript variable state is resetted from time to time.\nMain reason that cause this issue: adding a script to Project's AutoLoad section.\nIf you remove from autoload, then bug disappear. OR if you remove this script from Node's script section in Inspector.\nSo I guess, if the same script is allowed to be in Autoload and attached to node - then we have a bug. Otherwise - we should popup an error messagebox to user saying like he cannot have same script in autoload & attach to node. Steps to reproduce:\nOpen project in Godot, run it and see output tab.\nYou will see log like this:\nres: 0, val: False\nres: 3, val: False\nres: 0, val: False\nSETTING TRUE!\nres: 1, val: True\nres: 3, val: False <-- bug\nSETTING TRUE!\nres: 1, val: True\nres: 0, val: False <-- bug\nSETTING TRUE!\nres: 1, val: True\nSETTING TRUE!\nres: 1, val: True\nres: 0, val: True\nres: 0, val: True\nres: 3, val: True\nres: 3, val: True\nres: 0, val: True\nSETTING TRUE!\nres: 1, val: True\nSETTING FALSE!\nres: 2, val: False\nres: 0, val: True <-- bug\nres: 0, val: False Link to minimal example project:\n<URL> ", "code": [], "labels": ["archived", "bug", "topic:gdscript"]}
{"project": "godotengine_godot", "title": "Save and Close Crashing Editor", "description": "On Windows 10 x64 Running Godot x32 from the most recent build from the master branch. Steps to reproduce It seems to be happening in both 2D and 3D scenes. Console output only says - \"CrashHandlerException: Program crashed\"  ", "code": [], "labels": ["topic:editor", "bug"]}
{"project": "travis-ci_travis-ci", "title": "Build status and logs do not refresh in Safari", "description": "Builds, which are already finished, are stuck in started/booting/in progress state. No new logs appear when build is already in progress. This results in no changes on screen - except the timer which may show that build takes hours if you keep the tab open for so long. Everything works perfectly on Chrome. <CODE> ", "code": ["[Error] The Content Security Policy directive 'frame-ancestors' is ignored when delivered in a report-only policy.\n[Error] [Report Only] Refused to execute a script because its hash, its nonce, or 'unsafe-inline' does not appear in the script-src directive of the Content Security Policy. (50655512, line 0)\n[Error] WebSocket connection to 'wss://ws.pusherapp.com/app/59236bc0716a551eab40?protocol=7&client=js&version=2.2.4&flash=false' failed: Failed to send WebSocket frame.\n\t(anonymous function) (pusher.js:2164)\n\t(anonymous function) (pusher.js:266)\n\t(anonymous function) (pusher.js:236)\n\tr (vendor-91b4b262d93160c117068e19c449b12f.js:4300)\n[Warning] Error (vendor-91b4b262d93160c117068e19c449b12f.js, line 4264)\n[Error] WebSocket connection to 'wss://ws.pusherapp.com/app/59236bc0716a551eab40?protocol=7&client=js&version=2.2.4&flash=false' failed: Failed to send WebSocket frame.\n\t(anonymous function) (pusher.js: 2164)\n\t(anonymous function) (pusher.js: 266)\n\t(anonymous function) (pusher.js:236)\n\tr (vendor-91b4b262d93160c117068e19c449b12f.js:4300)\n[Warning] Error \u2013 {type: \"WebSocketError\", error: Object} (vendor-91b4b262d93160c117068e19c449b12f.js, line 4264)\n{type: \"WebSocketError\", error: Object}Object\n[Error] The Content Security Policy directive 'frame-ancestors' is ignored when delivered in a report-only policy. (x2)\n[Error] [Report Only] Refused to execute a script because its hash, its nonce, or 'unsafe-inline' does not appear in the script-src directive of the Content Security Policy. (about:blank, line 0)\n[Error] [Report Only] Refused to execute a script because its hash, its nonce, or 'unsafe-inline' does not appear in the script-src directive of the Content Security Policy. (50655512, line 0)\n"], "labels": ["stale"]}
{"project": "Squirrel_Squirrel.Windows", "title": "Downloading optional files on demand", "description": "This is not an issue just a question:\nClickOnce provides the ability to mark certain files as optional by assigning group names to files.\nThis allows the application to decide at run time which optional files are needed and download them on demand and load them using reflection.\nIs this supported with Squirrel? ", "code": [], "labels": ["wontfix"]}
{"project": "arendst_Tasmota", "title": "Schedule like in original firmware", "description": "Hi, before i flash Pow with this firmware i have question is possible to have Schedule to power on and off devices connected to pow but not with mqtt but like standalone ", "code": [], "labels": ["stale"]}
{"project": "mozilla_multi-account-containers", "title": "Feature Request: Reorganize windows (not just tabs) by category", "description": "I am a FF user who often has multiple windows with a large amount of tabs per-window. I will usually try to organize myself by keeping websites of the same category in the same window instance (all music sites together, all shopping, all social media, etc). It would be useful to me to be able to use the categorizing tabs feature to sort and move tabs that are assigned to the same category into the same 'window' instance of FF (as FF defines windows) Use Case: BEFORE Window 1 Window 2: AFTER\nWindow 1 (all music tabs) Window 2 (All shopping tabs) Window 3 (all FB tabs) Window 4 (uncategorized tabs) My suggestion would be to be able to do this on a per-window basis, and executing this action on multiple windows would sort things into the same window categories (rather than creating entirely new windows) ", "code": [], "labels": ["enhancement"]}
{"project": "apache_skywalking", "title": "Why a trace chain displays two operation names", "description": "\nthey have same traceId ", "code": [], "labels": ["question"]}
{"project": "prettier_prettier", "title": "I wrote a pre-commit hook. Any good place to put it?", "description": "I'd file a PR with my pre-commit hook to verify that all changed javascript files are formatted properly: <URL> , but there doesn't seem to be a sensible place in the repository for it. Any ideas? I think it'd be useful to at least point people to? Also, it can be MIT licensed, I just put something on there so it said something. I 100% do not care about the license. ", "code": [], "labels": ["locked-due-to-inactivity"]}
{"project": "ytdl-org_youtube-dl", "title": "[mirror] Add support for Mirror.co.uk", "description": "Add -v flag to your command line you run youtube-dl with, copy the whole output and insert it here. It should look similar to one below (replace it with your log inserted between triple ```): <CODE> Note that youtube-dl does not support sites dedicated to copyright infringement. In order for site support request to be accepted all provided example URLs should not violate any copyrights. Unable to download the video on Mirror.co.uk. ", "code": ["$ youtube-dl -v http://www.mirror.co.uk/news/world-news/richard-hammond-switzerland-crash-video-10599724\n[debug] System config: []\n[debug] User config: []\n[debug] Custom config: []\n[debug] Command-line args: [u'-v', u'http://www.mirror.co.uk/news/world-news/richard-hammond-switzerland-crash-video-10599724']\n[debug] Encodings: locale UTF-8, fs UTF-8, out UTF-8, pref UTF-8\n[debug] youtube-dl version 2017.06.05\n[debug] Python version 2.7.12 - Linux-4.4.0-72-generic-x86_64-with-Ubuntu-16.04-xenial\n[debug] exe versions: ffmpeg 2.8.11-0ubuntu0.16.04.1, ffprobe 2.8.11-0ubuntu0.16.04.1\n[debug] Proxy map: {}\n[generic] richard-hammond-switzerland-crash-video-10599724: Requesting header\nWARNING: Falling back on generic information extractor.\n[generic] richard-hammond-switzerland-crash-video-10599724: Downloading webpage\n[generic] richard-hammond-switzerland-crash-video-10599724: Extracting information\nERROR: Unsupported URL: http://www.mirror.co.uk/news/world-news/richard-hammond-switzerland-crash-video-10599724\nTraceback (most recent call last):\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/generic.py\", line 1970, in _real_extract\n    doc = compat_etree_fromstring(webpage.encode('utf-8'))\n  File \"/usr/local/bin/youtube-dl/youtube_dl/compat.py\", line 2526, in compat_etree_fromstring\n    doc = _XML(text, parser=etree.XMLParser(target=_TreeBuilder(element_factory=_element_factory)))\n  File \"/usr/local/bin/youtube-dl/youtube_dl/compat.py\", line 2515, in _XML\n    parser.feed(text)\n  File \"/usr/lib/python2.7/xml/etree/ElementTree.py\", line 1653, in feed\n    self._raiseerror(v)\n  File \"/usr/lib/python2.7/xml/etree/ElementTree.py\", line 1517, in _raiseerror\n    raise err\nParseError: not well-formed (invalid token): line 8, column 81\nTraceback (most recent call last):\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 761, in extract_info\n    ie_result = ie.extract(url)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/common.py\", line 433, in extract\n    ie_result = self._real_extract(url)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/extractor/generic.py\", line 2795, in _real_extract\n    raise UnsupportedError(url)\nUnsupportedError: Unsupported URL: http://www.mirror.co.uk/news/world-news/richard-hammond-switzerland-crash-video-10599724\n\n...\n<end of log>\n"], "labels": ["site-support-request"]}
{"project": "helm_helm", "title": "Installing helm 3 on a circleci machine, the executable exits with a return code 1", "description": "When installing helm 3 on a CircleCI machine or docker image, the helm executable will only returns an exit code of 1 with no output, whatever what the arguments are Output of helm version: nothing. Only a return code of 1. But the installed version is 3.0.0 Output of kubectl version: 1.6.3, but shouldn't be relevant as no contact with the cluster is made Cloud Provider/Platform (AKS, GKE, Minikube etc.):  baremetal, but shouldn't be relevant as no contact with the cluster is made ", "code": [], "labels": ["question/support"]}
{"project": "tensorflow_tensorflow", "title": "[lite/micro] missing delete() in GreedyMemoryPlanner", "description": " does not override void operator delete(void *p) which results in link time error. ", "code": [], "labels": ["comp:lite", "type:bug"]}
{"project": "TrinityCore_TrinityCore", "title": "[Quest] The Tome of Valor", "description": "Description: Causes server to crash Current behaviour: When you are on the quest The Tome of Valor with id (1651) in Westfall and you are on the 3rd \"step\" and Daphne is running back it causes the server to crash. Expected behaviour: Not crash Steps to reproduce the problem: Branch(es): 3.3.5 TC rev. hash/commit: b1fa8ff TDB version: 3.3.5.62 Operating system: Windows 7 ", "code": [], "labels": ["Branch-3.3.5a", "Sub-Quests", "Comp-Database"]}
{"project": "opentx_opentx", "title": "Companion 2.2.3, radio simulator", "description": "Describe the bug\nOn Radio simulator window clicking on arrow up/down left/right trim buttons the trim behavior isn't reproduced, instead moving the slider the behavior is ok. To Reproduce Expected behavior\nClicking on arrow button the expectation is to reproduce the trim behavior General information ", "code": [], "labels": ["stale"]}
{"project": "kalessil_phpinspectionsea", "title": "False positive \"This makes no sense or enforces the operation result\"", "description": "Current behaviour (description/screenshot:) A colleague of mine likes to write symfony collection filters like this: <CODE> While I would agree that the \"true\" in the begginning of the return is a weird way to handle the filter, he absolutely wants it this way and PHP Inspections marks the \"true\" as \"This makes no sense or enforces the operation result\" error, which of course is not true. Expected behaviour Do not mark the true as making no sense, even so it's pretty ugly. Environment details PhpStorm 2018.3.1\nBuild #PS-183.4588.67, built on December 5, 2018\nLicensed to \nSubscription is active until April 25, 2019\nJRE: 1.8.0_152-release-1343-b16 amd64\nJVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o\nWindows 7 6.1 ", "code": ["    $allImages = $object->getImages()\n        ->filter(function (Image $image) use ($maxAge, $includeUnrated, $now) {\n            return true\n                && ($image->getCreated() <= $now)\n                && ($now <= $image->getDeleted())\n                && ($image->getAge() <= $maxAge)\n                && ((Audit::STATE_ACCEPTED === $image->getState()) || $includeUnrated)\n                && (Audit::STATE_REJECTED !== $image->getState())\n                ;\n        });\n"], "labels": ["fixed", "bug / false-positive"]}
{"project": "streamlink_streamlink", "title": "Make HLS chunk-lists playable", "description": "Instead of sending a playlist first some web sites immediately send chunk lists, like: <CODE> Firefox addon \"Native HLS Playback\" by Gaetan Hervouet has no issue playing such files. Streamlink gives an error: \"No playable streams found on this URL: ...\" Hope it's possible to fix. ", "code": ["#EXTM3U\n#EXT-X-VERSION:3\n#EXT-X-TARGETDURATION:6\n#EXT-X-MEDIA-SEQUENCE:666\n#EXTINF:2.0,\nvideo1.ts\n#EXTINF:2.0,\nvideo2.ts\n#EXTINF:2.0,\nvideo3.ts\n"], "labels": ["question"]}
{"project": "PokemonGoF_PokemonGo-Bot", "title": "Making the bot smarter to avoid being permanently banned", "description": "Making the bot smarter to avoid being permanently banned by changing the device ID and the altitude. This thread shows that those two parameters are easy bot flags: <URL>\nFaking them correctly could be a first step to avoid bans. Therefore I would suggest adding a new field to the config.json file where one can specify an arbitrary device ID, to differ from the currently hardcoded one.\nFor the altitude I would suggest using some kind of API that returns the altitude from a lat/long parameter. If using one is not possible (doesn't exist, is not free, or whatever reason) then I would suggest randomizing it between an interval of perfectly reasonable values. Bans are making the use of this bot way less entertaining, and waking towards fixing it would be a great way to keeping using this bot worth it. ", "code": [], "labels": ["Duplicate"]}
{"project": "serverless_serverless", "title": "Serverless Deploy Error", "description": "I am trying to deploy a function on aws lambda but it gives error as below plugins used are at ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat new ReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:195:28)\nat Object.createReadStream (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/graceful-fs.js:237:12)\nat copyFile (/home/keyur/Desktop/SN/node-serverless/states/node_modules/fs-extra/lib/copy/ncp.js:98:25)\nat /home/keyur/Desktop/SN/node-serverless/states/node_modules/fs-extra/lib/copy/ncp.js:82:9\nat /home/keyur/Desktop/SN/node-serverless/states/node_modules/fs-extra/lib/copy/ncp.js:208:43\nat callback (/home/keyur/Desktop/SN/node-serverless/states/node_modules/graceful-fs/polyfills.js:289:20)\nat callback (/home/keyur/.nvm/versions/node/v10.16.3/lib/node_modules/serverless/node_modules/graceful-fs/polyfills.js:295:20)\nat FSReqWrap.oncomplete (fs.js:153:21) ", "code": [], "labels": ["duplicate"]}
{"project": "realm_realm-js", "title": "ListView should spread the underlying prop types", "description": "", "code": [], "labels": ["T-Bug"]}
{"project": "akka_akka", "title": "2.0-M1 reference documentation contains references to `builder.addEdge`, `partial`, `closed`, and others", "description": "I went through the Scala reference doc for 2.0-M1 and noticed the text hasn't been fully updated. See for instance <URL>, which contains references to non existing methods builder.addEdge, partial, and closed. Or <URL>, which also contains references to  partial, closed, and also text that I believe is plain wrong now, e.g., In order to create a Source from a partial flow graph Source provides a special apply method that takes a function that must return an Outlet[T] [...]. These are just a couple of examples, there are likely more places where the text needs to be updated. ", "code": [], "labels": ["t:docs", "t:stream"]}
{"project": "microsoft_vscode", "title": "Jupyter Notebook Support: Live Markdown Preview", "description": "When writing long equations or matrices in markdown cells, within a Jupyter notebook, it becomes very difficult to \"see\" what you're doing. Having a live preview for markdown cells (rendered below the current cell being ended) would be tremendously helpful for this purpose. This is already available as an extension in Jupyter notebook (but not yet available in JupyterLab either) and it would be amazing to have it as a feature in VS Code as well. ", "code": [], "labels": ["*caused-by-extension"]}
{"project": "iview_iview", "title": "[Feature Request] Time component adds tooltip properties, whether the mouse skips over the full display time", "description": "\u5e0c\u671b\u9f20\u6807\u6ed1\u8fc7\uff0c\u4e5f\u80fd\u770b\u5230\u76f8\u5bf9\u65f6\u95f4\u7684\u5177\u4f53\u65f6\u95f4 ", "code": [], "labels": ["feature request"]}
{"project": "netblue30_firejail", "title": "[0.9.42-rc1] build failure on non-x86", "description": "src/faudit/syscall.c is using the header sys/io.h for ioperm/iopl, which is only available on x86 architectures.\nBecause of this the build is failing on other architectures:\n<URL> Can you please perform the ioperm/iopl checks only on x86 targets? ", "code": [], "labels": ["bug"]}
{"project": "rundeck_rundeck", "title": "Enhancement Proposal: Hashicorp Vault backend for Key \"Storage\"", "description": "I may, myself, put some work into this but between it being a long while since I've touched Java/Groovy, unfamiliarity with the rundeck codebase, and a general lack of time I wanted to throw out the proposal for someone else to tackle if interested As it currently stands there are two key storage backends, file and db -  <URL> While certain enhancements can be made in that direction, generally these lack several desirable qualities for secret management such as: encryption at rest, audibility, revocability, Role-based access control (per secret). While the bundled Jasypt Encryption Plugin addresses the first in principal, and other features of rundeck itself shine light on the others, overall it is far from easy to get this right starting from scratch. HashiCorp's Vault is one of a class of software lately being popularized to address these concerns in a service oriented fashion. Deferring to it as a storage mechanism would get Rundeck these gains \"for free\" Each of the above could in principal be done pursuant to any of the following ways to handle authentication Personally it is the premise of 3B or 2B that excite me. but 1A or 2A is probably the easiest to implement. The C's are probably important for feature completeness but irrelevant to me at the moment. To add something perhaps better stated in motivation, I am amongst the people who currently am using Rundeck as a ~short lived containerized service using something like jjethwa/rundeck#31 - this makes the file backend a no-go, though something like a consul-template coprocess could let me use it as a sneaky approach to implement this. The db works but because I am delegating db credentials to the container hosts (in my case under a fleet cluster) more or less at-will, I would prefer stronger guarantees for my needed secrets. And since I need to manage RBAC policies in other systems already, I'd like to not need to duplicate the logic into rundeck. Anyway, as I said, I might get to it - but if anyone else is excited to tackle it, please do \ud83d\ude04 ", "code": [], "labels": ["enhancement"]}
{"project": "gohugoio_hugo", "title": "Enhance default Menu sorting", "description": "The default Menu sorting only considers Weight and Name (see here).  We should add Identifier (and potentially URL) as an additional criteria so that entries like the following will have deterministic sorting: See discussion forum for more details about why the sorting could be non-deterministic. ", "code": [], "labels": ["Enhancement"]}
{"project": "NixOS_nixpkgs", "title": "pycurl tests fail on master", "description": "installing pycurl fails with test not running properly if i have time tonight, i'll look into it. ", "code": [], "labels": ["6.topic: python"]}
{"project": "helm_helm", "title": "helm create -> ingress template + values files should be slightly different", "description": "ingress paths should be a list in the values file like this: <CODE> and then in the ingress template something like this: <CODE> notice i added an 's' ", "code": ["ingress:\n  enabled: false\n  annotations: {}\n    # kubernetes.io/ingress.class: nginx\n    # kubernetes.io/tls-acme: \"true\"\n  paths: []\n  hosts:\n    - chart-example.local\n  tls: []\n  #  - secretName: chart-example-tls\n  #    hosts:\n  #      - chart-example.local\n", "{{- $ingressPaths := .Values.ingress.paths -}}\n...\n...\n.\n.\n.\n  rules:\n  {{- range .Values.ingress.hosts }}\n    - host: {{ . | quote }}\n      http:\n        paths:\n        {{- range $ingressPaths }}\n          - path: {{ . | quote }}\n            backend:\n              serviceName: {{ $fullName }}\n              servicePort: http\n        {{- end }}\n  {{- end }}\n"], "labels": ["feature"]}
{"project": "gravitational_teleport", "title": "audit_table_name doesn't appear in the DynamoDB section of the admin guide", "description": "What happened: Customer asked how to configure DynamoDB integration to use two separate tables for cluster state storage and audit log storage, because it isn't clear from the docs. What you expected to happen: This should be clear from the docs. Here's the actual way the config works (as taken from <URL> <CODE> ", "code": ["teleport:\n  storage:\n    type: dynamodb\n    region: us-west-2\n    table_name: teleport_state\n    audit_table_name: teleport_audit\n    audit_sessions_uri: s3://example.s3.bucket/records\n"], "labels": ["documentation"]}
{"project": "vector-im_riot-web", "title": "Make it easier to get people chatting (guest access on mobile?)", "description": "(This issue isn't really just about riot-web. It's really about the whole ecosystem, but I need a place to write it down and this will do\u2026) I've gotten several dozens of people to join Matrix in the last couple of weeks, and found the process unnecessarily complex. Often, I'd have to wait for the person to install the app so that I could then let them know how to connect with me, or join the conference chat room. Per se, that wasn't so bad as I used to time to explain some concepts around Matrix, but quite a few times we simply ran out of time, which hindered adoption. Furthermore, I found a lot of this to be repetitive and error-prone, thus calling for automation. In an ideal world, either of the two should be possible: Obviously, this can go to any level of detail, but maybe the following could be a viable way forward? Probably the two data files in (2.) and (3.) should be combined into one and then fed into the app at once, so as to simplify control flow for the user. With the Riot web client, no data file needs to be downloaded. A link to the webapp could encode all this information, or at least the URI where to download all these data. The mobile clients probably need to register themselves as a MIME handler for this type of file such that they get invoked to handle the download. ", "code": [], "labels": ["ui/ux", "feature", "p1"]}
{"project": "matomo-org_matomo", "title": "UI: use POST request instead of get to avoid parameters logging", "description": "Currently, many admin features use ajax requests with GET parameters. Parameters can include the token_auth and therefore is sensitive information. The requests to piwik are usually logged in the apache/nginx/iis access logs. Let's do a quick audit of the piwik source code, and change all these requests to POST, post params are not logged. ", "code": [], "labels": ["T: Task"]}
{"project": "OpenTTD_OpenTTD", "title": "Bridge Upgrade in OpenTTD", "description": "Liang25 opened the ticket and wrote: Reported version: Version?\nOperating system: All ", "code": [], "labels": ["Core", "flyspray"]}
{"project": "dotnet_roslyn", "title": "IntelliSense for OperationDescription does not find Behaviors member", "description": "Version Used: Visual Studio 2017 v15.1 (26403.7) Steps to Reproduce: Expected Behavior:\nWhen typing op.Beh, IntelliSense should suggest to autocomplete to op.Behaviors. Actual Behavior:\nIntelliSense does not see the Behaviors member at all, so typing it completely will make IntelliSense autocomplete to op.OperationBehaviors. You can then remove the Operation part manually again, and the code is still valid and compiles fine. IntelliSense is even able to jump to the member by pressing F12 on it. I have no idea what\u2019s going on here, but this is driving me crazy. IntelliSense just doesn\u2019t see the member although it is there and has been there for a long while. I\u2019ve confirmed this behavior on three different machines. ", "code": [], "labels": ["Resolution-By Design", "Area-IDE", "Bug"]}
{"project": "sequelize_sequelize", "title": "[2.0.0-dev13] Validation for virtual attributes", "description": "Validation for virtual attributes does not work\n2.0.0-dev13 ", "code": [], "labels": ["type: bug"]}
{"project": "ansible_ansible", "title": "AWS_URL not currently compatible with dynamodb_table", "description": "Feature Idea dynamodb_table <CODE> n/a n/a AWS_URL not currently compatible with dynamodb_table It should connect to local dynamodb instance instead of AWS endpoint. <CODE> This happens because ec2_url is not used by connect_to_aws: <URL> ", "code": ["ansible 2.3.1.0\n  config file =\n  configured module search path = Default w/o overrides\n  python version = 2.7.10 (default, Aug 22 2015, 20:33:39) [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.1)]\n", "fatal: [localhost]: FAILED! => {\"changed\": false, \"failed\": true, \"hash_key_name\": \"id\", \"hash_key_type\": \"STRING\", \"indexes\": [{\"hash_key_name\": \"uri\", \"name\": \"uri-created_at\", \"range_key_name\": \"created_at\", \"read_capacity\": 1, \"type\": \"global_all\", \"write_capacity\": 1}], \"msg\": \"Failed to create/update dynamo table due to error: Traceback (most recent call last):\\n  File \\\"/var/folders/18/5wdtlv6962j6414mh8__cskr0000gn/T/ansible_xZYL7s/ansible_module_dynamodb_table.py\\\", line 210, in create_or_update_dynamo_table\\n    if dynamo_table_exists(table):\\n  File \\\"/var/folders/18/5wdtlv6962j6414mh8__cskr0000gn/T/ansible_xZYL7s/ansible_module_dynamodb_table.py\\\", line 262, in dynamo_table_exists\\n    raise e\\nJSONResponseError: JSONResponseError: 400 Bad Request\\n{u'message': u'The security token included in the request is invalid.', u'__type': u'com.amazon.coral.service#UnrecognizedClientException'}\\n\", \"range_key_name\": null, \"range_key_type\": \"STRING\", \"read_capacity\": 1, \"region\": null, \"table_name\": \"page_releases_dev\", \"write_capacity\": 1}\n"], "labels": ["traceback", "support:community", "feature", "module", "affects_2.3", "has_pr", "aws", "cloud"]}
{"project": "oppia_oppia", "title": "On the registration page, recognize invalid usernames as early as possible.", "description": "<CODE> Original issue reported on code.google.com by s...@google.com on 30 Jul 2014 at 12:05 ", "code": ["In as much detail as possible, please describe what you would like to see.\n\n1. Set up a fresh instance of Oppia and navigate to the Contribute page.\n2. You will be asked to log in, provide a username, and agree to the site \nconditions.\n3. If the user enters a username that is already in use, they only find that \nout after clicking 'Submit'. Instead, it would be nice to do the following: on \na blur event from the username input field, do a backend query to check whether \nthat username is already in use. If it is, display the error message \"Sorry, \nthat username is already in use.\" in red text inline, before the user clicks \nthe 'Submit' button.\n\n"], "labels": ["important", "auto-migrated"]}
{"project": "transmission-remote-gui_transgui", "title": "Transgui 3.0.1 and svn versions will not compile", "description": "<CODE> Original issue reported on code.google.com by weba...@gmail.com on 7 Apr 2011 at 9:16 ", "code": ["Sveral attempts to compile transgui from ARCH linux AUR, and from svn versions \n593, 519, 419 will not compile.\n\nOutput is the same on all attempts;\nNote: environment config file not found - using defaults\nNOTE: miscellaneous options file not found - using defaults\nTLazPackageGraph.CheckIfPackageNeedsCompilation  No state file for trcomp 1.0\n[TExternalToolList.Run] CmdLine=\"/usr/bin/fpc -B  -MObjFPC -Scgi -O1 -gl \n-vewnhi -l -Fu/usr/lib/lazarus/lcl/units/i386-linux \n-Fu/usr/lib/lazarus/lcl/units/i386-linux/gtk2 \n-Fu/usr/lib/lazarus/packager/units/i386-linux \n-Fu/var/abs/local/yaourtbuild/transmission-remote-gui-svn/src/transmission-remot\ne-gui/ -Fu. \n-FU/var/abs/local/yaourtbuild/transmission-remote-gui-svn/src/transmission-remot\ne-gui/lib/i386-linux/ -dLCL -dLCLgtk2 trcomp.pas\" \nWorkDir=\"/var/abs/local/yaourtbuild/transmission-remote-gui-svn/src/transmission\n-remote-gui/\"\nHint: Start of reading config file /etc/fpc.cfg\nHint: End of reading config file /etc/fpc.cfg\nFree Pascal Compiler version 2.4.2 [2010/11/14] for i386\nCopyright (c) 1993-2010 by Florian Klaempfl\nTarget OS: Linux for i386\nCompiling trcomp.pas\nCompiling vargrid.pas\nCompiling varlist.pas\nvargrid.pas(74,28) Hint: Parameter \"Sender\" not used\nvargrid.pas(441,41) Error: Wrong number of parameters specified for call to \n\"DrawGridCheckboxBitmaps\"\ngrids.pas(3877,23) Hint: Found declaration: \nTCustomGrid.DrawGridCheckboxBitmaps(const LongInt,const LongInt,const \nTRect,const TCheckBoxState);\nvargrid.pas(540,47) Error: Wrong number of parameters specified for call to \n\"DrawGridCheckboxBitmaps\"\ngrids.pas(3877,23) Hint: Found declaration: \nTCustomGrid.DrawGridCheckboxBitmaps(const LongInt,const LongInt,const \nTRect,const TCheckBoxState);\nvargrid.pas(1002) Fatal: There were 2 errors compiling module, stopping\nTExternalToolList.Run Exception: \n/var/abs/local/yaourtbuild/transmission-remote-gui-svn/src/transmission-remote-g\nui/vargrid.pas(1002) Fatal: There were 2 errors compiling module, stopping\nERROR: tool reported error\n\nSeems I have all the necessary tools and libs as far as I know.\n\nI've run both make and lazbuild transgui.lpi.\n\n"], "labels": ["Priority-Low", "auto-migrated"]}
{"project": "JuliaLang_julia", "title": "Cannot build sys image- Win 64 0.5.1", "description": "I am trying to patch an earlier bug I reported on this website (regarding arrays with 6 or more subscripts) in 0.5.1.  However, the instructions for building a system image from the documentation are apparently not working for me.  This is Julia 0.5.1 for Windows 10 - 64 bit that I installed yesterday via the self-installer from the Julia download site.  I issued the commands: and <CODE> After many lines flew by on my console window, eventually I received a message stating that the build was successful: <CODE> However, the old sys.dll was not overwritten as you can see from the date: <CODE> ", "code": ["julia> build_sysimg(force=true)\n", "C:\\Users\\vavasis\\AppData\\Local\\Julia-0.5.1\\share\\julia\\base\\precompile.jl\nINFO: System image successfully built at C:\\Users\\vavasis\\AppData\\Local\\Julia-0.5.1\\bin\\..\\lib\\julia\\sys.ji\nINFO: Julia will automatically load this system image at next startup\n", "c:\\Users\\vavasis\\AppData\\Local\\Julia-0.5.1\\lib\\julia>dir\n Volume in drive C is Windows8_OS\n Volume Serial Number is 88DB-A798\n\n Directory of c:\\Users\\vavasis\\AppData\\Local\\Julia-0.5.1\\lib\\julia\n\n2017-03-08  11:54 PM    <DIR>          .\n2017-03-08  11:54 PM    <DIR>          ..\n2017-03-08  11:52 PM         2,116,720 inference.ji\n2017-03-08  11:52 PM         7,253,763 inference.o\n2017-03-05  10:47 AM        42,798,819 sys-debug.dll\n2017-03-05  10:37 AM        41,515,369 sys.dll\n2017-03-08  11:54 PM        26,094,220 sys.ji\n2017-03-08  11:54 PM        48,834,489 sys.o\n               6 File(s)    168,613,380 bytes\n               2 Dir(s)  26,042,474,496 bytes free\n"], "labels": ["windows"]}
{"project": "kubernetes_kubernetes", "title": "Kubernetes pods still running even if they are evicted", "description": "What happened:\nI am running a daemonset of minIO using hostpath Volumes. I have attached dedicated disks to these nodes and mounted it on \"/data/minio\" and mount that into each pod. I haven't edited the default threshold values of kubelet on any node. On event of diskpressure, the minio pods are getting evicted but the kublet still keeps on trying to delete the pods: Aug 13 21:05:45 staging-node2 kubelet[2188]: I0813 21:05:45.968179    2188 kubelet_pods.go:1073] Killing unwanted pod \"minio-kjrkc\"    Aug 13 21:05:45 staging-node2 kubelet[2188]: I0813 21:05:45.975372    2188 kuberuntime_container.go:559] Killing container \"docker://6da1247718f8e6c92399e231f8c31ff1c510737c658ac2aca87c1659aa6b51cc\" with 30 second grace period docker logs on the container shows it's up even if it got TERMINATED signal. Now, even though new pods are scheduled on these nodes , they immediately get evicted as the node always is under diskpressure. What you expected to happen:\nkubelet to kill the container gracefully once the pod is evicted How to reproduce it (as minimally and precisely as possible):\napiVersion: apps/v1 kind: DaemonSet metadata: name: minio labels: app: minio spec: selector: matchLabels: app: minio template: metadata: labels: app: minio spec: nodeSelector: minio-server: \"true\" hostNetwork: true volumes: - name: storage hostPath: path: /data/minio/ containers: - name: minio env: - name: MINIO_ACCESS_KEY value: \"minio\" - name: MINIO_SECRET_KEY value: \"minio\" image: minio/minio:RELEASE.2019-07-24T02-02-23Z args: - server - http://node1:9000/data/minio - http://node2:9000/data/minio - http://node3:9000/data/minio - http://node4:9000/data/minio ports: - containerPort: 9000 volumeMounts: - name: storage mountPath: /data/minio/ \nAnything else we need to know?: Environment: ", "code": [], "labels": ["lifecycle/rotten", "sig/node", "area/kubelet", "kind/bug"]}
{"project": "dbeaver_dbeaver", "title": "Compilation errors when running create or replace command", "description": "Is your feature request related to a problem? Please describe.\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\nThere has been multiple instances where i run a create or replace procedure/package command. After running there are no apparent error messages. I do not realize until i refresh the procedure list that there was in fact an error when creating the procedure\nDescribe the solution you'd like\nA clear and concise description of what you want to happen.\nThere should be the same error message when you run create or replace as if you would right click and compile the object. Right now there is no way to discern whether the command was successful or not.\nDescribe alternatives you've considered\nA clear and concise description of any alternative solutions or features you've considered. Additional context\nAdd any other context or screenshots about the feature request here. ", "code": [], "labels": ["feature request"]}
{"project": "supercollider_supercollider", "title": "Warp1 weird behaviour with 2-channel buffers", "description": "Simply load a stereo file in a buffer and use that with Warp, e.g. with the example patches, also setting the numchannels argument to 2. As soon as I load a 2-ch buffer (and change the argument of course), everything sounds off... it plays slower, and generally messed up. Everything works as expected with mono buffers. ", "code": [], "labels": ["bug"]}
{"project": "bumptech_glide", "title": "I delete Glide cache on the phone file ,then Glide cann't load picture to ImageView;", "description": "this is my code; then  the Activity load image still use disk cache, but the file is delete  so load fail;\nI want know  , has methed let glide back to the initial state ?\nMy English is so poor; Please Forgive me. Thanks. ", "code": [], "labels": ["question"]}
{"project": "kubernetes_kubernetes", "title": "Support 100 pods per node", "description": "This is a meta issue for aggregating the TODO items to support 100 pods per node. /cc @dchen1107 ", "code": [], "labels": ["sig/node", "priority/important-soon"]}
{"project": "nodejs_node-v0.x-archive", "title": "v0.10.28 Cluster blocks when more than 1 fork request is made on Windows 8 x64", "description": "If more than 1 cluster.fork() call is made in the code below on Windows 8 x64 ( no other windows OS versions tested ) then any request to http://localhost:8000 blocks the request Both workers execute the server create code and start listening, but neither responds On linux there are no issues, and if I reduce the call to a single fork on Windows it works as expected. ", "code": [], "labels": ["windows"]}
{"project": "istio_istio", "title": "bookinfo example doesn't work due to istio-proxy restarting", "description": "@dunjut commented on Wed Apr 11 2018 Is this a BUG or FEATURE REQUEST?:\nBug (maybe) Did you review <URL> and existing issues to identify if this is already solved or being worked on?:\nYes Bug:\nY/N What Version of Istio and Kubernetes are you using, where did you get Istio from, Installation details <CODE> Is Istio Auth enabled or not ?\nDid you install the stable istio.yaml, istio-auth.yaml....  or if using the Helm chart please provide full command line input.\nNot (using istio.yaml) What happened:\nI've installed istio-0.7.1 with sidecar injector and without auth. When trying the bookinfo example, I find out curl ... http://<gateway>:productpage doesn't give 200 status code. kubectl get pod shows bookinfo pods sidecar are periodically restarting, and for example reviews-v3/istio-proxy logs says <CODE> Besides, logs of istio-ca says <CODE> What you expected to happen:\ncurl gives 200 status code and I can keep following bookinfo example and other istio tasks. How to reproduce it:\nJust following the installation docs and bookinfo example. Feature Request:\nY/N Describe the feature: ", "code": ["istioctl version\nVersion: 0.7.1\nGitRevision: 62110d4f0373a7613e57b8a4d559ded9cb6a1cc8\nUser: root@c5207293dc14\nHub: docker.io/istio\nGolangVersion: go1.9\nBuildStatus: Clean\n\nkubectl version\nClient Version: version.Info{Major:\"1\", Minor:\"9\", GitVersion:\"v1.9.6\", GitCommit:\"9f8ebd171479bec0ada837d7ee641dec2f8c6dd1\", GitTreeState:\"clean\", BuildDate:\"2018-03-21T15:21:50Z\", GoVersion:\"go1.9.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"9\", GitVersion:\"v1.9.6\", GitCommit:\"9f8ebd171479bec0ada837d7ee641dec2f8c6dd1\", GitTreeState:\"clean\", BuildDate:\"2018-03-21T15:13:31Z\", GoVersion:\"go1.9.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n", "2018-04-11T11:05:08.019817Z     info    Version root@c5207293dc14-docker.io/istio-0.7.1-62110d4f0373a7613e57b8a4d559ded9cb6a1cc8-Clean\n2018-04-11T11:05:08.019852Z     info    Proxy role: model.Proxy{Type:\"sidecar\", IPAddress:\"10.10.0.180\", ID:\"reviews-v3-58ff7d665b-n5zsr.default\", Domain:\"default.svc.cluster.local\"\n}\n2018-04-11T11:05:08.019857Z     info    Attempting to lookup address: istio-mixer.istio-system\n2018-04-11T11:05:23.020299Z     info    Finished lookup of address: istio-mixer.istio-system\n2018-04-11T11:05:23.020892Z     info    Effective config: binaryPath: /usr/local/bin/envoy\nconfigPath: /etc/istio/proxy\nconnectTimeout: 10.000s\ndiscoveryAddress: istio-pilot.istio-system:8080\ndiscoveryRefreshDelay: 1.000s\ndrainDuration: 45.000s\nparentShutdownDuration: 60.000s\nproxyAdminPort: 15000\nserviceCluster: reviews\nstatsdUdpAddress: istio-mixer.istio-system:9125\nzipkinAddress: zipkin.istio-system:9411\n\n2018-04-11T11:05:23.021036Z     info    Monitored certs: []v1.CertSource{v1.CertSource{Directory:\"/etc/certs/\", Files:[]string{\"cert-chain.pem\", \"key.pem\", \"root-cert.pem\"}}}\n2018-04-11T11:05:23.021623Z     info    Starting proxy agent\n2018-04-11T11:05:23.021687Z     info    Received new config, resetting budget\n2018-04-11T11:05:23.021709Z     info    Reconciling configuration (budget 10)\n2018-04-11T11:05:23.022243Z     info    Epoch 0 starting\n2018-04-11T11:05:23.022841Z     info    Envoy command: [-c /etc/istio/proxy/envoy-rev0.json --restart-epoch 0 --drain-time-s 45 --parent-shutdown-time-s 60 --service-cluster reviews\n --service-node sidecar~10.10.0.180~reviews-v3-58ff7d665b-n5zsr.default~default.svc.cluster.local --max-obj-name-len 189 -l info --v2-config-only]\n[2018-04-11 11:05:23.043][13][info][main] external/envoy/source/server/server.cc:178] initializing epoch 0 (hot restart version=9.200.16384.256.options=capacity=16384, num_slots=820\n9 hash=228984379728933363)\n[2018-04-11 11:05:23.049][13][info][config] external/envoy/source/server/configuration_impl.cc:52] loading 0 listener(s)\n[2018-04-11 11:05:23.049][13][info][config] external/envoy/source/server/configuration_impl.cc:92] loading tracing configuration\n[2018-04-11 11:05:23.049][13][info][config] external/envoy/source/server/configuration_impl.cc:101]   loading tracing driver: envoy.zipkin\n[2018-04-11 11:05:23.049][13][info][config] external/envoy/source/server/configuration_impl.cc:119] loading stats sink configuration\n[2018-04-11 11:05:23.050][13][critical][main] external/envoy/source/server/server.cc:71] error initializing configuration '/etc/istio/proxy/envoy-rev0.json': malformed IP address: i\nstio-mixer.istio-system\n[2018-04-11 11:05:23.050][13][info][main] external/envoy/source/server/server.cc:392] exiting\n2018-04-11T11:05:23.053615Z     warn    Epoch 0 terminated with an error: exit status 1\n2018-04-11T11:05:23.053890Z     warn    Aborted all epochs\n2018-04-11T11:05:23.053950Z     info    Epoch 0: set retry delay to 200ms, budget to 9\n2018-04-11T11:05:23.254664Z     info    Reconciling configuration (budget 9)\n2018-04-11T11:05:23.254714Z     info    Epoch 0 starting\n2018-04-11T11:05:23.255350Z     info    Envoy command: [-c /etc/istio/proxy/envoy-rev0.json --restart-epoch 0 --drain-time-s 45 --parent-shutdown-time-s 60 --service-cluster reviews\n --service-node sidecar~10.10.0.180~reviews-v3-58ff7d665b-n5zsr.default~default.svc.cluster.local --max-obj-name-len 189 -l info --v2-config-only]\n[2018-04-11 11:05:23.562][17][info][main] external/envoy/source/server/server.cc:178] initializing epoch 0 (hot restart version=9.200.16384.256.options=capacity=16384, num_slots=820\n9 hash=228984379728933363)\n[2018-04-11 11:05:23.572][17][info][config] external/envoy/source/server/configuration_impl.cc:52] loading 0 listener(s)\n[2018-04-11 11:05:23.574][17][info][config] external/envoy/source/server/configuration_impl.cc:92] loading tracing configuration\n...\n...\n", "...\n...\n2018-04-11T10:47:28.448614Z     info    adding registry entry \"spiffe://cluster.local/ns/default/sa/default\" -> \"spiffe://cluster.local/ns/default/sa/default\"\n2018-04-11T10:47:28.448623Z     info    adding registry entry \"spiffe://cluster.local/ns/default/sa/spinnaker-service-account\" -> \"spiffe://cluster.local/ns/default/sa/spinnaker-service-account\"\n2018-04-11T10:47:31.184608Z     error   Failed to create secret in attempt 1/3, (error: secrets \"istio.istio-sidecar-injector-service-account\" already exists)\n2018-04-11T10:47:32.206160Z     error   Failed to create secret in attempt 2/3, (error: secrets \"istio.istio-sidecar-injector-service-account\" already exists)\n2018-04-11T10:47:33.218719Z     error   Failed to create secret in attempt 3/3, (error: secrets \"istio.istio-sidecar-injector-service-account\" already exists)\n2018-04-11T10:47:34.222762Z     error   Failed to create secret for service account \"istio-sidecar-injector-service-account\"  (error: secrets \"istio.istio-sidecar-injector-service-account\" already exists), retries 3 times\n2018-04-11T10:47:58.284090Z     error   failed to create JWT authenticator (error Get https://accounts.google.com/.well-known/openid-configuration: dial tcp: i/o timeout)\n2018-04-11T10:47:58.284306Z     info    Istio CA has started\n2018-04-11T10:47:58.284315Z     info    Starting GRPC server on port 8060\n...\n...\n"], "labels": ["area/environments", "area/security"]}
{"project": "espressif_esp-idf", "title": "Floating point division bug", "description": "Hello, We've found a bug that seems to be caused by the compiler, and it's only related to floating point divisions, and only when the values to be divided are part of the parameters passed to a function. Please run the following test (using the idf application template) to reproduce it. Thanks! Any idea what might be going on? Thanks! Cheers,\nDaniel ", "code": [], "labels": ["Type: Bug"]}
{"project": "npm_npm", "title": "EHOSTDOWN when installing eslint", "description": "when I run\nnpm install -g eslint\nI get the following error:\nnpm ERR! Darwin 14.5.0\nnpm ERR! argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"install\" \"-g\" \"eslint\"\nnpm ERR! node v6.4.0\nnpm ERR! npm  v3.10.3\nnpm ERR! code EHOSTDOWN\nnpm ERR! errno EHOSTDOWN\nnpm ERR! syscall connect npm ERR! connect EHOSTDOWN 151.101.36.162:443 - Local (0.0.0.0:0) There is no npm-debug.log file in the directory, so I could not post or copy it. ", "code": [], "labels": ["support", "network"]}
{"project": "react-bootstrap_react-bootstrap", "title": "Tabs: allow to provide className for `<nav role=\"tablist\">`", "description": "I'm trying to do the following, and for that it'd be great if one can provide additional className to be added to <nav role=\"tablist\">. Currently, you can only provide class name or style object to tabs container (one level above <nav role=\"tablist\">)  ", "code": [], "labels": ["help wanted", "enhancement"]}
{"project": "wordpress-mobile_WordPress-Android", "title": "Crash report 2.7.1 - NPE in SyncMediaLibraryTask", "description": "<CODE> ", "code": ["java.lang.RuntimeException: An error occured while executing doInBackground()\nat android.os.AsyncTask$3.done(AsyncTask.java:299)\nat java.util.concurrent.FutureTask$Sync.innerSetException(FutureTask.java:273)\nat java.util.concurrent.FutureTask.setException(FutureTask.java:124)\nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:307)\nat java.util.concurrent.FutureTask.run(FutureTask.java:137)\nat android.os.AsyncTask$SerialExecutor$1.run(AsyncTask.java:230)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1076)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:569)\nat java.lang.Thread.run(Thread.java:856)\nCaused by: java.lang.NullPointerException\nat org.xmlrpc.android.ApiHelper$SyncMediaLibraryTask.prepareErrorMessage(ApiHelper.java:651)\nat org.xmlrpc.android.ApiHelper$SyncMediaLibraryTask.doInBackground(ApiHelper.java:617)\nat org.xmlrpc.android.ApiHelper$SyncMediaLibraryTask.doInBackground(ApiHelper.java:566)\nat android.os.AsyncTask$2.call(AsyncTask.java:287)\nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:305)\n... 5 more```\n"], "labels": ["bug"]}
{"project": "qgis_QGIS", "title": "Qgis crashes when triple-clicking on the Vertex Tool button", "description": "Describe the bug\nQgis crashes when triple clicking on the Vertex tool button. How to Reproduce QGIS and OS versions\n\u0388\u03ba\u03b4\u03bf\u03c3\u03b7 QGIS\n3.9.0-Master\n\u0395\u03c0\u03b1\u03bd\u03ac\u03bb\u03b7\u03c8\u03b7 \u03ba\u03c9\u03b4\u03b9\u03ba\u03bf\u03cd QGIS\naccbb2d\nCompiled against Qt\n5.11.2\nRunning against Qt\n5.11.2\nCompiled against GDAL/OGR\n2.4.1\nRunning against GDAL/OGR\n2.4.1\nCompiled against GEOS\n3.7.2-CAPI-1.11.0\nRunning against GEOS\n3.7.2-CAPI-1.11.0 b55d2125\n\u0388\u03ba\u03b4\u03bf\u03c3\u03b7 \u03a0\u03b5\u03bb\u03ac\u03c4\u03b7 PostgreSQL\n9.2.4\n\u0388\u03ba\u03b4\u03bf\u03c3\u03b7 SpatiaLite\n4.3.0\n\u0388\u03ba\u03b4\u03bf\u03c3\u03b7 QWT\n6.1.3\n\u0388\u03ba\u03b4\u03bf\u03c3\u03b7 QScintilla2\n2.10.8\nCompiled against PROJ\n5.2.0\nRunning against PROJ\nRel. 5.2.0, September 15th, 2018\nThis copy of QGIS writes debugging output.\nOS Version\nWindows 10 (10.0) Additional context Crash ID: c6e2d1924decab0299b1b05113a4109bcc1d5d71 Stack Trace QWidget::show :\nQgsIdentifyResultsDialog::vectorLayer :\nQgsIdentifyResultsDialog::vectorLayer :\nQgsIdentifyResultsDialog::vectorLayer :\nQgsIdentifyResultsDialog::vectorLayer :\nQTimer::timeout :\nQObject::event :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsAuxiliaryLayer::isHiddenProperty :\nQCoreApplication::notifyInternal2 :\nQEventDispatcherWin32Private::sendTimerEvent :\nQEventDispatcherWin32::event :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsAuxiliaryLayer::isHiddenProperty :\nQCoreApplication::notifyInternal2 :\nQCoreApplicationPrivate::sendPostedEvents :\nqt_plugin_query_metadata :\nQEventDispatcherWin32::processEvents :\nCallWindowProcW :\nDispatchMessageW :\nQEventDispatcherWin32::processEvents :\nqt_plugin_query_metadata :\nQEventLoop::exec :\nQCoreApplication::exec :\nQgsIdentifyResultsDialog::vectorLayer :\nBaseThreadInitThunk :\nRtlUserThreadStart : QGIS Info\nQGIS Version: 3.9.0-Master\nQGIS code revision: accbb2d\nCompiled against Qt: 5.11.2\nRunning against Qt: 5.11.2\nCompiled against GDAL: 2.4.1\nRunning against GDAL: 2.4.1 System Info\nCPU Type: x86_64\nKernel Type: winnt\nKernel Version: 10.0.16299 Crash ID: 4629476b9e625e46d57da6dfa51d20ef94b80574 Stack Trace QWidget::show :\nQgisApp::activeLayerChanged :\nQgisApp::activeLayerChanged :\nQgisApp::activeLayerChanged :\nQgisApp::activeLayerChanged :\nQTimer::timeout :\nQObject::event :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsCentroidFillSymbolLayer::operator= :\nQCoreApplication::notifyInternal2 :\nQEventDispatcherWin32Private::sendTimerEvent :\nQEventDispatcherWin32::event :\nQApplicationPrivate::notify_helper :\nQApplication::notify :\nQgsCentroidFillSymbolLayer::operator= :\nQCoreApplication::notifyInternal2 :\nQCoreApplicationPrivate::sendPostedEvents :\nqt_plugin_query_metadata :\nQEventDispatcherWin32::processEvents :\nCallWindowProcW :\nDispatchMessageW :\nQEventDispatcherWin32::processEvents :\nqt_plugin_query_metadata :\nQEventLoop::exec :\nQCoreApplication::exec :\nQgisApp::activeLayerChanged :\nBaseThreadInitThunk :\nRtlUserThreadStart : QGIS Info\nQGIS Version: 3.7.0-Master\nQGIS code revision: 840ab03\nCompiled against Qt: 5.11.2\nRunning against Qt: 5.11.2\nCompiled against GDAL: 2.4.1\nRunning against GDAL: 2.4.1 System Info\nCPU Type: x86_64\nKernel Type: winnt\nKernel Version: 10.0.16299 ", "code": [], "labels": ["Bug", "Crash/Data Corruption"]}
{"project": "angular-ui_bootstrap", "title": "custom templateUrl appears behind custom windowTemplateUrl in $modal", "description": "I've made a plunker here: <URL> In my application this is happening as well. Although it appears to work fine in version 0.12.0. For some reason it seems as though the presence of the custom windowTemplateUrl causes the the templateUrl to be hidden. I could have easily missed something in my implementation. I tried to make the plnkr as simple as possible. Let me know what you think. -Steven ", "code": [], "labels": ["component: modal", "resolution: support"]}
{"project": "angular_material", "title": "md-menu: md-backdrop does not get removed", "description": "I have a hard time reproducing this but sometimes (like every 5th time) when using the md-menu the md-backdrop does not get removed when clicking on a menu option, and the whole site becomes unclickable. This is what the end of my html page looks like when it stops working. EDIT: At first I suspected md-scroll-mask caused this, but it apparently didn't ", "code": [], "labels": ["needs: more info", "needs: investigation", "priority: medium"]}
{"project": "jellyfin_jellyfin", "title": "Add sidebar to wiki", "description": "Worked out how to add a sidebar to the wiki allowing for links to headers inside of a specific page. Gist of the sidebar md file is here. Can see what it looks like and how it works here. ", "code": [], "labels": ["documentation"]}
{"project": "tutao_tutanota", "title": "Version info in settings view overlaps settings options", "description": "To Reproduce\nOpen Settings view and reduce window size Expected behavior\nVersion info should be stick to the bottom and settings option should start scrolling Screenshots\nIf applicable, add screenshots to help explain your problem. ", "code": [], "labels": ["bug"]}
{"project": "edenhill_librdkafka", "title": "commitasync triggers assert, one  opaque value remains 0, 1 proposal and a few questions", "description": "Hi Magnus, After a week of Kafka 0.9 I came up with the following questions  & issues for you, sorry for the spam :) ", "code": [], "labels": ["bug", "question"]}
{"project": "material-components_material-components-web", "title": "options has an unknown property 'importer'.", "description": "material-components-web/docs/getting-started.md <CODE> webpack.config.js <CODE> ", "code": ["ERROR in ./app.scss\nModule build failed (from ./node_modules/sass-loader/dist/cjs.js):\nValidationError: Invalid options object. Sass Loader has been initialised using an options object that does not match the API schema.\n - options has an unknown property 'importer'. These properties are valid:\n   object { implementation?, sassOptions?, prependData?, sourceMap?, webpackImporter? }\n    at validate (/Volumes/Backup/material-design-web/node_modules/schema-utils/dist/validate.js:50:11)\n    at Object.loader (/Volumes/Backup/material-design-web/node_modules/sass-loader/dist/index.js:36:28)\n @ multi ./app.scss ./app.js main[0]\n", "const autoprefixer = require(\"autoprefixer\");\n\nconst path = require(\"path\");\n\nfunction tryResolve_(url, sourceFilename) {\n  // Put require.resolve in a try/catch to avoid node-sass failing with cryptic libsass errors\n  // when the importer throws\n  try {\n    return require.resolve(url, { paths: [path.dirname(sourceFilename)] });\n  } catch (e) {\n    return \"\";\n  }\n}\n\nfunction tryResolveScss(url, sourceFilename) {\n  // Support omission of .scss and leading _\n  const normalizedUrl = url.endsWith(\".scss\") ? url : `${url}.scss`;\n  return (\n    tryResolve_(normalizedUrl, sourceFilename) ||\n    tryResolve_(\n      path.join(\n        path.dirname(normalizedUrl),\n        `_${path.basename(normalizedUrl)}`\n      ),\n      sourceFilename\n    )\n  );\n}\n\nfunction materialImporter(url, prev) {\n  if (url.startsWith(\"@material\")) {\n    const resolved = tryResolveScss(url, prev);\n    return { file: resolved || url };\n  }\n  return { file: url };\n}\n\nmodule.exports = {\n  entry: [\"./app.scss\", \"./app.js\"],\n  output: {\n    filename: \"bundle.js\"\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.scss$/,\n        use: [\n          {\n            loader: \"file-loader\",\n            options: {\n              name: \"bundle.css\"\n            }\n          },\n          { loader: \"extract-loader\" },\n          { loader: \"css-loader\" },\n          {\n            loader: \"postcss-loader\",\n            options: {\n              plugins: () => [autoprefixer()]\n            }\n          },\n          {\n            loader: \"sass-loader\",\n            options: {\n              importer: materialImporter \n            }\n          }\n        ]\n      },\n      {\n        test: /\\.js$/,\n        loader: \"babel-loader\",\n        query: {\n          presets: [\"@babel/preset-env\"]\n        }\n      }\n    ]\n  }\n};\n\n\n"], "labels": ["bug"]}
{"project": "codecombat_codecombat", "title": "Colors tab broken for fangrider", "description": "I just tried uploading the new colorizable fangrider sprite that Pavel handed us, and the color tab appears to be broken: <URL> The JS console doesn't report anything suspicious, but I'm unable to see the \"colors\" tab at all. ", "code": [], "labels": ["bug"]}
{"project": "woocommerce_woocommerce", "title": "Long text in shipping method in checkout page is not aligned with the radio button", "description": "screen capture  :\n<URL> Text should be aligned with the radio button ", "code": [], "labels": ["can't reproduce"]}
{"project": "retorquere_zotero-better-bibtex", "title": "org-ref quick copy format", "description": "Would it be possible to add the org-ref format to quick copy? It is very similar to the orgmode format except instead of the \"@\" it uses \"cite:\". So a reference would look like: <CODE> with orgmode and <CODE> with org-ref where \"Wei2015\" is the cite key. ", "code": ["@Wei2015\n", "cite:Wei2015\n"], "labels": ["enhancement"]}
{"project": "ansible_ansible", "title": "Unable to Ping from ansible machine remote machine", "description": "/etc/ansible/hosts <CODE> <CODE> ", "code": ["2.3.2\n", "| UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: OpenSSH_6.6.1, OpenSSL 1.0.1f 6 Jan 2014\\r\\ndebug1: Reading configuration data /etc/ssh/ssh_config\\r\\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\\r\\ndebug1: auto-mux: Trying existing master\\r\\ndebug1: Control socket \\\"/root/.ansible/cp/8625c99978\\\" does not exist\\r\\ndebug2: ssh_connect: needpriv 0\\r\\ndebug1: Connecting to xx.xx.xx.xx [xx.xx.xx.xx] port 22.\\r\\ndebug2: fd 3 setting O_NONBLOCK\\r\\ndebug1: connect to address xx.xx.xx.xx port 22: Connection timed out\\r\\nssh: connect to host xx.xx.xx.xx port 22: Connection timed out\\r\\n\",\n    \"unreachable\": true\n\n"], "labels": ["support:core", "affects_2.3", "bug"]}
{"project": "ant-design_ant-design-mobile", "title": "config-overrides.js \u4e0epostcss-preset-env\u63d2\u4ef6\u7ed3\u5408\u95ee\u9898", "description": "2.1.11 ant-design/antd-mobile-samples#64 \u6211\u7684\u5de5\u7a0b\u662f\u7528create-react-app\u521b\u5efa\u7684\uff0c\u7136\u540e\u4f7f\u7528\u4e86 config-overrides.js.\n\u73b0\u5728\u6211\u9700\u8981\u4f7f\u7528postcss-preset-env,\u6765\u5b9e\u73b0cssnext\u7684\u4e00\u4e9b\u529f\u80fd.\n\u4f46\u662f\u5f53\u6211\u8fd9\u6837\u52a0\u5165\u65f6\uff0cpostcss-preset-env\u63d2\u4ef6\u5c31\u65e0\u6548\uff0cant-mobile\u6709\u6548 <CODE> \u5982\u679c\u6211\u7528\u8fd9\u4e2a\u81ea\u5df1\u5199\u7684\u63d2\u4ef6react-app-rewire-postcss-preset-env \u6765\u4f7f postcss-preset-env\u63d2\u4ef6\u751f\u6548\uff0c\u4f46\u8fd9\u6837 exclude:/node_modules|antd-mobile\\.css/\u7f3a\u4e0d\u751f\u6548\u4e86\n\u4ee3\u7801\u5982\u4e0b,\u6211\u5728\u63d2\u4ef6\u4e2d\u5df2\u7ecf\u6dfb\u52a0\u4e86exclude:/node_modules|antd-mobile\\.css/ <CODE> postcss-preset-env\u548cant-mobile\u7684\u6837\u5f0f\u80fd\u591f\u540c\u65f6\u751f\u6548 ant-mobile\u7684\u4e0d\u80fd\u88abexclude\u6389 ", "code": ["  config.module.rules[1].oneOf.unshift(\n    {\n      test: /\\.css$/,\n      exclude: /node_modules|antd-mobile\\.css|src\\\\index\\.css|iconfonts\\.css/,\n      use: [\n        require.resolve('style-loader'),\n        {\n          loader: require.resolve('css-loader'),\n          options: {\n            modules: true,\n            importLoaders: 1,\n            localIdentName: '[local]___[hash:base64:5]'\n          },\n        },\n        {\n          loader: require.resolve('postcss-loader'),\n          options: {\n            // Necessary for external CSS imports to work\n            // https://github.com/facebookincubator/create-react-app/issues/2677\n            ident: 'postcss',\n            plugins: () => [\n              require('postcss-preset-env')({stage:0}),//support css-modules @value\n              require('postcss-flexbugs-fixes'),\n              autoprefixer({\n                browsers: [\n                  '>1%',\n                  'last 4 versions',\n                  'Firefox ESR',\n                  'not ie < 9', // React doesn't support IE8 anyway\n                ],\n                flexbox: 'no-2009',\n              }),\n            ],\n          },\n        }\n      ]\n    }\n  );\n", "const rewireCssModules = require('react-app-rewire-postcss-preset-env');\n\nmodule.exports = function override(config, env) {\n    // ...\n    config = rewireCssModules(config, env,{stage:0,browsers:'> 2%'});\n    // ...\n    return config;\n}\n"], "labels": ["type: question"]}
{"project": "conda_conda", "title": "ideas for packaging as rpm/deb", "description": "Okay, so this forms my official feature request for a .deb or .rpm to install conda system-wide so that sysadmins have an easier way to provide access to conda. @tswicegood requested I dump this here folllowing our chat at PyCon... So, the ideas we talked about: This enables a shared package cache that only the conda user can write to but all conda users can read from, this means that we get the win of only pulling packages over the network once for each machine. The only rough edge I can think of is whether conda running as the conda user could write to the current users home directory, if that's where they want their conda environment created. ", "code": [], "labels": ["type-feature"]}
{"project": "dotnet_aspnetcore", "title": "Select Multiple not rendering correct selections when updating during async callback", "description": "I have 2 select list with multiple set on both of them.  They are linked so that each acts as a filter for the other, kind of like how Excel's filter works.  When I select 2 options and apply the filter (which calls back and updates the list), my 2 selected options are selected, but another 2 random options are selected.  I can see from the logging that only my 2 selected options were set, but when I query the select through JS interop, I can see that 4 options are selected. I am attaching the full solution.\nRun the BlazorLinkedMultiSelectDemo.Server,\nClick the FirstName's \"Andy\" and \"Jeff\"\nClick Apply.\n\"Andy\" and \"Jeff\" stay selected, but also \"Annie\" and \"Julie\" appear as selected. Actually, the list starts with just \"Andy\" and \"Jeff\" selected, but less than a second later \"Annie\" and \"Julie\" get selected.  I cannot tell if the log messages below come out before or after \"Annie\" and \"Julie\" are selected. My logging shows as the last messages:\nWASM: FirstName HTML Update writing NOT selected option Alexa\nWASM: FirstName HTML Update writing NOT selected option Andrew\nWASM: FirstName HTML Update writing selected option Andy\nWASM: FirstName HTML Update writing NOT selected option Annie\nWASM: FirstName HTML Update writing NOT selected option Janice\nWASM: FirstName HTML Update writing selected option Jeff\nWASM: FirstName HTML Update writing NOT selected option Jerry\nWASM: FirstName HTML Update writing NOT selected option Julie\nWASM: FirstName HTML Update writing NOT selected option Sam\nWASM: FirstName HTML Update writing NOT selected option Sarah\nWASM: FirstName HTML Update writing NOT selected option Shelly\nWASM: FirstName HTML Update writing NOT selected option Steve So, I am not setting \"Annie\" and \"Julie\" The code snipped that renders the select looks like this: <CODE> BlazorLinkedMultiSelectDemo.zip ", "code": ["<select ref=\"sel\" multiple=\"multiple\" onchange=\"@SelectionChanged\"  style=\"height: 10rem;\">\n          @foreach (string s in ToFilteredStringList())\n            {\n                if (selections.Contains(s))\n                {\n                       Console.WriteLine(Title + \" HTML Update writing selected option \" + s);\n                       <option value=\"@s\" selected=\"selected\">@s</option>\n                 }\n                else\n                {\n                      Console.WriteLine(Title + \" HTML Update writing NOT selected option \" + s);\n                      <option value=\"@s\">@s</option>\n                 }\n            }\n  </select>\n"], "labels": ["area-blazor"]}
{"project": "pytest-dev_pytest", "title": "Some plugin hooks missing from docs", "description": "The hooks listed below are not listed in the generated documentation.  I have low confidence I'm organizing them correctly but I'll submit a PR in case that eases discussion of where they do belong. ", "code": [], "labels": ["type: docs"]}
{"project": "grails_grails-core", "title": "GRAILS-5829: Access to plugins.grails.org", "description": "Original Reporter: npellow\nEnvironment: Not Specified\nVersion: Not Specified\nMigrated From: <URL> Hi, I would like to release a Grails plugin and have it available in plugins.grails.org .\nHow do I go about requesting access to release a plugin there ?\nI have read: <URL> however can't seem to find the wiki that is referred to. The plugin will be called the \"grails-clover\". Cheers,\nNick Pellow. ", "code": [], "labels": ["Major", "Task", "Not a Bug"]}
{"project": "Icinga_icinga2", "title": "[dev.icinga.com #9851] Remove GetModifiedAttributes/SetModifiedAttributes", "description": "This issue has been migrated from Redmine: <URL> Created by mfriedrich on 2015-08-06 12:37:54 +00:00 Assignee: mfriedrich\nStatus: Resolved  (closed on 2015-09-29 12:52:35 +00:00)\nTarget Version: 2.4.0\nLast Update: 2015-09-30 16:29:24 +00:00 (in Redmine) <CODE> Changesets 2015-09-29 12:24:39 +00:00 by mfriedrich 1813c09 <CODE> 2015-09-29 12:24:39 +00:00 by mfriedrich 487ef51 <CODE> 2015-09-29 12:24:39 +00:00 by mfriedrich bb3b724 <CODE> 2015-09-29 12:56:04 +00:00 by mfriedrich 3e34201 <CODE> 2015-09-30 08:04:37 +00:00 by mfriedrich 19e7524 <CODE> Parent Task: #9081 Relations: ", "code": ["Backport?: No\nInclude in Changelog: 0\n", "Remove dead code from old modified attributes\n\nrefs #9851\n", "Remove dead code from old mod attrs in the cluster\n\nrefs #9851\n", "Fix object sync for modified attributes\n\nrefs #9851\nrefs #9927\nrefs #9081\n", "Docs: Remove obsolete mod attr commands\n\nrefs #9851\n", "Fix problem with non-existing objects in config sync updates\n\nrefs #9851\nrefs #9927\nrefs #9081\n"], "labels": ["enhancement", "Low", "area/api"]}
{"project": "bitcoinj_bitcoinj", "title": "Peer thread running wild", "description": "Originally reported on Google Code with ID 161 <CODE> Reported by andreas.schildbach on 2012-03-21 19:59:55 ", "code": ["I just witnessed two Peer threads downloading at the same time.\n\nIt started with one thread downloading quite slow (5 blocks/second). I decided to stop\nthe PeerGroup, because I did not want to wait this long. But the thread did not stop,\nit continued downloading. I started the app again (instantiating a new PeerGroup I\nguess), and now two Peers were downloading at the same time, but at different block\nheights. The app continuously switched between \"2 weeks behind\" and \"10 weeks behind\".\nAt some point the running wild Peer stopped, but it really took a while. I hope my\nblockchain was not damaged by this incident.\n\n"], "labels": ["Priority-Medium"]}
{"project": "ionic-team_ionic", "title": "RC.0 - <ion-tabs> are not visible in the Chrome browser, ok in Device Mode", "description": "Just playing with the new ionic2 RC0 release using the ionic2-starter-tabs, and I noticed that the bottom tabs <ion-tabs> are not visible in Chrome in the browser. The ARE visible in Chrome when in Device Mode. Seems to work fine in Safari. Bottom tabs appear. Steps to reproduce: <CODE> Other information: (e.g. stacktraces, related issues, suggestions how to fix, stackoverflow links, forum links, etc) Which Ionic Version?  v2 RC.0 For Ionic 1 issues - <URL> For Ionic 2 issues - <URL> Run ionic info from terminal/cmd prompt: (paste output below) Your system information: Cordova CLI: 6.3.1\nIonic Framework Version: 2.0.0-rc.0\nIonic CLI Version: 2.1.0\nIonic App Lib Version: 2.1.0-beta.1\nios-deploy version: 1.8.6\nios-sim version: 5.0.8\nOS: Mac OS X El Capitan\nNode Version: v5.12.0\nXcode version: Xcode 7.3 Build version 7D175 ", "code": ["ionic start --v2 myProject\ncd myProject\nionic serve\n"], "labels": ["needs: reply", "v2"]}
{"project": "andresriancho_w3af", "title": "Parser multiprocessing pool is not repopulated", "description": "After one 60 second timeout, all I see is a repeating series of: <CODE> With different URLs. ", "code": ["[timeout] The parser took more than 60 seconds to complete parsing of \"http://www.clarin.com/medios/tapas-diarios-lunes-mayo_0_1351064987.html\", killed it!\nFailed to find a suitable document parser. Exception \"There is no parser for \"http://www.clarin.com/medios/tapas-diarios-lunes-mayo_0_1351064987.html\".\"\n...\n"], "labels": ["priority:high", "bug", "core"]}
{"project": "chartjs_Chart.js", "title": "y-axis tick mark showing up after the label text after upgrading to v2.7.2", "description": "The tick marks should be before the label.\nSee below screenshot from v2.7.1\n the tick marks are rendering after the labels ", "code": [], "labels": ["type: bug"]}
{"project": "angular-ui_angular-google-maps", "title": "Dynamic change of Marker's options doesn't propagate the change [branch please?]", "description": "I think there is no watch implemented for Marker's options because when changing Marker's location (for example), it updates the marker. As a temporary workaround I've used this: ", "code": [], "labels": ["enhancement"]}
{"project": "owncloud_client", "title": "[OpenSUSE] monochrome icons should be black on openSUSE, (not white)", "description": "Seen with 2.4.2 daily and 2.5.0 daily as of 20180621: \n Note, how the tray icon is next to invisible on light gray background of the KDE desktop. ", "code": [], "labels": ["sev3-medium"]}
{"project": "protocolbuffers_protobuf", "title": "Documentation for timestamp unclear on \"whole seconds\" JSON formatting", "description": "The JSON documentation for Timestamp states: It's unclear whether the Unix epoch (for example) should be formatted as 1970-01-01T00:00:00Z or 1970-01-01T00:00:00.000Z. Looking at the C++ code, it seems like it's the former - but that should be clarified in the documentation. ", "code": [], "labels": ["documentation"]}
{"project": "MicrosoftDocs_live-share", "title": "[VS Code] Could not connect to the server. Check that you are using a valid service endpoint.", "description": "Could not connect to the server. Check that you are using a valid service endpoint. ", "code": [], "labels": ["duplicate", "vscode"]}
{"project": "electron-userland_electron-builder", "title": "MSI fails with CNDL1147", "description": "msi bundling fails with tons of the following errors: Error: Exit code: 1147. Command failed: C:\\ ... \\AppData\\Local\\electron-builder\\cache\\wix\\wix-4.0.0.5512.2\\candle.exe -arch x64 -dappDir=C:\\ ... \\packages\\win-unpacked -pedantic -wx project.wxs C:\\Users\\ ... \\packages\\__msi-temp-x64\\project.wxs(259) : error CNDL1147 : Backslash terminate the Component/@Directory attribute's inline directory value 'resources\\app.asar.unpacked\\node_modules\\ ... _u'. A backslash ensures a directory name will not be mistaken for a direct ory reference. NSIS builds are running fine. Is this a bug or am I doing something wrong? Maybe this is related to #2272? ", "code": [], "labels": ["duplicate"]}
{"project": "saltstack_salt", "title": "Unable to set multiple RabbitMQ tags", "description": "When I try to set mutliple tags to a RabbitMQ user, either via state or via CLI, it sets only one tag that is the join of all the tags I want to set. What we actually want is to set multiple tags. salt 'mymqnode' rabbitmq.set_user_tags 'my_user' tags='[\"tag1\", \"tag2\"]'\nThis sets tag tag1 tag2 to my_user, but not the tag tag1 and the tag tag2. Also reproductible via states. <CODE> ", "code": ["Salt Version:\n           Salt: 2017.7.0\n \nDependency Versions:\n           cffi: 1.5.2\n       cherrypy: Not Installed\n       dateutil: 2.4.2\n      docker-py: Not Installed\n          gitdb: 0.6.4\n      gitpython: 1.0.1\n          ioflo: Not Installed\n         Jinja2: 2.8\n        libgit2: 0.24.0\n        libnacl: Not Installed\n       M2Crypto: 0.21.1\n           Mako: 1.0.3\n   msgpack-pure: Not Installed\n msgpack-python: 0.4.6\n   mysql-python: Not Installed\n      pycparser: 2.14\n       pycrypto: 2.6.1\n   pycryptodome: Not Installed\n         pygit2: 0.24.0\n         Python: 2.7.12 (default, Nov 19 2016, 06:48:10)\n   python-gnupg: 0.3.8\n         PyYAML: 3.11\n          PyZMQ: 15.2.0\n           RAET: Not Installed\n          smmap: 0.9.0\n        timelib: Not Installed\n        Tornado: 4.2.1\n            ZMQ: 4.1.4\n \nSystem Versions:\n           dist: Ubuntu 16.04 xenial\n         locale: UTF-8\n        machine: x86_64\n        release: 4.4.0-78-generic\n         system: Linux\n        version: Ubuntu 16.04 xenial\n"], "labels": ["Bug"]}
{"project": "palantir_blueprint", "title": "What's the reason for the lack of a JS API for some components?", "description": "Most things seem to have both a JS and a CSS API, however NavBar does not. Is there an actual reason for this? If this is a React-centric UI toolkit then I should be able to do <NavBar>...</NavBar> instead of writing masses of HTML, no? Of course I could just write my own NavBar component but that kind of defeats the point, does it not? @cmslewis checklist: ", "code": [], "labels": ["help wanted", "Package: core", "Domain: API"]}
{"project": "twbs_bootstrap", "title": "Dropdown not aligning when text-center is applied for div", "description": "When text-center class is used along with dropdown component, alignment is not centered for context menu\n While disabling text-center alignment property it works fine, but it loses container alignment\n ", "code": [], "labels": ["css"]}
{"project": "aspnet_AspNetCore.Docs", "title": "Running the app in VSCode", "description": "This article glosses over the setup of vscode to run a dotnet app.  It might help to add in a bit about the setup of a tasks.json and launch.json file. This article is helpful:  <URL> @Rick-Anderson \t edit: If this content is added, it should go in the /includes folder as this is no unique to WebAPI. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["Source - Docs.ms", "doc-enhancement", "P2"]}
{"project": "dotnet_aspnetcore", "title": "Reading Files in Client-side Blazor", "description": "In Client-side blazor, How to read the static files? . I am using 'System.IO' for file streaming. Can any one please help on this? object FileData = Json.Deserialize<object>(System.IO.File.ReadAllText(System.IO.Path.GetFullPath(path))); Is there alternate for reading static files in blazor client-side?  ", "code": [], "labels": ["area-blazor"]}
{"project": "appium_appium", "title": "Appium-android-driver real deviceName return the device udid", "description": "When I request all the device \"capabilities\" used for a test, the deviceName value that I get is the udid of the device. When I do a test to any android device I would like to have all device attributes used for that test. I noticed the deviceName that Appium response is in fact the udid. I look up to your appium-android-driver and noticed that the lib/driver.js on startAndroidSession you have the deviceName as this.adb.curDeviceId.  My question is if is it intended to be like this, the udid as the real deviceName? If not I can provide a PR. [debug] [Chromedriver] Changed state to 'online'\n[Appium] New AndroidDriver session created successfully, session e925eec0-3498-4621-8655-600ff352cd47 added to master session list\n[debug] [BaseDriver] Event 'newSessionStarted' logged at 1494416175630 (12:36:15 GMT+0100 (WEST))\n[debug] [MJSONWP] Responding to client with driver.createSession() result: {\"platform\":\"LINUX\",\"webStorageEnabled\":false,\"takesScreenshot\":true,\"javascriptEnabled\":true,\"databaseEnabled\":false,\"networkConnectionEnabled\":true,\"locationContextEnabled\":false,\"warnings\":{},\"desired\":{\"browserName\":\"Chrome\",\"platformName\":\"Android\",\"deviceName\":\"A0001\",\"udid\":\"81cc7d9\"},\"browserName\":\"Chrome\",\"platformName\":\"Android\",\"deviceName\":\"81cc7d9\",\"udid\":\"81cc7d9\",\"deviceUDID\":\"81cc7d9\",\"platformVersion\":\"6.0.1\",\"deviceScreenSize\":\"1080x1920\",\"deviceModel\":\"A0001\",\"deviceManufacturer\":\"OnePlus\"}\n[HTTP] <-- POST /wd/hub/session 200 22423 ms - 586 <CODE> The output that I get is: Capabilities <CODE> ", "code": [" DesiredCapabilities capability = new DesiredCapabilities();\n\n capability.setCapability(MobileCapabilityType.PLATFORM_NAME, \"Android\");\n capability.setCapability(MobileCapabilityType.BROWSER_NAME, \"Chrome\");\n capability.setCapability(MobileCapabilityType.DEVICE_NAME, \"A0001\");\ncapability.setCapability(\"udid\", \"81cc7d9\");\n  WebDriver driver;\n   driver = new AndroidDriver<MobileElement>(new URL(\"http://127.0.0.1:4723/wd/hub\"), capability);\n System.out.println(((RemoteWebDriver)driver).getCapabilities());\n", "[{\n    deviceScreenSize = 1080 x1920,\n    networkConnectionEnabled = true,\n    warnings = {},\n    databaseEnabled = false,\n    deviceName = 81 cc7d9,\n    platform = LINUX,\n    deviceUDID = 81 cc7d9,\n    desired = {\n        browserName = Chrome,\n        platformName = Android,\n        udid = 81 cc7d9,\n        deviceName = A0001\n    },\n    platformVersion = 6.0 .1,\n    webStorageEnabled = false,\n    locationContextEnabled = false,\n    takesScreenshot = true,\n    browserName = Chrome,\n    javascriptEnabled = true,\n    deviceModel = A0001,\n    platformName = Android,\n    udid = 81 cc7d9,\n    deviceManufacturer = OnePlus\n}]\n"], "labels": ["Question", "Android"]}
{"project": "divio_django-cms", "title": "Links wrong after publishing a page", "description": "If you publish a page in the django CMS sidebar, after the refresh the links in the sidebar are not correct: Wrong: <URL> It should be: <URL> ", "code": [], "labels": ["needs more info"]}
{"project": "matomo-org_matomo", "title": "Whois Live Plugin", "description": "Similar to the Live plugin, but much simpler. Provides one widget, which: I wrote this plugin to get a better overview of current visitors location, settings and so on. A comprehensive overview, which is not provided by the standard widgets - data was spread out in different widgets, but none showed a combined view of ip, settings, provider and referer per visit. The UI of the Live plugin was too confusing (at least for me). Note, that it probably does not make much sense for high traffic sites. You can download it here:\n<URL> Works in Piwik 0.5.5 (other versions not tested). Maybe it could be integrated into the Core? License is GPL. Keywords: plugin, live, whois, third-party-plugin ", "code": [], "labels": ["R: worksforme", "T: New feature"]}
{"project": "MicrosoftDocs_azure-docs", "title": "How to resolve ARM template resource limit error after integrating ADF with Git", "description": "Hi, Recently, we have integrated our Azure Data factory with Azure DevOps Git and created a publish_config.json with publish branch. Currently our ADF has more than 800 resources. So, when I tried to publish any changes to ADF, it is giving me an error  - \"Deployment template validation failed: 'The number of template resources limit exceeded. Limit: '800' and actual: 'XXX'. I saw that the resolution to this error is to use linked or nested templates - <URL> Now, my question is how do we resolve this error when ADF is integrated with Git? Since ADF takes care of creating ARM templates and uploading them to Git automatically whenever we do publish. \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["product-question", "cxp", "triaged", "data-factory/svc"]}
{"project": "npm_npm", "title": "npm ERR! Maximum call stack size exceeded", "description": "I am unable to update the npm packages. Please find attached log. resume: <CODE> Jackson ", "code": ["npm WARN install:array-differ ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/verb/node_modules/template/node_modules/load-templates/node_modules/map-files/node_modules/globby/node_modules/array-differ' -> '/usr/local/lib/node_modules/update/node_modules/extract-comments/node_modules/array-differ'\nnpm WARN install:array-uniq ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/verb/node_modules/template/node_modules/load-templates/node_modules/map-files/node_modules/globby/node_modules/array-union/node_modules/array-uniq' -> '/usr/local/lib/node_modules/update/node_modules/extract-comments/node_modules/array-uniq'\nnpm WARN install:array-unique ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/filter-array/node_modules/array-unique' -> '/usr/local/lib/node_modules/update/node_modules/filter-array/node_modules/array-unique'\nnpm WARN install:minimatch ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/glob-stream/node_modules/minimatch' -> '/usr/local/lib/node_modules/update/node_modules/glob-stream/node_modules/minimatch'\nnpm WARN install:has-value ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/has-any-deep/node_modules/has-value' -> '/usr/local/lib/node_modules/update/node_modules/has-any-deep/node_modules/has-value'\nnpm WARN install:export-files ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/verb/node_modules/helper-license/node_modules/markdown-utils/node_modules/export-files' -> '/usr/local/lib/node_modules/update/node_modules/helper-related/node_modules/export-files'\nnpm WARN install:is-number ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/helper-related/node_modules/is-number' -> '/usr/local/lib/node_modules/update/node_modules/helper-related/node_modules/is-number'\nnpm WARN install:relative ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/js-comments/node_modules/relative' -> '/usr/local/lib/node_modules/update/node_modules/js-comments/node_modules/relative'\nnpm WARN install:object.omit ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/load-templates/node_modules/object.omit' -> '/usr/local/lib/node_modules/update/node_modules/load-templates/node_modules/object.omit'\nnpm WARN install:object.pick ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/load-templates/node_modules/object.pick' -> '/usr/local/lib/node_modules/update/node_modules/load-templates/node_modules/object.pick'\nnpm WARN install:option-cache ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/load-templates/node_modules/option-cache' -> '/usr/local/lib/node_modules/update/node_modules/load-templates/node_modules/option-cache'\nnpm WARN install:ansi-styles ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/verb/node_modules/helper-apidocs/node_modules/js-comments/node_modules/lodash-helpers/node_modules/chalk/node_modules/ansi-styles' -> '/usr/local/lib/node_modules/update/node_modules/logging-helpers/node_modules/ansi-styles'\nnpm WARN install:ms ENOENT: no such file or directory, rename '/usr/local/lib/node_modules/update/node_modules/lookup-path/node_modules/ms' -> '/usr/local/lib/node_modules/update/node_modules/lookup-path/node_modules/ms'\nnpm ERR! Darwin 14.5.0\nnpm ERR! argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"install\" \"-g\" \"npm\" \"to\" \"update\"\nnpm ERR! node v4.0.0\nnpm ERR! npm  v3.3.5\n\nnpm ERR! Maximum call stack size exceeded\nnpm ERR! \nnpm ERR! If you need help, you may report this error at:\nnpm ERR!     <https://github.com/npm/npm/issues>\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     /Users/xereda/Sites/giceruttiapp/npm-debug.log\n"], "labels": ["bug"]}
{"project": "odoo_odoo", "title": "PY3/V11 String Decoding : AttributeError: 'str' object has no attribute 'decode'", "description": "Importable module with static files when running Odoo v11.0 with python3 runs into following error Traceback (most recent call last):\nFile \"/home/odoo/code/odoo/addons/base_import_module/models/ir_module.py\", line 126, in import_zipfile\nself._import_module(mod_name, path, force=force)\nFile \"/home/odoo/code/odoo/addons/base_import_module/models/ir_module.py\", line 82, in _import_module\nurl_path = url_path.decode(sys.getfilesystemencoding())\nAttributeError: 'str' object has no attribute 'decode' With Python3 Odoo code is trying to decode an object that is already decoded at <URL>\nLine 82 in import module will have a str, there is no need to decode from file system encoding anymore. Thank You ", "code": [], "labels": ["P3", "11.0"]}
{"project": "opentx_opentx", "title": "Instant trim autorepeats at full speed", "description": "SHdown Instant Trim, press SH... trim goes to end instantly with continuous beeping ", "code": [], "labels": ["bug"]}
{"project": "square_okhttp", "title": "Tag critical Java tests with @JavaApiTest", "description": "I assume new tests we will increasingly write with Kotlin, particularly with some kotlin specific surface area.  So tagging the tests that should remain in Java would be useful, and migrating some to cleaner Kotlin APIs e.g. CallTest? ", "code": [], "labels": ["enhancement"]}
{"project": "kubernetes_kubernetes", "title": "BenchmarkCheckRetryClosesBody is failing", "description": "It seems to be consistently failing with: <CODE> <URL> @kubernetes/sig-api-machinery-bugs ", "code": ["goos: linux\ngoarch: amd64\npkg: k8s.io/kubernetes/vendor/k8s.io/client-go/rest\nBenchmarkCheckRetryClosesBody-8   \t--- FAIL: BenchmarkCheckRetryClosesBody-8\n    request_test.go:1451: Unexpected error: Post http://127.0.0.1:36871/api/v1/foo/bar/baz?timeout=1s: context canceled &url.Error{Op:\"Post\", URL:\"http://127.0.0.1:36871/api/v1/foo/bar/baz?timeout=1s\", Err:(*errors.errorString)(0xc000086220)}\nFAIL\nexit status 1\nFAIL\tk8s.io/kubernetes/vendor/k8s.io/client-go/rest\t0.023s\n"], "labels": ["kind/bug", "sig/api-machinery"]}
{"project": "fritzing_fritzing-app", "title": "program stops working when sherching parts bin", "description": "From helihatf...@gmail.com on December 15, 2013 20:26:39 What steps will reproduce the problem? 1.click the search and type logo and hit enter then program stops working every time.\n2.Newest Fritzing\n3.Windows 7 Attach your sketch file and/or custom part files to the bug report. What is the expected output? What do you see instead? What version of Fritzing are you using? On what operating system? Please provide any additional information below. Original issue: <URL> ", "code": [], "labels": ["bug"]}
{"project": "nwjs_nw.js", "title": "The resource in packed nw app could not be open because of permission issue", "description": "I was trying to run a applescript to open a .mov file triggering by the command in the packed nwjs app. However, it says permission is required to open the .mov file. The .mov is located within the packed nwjs app. And before packing up the app, I changed the permission of .mov file to read and write.\nThe nwjs version I am using is 0.19.1, and it was running on Mac. ", "code": [], "labels": ["needinfo"]}
{"project": "adobe_brackets", "title": "Not all files open in a new project", "description": "Hi. I have the following issue: when I open a certain directory as a project, not all files are opened:  Though there are many files in subfolders (css, images, etc...)  I tried to open other directories and everything was ok. ", "code": [], "labels": ["needs review"]}
{"project": "microsoft_vscode", "title": "For version 1.36.1 of vs code, the jump is very slow when you click on the method in typescript", "description": "For version 1.36.1 of vs code, the jump is very slow when you click on the method in typescript ", "code": [], "labels": ["typescript", "needs more info"]}
{"project": "quasarframework_quasar", "title": "Add router 'prefixWith' helper", "description": "Is your feature request related to a problem? Please describe.\nWhen using vue router, it's currently not possible to logically group multiple routes with the same prefix while keeping them at the same router-outlet level of ther others. Example Describe the solution you'd like\nCurrent suggested workaround is to create a prefixWith helper, which would already be enough. Another step would be to detect when component isn't provided on the parent route and automatically flat it, or add a logical property which serve the same purpose (detect routes to be flattened) but is more explicit about what's going to happen. Describe alternatives you've considered\nAdding a notice on the docs linking to the proposed solution from Evan You. ", "code": [], "labels": ["feature request"]}
{"project": "PowerDNS_pdns", "title": "Slave pdns server does not change master upon termination", "description": "I have a slave pdns with bind backend listening to several different masters for SOA updates and notifications. If the server is on and the first IP in the list is terminated, my slave pdns can't connect to it to get SOA updates even though he gets notified by other masters that a change need to be made. This obviously gets solved if I restart my pdns server, in which case it takes the next ip in list, but the connection is always only kept with the first master. I would like for the slave to either: I'll only give slave information as they are what's relevant: named.conf file: <CODE> pdns.conf file: <CODE> Thanks in advance ", "code": ["options {\n    directory \"/var/powerdns/bind\";\n};\n\nzone \"example.com\" IN {\n    type slave;\n    file \"example.com\";\n    masters { 52.91.135.125; 54.175.233.140; 54.208.97.41; };\n};\n", "config-dir=/etc/powerdns\ndaemon=yes\nguardian=yes\ndisable-axfr=yes\ndisable-tcp=yes\nlocal-port=53\nlog-dns-details=on\nloglevel=3\nmaster=no\nslave=yes\nsetgid=pdns\nsetuid=pdns\nsocket-dir=/var/run\nversion-string=powerdns\nlaunch=bind\nbind-config=/var/powerdns/bind/named.conf\ninclude-dir=/etc/powerdns/pdns.conf.d\nbind-check-interval=600\nallow-notify-from=0.0.0.0/0\ndistributor-threads=3\nnegquery-cache-ttl=10\nquery-cache-ttl=20\nreceiver-threads=1\nretrieval-threads=2\nslave-cycle-interval=60\n"], "labels": ["enhancement", "auth"]}
{"project": "microsoft_vscode", "title": "Visual bug after resizing interactive Python shell", "description": "Issue:\nAfter resizing the interactive Python shell and printing a list from the shell, there is dead space beneath the shell's input box (please refer to the lower right side of the screenshot). This bug is not present in VS Code 1.39.2.  Steps to Reproduce: Does this issue occur when all extensions are disabled?: No. However, Python code cannot be run without the Python extension (ms-python.python). ", "code": [], "labels": ["*caused-by-extension"]}
{"project": "wordpress-mobile_WordPress-iOS", "title": "Remove NSObject+BlockObservation", "description": "It should no longer be necessary (not sure that it ever really was). ", "code": [], "labels": ["enhancement"]}
{"project": "mysqljs_mysql", "title": "Multiple insertion in mysql database, You have an error in your SQL syntax; check the manual that corresponds to your MySQL", "description": "I want to insert multiple record at the same time in the database and for that here is my sql instruction :   insert into tabo (fee,doo,ple,idur) values (?,?,?,?),(?,?,?,?),(?,?,?,?),(?,?,?,?) ON duplicate key update tabo.doo=values(doo),tabo.fee=values(fee); Whe I am executing it, it is bringing this error: I am not able to know where exactly I have an error. I need help to know what is wrong with my query. Here is my table tabo structure: I am using nodejs but even in mysql the query is not running and the package(module) I am using is mysqljs/mysql : Here is my code: ", "code": [], "labels": ["question"]}
{"project": "dart-lang_sdk", "title": "Negation of a void value produces no error", "description": "This code produces no error with the analyzer: cc @MichaelRFairhurst ", "code": [], "labels": ["type-bug", "area-analyzer", "P2"]}
{"project": "angular_components", "title": "[mat-tab] Tabs distorted at zoom", "description": "When zoomed in, tab link headers should be truncated properly The text is cut off. Example:\n ", "code": [], "labels": ["P4"]}
{"project": "influxdata_chronograf", "title": "Add stack graph type", "description": "Would be nice to have stacked graphs.  Could use dygraph's stacked graph:\n<URL> ", "code": [], "labels": ["feature request", "design"]}
{"project": "bundler_bundler", "title": "[Windows] ruby 2.5 (via RubyInstaller2) crashes `ruby bin/rake spec:deps`", "description": "<CODE> leads to: <CODE> <URL> The lines indicating a problem here seem to be these two: <CODE> If I understand this correctly, the 2.5.0 Ruby seems to come with a rake by itself, which clashes which one that is tried to be installed. \ud83d\udc0a ", "code": ["2019-01-10T19:31:36.0873970Z Found tool in cache: Ruby 2.5.0 x64\n2019-01-10T19:31:36.0914316Z Prepending PATH environment variable with directory: C:\\hostedtoolcache\\windows\\Ruby\\2.5.0\\x64\\bin\n", "2019-01-10T19:31:37.9844063Z ruby bin/rake spec:deps\n2019-01-10T19:31:38.0506871Z ##[command]\"C:\\Windows\\system32\\cmd.exe\" /D /E:ON /V:OFF /S /C \"CALL \"D:\\a\\_temp\\7b062f07-327f-4fd0-bb85-e840e8d07faa.cmd\"\"\n2019-01-10T19:31:43.1091783Z Could not find 'automatiek' (~> 0.1.0) among 29 total gem(s)\n2019-01-10T19:31:43.1092468Z Checked in 'GEM_PATH=C:/Users/VssAdministrator/.gem/ruby/2.5.0;C:/hostedtoolcache/windows/Ruby/2.5.0/x64/lib/ruby/gems/2.5.0', execute `gem env` for more information (Gem::MissingSpecError)\n2019-01-10T19:31:43.1092869Z Could not find 'mustache' (= 0.99.6) among 29 total gem(s)\n2019-01-10T19:31:43.1093100Z Checked in 'GEM_PATH=C:/Users/VssAdministrator/.gem/ruby/2.5.0;C:/hostedtoolcache/windows/Ruby/2.5.0/x64/lib/ruby/gems/2.5.0', execute `gem env` for more information (Gem::MissingSpecError)\n2019-01-10T19:31:43.1095559Z Could not find 'rake' (~> 10.0) - did find: [rake-12.3.0]\n2019-01-10T19:31:43.1095795Z Checked in 'GEM_PATH=C:/Users/VssAdministrator/.gem/ruby/2.5.0;C:/hostedtoolcache/windows/Ruby/2.5.0/x64/lib/ruby/gems/2.5.0', execute `gem env` for more information (Gem::MissingSpecVersionError)\n2019-01-10T19:31:43.1097008Z Could not find 'rdiscount' (~> 2.2) among 29 total gem(s)\n2019-01-10T19:31:43.1097239Z Checked in 'GEM_PATH=C:/Users/VssAdministrator/.gem/ruby/2.5.0;C:/hostedtoolcache/windows/Ruby/2.5.0/x64/lib/ruby/gems/2.5.0', execute `gem env` for more information (Gem::MissingSpecError)\n2019-01-10T19:31:43.1098491Z Could not find 'ronn' (~> 0.7.3) among 29 total gem(s)\n2019-01-10T19:31:43.1098762Z Checked in 'GEM_PATH=C:/Users/VssAdministrator/.gem/ruby/2.5.0;C:/hostedtoolcache/windows/Ruby/2.5.0/x64/lib/ruby/gems/2.5.0', execute `gem env` for more information (Gem::MissingSpecError)\n2019-01-10T19:31:43.1100463Z Could not find 'rspec' (~> 3.6) among 29 total gem(s)\n2019-01-10T19:31:43.1100763Z Checked in 'GEM_PATH=C:/Users/VssAdministrator/.gem/ruby/2.5.0;C:/hostedtoolcache/windows/Ruby/2.5.0/x64/lib/ruby/gems/2.5.0', execute `gem env` for more information (Gem::MissingSpecError)\n2019-01-10T19:31:43.1102069Z Could not find 'rspec_junit_formatter' (~> 0.2.3) among 29 total gem(s)\n2019-01-10T19:31:43.1102324Z Checked in 'GEM_PATH=C:/Users/VssAdministrator/.gem/ruby/2.5.0;C:/hostedtoolcache/windows/Ruby/2.5.0/x64/lib/ruby/gems/2.5.0', execute `gem env` for more information (Gem::MissingSpecError)\n2019-01-10T19:31:47.5349299Z C:/hostedtoolcache/windows/Ruby/2.5.0/x64/bin/ruby.exe -S gem install --no-document --conservative 'automatiek:~> 0.1.0' 'mustache:= 0.99.6' 'rake:~> 10.0' 'rdiscount:~> 2.2' 'ronn:~> 0.7.3' 'rspec:~> 3.6' 'rspec_junit_formatter:~> 0.2.3' 'rubocop:= 0.50.0'\n2019-01-10T19:31:56.5732632Z ERROR:  Error installing rake:\n2019-01-10T19:31:56.5733185Z \t\"rake\" from rake conflicts with C:/hostedtoolcache/windows/Ruby/2.5.0/x64/bin/rake\n2019-01-10T19:33:35.8677723Z Successfully installed automatiek-0.1.2\n2019-01-10T19:33:35.8678506Z Successfully installed mustache-0.99.6\n2019-01-10T19:33:35.8678810Z Temporarily enhancing PATH for MSYS/MINGW...\n2019-01-10T19:33:35.8679188Z Building native extensions. This could take a while...\n2019-01-10T19:33:35.8679385Z Successfully installed rdiscount-2.2.0.1\n2019-01-10T19:33:35.8679586Z Building native extensions. This could take a while...\n2019-01-10T19:33:35.8681194Z Successfully installed hpricot-0.8.6\n2019-01-10T19:33:35.8681427Z Successfully installed ronn-0.7.3\n2019-01-10T19:33:35.8681666Z Successfully installed rspec-support-3.8.0\n2019-01-10T19:33:35.8681890Z Successfully installed rspec-core-3.8.0\n2019-01-10T19:33:35.8682148Z Successfully installed diff-lcs-1.3\n2019-01-10T19:33:35.8682367Z Successfully installed rspec-expectations-3.8.2\n2019-01-10T19:33:35.8682606Z Successfully installed rspec-mocks-3.8.0\n2019-01-10T19:33:35.8682776Z Successfully installed rspec-3.8.0\n2019-01-10T19:33:35.8682969Z Successfully installed builder-3.2.3\n2019-01-10T19:33:35.8683142Z Successfully installed rspec_junit_formatter-0.2.3\n2019-01-10T19:33:35.8683342Z Building native extensions. This could take a while...\n2019-01-10T19:33:35.8683512Z Successfully installed rainbow-2.2.2\n2019-01-10T19:33:35.8683863Z Successfully installed ast-2.4.0\n2019-01-10T19:33:35.8684048Z Successfully installed parser-2.5.3.0\n2019-01-10T19:33:35.8684224Z Successfully installed powerpack-0.1.2\n2019-01-10T19:33:35.8684449Z Successfully installed ruby-progressbar-1.10.0\n2019-01-10T19:33:35.8684647Z Successfully installed unicode-display_width-1.4.1\n2019-01-10T19:33:35.8684850Z Successfully installed parallel-1.12.1\n2019-01-10T19:33:35.8685023Z Successfully installed rubocop-0.50.0\n2019-01-10T19:33:35.8685235Z 21 gems installed\n2019-01-10T19:33:35.8767919Z rake aborted!\n2019-01-10T19:33:35.8768113Z Command failed with status (1): [C:/hostedtoolcache/windows/Ruby/2.5.0/x64/...]\n2019-01-10T19:33:35.8768284Z D:/a/1/s/Rakefile:57:in `block (2 levels) in <top (required)>'\n2019-01-10T19:33:35.8768348Z D:/a/1/s/Rakefile:33:in `block in invoke'\n2019-01-10T19:33:35.8768408Z D:/a/1/s/Rakefile:32:in `invoke'\n2019-01-10T19:33:35.8768480Z Tasks: TOP => spec:deps\n2019-01-10T19:33:35.8768532Z (See full trace by running task with --trace)\n2019-01-10T19:33:35.9873562Z ##[error]Cmd.exe exited with code '1'.\n2019-01-10T19:33:36.0280693Z ##[section]Finishing: ruby bin/rake spec:deps\n\n", "2019-01-10T19:31:56.5732632Z ERROR:  Error installing rake:\n2019-01-10T19:31:56.5733185Z \t\"rake\" from rake conflicts with C:/hostedtoolcache/windows/Ruby/2.5.0/x64/bin/rake\n"], "labels": ["platform: windows"]}
{"project": "RocketMap_RocketMap", "title": "Scans can easily overlap, resulting in suboptimal scanning", "description": "When moving around the scan location manually, or following the users location, a lot of overlapping can occur. This is a suggestion on how to resolve this. When scanning areas, it would make sense not to rescan something that has been covered just seconds ago. You will not get any new information out of this area. I would expect the searcher to not re-scan areas until after a certain period of time (say 3 minutes). If placing searches manually (moving the pin in the map) or when using the Follow users location feature, a lot of overlapping will occur.  I can envision two ways to fix this. One. Check the DB for recently scanned areas, and see if the center you want to scan is \"close enough\" to any center that was scanned during some timeframe. This can be costly in two ways: It's a lot of queries to perform that may cover large sets of data, and if spatial features are not enabled in the underlying DB, it won't be possible to use efficient data structures to find close proximity locations. Two. Create a grid spanning the entire world, starting from 0,0 and moving out 60 meters pr. point east/west. In the next rows, 52 meters north/south, the same pattern appears, but adjusted slightly so we get the same hex grid as now. Now it is possible, given any location, to calculate the \"fixed\" center of this location, and use the fixed points instead. As each point will be deterministically fixed to a location, we can assign a unique id to the location, which can then be used a primary key in a database. Doing so, makes it possible to do instant lookups in the DB to find the previous scan (if any) on a given location. Note Example calculation (i use meters here, as the lat/lon become very small for 70 meters): And then for the id for each fixed point: As we move approx 60 meters east/west for each column, we can cover the circumference of earth (40.000 km) with 666.666 points. The same should be true for the north/south. These numbers fit well within 32 bit integer, so we can pack them together in a single 64 bit integer by this: col << 32 | row Note: ", "code": [], "labels": ["new feature"]}
{"project": "grails_grails-core", "title": "GRAILS-6208: mistakes in cascade doc", "description": "Original Reporter: david_beutel\nEnvironment: Not Specified\nVersion: 1.2.2\nMigrated From: <URL> <URL> has an example <CODE> shouldn't it be <CODE> Also, that section lists \"create\" as a valid setting, but I get org.hibernate.MappingException: Unsupported cascade style: create Should it be \"persist\" instead?  I haven't found good docs for this, but org.hibernate.cfg.AnnotationBinder looks that way (and also has \"replicate\"). ", "code": ["addresses cascade:\"all-delete-orphan\"\n", "addresses cascade:\"all,delete-orphan\"\n"], "labels": ["Major", "Bug", "Fixed"]}
{"project": "arendst_Tasmota", "title": "Multi mqtt messages or alt", "description": "Hi guys,\nI've modified my wireless doorbell to use Tasmota and communicate with my Home Assistant\nAnd worked well as a binary sensor on and off.\nMy issue is every time I lose power or reset door bell it reverts the bell tune to default and needs resetting so I programmed one pin as switch 2\nFor my sensor on n off then one pin as a relay to\nChange tunes on the door bell all this will works fine but I can only receive one mqtt message at a time so either I can activate the relay via the Tasmota interface for tune selection of my door bell but this also now sends the mqtt message and can no longer get a mqtt message for the input. Ideal solution\n2 x mqtt messages one for relay one for a sensor. Alt solution no mqtt messages for relay on off but still able to turn on n off via Web interface and the input to trigger a mqtt message on off Any help please save me as I'm going insane trying to figure this out ", "code": [], "labels": ["stale"]}
{"project": "0xd4d_dnSpy", "title": "[Bug] [Unity C# assembly] Unable to subscribe method to the event", "description": "I mentioned it some time ago but did not understood myself much about it. Now I do so I wanted to make a proper bug report.\n<URL>\n<URL> Compiler reports ambiguity between X and Y. ", "code": [], "labels": ["question"]}
{"project": "saltstack_salt", "title": "ssh_known_hosts.present creates wrong known_hosts lines", "description": "This happens with 2015.5.7 as well as with 2015.8.2 <CODE> This state will create a wrong line in /etc/ssh/ssh_known_hosts like this: <CODE> And because the ssh commands salt uses to find the desired lines will of cource not find the wrong line, salt will add it every time the state runs. Correct would be: <CODE> So it seems, that the port is being added to the hostname part twice. relevant debug output: <CODE> ", "code": ["ssh_known_hosts_foo.example.com:\n  ssh_known_hosts.present:\n    - hash_known_hosts: False\n    - name: foo.example.com\n    - port: 2222\n    - fingerprint: 00:b2:9e:d2:c2:5e:1e:22:cb:50:dc:aa:6a:6f:b7:a2\n    - enc: ssh-ed25519\n", "[[foo.example.com]:2222]:2222 ssh-ed25519 AAAAC3NzaC1lZDI1AAE5AAAAIGllWa0M0xaAbSZgTpMAsILmZTUWViE6txdeLIgvIjNP\n", "[foo.example.com]:2222 ssh-ed25519 AAAAC3NzaC1lZDI1AAE5AAAAIGllWa0M0xaAbSZgTpMAsILmZTUWViE6txdeLIgvIjNP\n", "[DEBUG   ] LazyLoaded ssh_known_hosts.present\n[INFO    ] Running state [foo.example.com] at time 19:32:23.883400\n[INFO    ] Executing state ssh_known_hosts.present for foo.example.com\n[DEBUG   ] LazyLoaded ssh.set_known_host\n[INFO    ] Executing command 'ssh-keygen -F \"[foo.example.com]:2222\" -f \"/etc/ssh/ssh_known_hosts\"' in directory '/root'\n[DEBUG   ] output:\n[INFO    ] Executing command 'ssh-keyscan -p 2222 -t ssh-ed25519 foo.example.com' in directory '/root'\n[DEBUG   ] output: # foo.example.com:2222 SSH-2.0-OpenSSH_7.1p1-hpn14v9\n[foo.example.com]:2222 ssh-ed25519 AAAAC3NzaC1lZDI1AAE5AAAAIGllWa0M0xaAbSZgTpMAsILmZTUWViE6txdeLIgvIjNP\n[INFO    ] Executing command 'ssh-keygen -R \"foo.example.com\" -f \"/etc/ssh/ssh_known_hosts\"' in directory '/root'\n[DEBUG   ] output: Host foo.example.com not found in /etc/ssh/ssh_known_hosts\n[DEBUG   ] Ensuring ssh config dir \"/etc/ssh\" exists\n[DEBUG   ] /etc/ssh already exists, no need to create it\n[INFO    ] {'new': {'port': 2222, 'hostname': '[foo.example.com]:2222', 'enc': 'ssh-ed25519', 'key': 'AAAAC3NzaC1lZDI1AAE5AAAAIGllWa0M0xaAbSZgTpMAsILmZTUWViE6txdeLIgvIjNP', 'fingerprint': '00:b2:9e:d2:c2:5e:1e:22:cb:50:dc:aa:6a:6f:b7:a2'}, 'old': None}\n[INFO    ] Completed state [foo.example.com] at time 19:32:23.986815\n"], "labels": ["High Severity", "State Module", "Bug", "Fixed Pending Verification", "Platform", "P4"]}
{"project": "qgis_QGIS", "title": "WMS performance degraded", "description": "Author Name: Tobias Schneider (Tobias Schneider)\nOriginal Redmine Issue: 10247\nAffected QGIS version: master\nRedmine category:web_services_clients/wms I checked this with two computer on the same Internet connection: I moved the view with the same WMS layer activated and checked the load time:\n*QGIS 2.2 (Ubuntu 13.10 - 64 bit): ~ 2 seconds\n*QGIS 2.3 (Ubuntu 14.04 - 64 bit): ~ 4 to 5 seconds The 13.10 computer is also weaker (Lenovo SL 510, Intel Core 2 Duo, GM45 graphics) compared to ProBook 6570b (Intel Core i3-3120M CPU @ 2.50GHz \u00d7 4, Ivybridge graphics). Please prioritize this, because WMS editing with 5 second lag is pretty painful ;) ", "code": [], "labels": ["Bug", "Data Provider"]}
{"project": "kubernetes_kubernetes", "title": "Deleting not scheduled POD cause scheduler errors", "description": "Deleting not scheduled POD cause scheduler errors.\nkube-scheduler log contains messages like Steps to reproduce: Kubernetes version: 1.4.5 Environment: ", "code": [], "labels": ["sig/scheduling", "kind/bug"]}
{"project": "dotnet_aspnetcore", "title": "Can I suggest a suggestion about anomalies?", "description": "A lot of duplicate exception code, increasing the amount of code, can it be streamlined into a single line?   Too much One line of code can do it   ", "code": [], "labels": ["discussion"]}
{"project": "hasura_graphql-engine", "title": "Relationships docs specify manual_mapping attribute", "description": "The relationship metadata docs specify a manual_mapping attribute that doesn't work or exist: <URL> Opening issue to have a number to report in a forthcoming PR ", "code": [], "labels": ["c/server"]}
{"project": "pouchdb_pouchdb", "title": "Race condition cloning test is faily", "description": "This test (ee770fe) is faily for socket-pouch because the constructor takes awhile to start up, so here is the sequence of events: IMO a better test would be if the user mutates the document immediately after calling db.put(). But for PouchDB to pass that test, we would need to aggressively clone immediately for every API call (synchronously). As a side note, I think these particular tests are kinda dumb because as long as you write clean code, this issue should never come up. But I guess we are at the point with the development of PouchDB that most of the remaining issues to resolve are minor ones with niche value. ", "code": [], "labels": ["enhancement"]}
{"project": "phpmyadmin_phpmyadmin", "title": "'Show All' doesn't work (browse foreign values)", "description": "When setting the $cfg[\u2018ShowAll\u2019] directive to TRUE, pressing the \u201cShow All\u201d button shows\nan empty set of results, rather than the full set of\nresults. This was working on phpmyadmin 2.5.7-pl1 with MySQL 4.1.11. - Original URL: <URL>\n- Original author: hspirit\n- Found in version: 2.6.3-pl1 ", "code": [], "labels": ["bug"]}
{"project": "minio_minio", "title": "minio error with aws-sdk-js", "description": "@ajarbehari on #minio gitter: <CODE> ", "code": ["I am porting and web application that uses aws js sdk from S3 to Minio . I found two issues : First when I \naccess an image with public-read access using <img ng-src={{ImageUrl}} > I get a Access Denied error .\n Second when I use listBuckets I get a cross origin error as below : XMLHttpRequest cannot load\n http://publicIP:10000/. The request was redirected to 'http://publicIP:10000/minio/', which is disallowed\n for cross-origin requests that require preflight. I have set ssl enable false and S3forcepath style as true\n while making connection . Can anyone point out the cause of these errors ?\n"], "labels": ["bug"]}
{"project": "keras-team_keras", "title": "Here, How to use convolution1D to deal series characters?", "description": "I have a five dimentions series vector. I want to use Convolution1D to get series characters\nbut I have some problems. I couldn't understand the difference about input_dim and input _length in Convoltion1D.\ncoding:\n` x_test=np.random.random_sample((100,5))\ny_test=np.random.randint(2,size=100) model= Sequential()\nmodel.add(Convolution1D(nb_filter=1,filter_length=2,input_dim=5))\nmodel.add(Flatten())\nmodel.add(Dense(1))\nmodel.compile(optimizer='sgd', loss='mse')\nmodel.fit(x_test,y_test)\n`\nbut it is wrong, It says I don't input parameter 'input_length'\nSo I change the code\ncode is following: x_test=np.random.random_sample((100,5))\ny_test=np.random.randint(2,size=100) model= Sequential()\nmodel.add(Convolution1D(nb_filter=1,filter_length=2,input_dim=5,input_dim=5))\nmodel.add(Flatten())\nmodel.add(Dense(1))\nmodel.compile(optimizer='sgd', loss='mse')\nmodel.fit(x_test,y_test)\n`\nHowever, it is still wrong, It says my input-dimensions is wrong? anyone know it? ", "code": [], "labels": ["stale"]}
{"project": "google_ExoPlayer", "title": "DRM: Check key status before adapting to a different representation (API level 23+)", "description": "We use Widevine DRM together with ExoPlayer. When we limit allowed_track_types on our Widevine proxy eg. to SD_ONLY and we try playing DASH containing some HD tracks, the playback fails with the following error when the player tries to adapt to an HD track. <CODE> The expected behaviour would be that player wouldn't switch to a video track it doesn't have a license for. Is ExoPlayer able to handle this situation itself or we have to make a workaround, eg. by making an initial track selection excluding HD tracks? Shaka player is handling this situation correctly, ie. it's not adapting to a not allowed track. This is more of a question, so I'm not enclosing any test content or adb bugreport. If you believe this could be an issue related to ExoPlayer, I can provide that afterwards. Set allowed_track_types in Widevine proxy to SD_ONLY.\nPlay content containing HD track. 2.8.2 Amlogic STB with Android 6.0.1\nAmlogic STB with Android 8.0 ", "code": ["E/WVCdm: PolicyEngine::CanDecrypt Key '5955A05307225C50B4B4A556155C12A1' not in license.\n    Decrypt error result in session sid32 during encrypted block: 5\nD/VodPlayerFragment$MediaSourceListener: onDownstreamFormatChanged(format: Format(5, video/mp4, video/avc, 4500000, null, [1920, 1080, 23.98], [-1, -1]))\nE/ExoPlayerImplInternal: Playback error.\n    com.google.android.exoplayer2.ExoPlaybackException\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:771)\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:574)\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:518)\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:301)\n        at android.os.Handler.dispatchMessage(Handler.java:101)\n        at android.os.Looper.loop(Looper.java:164)\n        at android.os.HandlerThread.run(HandlerThread.java:65)\n     Caused by: android.media.MediaCodec$CryptoException: Crypto key not available\n        at android.media.MediaCodec.native_queueSecureInputBuffer(Native Method)\n        at android.media.MediaCodec.queueSecureInputBuffer(MediaCodec.java:2532)\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:762)\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:574)\u00a0\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:518)\u00a0\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:301)\u00a0\n        at android.os.Handler.dispatchMessage(Handler.java:101)\u00a0\n        at android.os.Looper.loop(Looper.java:164)\u00a0\n        at android.os.HandlerThread.run(HandlerThread.java:65)\u00a0\n"], "labels": ["enhancement"]}
{"project": "osmandapp_Osmand", "title": "Faciltate editing POI coordinates", "description": "I often have precise coordinates for POIs that I want to add to the map. However, I'm limited to using my finger to make a new POI, and I can't edit the coordinates once the POI is created. Being able to edit the coordinates would allow people to add precise points to the map and then navigate to them. ", "code": [], "labels": ["Nice to Have"]}
{"project": "explosion_spaCy", "title": "Generate generic sentences and then train the model on top of that. Is it a good idea?", "description": "I am training a model from scratch to predict food items from the text. I have tagged around 500 sentences to train my model and the accuracy is pretty good. But, I am a bit worried about the unseen real-world data so I have come up with an interesting idea. So I wanted to know some experienced person thought in this interesting idea. Original training Sentences: So is this a good to generate training sentences like this.\nBenefits which I think: Thanks, Please let me know thoughts on this approach. ", "code": [], "labels": ["usage"]}
{"project": "jOOQ_jOOQ", "title": "Add sections to the manual explaining how to use JPADatabase", "description": "\nNo description provided.\n ", "code": [], "labels": ["P: Medium", "C: Documentation", "C: Code Generation", "R: Fixed", "T: Enhancement"]}
{"project": "steelbrain_linter", "title": "atom-typescript mixing up characters", "description": "Atom 1.20.1 x64 Windows\nLinter 2.2.0\nLinter-ui-default 1.6.10 Hi, been getting these errors several times a day for the past few weeks (haven't been using this much longer than that so not sure if it's been since a particular update...). Not even sure if it's linter or linter ui... Once the bug has occurred, further manipulation of the characters in the editor will cause even stranger output in the error message. i.e. here forFeatureFeclarations may become arationsFeatfor simply by backspacing a few characters.  Restarting Atom always resolves it. Seems to happen anywhere \\ anytime, haven't noticed any sequence of events causing it, but will keep an eye out. Cheers! ", "code": [], "labels": ["external"]}
{"project": "dompdf_dompdf", "title": "Links not opening in new tab", "description": "I have lots of anchor tags and I have used base tag to open all of them in new tab. But the links are not opening in new tab. ", "code": [], "labels": ["enhancement"]}
{"project": "EOSIO_eos", "title": "mongo_db_plugin  FC Exception while processing accepted block trace ABI serialization time has exceeded the deadline (3015010)", "description": "2018-08-14T07:18:51.475 thread-1   mongo_db_plugin.cpp:243       consume_blocks       ] queue size: 661\n2018-08-14T07:23:11.122 thread-1   mongo_db_plugin.cpp:567       process_accepted_blo ] FC Exception while processing accepted block trace ABI serialization time has exceeded the deadline (3015010)\nserialization time limit 15000000us exceeded\nFailed to serialize type Has anyone encountered this problem? If and solve him ", "code": [], "labels": ["Support"]}
{"project": "owncloud_client", "title": "[Windows] No overlay icon/Context menu in Testpilot and normal client at same time", "description": "After installing the testpilot does not show any overlay icons or context menu. After playing around a little bit, I got the overlay icons but as I got them on the Testpilot, they disappeared on the folder of my regular client. Sync process is still working. If I can't have them on both clients at the same time, I'd prefer to keep the overlay icons and the context menu on the regular client. Testpilot: 2.0.0rc1 (build 5408)\nregular client: 1.8.4 (build 5267)\nWin 7 (64-bit) edit: context-menu stays with the regular client, even when overlay icons are shown on the testpilot.\nWindows was not restarted. ", "code": [], "labels": ["bug"]}
{"project": "vaadin_framework", "title": "SCSS Pre-Compiler fails to compile style attribute \"filter\"", "description": "Originally by TobiasMeister98 [[br]] Create a new Vaadin 7 project and set the content of the UI to contain a random layout. Then add a style name to it, so it can be targeted later via css: Then add the following styles to your css stylesheet: Finally publish the project to a webserver and navigate to the respective webpage.\nThe SCSS Pre-Compiler will throw an exception. [[br]] 10:34:51,390 SEVERE [com.vaadin.sass.internal.handler.SCSSDocumentHandlerImpl] (default task-62) Error when parsing file\n.../Test.war/VAADIN/themes/test/test.scss on line 7, column 3\n10:34:51,390 SEVERE [com.vaadin.sass.internal.handler.SCSSDocumentHandlerImpl] (default task-62) encountered \"filter\". Was expecting one of: \"-\" \"and\" \"or\" \"not\" \"#{\" \"through\" \"in\"  \"-\"  \"and\" \"or\" \"not\" \"in\" \"through\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" \"#{\" Imported from <URL> issue #19341 ", "code": [], "labels": ["bug"]}
{"project": "python_mypy", "title": "Unions break with `isinstance()`", "description": "Mypy incorrectly reports two errors in this (python 2) snippet. <CODE> If lines 5 and 6 are removed, the errors disappear. If line 7 is replaced with if True:, the error on line 8 remains. Replacing unicode with str and running mypy in py3 mode also makes the errors disappear. ", "code": ["$ nl -ba /tmp/foo.py\n     1  import typing\n     2  \n     3  def foo(value):\n     4      # type: (typing.Union[unicode, bytes]) -> None\n     5      if isinstance(value, unicode):\n     6          return\n     7      if not isinstance(value, bytes):\n     8          raise TypeError(\"Expected bytes or unicode; got %r\" % type(value))\n$ PYTHONPATH=.  scripts/mypy --py2 /tmp/foo.py\n/tmp/foo.py: note: In function \"foo\":\n/tmp/foo.py:7: error: Argument 1 to \"isinstance\" has incompatible type \"Union[object, object]\"; expected \"object\"\n/tmp/foo.py:8: error: No overload variant of \"type\" matches argument types [Union[<ERROR>, <ERROR>, <ERROR>, <ERROR>]]\n"], "labels": ["bug"]}
{"project": "serverless_serverless", "title": "Referencing `${self:}` leads to crash in the print command", "description": "When referencing ${self:} with the new circular variables support, the print command will crash with a stack overflow. (For details see #4144 (review) and the discussion in the PR). This is due to a missing circular object support in the modules to traverse the service object tree used by the print command. ", "code": [], "labels": ["bug"]}
{"project": "googleapis_google-cloud-go", "title": "Support Go modules", "description": "Since 1.11 begins (experimental) support for Go modules, we should update this library to include a go.mod file and all necessary artifacts to support Go modules. ", "code": [], "labels": ["type: feature request"]}
{"project": "Meituan-Dianping_mpvue", "title": "TypeError: Cannot read property 'indexOf' of undefined", "description": "\u95ee\u9898\u590d\u73b0\u6b65\u9aa4: \u8fd9\u662f\u6211\u5728\u79fb\u690d SPA \u5230 mpvue \u7684\u65f6\u5019\u51fa\u73b0\u7684\uff0c\u5176\u5b83\u73af\u5883\u6050\u6015\u96be\u4ee5\u590d\u73b0\u3002 \u671f\u671b\u7684\u8868\u73b0: \u4e0d\u62a5\u9519 \u89c2\u5bdf\u5230\u7684\u8868\u73b0: \u51fa\u73b0\u4e00\u4e2a\u62a5\u9519\uff0c\u4f46\u662f\u7f16\u8bd1\u6210\u529f\u3002 \u63a7\u5236\u53f0\u8f93\u51fa\uff1a \u8fdb\u53bb\u6e90\u7801\u540e\u53d1\u73b0\u662f Resolver.prototype.parse \u7684\u53c2\u6570 identifier \u4e3a undefined \u5bfc\u81f4\u7684\uff0c\u8fdb\u4e00\u6b65\u5230\u7236\u7ea7\uff0c\u53d1\u73b0 ParsePlugin.prototype.apply \u51fd\u6570\u5904\u7406\u5230\u67d0\u9879\u65f6 request.request \u4e3a undefined\uff0c\u8f93\u51fa\u8fd9\u4e2a request \u7684\u503c\u4e3a\uff1a \u5c4f\u5e55\u622a\u56fe\u548c\u52a8\u6001 GIF \u56fe  ", "code": [], "labels": ["wontfix"]}
{"project": "qbittorrent_qBittorrent", "title": "Crash report", "description": "qBittorrent has crashed\nPlease report a bug at <URL> and provide the following backtrace. qBittorrent version: v3.2.3\nLibtorrent version: 1.0.6.0\nQt version: 4.8.7\nBoost version: 1.55.0 <CODE> ", "code": ["#  0 qbittorrent.exe      0x0000000000b0a0c4 straceWin::getBacktrace()\n#  1 qbittorrent.exe      0x0000000000b0b69f sigsegvHandler(__formal)\n#  2 qbittorrent.exe      0x000000000126f63c _XcptFilter(xcptnum, pxcptinfoptrs)\n#  3 qbittorrent.exe      0x000000000126273a __tmainCRTStartup()\n#  4 qbittorrent.exe      0x0000000001273a74 _EH4_CallFilterFunc()\n#  5 qbittorrent.exe      0x00000000012632ef _except_handler4(ExceptionRecord, EstablisherFrame, ContextRecord, DispatcherContext)\n#  6 ntdll.dll            0x00000000778bd652 RtlConvertUlongToLargeInteger()\n#  7 ntdll.dll            0x00000000778bd624 RtlConvertUlongToLargeInteger()\n#  8 ntdll.dll            0x00000000778aae6f KiUserExceptionDispatcher()\n#  9 qbittorrent.exe      0x0000000000b75d06 PropertiesWidget::loadDynamicData()\n#10 qbittorrent.exe      0x0000000000bf3e75 PropertiesWidget::qt_static_metacall(_o, _c, _id, _a)\n#11 qbittorrent.exe      0x0000000001037f35 QMetaObject::activate()\n#12 qbittorrent.exe      0x0000000001057897 QTimer::timerEvent()\n#13 qbittorrent.exe      0x0000000001035ae1 QObject::event()\n#14 qbittorrent.exe      0x0000000000c96242 QApplicationPrivate::notify_helper()\n#15 qbittorrent.exe      0x0000000000c94d91 QApplication::notify()\n#16 qbittorrent.exe      0x0000000000b087ef Application::notify(receiver, event)\n#17 qbittorrent.exe      0x00000000010489df QCoreApplication::notifyInternal()\n#18 qbittorrent.exe      0x0000000000c9919f QCoreApplication::sendEvent()\n#19 qbittorrent.exe      0x00000000010a2b71 QEventDispatcherWin32Private::sendTimerEvent()\n#20 qbittorrent.exe      0x00000000010a2783 qt_internal_proc()\n#21 USER32.dll           0x00000000749a4923 CharNextW()\n#22 USER32.dll           0x0000000074984790 CallWindowProcW()\n#23 USER32.dll           0x0000000074984091 DispatchMessageW()\n#24 USER32.dll           0x0000000074983e50 DispatchMessageW()\n#25 qbittorrent.exe      0x00000000010a31fb QEventDispatcherWin32::processEvents()\n#26 qbittorrent.exe      0x0000000000dc55cd QGuiEventDispatcherWin32::processEvents()\n#27 qbittorrent.exe      0x000000000109c5f2 QEventLoop::processEvents()\n#28 qbittorrent.exe      0x000000000109c6cf QEventLoop::exec()\n#29 qbittorrent.exe      0x0000000001048c1b QCoreApplication::exec()\n#30 qbittorrent.exe      0x0000000000b0864b Application::exec(params)\n#31 qbittorrent.exe      0x0000000000b0b1c4 main(argc, argv)\n#32 qbittorrent.exe      0x00000000010d9e7e WinMain()\n#33 qbittorrent.exe      0x0000000001262713 __tmainCRTStartup()\n#34 KERNEL32.DLL         0x0000000076e43744 BaseThreadInitThunk()\n#35 ntdll.dll            0x000000007789a064 RtlSetCurrentTransaction()\n#36 ntdll.dll            0x000000007789a02f RtlSetCurrentTransaction()\n\n\nList of linked Modules:\nqbittorrent               0x0000000000ae0000 Image: C:\\Program Files (x86)\\qBittorrent\\qbittorrent.exe\n                                    .\\qbittorrent.pdb\nntdll                     0x0000000077840000 Image: C:\\Windows\\SYSTEM32\\ntdll.dll\nKERNEL32                  0x0000000076e30000 Image: C:\\Windows\\SYSTEM32\\KERNEL32.DLL\nKERNELBASE                0x0000000076780000 Image: C:\\Windows\\SYSTEM32\\KERNELBASE.dll\nADVAPI32                  0x0000000076f20000 Image: C:\\Windows\\SYSTEM32\\ADVAPI32.dll\nmsvcrt                    0x0000000077380000 Image: C:\\Windows\\SYSTEM32\\msvcrt.dll\nsechost                   0x0000000074e40000 Image: C:\\Windows\\SYSTEM32\\sechost.dll\nRPCRT4                    0x00000000774a0000 Image: C:\\Windows\\SYSTEM32\\RPCRT4.dll\nSspiCli                   0x0000000074950000 Image: C:\\Windows\\SYSTEM32\\SspiCli.dll\ndbghelp                   0x000000006eae0000 Image: C:\\Windows\\SYSTEM32\\dbghelp.dll\nCRYPTBASE                 0x0000000074940000 Image: C:\\Windows\\SYSTEM32\\CRYPTBASE.dll\nbcryptPrimitives          0x00000000748e0000 Image: C:\\Windows\\SYSTEM32\\bcryptPrimitives.dll\nSHELL32                   0x0000000074e90000 Image: C:\\Windows\\SYSTEM32\\SHELL32.dll\nwindows.storage           0x0000000076950000 Image: C:\\Windows\\SYSTEM32\\windows.storage.dll\ncombase                   0x0000000076470000 Image: C:\\Windows\\SYSTEM32\\combase.dll\nshlwapi                   0x0000000076900000 Image: C:\\Windows\\SYSTEM32\\shlwapi.dll\nGDI32                     0x00000000775f0000 Image: C:\\Windows\\SYSTEM32\\GDI32.dll\nUSER32                    0x0000000074970000 Image: C:\\Windows\\SYSTEM32\\USER32.dll\nkernel.appcore            0x0000000077740000 Image: C:\\Windows\\SYSTEM32\\kernel.appcore.dll\nshcore                    0x0000000076630000 Image: C:\\Windows\\SYSTEM32\\shcore.dll\npowrprof                  0x0000000074d30000 Image: C:\\Windows\\SYSTEM32\\powrprof.dll\nprofapi                   0x00000000777a0000 Image: C:\\Windows\\SYSTEM32\\profapi.dll\nCOMDLG32                  0x0000000074d80000 Image: C:\\Windows\\SYSTEM32\\COMDLG32.dll\nOLEAUT32                  0x0000000074c90000 Image: C:\\Windows\\SYSTEM32\\OLEAUT32.dll\nIMM32                     0x00000000766f0000 Image: C:\\Windows\\SYSTEM32\\IMM32.dll\nCOMCTL32                  0x000000006b810000 Image: C:\\Windows\\WinSxS\\x86_microsoft.windows.common-controls_6595b64144ccf1df_5.82.10240.16384_none_49c02355cf03478c\\COMCTL32.dll\nMSCTF                     0x0000000076310000 Image: C:\\Windows\\SYSTEM32\\MSCTF.dll\nWS2_32                    0x0000000076250000 Image: C:\\Windows\\SYSTEM32\\WS2_32.dll\nNSI                       0x00000000766d0000 Image: C:\\Windows\\SYSTEM32\\NSI.dll\nWINMM                     0x0000000073fb0000 Image: C:\\Windows\\SYSTEM32\\WINMM.dll\nole32                     0x0000000077290000 Image: C:\\Windows\\SYSTEM32\\ole32.dll\nCRYPT32                   0x0000000076fa0000 Image: C:\\Windows\\SYSTEM32\\CRYPT32.dll\nMSASN1                    0x0000000074c60000 Image: C:\\Windows\\SYSTEM32\\MSASN1.dll\nMSWSOCK                   0x00000000744c0000 Image: C:\\Windows\\SYSTEM32\\MSWSOCK.dll\nWINMMBASE                 0x0000000002090000 Image: C:\\Windows\\SYSTEM32\\WINMMBASE.dll\ncfgmgr32                  0x0000000076430000 Image: C:\\Windows\\SYSTEM32\\cfgmgr32.dll\nDEVOBJ                    0x0000000074420000 Image: C:\\Windows\\SYSTEM32\\DEVOBJ.dll\nnvinit                    0x0000000074600000 Image: C:\\Windows\\SYSTEM32\\nvinit.dll\nVERSION                   0x00000000745f0000 Image: C:\\Windows\\SYSTEM32\\VERSION.dll\ndetoured                  0x000000000f000000 Image: C:\\Program Files (x86)\\NVIDIA Corporation\\CoProcManager\\detoured.dll\nnvd3d9wrap                0x0000000074340000 Image: C:\\Program Files (x86)\\NVIDIA Corporation\\CoProcManager\\nvd3d9wrap.dll\nSETUPAPI                  0x0000000074ab0000 Image: C:\\Windows\\SYSTEM32\\SETUPAPI.dll\nnvdxgiwrap                0x0000000074320000 Image: C:\\Program Files (x86)\\NVIDIA Corporation\\CoProcManager\\nvdxgiwrap.dll\nuxtheme                   0x0000000074570000 Image: C:\\Windows\\system32\\uxtheme.dll\ndwmapi                    0x00000000742d0000 Image: C:\\Windows\\system32\\dwmapi.dll\nuserenv                   0x0000000073ea0000 Image: C:\\Windows\\system32\\userenv.dll\nbcrypt                    0x0000000074480000 Image: C:\\Windows\\SYSTEM32\\bcrypt.dll\nCRYPTSP                   0x00000000744a0000 Image: C:\\Windows\\SYSTEM32\\CRYPTSP.dll\nrsaenh                    0x0000000074450000 Image: C:\\Windows\\system32\\rsaenh.dll\nwshqos                    0x000000006b540000 Image: C:\\Windows\\system32\\wshqos.dll\nwshtcpip                  0x000000006b530000 Image: C:\\Windows\\SYSTEM32\\wshtcpip.DLL\nwship6                    0x000000006b520000 Image: C:\\Windows\\SYSTEM32\\wship6.dll\nIphlpapi                  0x0000000073e70000 Image: C:\\Windows\\SYSTEM32\\Iphlpapi.dll\nWINNSI                    0x0000000073e60000 Image: C:\\Windows\\SYSTEM32\\WINNSI.DLL\ndhcpcsvc6                 0x0000000071f20000 Image: C:\\Windows\\SYSTEM32\\dhcpcsvc6.DLL\ndhcpcsvc                  0x0000000071f00000 Image: C:\\Windows\\SYSTEM32\\dhcpcsvc.DLL\nDNSAPI                    0x0000000074200000 Image: C:\\Windows\\SYSTEM32\\DNSAPI.dll\nrasadhlp                  0x0000000074190000 Image: C:\\Windows\\System32\\rasadhlp.dll\nfwpuclnt                  0x00000000741a0000 Image: C:\\Windows\\System32\\fwpuclnt.dll\nclbcatq                   0x00000000777b0000 Image: C:\\Windows\\SYSTEM32\\clbcatq.dll\ndataexchange              0x000000006f5c0000 Image: C:\\Windows\\system32\\dataexchange.dll\nd2d1                      0x000000006f130000 Image: C:\\Windows\\system32\\d2d1.dll\ndcomp                     0x000000006f090000 Image: C:\\Windows\\system32\\dcomp.dll\nd3d11                     0x000000006ee70000 Image: C:\\Windows\\system32\\d3d11.dll\ndxgi                      0x000000006edf0000 Image: C:\\Windows\\system32\\dxgi.dll\ntwinapi.appcore           0x000000006ed30000 Image: C:\\Windows\\system32\\twinapi.appcore.dll\n"], "labels": ["Crash"]}
{"project": "spring-projects_spring-security-oauth", "title": "Unknown Exception handling is hard to trace", "description": "instead of getting a stacktrace errors are simply logged as info, and given the message, this is an expecial problem with the generic exception handling of TokenEndopoint.handleException related to #1200 and #1202 ", "code": [], "labels": ["Duplicate"]}
{"project": "NodeBB_NodeBB", "title": "Default Browser Title Does Not Work", "description": "Version: v0.5.5 There is an item called \"Browser Title\" in the General setting page. It says, However, I found that the site title will be \"NodeBB\" unless I set a specified one no matter what the \"Site Title\" is. Thanks! ", "code": [], "labels": ["bug"]}
{"project": "hapijs_joi", "title": "Password confirmation validation", "description": "Currently I'm using the following schema, in conjunction with <URL> <CODE> However this is leading to situations which might be incorrect, but are definitely unwanted: How can I ensure that confirmPassword matches something like oi.string().min(6).max(20).required() and also matches password? ", "code": ["validatorTypes: function() {\n    return {\n        username: Joi.string().min(4).max(20).required().label(this.refs.username.props.label),\n        email: Joi.string().email().required().label(this.refs.email.props.label),\n        password: Joi.string().min(6).max(20).required().label(this.refs.password.props.label),\n        confirmPassword: Joi.any().valid(Joi.ref('password')).required().label(this.refs.confirmPassword.props.label)\n    };\n},\n"], "labels": ["non issue"]}
{"project": "golang_go", "title": "x/sys/unix: missing xattr symlink xattr syscall functions", "description": "The following syscall functions are not implemented, but are necessary if you need to copy symlinks while preserving xattrs: Are they going to be implemented? How can we implement them in a separate package? ", "code": [], "labels": ["FrozenDueToAge"]}
{"project": "kubesphere_kubesphere", "title": "\u4e3b\u673a\u7684CPU\u548c\u5185\u5b58\u5360\u7528\u663e\u793a\u4e0ekubectl top nodes\u663e\u793a\u4e0d\u4e00\u81f4", "description": "  ", "code": [], "labels": ["kind/bug", "area/monitoring"]}
{"project": "elastic_elasticsearch", "title": "simple_query_string gives java.lang.IllegalArgumentException: Illegal shift value, must be 0..63; got shift=2147483647", "description": "Hi Team, I have got the following error when using simple_query_string with multiple fields containing numeric field.\nVersion: 2.2.0\nOS: Windows Sample data:\ncurl -XPUT http://localhost:9200/blog/post/1 -d '{\"foo\":123, \"bar\":\"xyzzy\"}'\ncurl -XPUT http://localhost:9200/blog/post/2 -d '{\"foo\":456, \"bar\":\"xyzzy\"}' Use simple_query_string with multiple fields\ncurl -XGET http://localhost:9200/blog/post/_search?pretty=1 -d '{\"query\":{\"simple_query_string\":{\"query\":\"123\",\"fields\":[\"foo\",\"bar\"]}}}' Error\n{ \"error\": { \"root_cause\": [ { \"type\": \"illegal_argument_exception\", \"reason\": \"Illegal shift value, must be 0..63; got shift=2147483647\" } ], \"type\": \"search_phase_execution_exception\", \"reason\": \"all shards failed\", \"phase\": \"query\", \"grouped\": true, \"failed_shards\": [ { \"shard\": 0, \"index\": \"blog\", \"node\": \"6jVhZCw3Tau3cP5VtEg8Tw\", \"reason\": { \"type\": \"illegal_argument_exception\", \"reason\": \"Illegal shift value, must be 0..63; got shift=2147483647\" } } ] }, \"status\": 400 } multi_match query works with the same fields\ncurl -XGET http://localhost:9200/blog/post/_search?pretty=1 -d '{\"query\":{\"bool\":{\"must\":[{\"multi_match\":{\"query\":\"123\",\"type\":\"cross_fields\",\"fields\":[\"foo\",\"bar\"],\"operator\":\"and\"}}]}}}' Issue similar to #15860 ", "code": [], "labels": [":Search/Search", ">bug"]}
{"project": "stan-dev_stan", "title": "gradient of src/stan/agrad/rev/ceil returns 0 for NaN input", "description": "It should return NaN ", "code": [], "labels": ["bug"]}
{"project": "grommet_grommet", "title": "Support target on Layer component", "description": "Currently, Layer's don't support the target property (How its used in the Drop Component) and therefore can't be positioned relative to an element. With target on a layer, it would be possible to add something like the Google Calendar popup for event creation. The background has an overlay similar to what the Layer already offers, what's missing though is the possibility to target the element. Therefore its only possible to align the Layer in the middle or on the side of the page.  ", "code": [], "labels": ["discussion", "enhancement"]}
{"project": "grails_grails-core", "title": "GRAILS-6471: Running list-plugins and specifying the repository causes and error", "description": "Original Reporter: christianhepworth\nEnvironment: Not Specified\nVersion: 1.3.2\nMigrated From: <URL> When running \"grails list-plugins\" and specifying a repository I get the following error: {code}$ grails list-plugins -repository=customPluginRepository\nWelcome to Grails 1.3.2 - <URL>\nLicensed under Apache Standard License 2.0\nGrails home is set to: c:/grails-1.3.2 Base Directory: C:\\GrailsTestArea\\EventsTest2\nResolving dependencies...\nDependencies resolved in 2000ms.\nRunning script c:\\grails-1.3.2\\scripts\\ListPlugins_.groovy\nEnvironment set to development\nConfigured HTTP proxy: smithers:8080\nError executing script ListPlugins: groovy.lang.MissingMethodException: No signature of method: _GrailsPlugins_groovy.configureRepositoryF\norName() is applicable for argument types: (java.lang.String) values: [cpp-plugin-repository]\ngroovy.lang.MissingMethodException: No signature of method: _GrailsPlugins_groovy.configureRepositoryForName() is applicable for argument\ntypes: (java.lang.String) values: [cpp-plugin-repository]\nat gant.Gant$_dispatch_closure5.doCall(Gant.groovy:391)\nat gant.Gant$_dispatch_closure7.doCall(Gant.groovy:415)\nat gant.Gant$_dispatch_closure7.doCall(Gant.groovy)\nat gant.Gant.withBuildListeners(Gant.groovy:427)\nat gant.Gant.this$2$withBuildListeners(Gant.groovy)\nat gant.Gant$this$2$withBuildListeners.callCurrent(Unknown Source)\nat gant.Gant.dispatch(Gant.groovy:415)\nat gant.Gant.this$2$dispatch(Gant.groovy)\nat gant.Gant.invokeMethod(Gant.groovy)\nat gant.Gant.executeTargets(Gant.groovy:590)\nat gant.Gant.executeTargets(Gant.groovy:589)\nCaused by: groovy.lang.MissingMethodException: No signature of method: _GrailsPlugins_groovy.configureRepositoryForName() is applicable fo\nr argument types: (java.lang.String) values: [cpp-plugin-repository]\nat _GrailsPlugins_groovy$_run_closure5.doCall(_GrailsPlugins_groovy:136)\nat gant.Gant$_dispatch_closure5.doCall(Gant.groovy:381)\n... 10 more\n--- Nested Exception ---\ngroovy.lang.MissingMethodException: No signature of method: _GrailsPlugins_groovy.configureRepositoryForName() is applicable for argument\ntypes: (java.lang.String) values: [customPluginRepository]\nat _GrailsPlugins_groovy$_run_closure5.doCall(_GrailsPlugins_groovy:136)\nat gant.Gant$_dispatch_closure5.doCall(Gant.groovy:381)\nat gant.Gant$_dispatch_closure7.doCall(Gant.groovy:415)\nat gant.Gant$_dispatch_closure7.doCall(Gant.groovy)\nat gant.Gant.withBuildListeners(Gant.groovy:427)\nat gant.Gant.this$2$withBuildListeners(Gant.groovy)\nat gant.Gant$this$2$withBuildListeners.callCurrent(Unknown Source)\nat gant.Gant.dispatch(Gant.groovy:415)\nat gant.Gant.this$2$dispatch(Gant.groovy)\nat gant.Gant.invokeMethod(Gant.groovy)\nat gant.Gant.executeTargets(Gant.groovy:590)\nat gant.Gant.executeTargets(Gant.groovy:589)\nError executing script ListPlugins: groovy.lang.MissingMethodException: No signature of method: _GrailsPlugins_groovy.configureRepositoryF\norName() is applicable for argument types: (java.lang.String) values: [customPluginRepository]{code} ", "code": [], "labels": ["Major", "Bug", "Fixed"]}
{"project": "dart-lang_sdk", "title": "Documentation for pkg collection looks broken", "description": "This issue was originally filed by @stevenroose The fact that there is a (Google-authored) collection package in pub is very confusing, considering the existence of the dart:collection built-in package. Is it possible to merge these? Also, the package:collection package has no online documentation. It's pub page is here: <URL> There is no link to the documentation as there is with most pub packages.\n(I think the best link to point users to is this one: <URL>\nI got this link by manually removing the dart- prefix from the URL.) ", "code": [], "labels": ["closed-obsolete", "Type-Defect"]}
{"project": "timgrossmann_InstaPy", "title": "set_automated_followed_pool error 'datetime.datetime' object has no attribute 'timestamp'", "description": "Hello,\nI am running InstaPy without any issues so far, but at the top of log the error in the subject comes up.\nWhat kind of error is it? ", "code": [], "labels": ["wontfix"]}
{"project": "hashicorp_terraform", "title": "'diffs didn't match during apply' while embedding Packer into a template_file provisioner", "description": "I am working on a sample Lift project which utilizes terraform and packer to deploy itself without any existing AWS infrastructure.  Since packer takes as input the VPC ID, subnet ID, and security group ID; and produces as output an AMI to be used in an Autoscaling Launch Configuration, it would be ideal to run packer embedded during the terraform apply.  Without a solution proposed by issues #1586 and #2789, I have resorted to a workaround proposed on the mailing list topic Packer+Terraform best practices?. The approach works by creating a pair of template_file resources, calling a script to invoke packer and write the resulting AMI ID into a file, then reading the file as a var.  The terraform config looks like this: <CODE> When running the project against an empty infrastructure, everything works except the creation of the autoscaling config: <CODE> What is interesting is you can take the AMI ID produced, hard-code it into the terraform config and remove the provisioner... <CODE> Then the apply works.  Even more interesting is you can now undo the hard-code/removal of the provisioner and it continues to work!  It's only the bootstrapping case that doesn't work.  Note that you must hard code it once it get it out of this state.  Repeatedly applying the config does not work. You can see the output from terraform and packer runs here.  The copy/paste is verbatim, sans obfuscated passwords. first-run.txt is the output from running terraform apply with a blank state in AWS. (doesn't work)\nsecond-run.txt is the output from running apply a second time with no changes. (still doesn't work)\nafter-hard-code.txt is the output after hard-coding the AMI ID and removing the packer provisioner. (works)\nfinal.txt is the output after undoing the hard-code and reinstating the packer provisioner. (still works) To help you reproduce this issue, I have created a separate branch called terraform-bug.  There I have ripped out the application bundling to make reproducing this easier.  In this branch, packer will only install the JVM but not install the application.  With terraform and packer on the path, you can simply invoke deploy.sh. deploy.sh will complain until you have the following environment variables set: <CODE> This issue can be reproduced with the latest Terraform (0.6.3) and Packer (0.8.6) versions. ", "code": ["resource \"template_file\" \"packer\" {\n  filename = \"/dev/null\"\n  depends_on = \"template_file.packer_runner\"\n  vars {\n    ami = \"${file(var.ami_txt)}\"\n  }\n}\nresource \"template_file\" \"packer_runner\" {\n  filename = \"/dev/null\"\n\n  provisioner \"local-exec\" {\n    command = \"./bake.sh (...a bunch of variables...)\"\n  }\n}\n\nvariable \"ami_txt\" {\n  default = \"./ami.txt\"\n}\n", "* aws_launch_configuration.lift_as_conf: diffs didn't match during apply. This is a bug with Terraform and should be reported.\n", "resource \"template_file\" \"packer\" {\n  filename = \"/dev/null\"\n  depends_on = \"template_file.packer_runner\"\n  vars {\n    ami = \"ami-0b8a714f\"\n  }\n}\nresource \"template_file\" \"packer_runner\" {\n  filename = \"/dev/null\"\n\n#  provisioner \"local-exec\" {\n#    command = \"./bake.sh (...a bunch of variables...)\"\n#  }\n}\n\nvariable \"ami_txt\" {\n  default = \"./ami.txt\"\n}\n", ": ${AWS_ACCESS_KEY_ID:?\"Must supply AWS_ACCESS_KEY_ID environment variable\"}\n: ${AWS_SECRET_ACCESS_KEY:?\"Must supply AWS_SECRET_ACCESS_KEY environment variable\"}\n: ${TF_STATE_BUCKET:?\"Must supply TF_STATE_BUCKET environment variable (The S3 bucket to store terraform state)\"}\n: ${TF_STATE_KEY:?\"Must supply TF_STATE_KEY environment variable (The S3 key to store terraform state)\"}\n: ${DB_USERNAME:?\"Must supply DB_USERNAME environment variable\"}\n: ${DB_PASSWORD:?\"Must supply DB_PASSWORD environment variable\"}\n"], "labels": ["bug", "core"]}
{"project": "eslint_eslint", "title": "`--no-ignore` not work with `--stdin-filename`", "description": "Tell us about your environment What parser (default, Babel-ESLint, etc.) are you using? default What did you do? Please include the actual source code causing the issue, as well as the command that you used to run ESLint. I am using Vim plugin ale, this plugin always call eslint with  --stdin-filename, even I append --no-ignore to ale option, eslint still ignore the file, so all the files in my $HOME always be ignored when it is opened in Vim. What did you expect to happen? File shouln't be ignored with below command: Are you willing to submit a pull request to fix this bug? No ", "code": [], "labels": ["accepted", "bug", "core"]}
{"project": "Yoast_wordpress-seo", "title": "Error after importing data from SEO Ultimate", "description": "After importing data from the SEO Ultimate plugin into the Yoast SEO plugin, I got this notice:  I expected the import to be completed correctly and to see this message only:   ", "code": [], "labels": ["bug"]}
{"project": "dotnet_wcf", "title": "Create xunit trait for certificate-requiring tests", "description": "Create an xunit trait to mark tests requiring certificates so they can be excluded or run separately.\nI'm finding it difficult to run all tests x-plat without being able to isolate http from https. This will also allow us to exclude any tests requiring certificate installation on developers' machines if they so choose. ", "code": [], "labels": ["Infrastructure", "test bug"]}
{"project": "microsoft_vscode", "title": "Not searching some files that aren't in an open folder", "description": "Issue Type: Bug I've been having this problem for a few weeks - it used to work correctly. I have tested without extensions and it still occurs. I open a set of log files (not a folder) and want to search all of them for errors. There are files with *.err file extensions which are repeatedly not getting searched in unless I click to focus them. Precondition: Steps:  VS Code version: Code - Insiders 1.29.0-insider (9b2a7f4, 2018-11-02T13:42:21.142Z)\nOS version: Windows_NT x64 10.0.15063 ", "code": [], "labels": ["search", "bug"]}
{"project": "jaredpalmer_formik", "title": "The motivation behind using void for component property", "description": "Hi, I just recently came across this chunk in formik source code, which is causing type inconsistencies in my app when trying to use component for FieldArray: <CODE> Could you please explain why void type is used for component properties here? ", "code": ["export interface SharedRenderProps<T> {\n    component?: string | React.ComponentType<T | void>;\n    render?: ((props: T) => React.ReactNode);\n    children?: ((props: T) => React.ReactNode);\n}\n"], "labels": ["stale"]}
{"project": "hashicorp_terraform", "title": "terraform crashed during terraform refresh v0.11.2", "description": "Hi Team, I'm getting below response when executing terraform refresh command <CODE> Terraform v0.11.2 Your version of Terraform is out of date! The latest version\nis 0.11.10. You can update by downloading from www.terraform.io/downloads.html Attached Please list the full steps required to reproduce the issue, for example: ", "code": ["panic: runtime error: invalid memory address or nil pointer dereference\n[signal 0xc0000005 code=0x0 addr=0x0 pc=0xb64649]\n\ngoroutine 11511 [running]:\ngithub.com/hashicorp/terraform/terraform.(*State).Lock(0x0)\n        /opt/gopath/src/github.com/hashicorp/terraform/terraform/state.go:95 +0x29\ngithub.com/hashicorp/terraform/terraform.(*State).SameLineage(0x0, 0xc04264d3e0, 0xc042244700)\n        /opt/gopath/src/github.com/hashicorp/terraform/terraform/state.go:628 +0x3b\ngithub.com/hashicorp/terraform/state/remote.(*State).WriteState(0xc0422447b0, 0x0, 0x0, 0x0)\n        /opt/gopath/src/github.com/hashicorp/terraform/state/remote/state.go:37 +0x111\ngithub.com/hashicorp/terraform/backend/local.(*Local).opRefresh(0xc0421a8210, 0x3f52700, 0xc0420520b8, 0xc0420fe0c0, 0xc042244780)\n        /opt/gopath/src/github.com/hashicorp/terraform/backend/local/backend_refresh.go:115 +0x46c\ngithub.com/hashicorp/terraform/backend/local.(*Local).(github.com/hashicorp/terraform/backend/local.opRefresh)-fm(0x3f52700, 0xc0420520b8, 0xc0420fe0c0, 0xc042244780)\n        /opt/gopath/src/github.com/hashicorp/terraform/backend/local/backend.go:230 +0x59\ngithub.com/hashicorp/terraform/backend/local.(*Local).Operation.func1(0xc0421a8210, 0xc0423d44b0, 0xc0423d4490, 0x3f52700, 0xc0420520b8, 0xc0420fe0c0, 0xc042244780)\n        /opt/gopath/src/github.com/hashicorp/terraform/backend/local/backend.go:254 +0xa1\ncreated by github.com/hashicorp/terraform/backend/local.(*Local).Operation\n        /opt/gopath/src/github.com/hashicorp/terraform/backend/local/backend.go:251 +0x191\n\n\n\n!!!!!!!!!!!!!!!!!!!!!!!!!!! TERRAFORM CRASH !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\nTerraform crashed! This is always indicative of a bug within Terraform.\nA crash log has been placed at \"crash.log\" relative to your current\nworking directory. It would be immensely helpful if you could please\nreport the crash with Terraform[1] so that we can fix this.\n\nWhen reporting bugs, please include your terraform version. That\ninformation is available on the first line of crash.log. You can also\nget it by running 'terraform --version' on the command line.\n\n[1]: https://github.com/hashicorp/terraform/issues\n\n!!!!!!!!!!!!!!!!!!!!!!!!!!! TERRAFORM CRASH !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"], "labels": ["crash", "bug"]}
{"project": "microsoft_azure-pipelines-tasks", "title": "Download GitHub Release repository drop down not showing all available repositories", "description": "Type: Bug\nEnter Task Name: Download GitHub Release (Preview)\n<URL> The Download GitHub Release (Preview) task doesn't show the full list of repositories from GitHub in the Repository drop down. There seems to be a limit to the amount of repos that are returned in the list. This also happens when attempting to use the GitHub Release artifact for a pipeline. Using the task step I can manually type the \"org-name/repo-name\" but this doesn't work for the GitHub Release artifact source type in the Source (repository) drop down. ", "code": [], "labels": ["Area: Release", "bug"]}
{"project": "arduino_Arduino", "title": "Add MS5837-30BA pressure sensor library", "description": "Hello, This library supports the new MS5837-30BA pressure sensor. <URL> Please let me know if there are any issues. -Rusty ", "code": [], "labels": ["Component: Board/Lib Manager"]}
{"project": "apache_incubator-shardingsphere", "title": "\u91c7\u7528\u5206\u5e93\u5206\u8868\u540e,\u591a\u8868\u5173\u8054\u67e5\u8be2\u600e\u4e48\u5b9e\u73b0\u5206\u9875\u67e5\u8be2", "description": "Please answer these questions before submitting your issue. Thanks! 1.5\u7248\u672c\u7684\u4e2d\u95f4\u4ef6\u3002\u73b0\u5728\u6709t_package\u8868\uff0ct_transaction\u8868\uff0ct_package_skuinfo\u8868\uff0ct_package\u8868\u4e0et_transaction\u7684\u5173\u7cfb\u8868\u662ft_package_skuinfo\u8868\uff0c\u73b0\u5728\u6839\u636et_package\u53cat_transaction\u8868\u7684\u67e5\u8be2\u6761\u4ef6\uff0c\u600e\u4e48\u5206\u9875\u67e5\u8be2t_package\u8868\u7684\u8bb0\u5f55\u6570\u636e\u3002\u53c2\u8003sql:\nselect p.package_id from t_package inner join t_package_skuinfo s on p.package_id =s.package_id inner join\nt_transaction t on t.transaction_id=s.transaction_id where .......\u7531\u4e8epackage\u8868\u4e0epackage_skuinfo\u662f\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\u3002 \u8fd9\u6837\u67e5\u8be2\u4f1a\u51fa\u73b0\u6570\u636e\u91cd\u590d\u7684\u95ee\u9898 ", "code": [], "labels": ["question"]}
{"project": "beetbox_beets", "title": "discogs: Headings counting as tracks", "description": "I'm trying to import this album:\n<URL> There is 11 tracks in this album, and each side of the LP has a heading, \"The Mysterious Corona\" and \"M.B. Cyclus\". When importing the 11 tracks, the headings are seen as tracks, resulting in 2 missing tracks. <CODE> <CODE> ", "code": ["$ uname -a\nLinux x 4.4.0-53-generic #74-Ubuntu SMP Fri Dec 2 15:59:10 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n", "$ beet version\nbeets version 1.4.1\nPython version 2.7.12\nplugins: badfiles, chroma, copyartifacts, discogs, embedart, fetchart, info, missing, scrub, web\n"], "labels": ["bug"]}
{"project": "wordpress-mobile_WordPress-iOS", "title": "-[UIKeyboardTaskQueue waitUntilAllTasksAreFinished] may only be called from the main thread.", "description": "<CODE> ", "code": ["#11. Crashed: com.twitter.crashlytics.ios.exception\n0  WordPress                      0x627575 CLSProcessRecordAllThreads + 6436213\n1  WordPress                      0x627575 CLSProcessRecordAllThreads + 6436213\n2  WordPress                      0x62746d CLSProcessRecordAllThreads + 6435949\n3  WordPress                      0x61b93f CLSHandler + 6388031\n4  WordPress                      0x625ed7 __CLSExceptionRecord_block_invoke + 6430423\n5  libdispatch.dylib              0x1dab1083 _dispatch_client_callout + 22\n6  libdispatch.dylib              0x1dabd3a3 _dispatch_barrier_sync_f_invoke + 50\n7  WordPress                      0x6258d9 CLSExceptionRecord + 6428889\n8  WordPress                      0x625701 CLSExceptionRecordNSException + 6428417\n9  WordPress                      0x625217 CLSTerminateHandler() + 6427159\n10 libc++abi.dylib                0x1d65f93f std::__terminate(void (*)()) + 78\n11 libc++abi.dylib                0x1d65f14f __cxxabiv1::exception_cleanup_func(_Unwind_Reason_Code, _Unwind_Exception*) + 110\n12 libobjc.A.dylib                0x1d66b149 _objc_exception_destructor(void*) + 246\n13 CoreFoundation                 0x1e40ace1 +[NSException raise:format:] + 94\n14 Foundation                     0x1ecde0f1 -[NSAssertionHandler handleFailureInMethod:object:file:lineNumber:description:] + 92\n15 UIKit                          0x2348f0af -[UIKeyboardTaskQueue waitUntilAllTasksAreFinished] + 182\n16 UIKit                          0x2348fb93 -[UIKeyboardImpl setDelegate:force:] + 1436\n17 UIKit                          0x23489357 -[UIPeripheralHost(UIKitInternal) _reloadInputViewsForResponder:] + 1142\n18 UIKit                          0x23b240d1 -[UIPeripheralHost(UIKitInternal) _preserveInputViewsWithId:animated:reset:] + 528\n19 UIKit                          0x235eb7a9 -[UIPeripheralHost(UIKitInternal) _preserveInputViewsWithId:animated:] + 30\n20 UIKit                          0x237c1abf -[UIViewController _presentViewController:modalSourceViewController:presentationController:animationController:interactionController:completion:] + 1088\n21 UIKit                          0x237c3311 -[UIViewController _presentViewController:withAnimationController:completion:] + 4144\n22 UIKit                          0x237c57d5 __62-[UIViewController presentViewController:animated:completion:]_block_invoke + 332\n23 UIKit                          0x237c5a5d -[UIViewController _performCoordinatedPresentOrDismiss:animated:] + 444\n24 UIKit                          0x23555ba5 -[UIViewController presentViewController:animated:completion:] + 146\n25 WordPress                      0x2b2978 UIAlertController.presentFromRootViewController() -> () (UIAlertController+Helpers.swift)\n26 WordPress                      0x2b29c4 @objc UIAlertController.presentFromRootViewController() -> () (UIAlertController+Helpers.swift)\n27 WordPress                      0xb96e3 +[WPError showAlertWithTitle:message:withSupportButton:okPressedBlock:] (WPError.m:173)\n28 WordPress                      0xb939f +[WPError showAlertWithTitle:message:] (WPError.m:134)\n29 WordPress                      0xb934f +[WPError showXMLRPCErrorAlert:] (WPError.m:129)\n30 WordPress                      0x4fd3b __51-[WPAddPostCategoryViewController saveAddCategory:]_block_invoke.102 (WPAddPostCategoryViewController.m:127)\n31 WordPress                      0x125fd7 __81-[TaxonomyServiceRemoteXMLRPC createTaxonomyWithType:parameters:success:failure:]_block_invoke.129 (TaxonomyServiceRemoteXMLRPC.m:165)\n32 WordPress                      0x3fbeec partial apply for thunk (WordPressOrgXMLRPCApi.swift)\n33 WordPress                      0x3f8270 WordPressOrgXMLRPCApi.(callMethod(String, parameters : [AnyObject]?, success : (AnyObject, NSHTTPURLResponse?) -> (), failure : (error : NSError, httpResponse : NSHTTPURLResponse?) -> ()) -> NSProgress?).(closure #1) (WordPressOrgXMLRPCApi.swift:106)\n34 WordPress                      0x3fe934 partial apply for WordPressOrgXMLRPCApi.(callMethod(String, parameters : [AnyObject]?, success : (AnyObject, NSHTTPURLResponse?) -> (), failure : (error : NSError, httpResponse : NSHTTPURLResponse?) -> ()) -> NSProgress?).(closure #1) (WordPressOrgXMLRPCApi.swift)\n35 CFNetwork                      0x1e9368cd __75-[__NSURLSessionLocal taskForClass:request:uploadFile:bodyData:completion:]_block_invoke + 16\n36 CFNetwork                      0x1e949d13 __49-[__NSCFLocalSessionTask _task_onqueue_didFinish]_block_invoke + 268\n37 Foundation                     0x1ed0edb9 __NSBLOCKOPERATION_IS_CALLING_OUT_TO_A_BLOCK__ + 8\n38 Foundation                     0x1ec6185f -[NSBlockOperation main] + 146\n39 Foundation                     0x1ec529bb -[__NSOperationInternal _start:] + 774\n40 Foundation                     0x1ed1103b __NSOQSchedule_f + 190\n41 libdispatch.dylib              0x1dabdec5 _dispatch_queue_serial_drain + 840\n42 libdispatch.dylib              0x1dab4379 _dispatch_queue_invoke + 566\n43 libdispatch.dylib              0x1dabfa91 _dispatch_root_queue_drain + 378\n44 libdispatch.dylib              0x1dabf8b7 _dispatch_worker_thread3 + 106\n45 libsystem_pthread.dylib        0x1dc66937 _pthread_wqthread + 1168\n46 libsystem_pthread.dylib        0x1dc6648c start_wqthread + 8\n"], "labels": ["[Type] Crash"]}
{"project": "mautic_mautic", "title": "HTML content is appended to JSON response on error", "description": "An ajax call running on the click of the sort for Manage leads table seems to not display the data. I did notice theres json mixed with html. curl '<URL>' -X POST -H 'Pragma: no-cache' -H 'Origin: <URL>' -H 'Accept-Encoding: gzip, deflate' -H 'Accept-Language: en-US,en;q=0.8,es;q=0.6' -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36' -H 'Accept: application/json, text/javascript, */*; q=0.01' -H 'Cache-Control: no-cache' -H 'X-Requested-With: XMLHttpRequest' -H 'Cookie: mautic_lead_avatar_panel=expanded; mautic_session_name=' -H 'Connection: keep-alive' -H 'Referer: <URL>' -H 'Content-Length: 0' -H 'DNT: 1' --compressed Produces `{\"activeLink\":\"#mautic_lead_index\",\"mauticContent\":\"lead\",\"route\":\"/s/leads\",\"flashes\":\"\",\"notifications\":{\"content\":\"\\n\",\"lastId\":\"179\",\"hasNewNotifications\":false,\"updateAvailable\":true},\"browserNotifications\":[],\"newContent\":\"\\n\\u003Cdiv class=\\u0022table-responsive\\u0022\\u003E\\n    \\u003Ctable class=\\u0022table table-hover table-striped table-bordered\\u0022 id=\\u0022leadTable\\u0022\\u003E\\n        \\u003Cthead\\u003E\\n            \\u003Ctr\\u003E\\n                \\u003Cth class=\\u0022col-actions pl-20\\u0022\\u003E\\n  ...... cut out due to size .......   \"} ", "code": [], "labels": ["Bug"]}
{"project": "HabitRPG_habitica", "title": "blank messages can be sent through the Private Message (PM) system", "description": "The private message system should prevent a message being sent if nothing has been typed. It seems that players will accidentally click the message icon (possibly instead of the like button) and then accidentally click send instead of cancel. Clicking send on an empty message should close the message window without sending anything. Note that this change should not affect gifting of gems - it should still be possible to send gems with no message. ", "code": [], "labels": ["priority: minor"]}
{"project": "godotengine_godot", "title": "Resource view doesn't respond", "description": "Operating system or device:\nArch Linux  64bit The editor is compiled from master (latest commit was 9487a9b) Issue description (what happened, and what was expected): The resource view (or called resource window) doesn't respond when click or double click any resource file. Steps to reproduce: ", "code": [], "labels": ["topic:editor", "bug"]}
{"project": "craftcms_cms", "title": "[Bug] Plugin store unusable when omitScriptNameInUrls setting is set to false.", "description": "When clicking on the plugin store, it appears to ignore the omitScriptNameInUrls setting and try to redirect to /admin/plugin-store. ", "code": [], "labels": ["bug"]}
{"project": "angular_components", "title": "Tooltip position on smaller screen (< 599px)", "description": "Tooltip position on smaller screens. open examples in official site\n<URL>\nScreen size = smaller than 599px\nScroll to place element on the top\nCan Not reproduce on StackBlitz  : <URL>\nPerhaps it is dependent from content or document height Tooltip should save its behavior on all screens no desktop Latest versions ( official example ).\nChrome\nWindows \n ", "code": [], "labels": ["P4"]}
{"project": "PointCloudLibrary_pcl", "title": "Normal Estimation crashes in Release Mode", "description": "I'm trying to run some normal estimation code: <CODE> This works fine in debug mode. But in release mode, I get the message: <CODE> I found this issue, but I'd prefer to fix it using the All-in-one installer. ", "code": ["#include <iostream>\n#include <fstream>\n#include <pcl/io/pcd_io.h>\n#include <pcl/point_types.h>\n#include <pcl/point_representation.h>\n#include <pcl/features/normal_3d.h>\n\nint main() {\n\tpcl::PointCloud<pcl::PointXYZI>::Ptr cloud(new pcl::PointCloud<pcl::PointXYZI>);\n\tif (pcl::io::loadPCDFile(\"cloud.pcd\", *cloud) == -1) {\n\t\tstd::cerr << \"Failed to load \"<< std::endl;\n\t\treturn -1;\n\t}\n\n\tpcl::NormalEstimation<pcl::PointXYZI, pcl::Normal> ne;\n\tne.setInputCloud(cloud);\n\n\tpcl::search::KdTree<pcl::PointXYZI>::Ptr tree(new pcl::search::KdTree<pcl::PointXYZI>());\n\tne.setSearchMethod(tree);\n\n\t// Output datasets\n\tcloud_normals = pcl::PointCloud<pcl::Normal>::Ptr(new pcl::PointCloud<pcl::Normal>);\n\n\t// Use all neighbors in a sphere of radius 3cm\n\tne.setRadiusSearch(0.03);\n\n\t// Compute the features\n\tne.compute(*cloud_normals);\n}\n", "[initCompute] Failed to allocate 2242154625 indices.\n"], "labels": ["platform: windows"]}
{"project": "hashicorp_terraform", "title": "Documentation for AWS_SQS_QUEUE_POLICY typo", "description": "Latest/Any Please list the resources as a list, for example: N/A N/A N/A Documentation should read:\nqueue_url - (Required) The URL of the SQS Queue to which to attach the policy Documentation has typo (SNS instead of SQS):\nqueue_url - (Required) The URL of the SNS Queue to which to attach the policy N/A N/A N/A ", "code": [], "labels": ["provider/aws", "documentation"]}
{"project": "jshint_jshint", "title": "\"2015\" value for `esversion` only accepted via inline directive", "description": "ECMAScript standards seem to\u00a0prefer year-based names for\u00a0their new yearly versions. Therefore it\u00a0might make\u00a0sense for\u00a0JSHint to\u00a0accept \"esversion\": 2015 as\u00a0an\u00a0equivalent of \"esversion\": 6, and\u00a0to\u00a0accept \"esversion\": 2016 as\u00a0an\u00a0equivalent of \"esversion\": 7, and\u00a0so\u00a0on. ", "code": [], "labels": ["Has PR", "P3"]}
{"project": "microsoft_react-native-code-push", "title": "i just want to ask a question", "description": "my react-native version is 0.55. does codepush support now? ", "code": [], "labels": ["documentation", "question"]}
{"project": "HaxeFoundation_haxe", "title": "ArrayAccess should be exposed in -xml", "description": "ArrayAccess is not exposed in the xml for dox. @nadako  says \"genxml should expose the cl_array_access field somehow\" ", "code": [], "labels": ["documentation"]}
{"project": "withspectrum_spectrum", "title": "Upload media to thread - drag n drop + upload from file picker", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement"]}
{"project": "angular_components", "title": "Expansion panels opened method is get called for all panels in accordian", "description": "This is a bug in accordian, where multiple expansion panels are getting emitted for a click on one expansion panel. It is supposed to emit opened method for only the selected panel. Not all the opened emits It is getting emitted for multiple expansion panels. Code Snippet\n<mat-accordion *ngFor=\"let module of modules; let mi = index;\"> <mat-expansion-panel [expanded]=\"miStep === mi\"  (opened)=\"openModulePanel(module.type, lang.code, mi)\" hideToggle> <mat-expansion-panel-header> <mat-panel-title> {{ module?.metaData?.displayName }} </mat-panel-title> </mat-panel-title> </mat-expansion-panel-header> </mat-expansion-panel> </mat-accordion> Difficult to handle child panels Angular: 5.2.8\nmaterial: 5.2.5\nTypescript: 2.4.2 No ", "code": [], "labels": ["cannot reproduce"]}
{"project": "thepracticaldev_dev.to", "title": "Not Authorized Error when Testing Admin User Banning", "description": "Related #4884 <CODE> ", "code": ["1) Admin bans user checks that the user is warned, has a note, and privileges are removed\n     Failure/Error: raise Pundit::NotAuthorizedError, \"You must be logged in\" unless user\n     \n     Pundit::NotAuthorizedError:\n       You must be logged in\n     \n     # ./app/policies/application_policy.rb:5:in `initialize'\n     # ./app/controllers/internal/application_controller.rb:12:in `authorize_admin'\n     # ./spec/system/internal/admin_bans_or_warns_user_spec.rb:9:in `block (2 levels) in <top (required)>'\n     # ./spec/rails_helper.rb:90:in `block (3 levels) in <top (required)>'\n     # ./spec/rails_helper.rb:90:in `block (2 levels) in <top (required)>'\nFinished in 7 minutes 17 seconds (files took 8.06 seconds to load)\n3180 examples, 1 failure\nFailed examples:\nrspec ./spec/system/internal/admin_bans_or_warns_user_spec.rb:38 # Admin bans user checks that the user is warned, has a note, and privileges are removed\n"], "labels": ["good first issue", "help wanted"]}
{"project": "gwtproject_gwt", "title": "IE8 Uncaught exeption in DOMImplTriden.dispatchEvent", "description": "Originally reported on Google Code with ID 3980 <CODE> Reported by fasaxc on 2009-08-24 15:55:18 ", "code": ["Found in GWT Release (e.g. 1.5.3, 1.6 RC):\n\n1.7.0\n\nEncountered on OS / Browser (e.g. WinXP, IE6-7, FF3):\n\nInternet Explorer 8.  Firefox and earlier IE versions seem immune.\n\nDetailed description (please be as specific as possible):\n\nI left my GWT app running for a couple of hours in Internet Explorer 8\n(compiled-to-javascript mode).  When I returned, it had completely stopped\nresponding to input from the mouse.  Clicking on any buttons in the UI\nfocused them (dotted border visible) but did not do anything.  Even\nclicking on elements that were not part of GWT widgets failed.\n\nI saw many instances of the following errors via the error icon in the\nbottom left:\n\nMessage: Access is denied.\nLine: 2823\nChar: 5\nCode: 0\nURI:\nhttp://jetfire.datcon.co.uk/gadgets/conference/conferencewidget/39D1AD11A290BEC4BA40FAA9D9E6B0E8.cache.html\n\nThe relevant snippet of pretty JavaScript are as follows:\n\nfunction\ncom_google_gwt_user_client_impl_DOMImplTrident_$initEventSystem__Lcom_google_gwt_user_client_impl_DOMImplTrident_2(){\n  com_google_gwt_user_client_impl_DOMImplTrident_dispatchEvent = function(){\n    var oldEventTarget =\n(com_google_gwt_dom_client_DOMImplTrident_$clinit__() ,\ncom_google_gwt_dom_client_DOMImplTrident_currentEventTarget);\n    com_google_gwt_dom_client_DOMImplTrident_currentEventTarget = this;\n    if ($wnd.event.returnValue == null) {\n      $wnd.event.returnValue = true;\n      if\n(!com_google_gwt_user_client_DOM_previewEvent__Lcom_google_gwt_user_client_Event_2($wnd.event))\n{\n        com_google_gwt_dom_client_DOMImplTrident_currentEventTarget =\noldEventTarget;\n        return;\n      }\n    }\n...\n\nLine 2823 is the line \"if ($wnd.event.returnValue == null) {\"\n\nShortest code snippet which demonstrates issue (please indicate where\nactual result differs from expected result):\n\nNot as yet.\n\nWorkaround if you have one:\n\nNone.\n\nLinks to relevant GWT Developer Forum posts:\n\n"], "labels": ["Category-UI", "Type-Defect"]}
{"project": "lervag_vimtex", "title": "Latest Commit #9a1f breaks vimtex", "description": "Issue I updated vimtex and ran \\ll in a latex file and got error messages: <CODE> mini.vim mini.tex start neovim with nvim -u mini.vim mini.tex Commands/Input press \\ll Observed Behaviour It compiles successfully, the preview pdf looks good but the error messages is annoying since it bumps up everytime I save my file(continuous mode). Expected Behaviour Note: if relevant, include the content of your .latexmkrc file I have no .latexmkrc file. Output from VimtexInfo <CODE> debug\nI ran git log -Sparse_packages_from_fls and got 2 commits: <CODE> Running git checkout master^ fixes this issue. ", "code": ["vimtex: Compilation completed\nError detected while processing function <SNR>90 callback nvim_output[9]..vimtex#compiler#callback:\nline    20:\nE716: Key not present in Dictinary: parse_packages_from_fls\n", "System info\n  OS: Linux 5.2.13-200.fc30.x86_64\n  Vim version: NVIM v0.3.8\n  Has clientserver: true\n  Servername: /tmp/nvim7gewjd/0\n\nvimtex project: mini\n  base: mini.tex\n  root: /home/sudongpo\n  tex: /home/sudongpo/mini.tex\n  out: /home/sudongpo/mini.pdf\n  log: /home/sudongpo/mini.log\n  aux: /home/sudongpo/mini.aux\n  fls: /home/sudongpo/mini.fls\n  compiler: latexmk\n    backend: nvim\n    output: /tmp/nvim7gewjd/1\n    configuration: \n      continuous: 1\n      callback: 1\n      latexmk options:\n        -verbose\n        -file-line-error\n        -synctex=1\n        -interaction=nonstopmode\n      latexmk engine: -pdf\n  viewer: General\n  qf: LaTeX logfile\n    config: \n      packages: \n        default: 1\n      default: 1\n  document class: minimal\n", "commit 9a1f524256b962c89580ecb4b3109e2682fcda50 (HEAD -> master, origin/master, origin/HEAD)\nAuthor: Karl Yngve Lerv\u00e5g <karl.yngve+git@gmail.com>\nDate:   Wed Sep 11 22:27:03 2019 +0200\n\n    Simplify package detection (cf. #1471)\n\ncommit 23a3b356ba1e90d4a9dbb085712376cab83ab19e (grafted)\nAuthor: Karl Yngve Lerv\u00e5g <karl.yngve+git@gmail.com>\nDate:   Tue Aug 27 22:44:12 2019 +0200\n\n    Fixed #1462\n"], "labels": ["bug"]}
{"project": "brave_browser-laptop", "title": "Access is denied. (Exception from HRESULT: 0x80070005 (E_ACCESSDENIED))", "description": "I am trying to install git hub desktop on windows 10 OS. And I am facing following exception. Please help.. Tried with turning off firewall settings. But it didn't help. ==================================================================== PLATFORM VERSION INFO\nWindows \t\t\t: 10.0.14393.0 (Win32NT)\nCommon Language Runtime \t: 4.0.30319.42000\nSystem.Deployment.dll \t\t: 4.6.1586.0 built by: NETFXREL2\nclr.dll \t\t\t: 4.6.1586.0 built by: NETFXREL2\ndfdll.dll \t\t\t: 4.6.1586.0 built by: NETFXREL2\ndfshim.dll \t\t\t: 10.0.14393.0 (rs1_release.160715-1616) SOURCES\nDeployment url\t\t\t: file:///C:/Users/Shree/Downloads/GitHub.application ERROR SUMMARY\nBelow is a summary of the errors, details of these errors are listed later in the log.\n* Activation of C:\\Users\\Shree\\Downloads\\GitHub.application resulted in exception. Following failure messages were detected:\n+ Access is denied. (Exception from HRESULT: 0x80070005 (E_ACCESSDENIED)) COMPONENT STORE TRANSACTION FAILURE SUMMARY\nNo transaction error was detected. WARNINGS\nThere were no warnings during this operation. OPERATION PROGRESS STATUS\n* [2/16/2017 11:18:37 PM] : Activation of C:\\Users\\Shree\\Downloads\\GitHub.application has started. ERROR DETAILS\nFollowing errors were detected during this operation.\n* [2/16/2017 11:18:37 PM] System.UnauthorizedAccessException\n- Access is denied. (Exception from HRESULT: 0x80070005 (E_ACCESSDENIED))\n- Source: System.Deployment\n- Stack trace:\nat System.Deployment.Internal.Isolation.IsolationInterop.GetUserStore(UInt32 Flags, IntPtr hToken, Guid& riid)\nat System.Deployment.Internal.Isolation.IsolationInterop.GetUserStore()\nat System.Deployment.Application.ComponentStore..ctor(ComponentStoreType storeType, SubscriptionStore subStore)\nat System.Deployment.Application.SubscriptionStore..ctor(String deployPath, String tempPath, ComponentStoreType storeType)\nat System.Deployment.Application.SubscriptionStore.get_CurrentUser()\nat System.Deployment.Application.ApplicationActivator.PerformDeploymentActivation(Uri activationUri, Boolean isShortcut, String textualSubId, String deploymentProviderUrlFromExtension, BrowserSettings browserSettings, String& errorPageUrl)\nat System.Deployment.Application.ApplicationActivator.ActivateDeploymentWorker(Object state) COMPONENT STORE TRANSACTION DETAILS\nNo transaction information is available. ", "code": [], "labels": ["invalid"]}
{"project": "docker_machine", "title": "Add \"save\" feature to permanent store data on VM", "description": "Hi,\nas boot2docker, I'm searching save option on docker-machine command to persist data on VM but I don't have found it. It's in you roadmap? Thanks in advantage\nEmiliano ", "code": [], "labels": ["kind/enhancement"]}
{"project": "golang_go", "title": "plugin: add Windows support", "description": "hi\nPlugin Pkg Work for Windows!?\ni want use this for mac,linux,win,... os.\nwhen(what time) fix this? <URL> ", "code": [], "labels": ["OS-Windows"]}
{"project": "rust-lang_rust", "title": "manual does not document \"object-methods cannot be type-generic\" restriction", "description": "While trying to clarify a somewhat important detail about the language, I discovered that this detail was not documented in the language reference manual: <URL> ", "code": [], "labels": ["A-docs"]}
{"project": "OpenTTD_OpenTTD", "title": "Vehicles: auto-refit on purchase if vehicle list filtered by cargo", "description": "SirXavius opened the ticket and wrote: Reported version: 1.4.4\nOperating system: Windows ", "code": [], "labels": ["Vehicles", "flyspray"]}
{"project": "tinymce_tinymce", "title": "Bug: Tinymce editor body does not display the content in modal popup in mozilla firefox", "description": "We have two editors. While opening the popup on link button click, first i check that whether any active editor is already activated or not, if any active editor is present then I display the warning message that \"By continue this operation you will lost your changes\", if user clicks \"Yes\" in confirmation then I remove the active editor and opens the popup window. Javascript code:\ntinymce.remove(); On opening the modal popup, I bind HTML content in the TextArea present in the PopUp and pass that TextArea Object as \"selector\" to tinymce and initialize it. HTML for Text Area\n<asp:TextBox ID=\"txtEditorContent\" runat=\"server\" AutoPostBack=\"false\" CssClass=\"editor-content\" TextMode=\"MultiLine\" /> Javascript code: Current Behavior: HTML content is not displayed in editor.\nExpected Behavior: HTML content is should be displayed in editor.  Note: This issue is only generated in the firefox, same code works fine in Chrome tinymce version: 4.7.11 ", "code": [], "labels": ["needs: more info", "browser: firefox"]}
{"project": "golang_go", "title": "golan", "description": "Please answer these questions before submitting your issue. Thanks! GOARCH=\"amd64\"\nGOBIN=\"\"\nGOEXE=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"linux\"\nGOOS=\"linux\"\nGOPATH=\"\"\nGORACE=\"\"\nGOROOT=\"/usr/lib/go-1.7\"\nGOTOOLDIR=\"/usr/lib/go-1.7/pkg/tool/linux_amd64\"\nCC=\"gcc\"\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build279210773=/tmp/go-build -gno-record-gcc-switches\"\nCXX=\"g++\"\nCGO_ENABLED=\"1\" package main import (\n\"fmt\"\n) func main() {\nfmt.Println(\"Hello, playground\")\nhello := make(chan int) <CODE> } If possible, provide a recipe for reproducing the error.\nA complete runnable program is good.\nA link on play.golang.org is best. The code  should have compiled. Compilation error. ", "code": ["    go func() {\n\thello <- 1\n}()\t\n\n    go f(){\n    \t//hello <- 2\n    }() \nhello_value := <- hello\nfmt.Println(hello_value)\n"], "labels": ["FrozenDueToAge"]}
{"project": "MarlinFirmware_Marlin", "title": "[FR] Add Drilling canned cycles to Marlin 2.0", "description": "Like I talk with @thinkyhead  on Discord,\nI'm sharing the implementation of Drilling Canned Cycles (G81, G82 and G83) On Last Bugfix from today just added the call of the cycles on gcode.cpp and gcode.h add variable on adv cfg: /** */\n#define DRILLING_CANNED_CYCLES and add the attached files of functions. This drilling cycles aren't optimized and on patterns you need to put the position of new hole and ask for cycle again. This isn't corrected because I don't have too much time to check a solution (one of the reason is the G80 be in use now for other functions). Wasn't perfect but it's a beginning. :) drilling cycles.zip ", "code": [], "labels": ["T: Feature Request"]}
{"project": "magit_magit", "title": "How to prevent a bunch of open magit buffers after a commit?", "description": "I have noticed that at the end of a committing session, I have these buffers remaining open: Is this behavior expected? If so how can I fix it? Also, probably related, at times after I finish committing by hitting C-c C-c in the commit log buffer, the magit status buffer gets buried. And then I need to C-x b to the status buffer to proceed with pushing. ", "code": [], "labels": ["support"]}
{"project": "sveltejs_svelte", "title": "each-else causes error", "description": "Regression in 1.23.0: Causes this error: ", "code": [], "labels": ["bug"]}
{"project": "slick_slick", "title": "User manual chapter targeting users with SQL experience", "description": "For Slick 2.1, as listed on the roadmap. ", "code": [], "labels": ["3 - Done"]}
{"project": "symfony_symfony", "title": "Symfony crashes after login", "description": "When following the guide to write a login page in the Symfony documentation and loading the users from my database, Symfony returns a HTTP 500 error. After that the webserver freezes.\nI am using a ArchLinux 4.13.7-1 x86_64 with PHP 7.1.10. My database is a MariaDB 10.1.28.\n\nWhen the crash happens there are no real information in the debug log except the following line:\n[Thu Sep 21 15:32:23 2017] PHP Fatal error:  Allowed memory size of 134217728 bytes exhausted (tried to allocate 262144 bytes) in Unknown on line 0\n\nI found out, that the issue does not occure when writing the users login credentials in the security.yml. This issue does also occure when using a Apache 2.4.28 webserver. Increasing the memory limit in the php.ini does not resolve the issue. Instead Symfony fills the maximum amount of memory with data.  For me, I have downgraded to Symfony version 3.3.2, where this issue does not occure, using the same code from the documentation. ", "code": [], "labels": ["Status: Waiting feedback"]}
{"project": "NLog_NLog", "title": "Version Number", "description": "Hi! I am using Nlog 4.5.1 in my application.  The version number and is identical to earlier versions of Nlog 4.0 I suppose this would not matter much if the older version was not in the GAC.  When an older version of Nlog is in the GAC, it becomes a problem.  Here is what i found: to work around the issue, i had to uninstall my application and the other application.  That removed NLog from the GAC.\nThen i installed my application, followed by the older application.  Both work OK. I am now stuck on this version of NLog until you support changing the version number.\nIf I must upgrade to a newer version of NLog, i must uninstall and reinstall both applications, or persuade the author of the application to not use the GAC. Please consider updating the version number in each release. Regards\nHabib ps.  you can see more info here:\n<URL> ", "code": [], "labels": ["duplicate", "wontfix"]}
{"project": "status-im_status-react", "title": "Non-reversible actions should be authenticated so I can protect my wallet/info/account and feel secure", "description": "As a user, I want my transactions and other non-reversible actions to be authenticated so I can protect my wallet/info/account and feel secure. Type: Feature Summary:  As a user I want to authenticate non-reversible actions, such as sending a transaction or deleting an account. Authenticating helps to create trust and security, whilst also making completely sure the user 100% intends to complete the action. I expect that important and non-reversible transactions will have proper security. When I'm sending a transaction I need to authenticate (works as expected). There may be other parts of the app that need authenticated actions? Pulled out of #2869. Please note part of this issue might be covered partially already (transaction signing). Part of the work of this issue is to clarify what exactly needs to be protected in what way. ", "code": [], "labels": ["stale"]}
{"project": "arduino_Arduino", "title": "add multiplePinOps to lib manager", "description": "Repository is here <URL> ", "code": [], "labels": ["Component: Board/Lib Manager"]}
{"project": "vuetifyjs_vuetify", "title": "[Bug Report] Ripple overlay on buttons don't disappear after clicking alternatively between left and right mouse buttons", "description": "Vuetify: 1.5.6\nVue: 2.6.9\nBrowsers: Chrome 73.0.3683.75\nOS: Linux x86_64 Just spam click both mouse buttons on top of the button, the ripple overlays won't go out unless you pass the mouse over and out of the button. The ripples should just go away. Some ripples remain until you hover in and out of the button, so they leave one by one. <URL>  ", "code": [], "labels": ["duplicate"]}
{"project": "keepassxreboot_keepassxc", "title": "Feature: Caps Lock", "description": "Please add a trigger that will notify the enabled Caps Lock. This will be very healthy. Thank in advance. ", "code": [], "labels": ["user interface", "wishlist"]}
{"project": "dart-lang_sdk", "title": "local_function_test broken on dart2js", "description": "After the three commits\ne6363dd\n107f611\n7568a4e\nthe two tests\nlanguage/local_function_test\ndart2js_extra/local_function_call_test\nhave a runtime error on all dart2js configurations, both browser and non-browser. Marking this failure in tests/language/language_dart2js.status and\ntests/compiler/dart2js_extra/dart2js_extra.status ", "code": [], "labels": ["type-bug", "P1", "web-dart2js"]}
{"project": "mapbox_mapbox-gl-js", "title": "Mapbox line-pattern distorts the image", "description": "I am applying line-pattern property to a Line but the result is distorted. The image width is a factor of two (32 or 64px) and I am using a fixed width for the line (I am not trying to scale it with the zoom - which is much worse btw) paint: {\n'line-pattern':fillPatternName,\n'line-width': 32,\n}, Example:\nHere is the pattern: <URL>\nAnd this is the actual result: <URL> As you can see it will create an angle in the pattern and also the repeat is inconsistent as it will start repeating the pattern without finishing the previous pattern draw (overlaping). ", "code": [], "labels": ["bug "]}
{"project": "googleapis_google-cloud-python", "title": "paginate through queries", "description": "I want to run a paginate query through bigquery client. However, it doesn't seem to be possible as QueryJob results function does not take max_results or  page_token to pass down to list_rows call. I want to ask if there's a way to run a paginate query with this BigQuery Client ? Thank you. ", "code": [], "labels": ["type: question", "api: bigquery"]}
{"project": "ansible_ansible", "title": "pamd broke /etc/pam.d/su file after task", "description": "pamd <CODE> But I use latest version from <URL> default Red Hat Enterprise Linux 7.3 pamd broke /etc/pam.d/su file after task Good /etc/pam.d/su file: <CODE> Bad /etc/pam.d/su file: <CODE> Spaces in system-auth module name. ", "code": ["ansible 2.3.0.0\n  config file = /etc/ansible/ansible.cfg\n  configured module search path = Default w/o overrides\n  python version = 2.7.5 (default, Aug  2 2016, 04:20:16) [GCC 4.8.5 20150623 (Red Hat 4.8.5-4)]\n", "#%PAM-1.0\nauth            required        pam_succeed_if.so uid < 40000\nauth            sufficient      pam_rootok.so\n# Uncomment the following line to implicitly trust users in the \"wheel\" group.\n#auth           sufficient      pam_wheel.so trust use_uid\n# Uncomment the following line to require a user to be in the \"wheel\" group.\n#auth           required        pam_wheel.so use_uid\nauth            substack        system-auth\nauth            include         postlogin\naccount         sufficient      pam_succeed_if.so uid = 0 use_uid quiet\naccount         include         system-auth\npassword        include         system-auth\nsession         include         system-auth\nsession         include         postlogin\nsession         optional        pam_xauth.so\n", "#%PAM-1.0\n# Uncomment the following line to implicitly trust users in the \"wheel\" group.\n#auth           sufficient      pam_wheel.so trust use_uid\n# Uncomment the following line to require a user to be in the \"wheel\" group.\n#auth           required        pam_wheel.so use_uid\nauth            required        pam_succeed_if.so uid < 40000\nauth            sufficient      pam_rootok.so\nauth            substack        system -auth\nauth            include postlogin\n\naccount         sufficient      pam_succeed_if.so uid = 0 use_uid quiet\naccount         include system -auth\n\npassword        include system -auth\n\nsession         include system -auth\nsession         include postlogin\nsession         optional        pam_xauth.so\n"], "labels": ["support:community", "module", "affects_2.3", "bug"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Unclosed bracket Bug", "description": "If we want to execute a query with an unclosed bracket, the whole phpMyAdmin interface moves into a frame... Video:\n<URL> ", "code": [], "labels": ["bug"]}
{"project": "paramiko_paramiko", "title": "Unknown exception: cannot join current thread", "description": "068bf63 introduced self.join() in transport.py -- which causes spurious tracebacks on authentication failure because it is not possible to join your own thread, this raises RuntimeError(\"cannot join current thread\") from threading.py. To reproduce using demo_server.py, simply generate many public keys and fail with them all -- reaching the hard-coded limit of 10 ( in _send_auth_result of auth_handler.py.py. <CODE> <CODE> <CODE> ", "code": ["$ for n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15; do echo | ssh-keygen -f /tmp/_$n; done\n$ ssh $(ls /tmp/_* | egrep '[0-9]$' | xargs -n 1 echo -i) -p 2200 user@localhost\nReceived disconnect from 127.0.0.1: 14: No more auth methods available\n", "$ python demo_server.py\nRead key: 60733844cb5186657fdedaa22b5a57d5\nListening for connection ...\nGot a connection!\nAuth attempt with key: c00d9692cde7305238cf7f57b720e8c3\nAuth attempt with key: de86194ef717cf2e7da7697de33d2578\nAuth attempt with key: 8a3c67327dea5d68f101d9455db2aa9b\nAuth attempt with key: 4fb3989e5db919a139c32b96d69a71c1\nAuth attempt with key: ddf541ef4b224588b37fa6976af4dcf0\nAuth attempt with key: 7ef8e4532219a8b8439c1edeb625c0ef\nAuth attempt with key: 02c5edc1a525fd241a29dca8dc3d959a\nAuth attempt with key: a0715d805c164e14faddf9e45c00144b\nAuth attempt with key: 4ce24af5ed716205dd83331560e61ce7\n*** No channel.\n$ cat demo_server.log\nDEB [20140710-22:18:38.395] thr=1   paramiko.transport: starting thread (server mode): 0x98efad0L\nINF [20140710-22:18:38.396] thr=1   paramiko.transport: Connected (version 2.0, client OpenSSH_6.2)\n\n...\n\nDEB [20140710-22:18:38.419] thr=1   paramiko.transport: Auth request (type=publickey) service=ssh-connection, username=user\nINF [20140710-22:18:38.419] thr=1   paramiko.transport: Auth rejected (publickey).\n\nx10\n\nERR [20140710-22:18:38.419] thr=1   paramiko.transport: Unknown exception: cannot join current thread\nERR [20140710-22:18:38.420] thr=1   paramiko.transport: Traceback (most recent call last):\nERR [20140710-22:18:38.420] thr=1   paramiko.transport:   File \"... paramiko/transport.py\", line 1455, in run\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:     self.auth_handler._handler_table[ptype](self.auth_handler, m)\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:   File \"... paramiko/auth_handler.py\", line 349, in _parse_userauth_request\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:     self._send_auth_result(username, method, result)\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:   File \"... paramiko/auth_handler.py\", line 240, in _send_auth_result\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:     self._disconnect_no_more_auth()\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:   File \"... paramiko/auth_handler.py\", line 144, in _disconnect_no_more_auth\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:     self.transport.close()\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:   File \"... paramiko/transport.py\", line 498, in close\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:     self.stop_thread()\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:   File \"... paramiko/transport.py\", line 1260, in stop_thread\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:     self.join(10)\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:   File \"... python2.7/threading.py\", line 940, in join\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:     raise RuntimeError(\"cannot join current thread\")\nERR [20140710-22:18:38.421] thr=1   paramiko.transport: RuntimeError: cannot join current thread\nERR [20140710-22:18:38.421] thr=1   paramiko.transport:\n", ">>> class T(threading.Thread):\n...    def run(self):\n...        self.join()\n>>> T().start()\nException in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python/2.7.7_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n    self.run()\n  File \"<ipython-input-6-e6c8a23b0b74>\", line 3, in run\n    self.join()\n  File \"/usr/local/Cellar/python/2.7.7_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 940, in join\n    raise RuntimeError(\"cannot join current thread\")\nRuntimeError: cannot join current thread\n"], "labels": ["Bug"]}
{"project": "magento_magento2", "title": "Functional tests failing on menu item select", "description": "When running the functional tests with selenium the tests are failing when trying to locate the XPath\n.//li[@role=\"menu-item\" and a[span=\"System\"]]/div[@class=\"submenu\"]. The reason for the test to fail is that the menu overlap is shown which changes the class to \"submenu _overlap\". The correct XPath should be .//li[@role=\"menu-item\" and a[span=\"System\"]]/div[@class=\"submenu _overlap\"] or .//li[@role\\\"menu-item\" and a[span=\"System\"]]/div[contains(@class, \"submenu\")]. The file to be updated is dev/tests/functional/tests/app/Magento/Backend/Test/Block/Menu.php ", "code": [], "labels": ["bug report", "Progress: needs update", "PS", "Issue: Ready for Work"]}
{"project": "dgraph-io_dgraph", "title": "Indefinite period of transaction conflicts after network partitions", "description": "After a period of network partitions, Dgraph 1.0.3-dev (5563bd2) can wind up stuck in a mode where all transactions which attempt to modify a key conflict immediately (e.g. on mutate, not commit). Using the schema <CODE> ... we build up a set of integers by performing mutations associating each integer with a fixed UID; e.g. to insert the number 5, we execute a transaction with a single mutation: To read this set, we query for all values associated with that UID using { q(func: uid($u)) { uid, value } }. As we saw in #2152, this appears to show a stale state of the DB: all values up to some number are present, then every subsequent acknowledged value is missing. To distinguish between stale reads and lost updates, we follow that read, in the same transaction, with a sequence of inserts or deletes to the exact triples which we believe were successfully inserted--if we read the 5, we insert {uid: \"0x01\", value: 5}, and if we failed to read 5, we delete {uid: \"0x01\", value: 5} instead. These update transactions fail immediately with a conflict. This state appears to persist indefinitely--in an hour without any network disruption, and no other transactions, every update failed in this way. In an optimistic concurrency control system, we would expect these updates to fail if another transaction modified and committed that key some time after our update transaction began and before it completed. If transaction start times were allocated sequentially, the conflict-failure of n sequential updates to the same key implies the existence of n ongoing update transactions affecting that key, but in this test, we have no such evidence. There are any number of timed-out transactions that might be applied just in time to cause these failures, but eventually we should exhaust those. Alternatively, these update transactions could be obtaining starting timestamps from some point far in the past, such that they conflict with an update transaction that completed long ago. To reproduce this behavior, try Jepsen d8bb86a5219d17abe5a4125581350571c5ffe209, and run <CODE> ", "code": ["value: [int] .\n", "lein run test -f --package-url https://github.com/dgraph-io/dgraph/releases/download/nightly/dgraph-linux-amd64.tar.gz -w uid-set --time-limit 120 --nemesis partition-random-halves --concurrency 2n --test-count 10\n"], "labels": ["kind/bug"]}
{"project": "phpstan_phpstan", "title": "Access to undefined property with `??` operator", "description": "When using the ?? operator, phpstan can report accesses to undefined properties <URL> PHPStan should probably not report anything here. For comparison, this does not cause anything to be reported. ", "code": [], "labels": ["bug"]}
{"project": "Unity-Technologies_ml-agents", "title": "python time.sleep prevents the environment from rendering", "description": "Hi, For a testing purpose, I'd like to slow down the number of actions I make per second in inference mode with gridworld. I have set a decision frequency of 1 and my timescale is 1 in inference. Therefore, in my python agent's loop, I put a sleep of 1sec between actions. The problem is that my environment stop rendering completely with these sleeps; I have a black screen and a rolling wheel of death ahah. As I understand from previous issue #299, the rendering system of the game is completely independent from the agent's one. Then, I don't understand why a sleep in my script, that is a separate process, would prevent the environment from rendering and displaying. Thanks in advance for the help, \u00c9mile ", "code": [], "labels": ["needs-info"]}
{"project": "onnx_onnx", "title": "Several version onnx do not work", "description": "First using 'conda install -c conda-forge onnx,thre onnx version is 1.1.2'.When using onnx.check.check_model: Then using 'conda install -c conda-forge protobuf numpy,pip install onnx',th error is : I also try  installing from source 1.3.0. the error is : source 1.2.2 also tried,error is : @huitseeker @ezyang @shinh @dougalsutherland ", "code": [], "labels": ["build"]}
{"project": "rubocop-hq_rubocop", "title": "Layout/MultilineHashBraceLayout auto-correct syntax error", "description": "Hi, I noticed that the auto-correct for Layout/MultilineHashBraceLayout sometimes causes syntax errors. This seems to happen when Don't introduce syntax errors. Auto-correct for Layout/MultilineHashBraceLayout can introduce syntax errors when a line ends with a comment. Run  rubocop --only Layout/MultilineHashBraceLayout --auto-correct test.rb where test.rb is the following file: This is auto-corrected to the following Notice that the closing ) of the function is now after the comment. Include the output of rubocop -V. Here's an example: <CODE> ", "code": ["$ rubocop -V\n0.57.1 (using Parser 2.5.1.0, running on ruby 2.4.1 x86_64-linux)\n"], "labels": ["bug"]}
{"project": "ionic-team_stencil", "title": "puppeteer-declarations.d.ts file has incorrect function signature for classList.contains", "description": "Stencil version: <CODE> I'm submitting a: [X ] bug report\n[ ] feature request\n[ ] support request => Please do not submit support requests here, use one of these channels: <URL> or <URL> Current behavior: The file found in:\nnode_modules\\@stencil\\core\\dist\\testing\\puppeteer\\puppeteer-declarations.d.ts contains the following inside of the interface E2EElement: <CODE> Expected behavior:\nThe contains function should not be returning a void, but rather be returning a boolean like so:\ncontains: (className: string) => boolean; ", "code": [" @stencil/core@0.15.2\n", "classList: {\n        /**\n         * Add specified class values. If these classes already exist in\n         * attribute of the element, then they are ignored.\n         */\n        add: (...tokens: string[]) => void;\n        /**\n         * Remove specified class values. Note: Removing a class that does\n         * not exist does NOT throw an error.\n         */\n        remove: (...tokens: string[]) => void;\n        /**\n         * If class exists then remove it, if not, then add it.\n         */\n        toggle: (token: string) => void;\n        /**\n         * Checks if specified class value exists in class attribute of the element.\n         */\n        contains: (className: string) => void;\n    };\n"], "labels": ["triage"]}
{"project": "fsharp_FAKE", "title": "Docs: a function index would be nice", "description": "The FAKE API documentation is hard to use: specifically, there's no one place to find out all the available functions. I can click through a bunch of namespaces until I find what I'm looking for, but it's not always obvious at all which namespace contains what. Here's a good example. I just tried to look for the </> operator, because I had to refresh my memory whether </> or @@ was the operator that strips leading slashes from the second part of the path. (It's @@, but I couldn't remember that). Here's the process I went through: I'd like to have an index of all FAKE functions available, in all namespaces. Each entry would look something like this (vague ASCII art, do not take this as the final design that I'd like to see): <CODE> The sort order I'd prefer to see would be to have ASCII letters sorted NOT case-sensitive, so that (for example) getBuildParam comes before GetDependenciesForReferencesFile which comes before getDrivesInfo. Also if Fake defines any operators that start with the | (vertical pipe) character, I'd like to see them sorted before the ASCII letters, so that all operators are clustered together in the index. This would take a custom sorter, since | is U+007C, coming after the lowercase letters if you sort in code point order. Finally, I'd like the index to have 27 links at the top (and maybe at the bottom as well) for ease of navigation: one link titled !@# (or whatever) that links to the names that start with non-letter characters, and then the letters A through Z as links to that section of the index. Each section would have a \"Back to top\" link, too. I had to grep the source code to find where the </> operator was defined. Any time you end up searching the source code, it's because the documentation was lacking in some way. Sometimes that's all right, but in this case, this was a very commonly-needed operator that I couldn't find, so we should improve the documentation so that it's easier to find. A function index is the best idea I have for that improvement. If you forget which namespace a particular operator or function is from, a long search or a grep through FAKE's source code are your only options at the moment. ", "code": ["</> path1 path2      Description of </>\nFrom Fake.EnvironmentHelper (auto-opened when you put \"open Fake\" in your build script)\n\n@@ path1 path2       Description of @@\nFrom Fake.EnvironmentHelper (auto-opened when you put \"open Fake\" in your build script)\n\n.\n.\n.\n\nPack setParams       Description of Pack\nFrom Fake.Paket (NOT auto-opened: need to put \"open Fake.Paket\" in your build script)\n"], "labels": ["documentation", "help wanted", "enhancement", "stale"]}
{"project": "odoo_odoo", "title": "[11.0] Cannot start inventory", "description": "Impacted versions:\n11.0 Steps to reproduce:\nStart a new inventory of a full location. Current behavior:\nSQL fails because the search of locations made in <CODE> returns no locations. Expected behavior:\nExpected to get correct list of ids to add them in args, but it fails. Video/Screenshot link (optional):\nI've checked in the shell the search and it didn't work ok, for some reason \"child_of\" operator is not working in the shell.  ", "code": ["    def _get_inventory_lines_values(self):\n        # TDE CLEANME: is sql really necessary ? I don't think so\n        locations = self.env['stock.location'].search([('id', 'child_of', [self.location_id.id])])\n        domain = ' location_id in %s'\n        args = (tuple(locations.ids),)\n"], "labels": ["Logistics", "11.0"]}
{"project": "checkstyle_checkstyle", "title": "AbstractJavadocCheck should process only doc comments placed before class, interface, constructor, method, or field declarations", "description": "From Javadoc guide:\nPlacement of comments - Documentation comments are recognized only when placed immediately before class, interface, constructor, method, or field declarations -- see the class example, method example, and field example. Documentation comments placed in the body of a method are ignored. Only one documentation comment per declaration statement is recognized by the Javadoc tool. ", "code": [], "labels": ["bug", "approved"]}
{"project": "strongloop_loopback-next", "title": "Project scaffolding via npx", "description": "I recently faced an issue where even after I globally installed the package, I couldn't use the commands. I fixed the issue. It just hit me that even loopback could bootstrap projects in the way create-react-app does it. I am not sure how feasible would it be for the team to do it or whether the team considers this suggestion helpful. ", "code": [], "labels": ["feature"]}
{"project": "OpenRCT2_OpenRCT2", "title": "Duplicate code.", "description": " is a duplicate of  and should be merged into one. ", "code": [], "labels": ["refactor"]}
{"project": "joomla_joomla-cms", "title": "Language installed by discover cannot be uninstalled", "description": "If you install a language using the discover method then it can never be uninstalled because the discover method doesnt not install the package and we have something to prevent you uninstalling a language ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "spring-projects_spring-boot", "title": "Upgrade to Kotlin 1.2.30", "description": "\nNo description provided.\n ", "code": [], "labels": ["priority: normal", "type: dependency-upgrade"]}
{"project": "joomla_joomla-cms", "title": "UTF-8 encoded tweets sent as unknown characters", "description": "When using JTwitterStatuses class to send UTF-8 encoded statuses/tweets, they show as unknown characters. ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "emscripten-core_emscripten", "title": "Is there support for building in visual studio 2017?", "description": "I'm looking into the documentation and i see this <URL> for instance, mentioning that there is no such support. I find some issues referencing this, such as #5259 but i do not find any documentation that suggests how this should be used? I might just be confused :) please help me clear this out if this is possible :) ", "code": [], "labels": ["wontfix"]}
{"project": "spring-projects_spring-framework", "title": "Deprecate MediaType.APPLICATION_JSON_UTF8 in favor of APPLICATION_JSON", "description": "In  spring-framework/spring-web/src/main/java/org/springframework/http/MediaType.java: <CODE> So it would be best to clarify the text and deprecate the constant. ", "code": [" * <p>This {@link MediaType#APPLICATION_JSON} variant should be used to set JSON\n * content type because while\n * <a href=\"https://tools.ietf.org/html/rfc7159#section-11\">RFC7159</a>\n * clearly states that \"no charset parameter is defined for this registration\", some\n * browsers require it for interpreting correctly UTF-8 special characters\n"], "labels": ["type: task"]}
{"project": "neovim_neovim", "title": "[RFC] build: revisit/fix USE_BUNDLED_BUSTED", "description": "USE_BUNDLED_BUSTED was added in #2447 (fe9ec9c), with the intention to skip building of deps needed for tests. From the name itself I understand it however as it would affect only \"busted\" itself, and not test dependencies in general.\nI.e. that you could use USE_BUNDLED_BUSTED=0, and still have tests working, when USE_BUNDLED_LUAROCKS=1 was used by default. I think the current behavior is OK, but at least the description should be clarified / extended then:  Also renaming it to USE_BUNDLED_TEST_ROCKS would make it more explicit (but should keep the old name anyway I guess). ", "code": [], "labels": ["build", "discuss"]}
{"project": "cloud-custodian_cloud-custodian", "title": "docs / policy authoring guide", "description": "\nNo description provided.\n ", "code": [], "labels": ["area/docs"]}
{"project": "arduino_Arduino", "title": "Add Library", "description": "I like to add this library to the Library Manager: <URL> Following the instructions provided here: '<URL>' Best Regards ", "code": [], "labels": ["Component: Board/Lib Manager"]}
{"project": "orientechnologies_orientdb", "title": "skip/limit does not work for aggregation", "description": "2.2.7 limit does not work for aggregation\n....\nselect list(id) from sometable where somefield = 'a' order by generated desc limit 2 expecting: only two elements will fit in result;\nactual: all elements fit ", "code": [], "labels": ["question"]}
{"project": "keepassxreboot_keepassxc", "title": "New entry is not saved when clicking Apply", "description": "When creating a new entry, the entry should be saved after clicking on Apply. The should be a new entry in the database, even when I leave the entry afterwards pressing Escape/clicking Cancel. There is no new entry, all information entered is lost. Create a new entry when after clicking Apply if the entry did not exist before. Alternatively (or additionally) there should at least be either a warning or a undo function (like an auto-save in trash) for leaving an unsaved new entry. After clicking apply I expect the entry to be saved. I lost new entries multiple times because I though apply would save them. I left the dialog open for some reasons, and later thought I could leave the dialog through pressing Escape (which is kind of a reflex when I do not expect to lose any data). KeePassXC - Version 2.2.2\nRevision: 6d46717 Libraries: Operating system: Arch Linux\nCPU architecture: x86_64\nKernel: linux 4.9.56-1-lts Enabled extensions: ", "code": [], "labels": ["bug"]}
{"project": "ccrama_Slide", "title": "\"Subreddit theme\" and \"Subreddit layout\" sections of settings", "description": "So, a more powerful way of editing per-subreddit styling. Tapping the subreddit brings up a popup, not a full page, to edit the colors, or in the case of layout, a full page. Both let you select presets.  Things would be similar for the layout section, but without the color circles. ", "code": [], "labels": ["Feature Request"]}
{"project": "aspnet_Mvc", "title": "Create Item Template for Page/PageModel", "description": "We will need an item template for Page/PageModel, and/or a dotnet new item that does the same. Needs to be resolved with @mlorbetske ", "code": [], "labels": ["feature", "3 - Done"]}
{"project": "reduxjs_redux", "title": "Example with flow types", "description": "It would be nice to see an example of using flow with redux. I've seen a few articles that start to explain how to use flow with redux and it just seems like it would be useful for people like myself who know how to use redux but not flow and want to see both be used in an example app. This article starts to show the benefits really quickly and It would be dope if someone familiar with flow could make add an example app in the examples folder. ", "code": [], "labels": ["examples"]}
{"project": "gitbucket_gitbucket", "title": "Support ed25519 for SSH", "description": "When I submit my SSH public key <CODE> Gitbucket tells me that it's invalid. It's definitely valid, but perhaps Gitbucket doesn't support ed25519 yet. That'd be a nice feature to have. ", "code": ["ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICKHoRRTDdoqmEQ9YFNFn75K0w6wdh1labhDzDCtTRO+ colindean\n"], "labels": ["help wanted", "feature"]}
{"project": "gatsbyjs_gatsby", "title": "When using linkImagesToOriginal, images do not render", "description": "When adding linkImagesToOriginal to options for gatsby-remark-images, images no longer render. Images should appear Images do not appear System:\nOS: macOS 10.14.1\nCPU: (12) x64 Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz\nShell: 3.2.57 - /bin/bash\nBinaries:\nNode: 11.9.0 - /usr/local/bin/node\nYarn: 1.13.0 - /usr/local/bin/yarn\nnpm: 6.8.0 - /usr/local/bin/npm\nLanguages:\nPython: 2.7.15 - /usr/local/bin/python\nBrowsers:\nChrome: 72.0.3626.121\nSafari: 12.0.1\nnpmPackages:\ngatsby: ^2.0.119 => 2.0.119\ngatsby-background-image: ^0.2.4 => 0.2.4\ngatsby-image: ^2.0.29 => 2.0.29\ngatsby-plugin-drift: ^1.0.0 => 1.0.0\ngatsby-plugin-favicon: ^3.1.5 => 3.1.5\ngatsby-plugin-manifest: ^2.0.17 => 2.0.17\ngatsby-plugin-offline: ^2.0.23 => 2.0.23\ngatsby-plugin-react-helmet: ^3.0.6 => 3.0.6\ngatsby-plugin-sharp: ^2.0.20 => 2.0.20\ngatsby-plugin-styled-components: ^3.0.5 => 3.0.5\ngatsby-plugin-typography: ^2.2.7 => 2.2.7\ngatsby-remark-images: ^3.0.5 => 3.0.5\ngatsby-source-filesystem: ^2.0.20 => 2.0.20\ngatsby-transformer-javascript-frontmatter: ^2.0.8 => 2.0.8\ngatsby-transformer-json: ^2.1.8 => 2.1.8\ngatsby-transformer-remark: ^2.2.5 => 2.2.5\ngatsby-transformer-sharp: ^2.1.13 => 2.1.13\nnpmGlobalPackages:\ngatsby-cli: 2.4.9 ", "code": [], "labels": ["stale?", "type: question or discussion"]}
{"project": "rancher_rancher", "title": "Kafka logging target is not working", "description": "Rancher versions: 2.0 master 1/03 Steps to Reproduce: ", "code": [], "labels": ["status/resolved", "kind/bug", "area/tools", "version/2.0"]}
{"project": "kivy_kivy", "title": "kivy's hello world issues in atom editor", "description": "Versions i write a code on atom editor when i want re write the example of code from kivy documentation\nthere is module error in my atom here's is the code from <URL> then the error pop up Traceback (most recent call last): File \"C:\\Users\\akbar\\Documents\\kivy.py\", line 1, in <module> from kivy.app import App File \"C:\\Users\\akbar\\Documents\\kivy.py\", line 1, in <module> from kivy.app import App ModuleNotFoundError: No module named 'kivy.app'; 'kivy' is not a package [Finished in 0.144s] when i recheck my pip my kivy has been already install with version 1.10.0\n ", "code": [], "labels": ["support"]}
{"project": "eclipse_che", "title": "How to speed up a custom assembly build?", "description": "I'm running the script below as part of our CI pipeline: <CODE> This takes 24 minutes to complete on a test machine. At the moment, the only file we are changing in our custom assembly is outeredge@dc8bb54. I'd appreciate some community advice on how we can speed up the build above. Can we just do a assembly/assembly-main && mvn clean install instead? I'm not clear whether the change above would then be \"built\" into the main assembly as it's in a plugin? Also, it doesn't look like the fast profile exists in the assembly-main pom.xml? Thanks! ", "code": ["##!/bin/bash\necho \"=> Building the binary\"\ndocker run --rm \\\n  -v $(pwd):/home/user/che-build \\\n  -w /home/user/che-build \\\n  eclipse/che-dev \\\n  mvn clean install -Pfast\n"], "labels": ["kind/question"]}
{"project": "agda_agda", "title": "typo in on-line doc", "description": "<CODE> Original issue reported on code.google.com by mech...@botik.ru on 17 Mar 2014 at 6:16 ", "code": ["Irrelevance\n-----------\n\nTable of contents\n...\n...  2. Irrelevant record fiels\n                             ~~\n"], "labels": ["documentation", "auto-migrated", "type: bug"]}
{"project": "Tribler_tribler", "title": "Refactor DownloadState", "description": "Currently the DownloadState class does not do what it reports, namely: <CODE> Instead, many of the methods (e.g. get_files_completion() and get_length()) query the live download's statistics. ", "code": ["Contains a snapshot of the state of the Download at a specific point in time.\n"], "labels": ["enhancement"]}
{"project": "meteor_meteor", "title": "React Native integration", "description": "Feature request: meteor add-platform react-native-ios/android I get the sense that everyone starting a new mobile app these days is using React Native \ud83d\ude04 Might be a big win for Meteor if it was the full-stack solution for building React Native apps. There are a few things that RN integration could look like. Here are some ideas: ", "code": [], "labels": ["Project:Mobile", "feature"]}
{"project": "ocaml_ocaml", "title": "optional argument cannot be erased assumes abstracted types cannot be functions", "description": "Original bug ID: 4447\nReporter: till\nAssigned to: @garrigue\nStatus: closed (set by @garrigue on 2010-04-27T07:30:35Z)\nResolution: won't fix\nPriority: normal\nSeverity: trivial\nCategory: ~DO NOT USE (was: OCaml general)\nMonitored by: jm @yakobowski compiling: module T (S:sig type t end)= struct\nlet cont (k:S.t) ?i:_  =\nk\nend raises the warning:\n\"Warning X: this optional argument cannot be erased.\" whilst: let cont k ?i:_ =\nk doesn't ", "code": [], "labels": ["wontfix", "bug"]}
{"project": "bcit-ci_CodeIgniter", "title": "PDO Postgres configuration discrepency", "description": "When allowing the pgsql subdriver to generate the full data source name property, dsn, it it appends username instead of user. ", "code": [], "labels": ["Bug"]}
{"project": "opnsense_core", "title": "Radius IP Management", "description": "Hello, what do you think about adding to file ipsec.inc  [<URL>](link to exact line) $authentication .= \"\\n\\trightsourceip = %radius\"; Im using it for assigning IP directly from radius, static IP bounded to user account.\nI think some of us use this solution by hardcoding source code which is bad and ugly hack. ", "code": [], "labels": ["feature"]}
{"project": "angular-ui_ui-grid", "title": "hideColumn, what should be changing ?", "description": "I'm trying to persist the visibility change of cols, so when a columnVisibilityChanged event happens, I save it to the database.\nAfter some debugging, I noticed that it was always saving visible as true. After doing some digging, I noticed that when a column changes from the menu $scope.hideColumn is setting :\n$scope.col.colDef.visible = false; However the actual saved value is col.visible, I'm not 100% sure what the fix should be, should hideColumn be affecting just colDef, or both ?\nor are changes to colDef reflected back to the visible at a later time ? (So I'd be saving too early) I'm not 100% sure as I can't really reproduce this on the website demos. ", "code": [], "labels": ["waiting-response"]}
{"project": "hluk_CopyQ", "title": "Bug or feature ?", "description": "Hi Thanks for a great app. If I copu a picture \u201cas picture\u201d from a web browser and insert the clip at a later time, nothing is inserted in excel, I have to manually in excel choose insert special, picture. I giuess its because it tries to insert html. Can that be disabled so that pictures copied from browser inserts as a picture by default ? Is there a trashcan or undelete option ? Using windows 10 and office 365 To Reproduce\nSteps to reproduce the behavior: Expected behavior\na picture should be inserted, but instead nothing in inserted. I have manually to choose in excel \"insert special\" and select picture for it to work. I would prefer that by default the picture is inserted Screenshots\nnone relevant Version, OS and Environment Additional context\nAdd any other context about the problem here. ", "code": [], "labels": ["bug"]}
{"project": "angular_components", "title": "Please add a guide for gestures", "description": "I wanted to support swiping on an image array to create an accordion kinda of control.\nmaterial has a GestureConfig provider that is very well written and wrappers hammerjs.\nA short guide in the material.angular.io site on how to use or configure it would help a lot. So that people would not have to dig into the code and be able to use an API for gestures that is tested and well defined. Latest. ", "code": [], "labels": ["feature", "docs"]}
{"project": "golang_go", "title": "test: fixedbugs/issue5162.go failing on netbsd/386", "description": "netbsd/386 is consistently failing.  Often it's because of runtime/pprof flaking, but occasionally runtime/pprof actually passes, and then netbsd/386 instead fails because of fixedbugs/issue5162.go.  E.g., see <URL> <CODE> It looks like that test generates a 16000 line .go file, which it then tries to run.  But it seems that 8g is dying with \"signal: killed\" for some reason.  I don't see any reason why Go would be purposefully sending SIGKILL to 8g in this test. Someone with access to a netbsd/386 machine (@minux?), please try running: <CODE> ", "code": ["##### ../test\n# go run run.go -- fixedbugs/issue5162.go\nexit status 1\ngo build command-line-arguments: /tmp/gobuilder/netbsd-386-minux-1ccc577b8a34/go/pkg/tool/netbsd_386/8g: signal: killed\n\nFAIL    fixedbugs/issue5162.go  79.542s\n", "go run $GOROOT/test/fixedbugs/issue5162.go > bug.go\ngo tool 8g bug.go\n"], "labels": ["FrozenDueToAge"]}
{"project": "vaadin_framework", "title": "Allow specify custom theme version to solve browser cache issues", "description": "When modifying custom themes between app releases, browser cache prevent loading the latest version which could mess a lot the vaadin app.\nSame thing for widgetset generated JS if the app embed modified custom widgets.\nTo solve this we should be able to programmatically setup application version and/or theme version so that vaadinBootstrap.js tells the browser to download the latest versions. For example for theme:\nYou could replace line 233 in vaadinBootstrap.js: <CODE> with <CODE> And allow to programmatically set themeVersion somewhere (SystemVersionsProvider like SystemMessagesProvider ?) For widgetset we could use applicationVersion within versionInfo object. ", "code": ["loadTheme(themeUri, versionInfo && versionInfo['vaadinVersion']);\n", "if (versionInfo && versionInfo['themeVersion'])\n    loadTheme(themeUri, versionInfo['themeVersion']);\nelse\n    loadTheme(themeUri, versionInfo && versionInfo['vaadinVersion']);\n\n"], "labels": ["enhancement"]}
{"project": "woocommerce_woocommerce", "title": "SKU not showing on all products and variable products images not changing on change size.", "description": "Installed the newest version of woocommerce. After the update i got some problems. SKU won't show on any product.\nAfter adding a new image to a variable product (it says sold out)\nAnd normally i can swap between sizes in products and te product image will be change form for example 1 litre to 5 litre. (small bottle to big bottle) ", "code": [], "labels": ["question"]}
{"project": "sqlitebrowser_sqlitebrowser", "title": "Crash when running query with columns selected for plot", "description": "Sometimes when re-running a query previously executed with columns already selected for plotting the\nsoftware would throw an index out of range error. The error happens in execution of  I found that sometimes the variables xdata and ydata differ in size with the limit used for the iteration loop.\nAssigning rowCount to a local variable and using it instead of function calls fixes the out of range error\nbut only part of the data is plotted. The table shows the complete data returned by the query. Version 3.10.1 in the debian repositores don't suffer from this problem. ", "code": [], "labels": ["crash", "bug"]}
{"project": "ytti_oxidized", "title": "fix memory leak", "description": "Oxidized probably leaks memory: aug 14th\nrancid   14581  5.1 26.6 1186764 271472 pts/9  Sl+  Jul29 1191:01 ruby /var/rancid//.rvm/gems/ruby-2.1.2/bin/oxidized aug 19th\nrancid   14581  5.5 27.6 1187792 281764 pts/9  Sl+  Jul29 1683:14 ruby /var/rancid//.rvm/gems/ruby-2.1.2/bin/oxidized This is with some 4k nodes (with 1h rotation), some new boxes may have been added in between, but shouldn't explain the increase. I've done some research into this, but it's not exactly trivial to troubleshoot memory use in MRI. It might also be better if instead trying to fix this, we refactor Nodes class out or at least make keep in memory at once only nodes being worked on, store it in disk in SQLite and get data from there. Would also give persistence on stats etc. ", "code": [], "labels": ["bug"]}
{"project": "openhab_openhab-addons", "title": "[vitotronic] VitotronicThingHandler does not handle the command REFRESH", "description": "VitotronicThingHandler should handle the framework command REFRESH Framework command REFRESH sent to optolink daemon, which cannot handle it Filter the REFRESH command and do not send it to the optolink daemon. ", "code": [], "labels": ["bug"]}
{"project": "tendermint_tendermint", "title": "docs: signature spec link is broken", "description": "On <URL> See the signature spec for more. => 404 ", "code": [], "labels": ["good first issue", "help wanted", "docs"]}
{"project": "gevent_gevent", "title": "SSLSocket.recv sometimes returns str or bytes", "description": "I'm having some trouble cleanly reproducing this, and may try more next week, but figured I'd submit this bug in case the problem is obvious: I'm running python 3.4 with gevent 1.1b6.  I have a class that inherits from WSGIServer that handles connections with: My log file shows: <CODE> SSLSocket should presumably consistently return bytes, rather than sometimes str or bytes.  (I've fixed the code above to \"if not data\" instead.) ", "code": ["Sat Jan 23 02:15:58 2016 INFO: data is , <class 'str'>\nSat Jan 23 02:15:58 2016 INFO: sock is <gevent._ssl3.SSLSocket object, fd=43, family=2, type=2049, proto=0>, <class 'gevent._ssl3.SSLSocket'>\nSat Jan 23 02:18:13 2016 INFO: data is b'', <class 'bytes'>\nSat Jan 23 02:18:13 2016 INFO: sock is <gevent._ssl3.SSLSocket object, fd=25, family=2, type=2049, proto=0>, <class 'gevent._ssl3.SSLSocket'>\n"], "labels": ["python3"]}
{"project": "moezbhatti_qksms", "title": "Deleting conversation resets block status", "description": "Currently, we store the blocked status of a conversation in the conversation model itself. This means that when the user deletes it, we no longer know if it should be blocked or not - and future messages that belong to that conversation will appear as normal unblocked messages We notice a similar effect of this with other conversation preferences like the theme and notification settings, but these are slightly less important to retain than the block status ", "code": [], "labels": ["bug"]}
{"project": "roundcube_roundcubemail", "title": "Drag and drop images into mail editor", "description": "Reported by thomasysliu on 25 Dec 2010 12:19 UTC as Trac ticket #1487651 When writing a mail, it often helps to augment text with images and diagrams. If there is a way to drag and drop image into mail editor <URL> Migrated-From: <URL> ", "code": [], "labels": ["worksforme", "enhancement", "C: User Interface"]}
{"project": "the-control-group_voyager", "title": "Table Columns Not Populated While Editing BREAD Relationships When voyager.prefix is set to ''", "description": "Due to a preference of the use of subdomain (e.g. admin.*) to prefix (e.g. site/admin), I set the voyager.prefix in voyager config to '' (empty string) and have done the same in my routes. So, my route(voyager.database.index), for instance, corresponds to '/database' and not '/admin/database' as default in voyager. Because of the route change, the JS script that loads table columns from table while editing a relationship between BREADs tries reaching out to the wrong url: '/admin/database/{table_name}' ", "code": [], "labels": ["question"]}
{"project": "notepad-plus-plus_notepad-plus-plus", "title": "Compare plugin started from CMD: comparison won't start automatically since N++ 7.6.6", "description": "Hi there.\nI don't know if this is the right place to ask, because it is about a plugin, but the issue appeared after the latest Notepad++ update so I thought it should be here. Plus the original author of the plugin left the project. Feel free to close this and tell me if this isn't the right place. I'm using the Compare plugin for Notepad++, and I have setup a commandline tool to launch Notepad++, open two files and automatically launch the comparison between them.\nThis has required me to download the Compare.exe file as explained in this Stackoverflow answer and put it in the Notepad++\\plugins\\ComparePlugin folder. Then, the files are called this way: <CODE> Now this used to work great, but yesterday there was a Notepad++ update (7.6.6), and since I installed it, the comparison doesn't start automatically anymore. Notepad++ opens the two files, and lauches comparison between them. 1st file (file1.txt) is on the left, 2nd file (file2.txt) is on the right. Notepad++ opens the two files (file1.txt in the first tab, file2.txt in the second tab), but it doesn't start the comparison. You have to manually launch the comparison, by clicking on the Compare button of the toolbar. Notepad++ v7.6.6   (32-bit)\nBuild time : Apr  3 2019 - 23:49:50\nPath : C:\\Program Files (x86)\\Notepad++\\notepad++.exe\nAdmin mode : OFF\nLocal Conf mode : OFF\nOS : Windows 10 (64-bit)\nPlugins : ComparePlugin.dll mimeTools.dll NppConverter.dll NppExport.dll Thanks by advance to anyone who can help! ", "code": ["\"C:\\Program Files (x86)\\Notepad++\\plugins\\ComparePlugin\\compare.exe\" \"C:\\file1.txt\" \"C:\\file2.txt\"\n"], "labels": ["plugin", "question"]}
{"project": "hazelcast_hazelcast", "title": "SetBasicDistributedTest.testNameBasedAffinity failure", "description": "maintenance (commit bee5a96) Failed on IBM JDK7: <URL> Stacktrace: <CODE> Standard output: <CODE> ", "code": ["org.junit.runners.model.TestTimedOutException: test timed out after 300000 milliseconds\n\tat java.io.BufferedInputStream.<init>(BufferedInputStream.java:207)\n\tat java.io.BufferedInputStream.<init>(BufferedInputStream.java:187)\n\tat sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:104)\n\tat sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:202)\n\tat java.net.URL.openStream(URL.java:1061)\n\tat com.hazelcast.util.ServiceLoader.parse(ServiceLoader.java:132)\n\tat com.hazelcast.util.ServiceLoader.getServiceDefinitions(ServiceLoader.java:92)\n\tat com.hazelcast.util.ServiceLoader.classIterator(ServiceLoader.java:78)\n\tat com.hazelcast.util.ServiceLoader.iterator(ServiceLoader.java:72)\n\tat com.hazelcast.internal.serialization.impl.PortableHookLoader.load(PortableHookLoader.java:49)\n\tat com.hazelcast.internal.serialization.impl.PortableHookLoader.<init>(PortableHookLoader.java:44)\n\tat com.hazelcast.internal.serialization.impl.SerializationServiceV1.<init>(SerializationServiceV1.java:89)\n\tat com.hazelcast.internal.serialization.impl.SerializationServiceV1$Builder.build(SerializationServiceV1.java:313)\n\tat com.hazelcast.internal.serialization.impl.DefaultSerializationServiceBuilder.createSerializationService(DefaultSerializationServiceBuilder.java:290)\n\tat com.hazelcast.internal.serialization.impl.DefaultSerializationServiceBuilder.build(DefaultSerializationServiceBuilder.java:243)\n\tat com.hazelcast.internal.serialization.impl.DefaultSerializationServiceBuilder.build(DefaultSerializationServiceBuilder.java:56)\n\tat com.hazelcast.instance.DefaultNodeExtension.createSerializationService(DefaultNodeExtension.java:188)\n\tat com.hazelcast.instance.Node.<init>(Node.java:209)\n\tat com.hazelcast.instance.HazelcastInstanceImpl.createNode(HazelcastInstanceImpl.java:164)\n\tat com.hazelcast.instance.HazelcastInstanceImpl.<init>(HazelcastInstanceImpl.java:132)\n\tat com.hazelcast.instance.HazelcastInstanceFactory.constructHazelcastInstance(HazelcastInstanceFactory.java:196)\n\tat com.hazelcast.instance.HazelcastInstanceFactory.newHazelcastInstance(HazelcastInstanceFactory.java:175)\n\tat com.hazelcast.test.TestHazelcastInstanceFactory.newHazelcastInstance(TestHazelcastInstanceFactory.java:112)\n\tat com.hazelcast.collection.impl.set.SetBasicDistributedTest.newInstances(SetBasicDistributedTest.java:42)\n\tat com.hazelcast.collection.impl.set.SetAbstractTest.testNameBasedAffinity(SetAbstractTest.java:285)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:56)\n\tat java.lang.reflect.Method.invoke(Method.java:620)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat com.hazelcast.test.FailOnTimeoutStatement$CallableStatement.call(FailOnTimeoutStatement.java:105)\n\tat com.hazelcast.test.FailOnTimeoutStatement$CallableStatement.call(FailOnTimeoutStatement.java:97)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:274)\n\tat java.lang.Thread.run(Thread.java:809)\n", "BuildInfo right after testNameBasedAffinity(com.hazelcast.collection.impl.set.SetBasicDistributedTest): BuildInfo{version='3.10.5-SNAPSHOT', build='20180814', buildNumber=20180814, revision=bee5a96, enterprise=false, serializationVersion=1}\nHiccups measured while running test 'testNameBasedAffinity(com.hazelcast.collection.impl.set.SetBasicDistributedTest):'\n10:52:10, accumulated pauses: 1349 ms, max pause: 589 ms, pauses over 1000 ms: 0\n10:52:15, accumulated pauses: 4537 ms, max pause: 1607 ms, pauses over 1000 ms: 2\n10:52:20, accumulated pauses: 4327 ms, max pause: 982 ms, pauses over 1000 ms: 0\n10:52:25, accumulated pauses: 6303 ms, max pause: 1927 ms, pauses over 1000 ms: 3\n10:52:30, accumulated pauses: 3766 ms, max pause: 1673 ms, pauses over 1000 ms: 2\n10:52:35, accumulated pauses: 4859 ms, max pause: 1862 ms, pauses over 1000 ms: 3\n10:52:40, accumulated pauses: 4803 ms, max pause: 1869 ms, pauses over 1000 ms: 3\n10:52:45, accumulated pauses: 5093 ms, max pause: 1893 ms, pauses over 1000 ms: 3\n10:52:50, accumulated pauses: 5881 ms, max pause: 1757 ms, pauses over 1000 ms: 4\n10:52:55, accumulated pauses: 4211 ms, max pause: 1874 ms, pauses over 1000 ms: 3\n10:53:00, accumulated pauses: 4873 ms, max pause: 3181 ms, pauses over 1000 ms: 2\n10:53:05, accumulated pauses: 4893 ms, max pause: 1550 ms, pauses over 1000 ms: 3\n10:53:10, accumulated pauses: 5122 ms, max pause: 1940 ms, pauses over 1000 ms: 3\n10:53:15, accumulated pauses: 6500 ms, max pause: 1911 ms, pauses over 1000 ms: 3\n10:53:20, accumulated pauses: 3103 ms, max pause: 1460 ms, pauses over 1000 ms: 2\n10:53:25, accumulated pauses: 5891 ms, max pause: 1882 ms, pauses over 1000 ms: 2\n10:53:30, accumulated pauses: 4211 ms, max pause: 1877 ms, pauses over 1000 ms: 2\n10:53:35, accumulated pauses: 5245 ms, max pause: 1899 ms, pauses over 1000 ms: 2\n10:53:40, accumulated pauses: 4622 ms, max pause: 1822 ms, pauses over 1000 ms: 3\n10:53:45, accumulated pauses: 4772 ms, max pause: 1970 ms, pauses over 1000 ms: 3\n10:53:50, accumulated pauses: 5735 ms, max pause: 1767 ms, pauses over 1000 ms: 3\n10:53:55, accumulated pauses: 4880 ms, max pause: 1696 ms, pauses over 1000 ms: 3\n10:54:00, accumulated pauses: 5179 ms, max pause: 1598 ms, pauses over 1000 ms: 3\n10:54:05, accumulated pauses: 5241 ms, max pause: 1704 ms, pauses over 1000 ms: 3\n10:54:10, accumulated pauses: 5142 ms, max pause: 1668 ms, pauses over 1000 ms: 3\n10:54:15, accumulated pauses: 3547 ms, max pause: 860 ms, pauses over 1000 ms: 0\n10:54:20, accumulated pauses: 5877 ms, max pause: 1753 ms, pauses over 1000 ms: 3\n10:54:25, accumulated pauses: 4978 ms, max pause: 1393 ms, pauses over 1000 ms: 3\n10:54:30, accumulated pauses: 4274 ms, max pause: 1763 ms, pauses over 1000 ms: 2\n10:54:35, accumulated pauses: 4973 ms, max pause: 1713 ms, pauses over 1000 ms: 3\n10:54:40, accumulated pauses: 4911 ms, max pause: 1642 ms, pauses over 1000 ms: 3\n10:54:45, accumulated pauses: 4835 ms, max pause: 1692 ms, pauses over 1000 ms: 3\n10:54:50, accumulated pauses: 5788 ms, max pause: 1474 ms, pauses over 1000 ms: 4\n10:54:55, accumulated pauses: 3956 ms, max pause: 1710 ms, pauses over 1000 ms: 2\n10:55:00, accumulated pauses: 5580 ms, max pause: 1654 ms, pauses over 1000 ms: 3\n10:55:05, accumulated pauses: 4453 ms, max pause: 1387 ms, pauses over 1000 ms: 1\n10:55:10, accumulated pauses: 6049 ms, max pause: 1551 ms, pauses over 1000 ms: 3\n10:55:15, accumulated pauses: 3949 ms, max pause: 1582 ms, pauses over 1000 ms: 3\n10:55:20, accumulated pauses: 5294 ms, max pause: 1611 ms, pauses over 1000 ms: 2\n10:55:25, accumulated pauses: 5053 ms, max pause: 1640 ms, pauses over 1000 ms: 3\n10:55:30, accumulated pauses: 5149 ms, max pause: 1544 ms, pauses over 1000 ms: 3\n10:55:35, accumulated pauses: 5150 ms, max pause: 1501 ms, pauses over 1000 ms: 2\n10:55:40, accumulated pauses: 4144 ms, max pause: 801 ms, pauses over 1000 ms: 0\n10:55:45, accumulated pauses: 5689 ms, max pause: 1238 ms, pauses over 1000 ms: 3\n10:55:50, accumulated pauses: 4232 ms, max pause: 1438 ms, pauses over 1000 ms: 2\n10:55:55, accumulated pauses: 5396 ms, max pause: 1305 ms, pauses over 1000 ms: 3\n10:56:00, accumulated pauses: 4448 ms, max pause: 1284 ms, pauses over 1000 ms: 3\n10:56:05, accumulated pauses: 5017 ms, max pause: 1351 ms, pauses over 1000 ms: 2\n10:56:10, accumulated pauses: 5284 ms, max pause: 1501 ms, pauses over 1000 ms: 3\n10:56:15, accumulated pauses: 4559 ms, max pause: 1214 ms, pauses over 1000 ms: 1\n10:56:20, accumulated pauses: 4484 ms, max pause: 1280 ms, pauses over 1000 ms: 2\n10:56:25, accumulated pauses: 6000 ms, max pause: 1345 ms, pauses over 1000 ms: 3\n10:56:30, accumulated pauses: 3919 ms, max pause: 1349 ms, pauses over 1000 ms: 2\n10:56:35, accumulated pauses: 5351 ms, max pause: 1314 ms, pauses over 1000 ms: 4\n10:56:40, accumulated pauses: 4975 ms, max pause: 1178 ms, pauses over 1000 ms: 3\n10:56:45, accumulated pauses: 5475 ms, max pause: 1359 ms, pauses over 1000 ms: 2\n10:56:50, accumulated pauses: 4091 ms, max pause: 1066 ms, pauses over 1000 ms: 1\n10:56:55, accumulated pauses: 5017 ms, max pause: 1124 ms, pauses over 1000 ms: 3\n10:57:00, accumulated pauses: 4710 ms, max pause: 1311 ms, pauses over 1000 ms: 1\n10:57:05, accumulated pauses: 5264 ms, max pause: 1208 ms, pauses over 1000 ms: 3\n10:57:10, accumulated pauses: 4873 ms, max pause: 1312 ms, pauses over 1000 ms: 2\n10:57:15, accumulated pauses: 946 ms, max pause: 946 ms, pauses over 1000 ms: 0\n10:58:20, accumulated pauses: 69115 ms, max pause: 69115 ms, pauses over 1000 ms: 1\n10:58:25, accumulated pauses: 4900 ms, max pause: 1271 ms, pauses over 1000 ms: 3\n10:58:30, accumulated pauses: 4941 ms, max pause: 1142 ms, pauses over 1000 ms: 2\n10:58:35, accumulated pauses: 5201 ms, max pause: 1092 ms, pauses over 1000 ms: 2\n10:58:40, accumulated pauses: 4480 ms, max pause: 1167 ms, pauses over 1000 ms: 1\n10:58:45, accumulated pauses: 5254 ms, max pause: 1127 ms, pauses over 1000 ms: 2\n10:58:50, accumulated pauses: 4847 ms, max pause: 1122 ms, pauses over 1000 ms: 3\n10:58:55, accumulated pauses: 4492 ms, max pause: 1058 ms, pauses over 1000 ms: 3\n10:59:00, accumulated pauses: 5541 ms, max pause: 1086 ms, pauses over 1000 ms: 2\n10:59:05, accumulated pauses: 4228 ms, max pause: 1058 ms, pauses over 1000 ms: 1\n10:59:10, accumulated pauses: 5417 ms, max pause: 1102 ms, pauses over 1000 ms: 1\n10:59:15, accumulated pauses: 4636 ms, max pause: 954 ms, pauses over 1000 ms: 0\n10:59:20, accumulated pauses: 4579 ms, max pause: 919 ms, pauses over 1000 ms: 0\n10:59:25, accumulated pauses: 5493 ms, max pause: 946 ms, pauses over 1000 ms: 0\n10:59:30, accumulated pauses: 5024 ms, max pause: 921 ms, pauses over 1000 ms: 0\n10:59:35, accumulated pauses: 4337 ms, max pause: 928 ms, pauses over 1000 ms: 0\n10:59:40, accumulated pauses: 5114 ms, max pause: 827 ms, pauses over 1000 ms: 0\n10:59:45, accumulated pauses: 4719 ms, max pause: 1027 ms, pauses over 1000 ms: 2\n10:59:50, accumulated pauses: 4993 ms, max pause: 1018 ms, pauses over 1000 ms: 1\n10:59:55, accumulated pauses: 4884 ms, max pause: 905 ms, pauses over 1000 ms: 0\n11:00:00, accumulated pauses: 5367 ms, max pause: 965 ms, pauses over 1000 ms: 0\n11:00:05, accumulated pauses: 4622 ms, max pause: 905 ms, pauses over 1000 ms: 0\n11:00:10, accumulated pauses: 4983 ms, max pause: 1241 ms, pauses over 1000 ms: 1\n11:00:15, accumulated pauses: 4862 ms, max pause: 862 ms, pauses over 1000 ms: 0\n11:00:20, accumulated pauses: 4570 ms, max pause: 919 ms, pauses over 1000 ms: 0\n11:00:25, accumulated pauses: 5152 ms, max pause: 781 ms, pauses over 1000 ms: 0\n11:00:30, accumulated pauses: 5024 ms, max pause: 822 ms, pauses over 1000 ms: 0\n11:00:35, accumulated pauses: 4737 ms, max pause: 761 ms, pauses over 1000 ms: 0\n11:00:40, accumulated pauses: 5433 ms, max pause: 839 ms, pauses over 1000 ms: 0\n11:00:45, accumulated pauses: 4471 ms, max pause: 892 ms, pauses over 1000 ms: 0\n11:00:50, accumulated pauses: 4844 ms, max pause: 776 ms, pauses over 1000 ms: 0\n11:00:55, accumulated pauses: 4903 ms, max pause: 753 ms, pauses over 1000 ms: 0\n11:01:00, accumulated pauses: 4892 ms, max pause: 697 ms, pauses over 1000 ms: 0\n11:01:05, accumulated pauses: 4545 ms, max pause: 655 ms, pauses over 1000 ms: 0\n11:01:10, accumulated pauses: 5159 ms, max pause: 647 ms, pauses over 1000 ms: 0\n11:01:15, accumulated pauses: 5073 ms, max pause: 609 ms, pauses over 1000 ms: 0\n11:01:20, accumulated pauses: 4783 ms, max pause: 563 ms, pauses over 1000 ms: 0\n11:01:25, accumulated pauses: 4711 ms, max pause: 537 ms, pauses over 1000 ms: 0\n11:01:30, accumulated pauses: 4773 ms, max pause: 560 ms, pauses over 1000 ms: 0\n11:01:35, accumulated pauses: 4848 ms, max pause: 499 ms, pauses over 1000 ms: 0\n11:01:40, accumulated pauses: 4773 ms, max pause: 517 ms, pauses over 1000 ms: 0\n11:01:45, accumulated pauses: 4774 ms, max pause: 500 ms, pauses over 1000 ms: 0\n11:01:50, accumulated pauses: 4725 ms, max pause: 458 ms, pauses over 1000 ms: 0\n11:01:55, accumulated pauses: 4818 ms, max pause: 426 ms, pauses over 1000 ms: 0\n11:02:00, accumulated pauses: 4776 ms, max pause: 390 ms, pauses over 1000 ms: 0\n11:02:05, accumulated pauses: 4776 ms, max pause: 352 ms, pauses over 1000 ms: 0\n11:02:10, accumulated pauses: 4797 ms, max pause: 311 ms, pauses over 1000 ms: 0\n11:02:15, accumulated pauses: 4758 ms, max pause: 266 ms, pauses over 1000 ms: 0\n11:02:20, accumulated pauses: 4490 ms, max pause: 205 ms, pauses over 1000 ms: 0\n11:02:25, accumulated pauses: 4534 ms, max pause: 198 ms, pauses over 1000 ms: 0\n11:02:30, accumulated pauses: 4341 ms, max pause: 126 ms, pauses over 1000 ms: 0\n11:02:35, accumulated pauses: 2579 ms, max pause: 85 ms, pauses over 1000 ms: 0\n11:02:40, accumulated pauses: 25 ms, max pause: 0 ms, pauses over 1000 ms: 0\n"], "labels": ["Team: Core", "Type: Test-Failure"]}
{"project": "vaadin_framework", "title": "button border offset in chrome", "description": "Originally by mwaschkowski When you zoom in/out, the buttons don't display properly. In chrome, the left side of the button is offset. In IE, some artifacts appear around the button. chrome v.11.0.696.60 (see attachment) tested in IE as well, and saw some artifacts around the buttons (IE v.8.0.7600.16385) Tested using the sampler, zoomed in/out with mouse wheel. Imported from <URL> issue #6939 ", "code": [], "labels": ["bug"]}
{"project": "rails_rails", "title": "why not run destroy callbacks when updating assoication_ids", "description": "<CODE> Rails version: 5.0.1 Ruby version: 2.3.1 ", "code": ["class Tag < ActiveRecord::Base\n  has_many :taggings\nend\n\nclass Tagging < ActiveRecord::Base\n  belongs_to :tag\n  belongs_to :car\nend\n\nclass Car < ActiveRecord::Base\n  has_many :taggings\n  has_many :tags, through: :taggings\nend\n\nCar.first.update tag_ids: []\n# if create tagging, it will execute callbacks,\n# but if destroy tagging, it will not execute callbacks.\n"], "labels": ["stale", "activerecord"]}
{"project": "mrdoob_three.js", "title": "OrbitControls : zoom damping ?", "description": "Few months ago #12179 was sent to provide OrbitControls with damping when zooming and panning, as this behaviour already exists when orbitting in OrbitControls, and for all actions in TrackballControls. In my opinion we can propose a smoother experience this way and I've been happy to use this version until now. The PR didn't go well however, may have looked surprising for any reason etc. Another way to go with this PR has been suggested in its last message but no news about it. So opening this issue instead : is damping for pan and zoom something developpers can benefit ? Or should this PR be closed ? Or is another one prefered ? If yes, what should be done differently ? Thanks ! ", "code": [], "labels": ["Question"]}
{"project": "roundcube_roundcubemail", "title": "Attachments not visible", "description": "Reported by simplexe on 22 Jul 2009 05:38 UTC as Trac ticket #1485991 Hi!\nI found yet another bug)\nIf the attached letters to more than 7-8 files, then the following file names do not fit in the panel and the attachment is not visible. Migrated-From: <URL> ", "code": [], "labels": ["worksforme", "bug", "C: User Interface"]}
{"project": "brave_brave-browser", "title": "Manual test run on OS X for 0.66.x - Release Hotfix 2 (Release Channel)", "description": "", "code": [], "labels": ["QA Pass-macOS", "QA/Yes", "tests", "release-notes/exclude", "OS/macOS"]}
{"project": "gohugoio_hugo", "title": "Odd live reload issue", "description": "While testing something completely different I found some odd behavour on my PC vs live reload when changing bundled images (and I guess bundled resources in general). I don't think this is a new issue, but I'll try to debug and fix it in a patch release. ", "code": [], "labels": ["Bug"]}
{"project": "ant-design_ant-design", "title": "4.0\u7248\u672cTree\u63a7\u4ef6\u5220\u9664\u8282\u70b9\u51fa\u9519", "description": " \u70b9\u51fb\u5220\u9664\u8282\u70b9\u62a5\u9519\uff1a \u6b63\u5e38\u5220\u9664 \u51fa\u9519 ", "code": [], "labels": [" Bug", "4.x"]}
{"project": "palantir_plottable", "title": "Enable 'object constancy' on data refresh by supporting a key function", "description": "'Object constancy' , as defined in <URL> ,\nrequires a 'key' function passed to selection.data()  to provide a unique identifier for each datum. This determines what goes in enter exit and update selections. Could dataset get a key method, and/or enhanced constructor, to specify this key function? Then, we'd need some way to get to the enter exit and update d3 transitions. ", "code": [], "labels": ["Type: Feature Request"]}
{"project": "kubernetes_kops", "title": "DO: Figure out a safer way to distribute DO_ACCESS_TOKEN", "description": "The DIGITALOCEAN_ACCESS_TOKEN is currently embed in the droplets user-data, which from a security perspective isn't ideal, as the user-data is freely available from every single pod in the cluster (curl <URL> Edit: I'm not 100% sure about this, as I did test on a bootkube cluster (kops does not work with DO and a AWS S3 bucket I figured out), but nevertheless I don't like that the token is stored in the user-data. Short-term:\nConfigure a local firewall rule as default, to limit access to the metadata service? Long-term:\nUse something else instead of DIGITALOCEAN_ACCESS_TOKEN. If someone manage to comprise a server and get hold on the token, they could delete everything. cc @andrewsykim ", "code": [], "labels": ["lifecycle/rotten"]}
{"project": "bumptech_glide", "title": "recycle put crash,but i closed memoryCache and no diskCache", "description": "glide-version\ncom.github.bumptech.glide:glide:4.3.1: devices :galaxy s8+ os:android8.0 code:\nImageUtil.getGlide(context, null, null)\n.asBitmap()\n.skipMemoryCache(true)\n.diskCacheStrategy(DiskCacheStrategy.NONE)\n.load(url)\n.into(callBack); error:\nwhen activity onDestory(),i destory bitmap\nthen throw \uff1a\nCannot pool recycled bitmap\ncom.bumptech.glide.load.engine.bitmap_recycle.LruBitmapPool.put(LruBitmapPool.java:86) expect\uff1a\nit colsed cache ,but why recylePool invoke put bitmap,this is a bug, it should be no cache no pool put ", "code": [], "labels": ["stale"]}
{"project": "sequelize_sequelize", "title": "String based operators are now deprecated", "description": "Hi, I've faced with next warning: <CODE> Can anyone explain what this means? Most queries in my app look like this: <CODE> What should I change? Thanks ", "code": ["sequelize deprecated String based operators are now deprecated. Please use Symbol based operators for better security, read more at http://docs.sequelizejs.com/manual/tutorial/querying.html#operators node_modules/sequelize/lib/sequelize.js:236:13\n", "User.findOne({\n                where: { id: userId },\n                attributes: [['id', 'uid'], 'name', 'gender', 'birthday', 'age', 'photoId', 'countryId', 'status'],\n                limit: 1,\n                raw: true\n            })\n"], "labels": ["question"]}
{"project": "microsoft_vscode-pull-request-github", "title": "SyntaxError: Unexpected end of JSON input", "description": "I see this in developer tools in one window. I haven't been using the extension in this window. I see it every time I reload the window. It's a multiroot workspace if that helps. <CODE> ", "code": [" ERR Unexpected end of JSON input: SyntaxError: Unexpected end of JSON input\n    at JSON.parse (<anonymous>)\n    at Object.t.fromPRUri (/Users/roblou/.vscode-insiders/extensions/github.vscode-pull-request-github-insiders-0.345.0/media/extension.js:1:53851)\n    at t.FileTypeDecorationProvider.provideDecoration (/Users/roblou/.vscode-insiders/extensions/github.vscode-pull-request-github-insiders-0.345.0/media/extension.js:8:6595)\n    at /Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:529:104\n    at Array.map (<anonymous>)\n    at e.$provideDecorations (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:528:972)\n    at t._doInvokeHandler (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:658:837)\n    at t._invokeHandler (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:658:509)\n    at t._receiveRequest (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:657:60)\n    at t._receiveOneMessage (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:656:59)\n    at /Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:653:895\n    at /Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:130:793\n    at e.fire (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:133:218)\n    at a (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:186:147)\n    at Socket.n._socketDataListener (/Applications/Visual Studio Code - Insiders.app/Contents/Resources/app/out/vs/workbench/node/extensionHostProcess.js:186:368)\n    at emitOne (events.js:116:13)\n    at Socket.emit (events.js:211:7)\n    at addChunk (_stream_readable.js:263:12)\n    at readableAddChunk (_stream_readable.js:250:11)\n    at Socket.Readable.push (_stream_readable.js:208:10)\n    at Pipe.onread (net.js:594:20)\n"], "labels": ["bug"]}
{"project": "vaadin_framework", "title": "Displaying component information in read-only mode.", "description": "Originally by krosh08 Vaadin 7.2.3 release removed input prompt from read-only or disabled ComboBox component (see #10573). However, it would be quite useful to display information in the component without setting the component's value. For example, if we want to display default application values (values, which the application will use if no user input is made). We suggest an additional API call to be added for this purpose. For example, setEmptyValueInfo()\nIf set, this information will be displayed in read-only mode of the component that has no value in the input-prompt-fashion (grayed out). In edit mode the input prompt will take precedence if specified. This should be applicable to all the Vaadin components, which allow input prompt (hint). Imported from <URL> issue #14676 ", "code": [], "labels": ["Stale"]}
{"project": "godotengine_godot", "title": "File Dialog modal closes on hidden file toggle keyboard shortcut after item selected and deselected", "description": "This issue also causes the editor to stay darkened once the modal is closed as per issue #30368\nGodot version: d897131 OS/device including version: Arch Linux Issue description: File Dialog modal closes on hidden file toggle keyboard shortcut after item selected and deselected. Expected behavior is a toggle that shows hidden files. Steps to reproduce: Minimal reproduction project: godot-darkened-after-dialog-shortcut.zip ", "code": [], "labels": ["topic:editor", "bug"]}
{"project": "flutter_flutter", "title": "Add2App passing data back and forth between Flutter view and native view is verbose", "description": "As shared in my Hackernoon article for Android, but it is similar in iOS Right now, developers can achieve it by themselves by wiring event channel and method channel to pass data back and forth between Flutter activity/view and native activity/view, but it is verbose to make it idiomatic for native developers. I think the framework can have some support to reduce the boilerplate code. ", "code": [], "labels": ["severe: new feature"]}
{"project": "ionic-team_ionic", "title": "perf: Modal is not working", "description": "Type: perf Platform: all I've used 3 modals in my whole code. but only this modal is not working.\nWhen I press the 'etc' button, it is clicked, but anything is happened.\nWhat is the problem? I think I've checked 'z-index' as well.\nHere is my code.   ", "code": [], "labels": ["ionitron:closed"]}
{"project": "joomla_joomla-cms", "title": "Nested Subforms not saving values", "description": "Create a module. Add a repeatable subform(lvl1). Inside this subform add another subform(lvl2). It should load the subforms from lvl1 & lvl2 and save the values from both subforms. It loads alright but it does not save any value from lvl2 or any deeper lvl if you created those (lvl3, 4, 5). Latest Joomla, PHP 7.10 This happens whenever you include a subform from the same module and even when you grab them out of another module. Especially with the latest you quickly get into trouble because whenever you pick a module that already has a subform init then it won't work. Which I believe one of the reason the subform was created in the first place. Don't get me wrong I love the subform and the functionality but I also think that nested subforms should work! I created a SO issue before I posted in here: <URL> It might hold some more valuable information. ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "gophish_gophish", "title": "Error when inserting email template when {{.BaseURL}} is used", "description": "Thanks for reaching out! We're happy to help resolve issues as quickly as possible. Please use this template when creating a new issue. If you do not follow this template format, your issue may be closed without comment. Before filing a new issue, please use the search bar at the top of the browser to search for similar issues. Also, please make sure you have read our documentation, which covers how to use Gophish. What version of Gophish are you using?:\nVersion 0.7 Brief description of the issue:\nI noticed from the commits that {{.BaseURL}} has been added as a templating reference, and I wanted to try it out. But it seems that there is an error inserting the email template when using {{.BaseURL}} Is it not supported yet? What are you expecting to see happen? :\nThe template is inserted, and when used the {{.BaseURL}} is replaced with the URL specified in the campaign What are you seeing happen?\nThe email template is not inserted. However, when the {{.BaseURL}} is removed from the template is is inserted into the database. If this question is related to email templates or landing pages not working as expected, please provide your template or landing page below: <CODE> Please provide any terminal output that may be relevant below: <CODE> Please provide as many steps as you can to reproduce the problem: ", "code": ["<html>\n    <body style=\"background-color: white;\">\n        <table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" style=\"width: 600px; background-color: #aaa;\" align=\"center\">\n            <tr>\n                <td style=\"background-color: #222; color: white; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 24pt; text-align: center;\">\n                    This is a test of GoPhish 0.7\n                </td>\n            </tr>\n            <tr>\n                <td style=\"padding: 20px; text-align: center; color: white; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14pt;\">\n                    Here should be a picture below using baseURL: {{.BaseURL}}<br>\n                    <center><img src=\"{{.BaseURL}}/static/test-image.png\"></center>\n                </td>\n            </tr>\n\n            <tr>\n                <td style=\"padding: 20px; text-align: center; color: white; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14pt;\">\n                    ... and here should be a link for the webpage {{.URL}}<br>\n                    <a href=\"{{.URL}}\">URL</a>\n                </td>\n            </tr>\n        </table>\n    </body>\n</html>\n", "time=\"2018-09-07T10:48:39+02:00\" level=error msg=\"template: template:12:191: executing \\\"template\\\" at <.BaseURL>: can't evaluate field BaseURL in type struct { models.Result; URL string; TrackingURL string; Tracker string; From string }\"\n"], "labels": ["bug", "high-priority"]}
{"project": "saltstack_salt", "title": "file.managed name corruption", "description": "Salt appears to be leaking memory with the name string for some of the file.managed entries: highstate: <CODE> Output from highstate: <CODE> Salt-call state.highstate: <CODE> Somehow garbage was appended to the name 'scaling_min_freq' vs 'scaling_min_freqxYi0OJ'. Version info: <CODE> ", "code": ["    cpu31_max_freq:\n        ----------\n        __env__:\n            base\n        __sls__:\n            ncar.cpu.sandybridge.compute\n        file:\n            ----------\n            - contents_pillar:\n                cpu:max_frequency\n            ----------\n            - name:\n                /sys/devices/system/cpu/cpu31/cpufreq/scaling_min_freq\n            - managed\n            ----------\n            - order:\n                10132\n", "    State: - file\n    Name:      /sys/devices/system/cpu/cpu31/cpufreq/scaling_min_freq\n    Function:  managed\n        Result:    False\n        Comment:   An exception occurred in this state: Traceback (most recent call last):\n  File \"/usr/lib/python2.6/site-packages/salt/state.py\", line 1305, in call\n    *cdata['args'], **cdata['kwargs'])\n  File \"/usr/lib/python2.6/site-packages/salt/states/file.py\", line 1157, in managed\n    dir_mode)\n  File \"/usr/lib/python2.6/site-packages/salt/modules/file.py\", line 2053, in manage_file\n    __opts__['cachedir'])\n  File \"/usr/lib/python2.6/site-packages/salt/utils/__init__.py\", line 603, in copyfile\n    tgt = mkstemp(prefix=bname, dir=dname)\n  File \"/usr/lib/python2.6/site-packages/salt/utils/__init__.py\", line 1000, in mkstemp\n    fd_, fpath = tempfile.mkstemp(*args, **kwargs)\n  File \"/usr/lib64/python2.6/tempfile.py\", line 293, in mkstemp\n    return _mkstemp_inner(dir, prefix, suffix, flags)\n  File \"/usr/lib64/python2.6/tempfile.py\", line 228, in _mkstemp_inner\n    fd = _os.open(file, flags, 0600)\nOSError: [Errno 2] No such file or directory: '/sys/devices/system/cpu/cpu31/cpufreq/scaling_min_freqxYi0OJ'\n\n        Changes:   \n", "[INFO    ] Executing state file.managed for /sys/devices/system/cpu/cpu30/cpufreq/scaling_max_freq\n[INFO    ] File /sys/devices/system/cpu/cpu30/cpufreq/scaling_max_freq is in the correct state\n[INFO    ] Executing state file.managed for /sys/devices/system/cpu/cpu31/cpufreq/scaling_governor\n[ERROR   ] An exception occurred in this state: Traceback (most recent call last):\n  File \"/usr/lib/python2.6/site-packages/salt/state.py\", line 1305, in call\n    *cdata['args'], **cdata['kwargs'])\n  File \"/usr/lib/python2.6/site-packages/salt/states/file.py\", line 1157, in managed\n    dir_mode)\n  File \"/usr/lib/python2.6/site-packages/salt/modules/file.py\", line 2053, in manage_file\n    __opts__['cachedir'])\n  File \"/usr/lib/python2.6/site-packages/salt/utils/__init__.py\", line 603, in copyfile\n    tgt = mkstemp(prefix=bname, dir=dname)\n  File \"/usr/lib/python2.6/site-packages/salt/utils/__init__.py\", line 1000, in mkstemp\n    fd_, fpath = tempfile.mkstemp(*args, **kwargs)\n  File \"/usr/lib64/python2.6/tempfile.py\", line 293, in mkstemp\n    return _mkstemp_inner(dir, prefix, suffix, flags)\n  File \"/usr/lib64/python2.6/tempfile.py\", line 228, in _mkstemp_inner\n    fd = _os.open(file, flags, 0600)\nOSError: [Errno 2] No such file or directory: '/sys/devices/system/cpu/cpu31/cpufreq/scaling_governorlj86AN'\n", "$ salt-master --versions-report\n           Salt: 0.17.4\n         Python: 2.6.6 (r266:84292, Sep 12 2011, 14:03:14)\n         Jinja2: 2.2.1\n       M2Crypto: 0.20.2\n msgpack-python: 0.1.13\n   msgpack-pure: Not Installed\n       pycrypto: 2.0.1\n         PyYAML: 3.10\n          PyZMQ: 2.2.0.1\n            ZMQ: 3.2.4\n[root@pronghorn04 ~]# salt-minion --versions-report\n           Salt: 0.17.4\n         Python: 2.6.6 (r266:84292, Sep 12 2011, 14:03:14)\n         Jinja2: 2.2.1\n       M2Crypto: 0.20.2\n msgpack-python: 0.1.13\n   msgpack-pure: Not Installed\n       pycrypto: 2.0.1\n         PyYAML: 3.10\n          PyZMQ: 2.2.0.1\n            ZMQ: 3.2.3\n"], "labels": ["stale"]}
{"project": "dart-lang_sdk", "title": "dart2js does not support async/await", "description": "Error: Experimental language feature 'async/await' is not supported. But it is not an experimental feature anymore. ", "code": [], "labels": ["Type-Defect", "closed-duplicate", "web-dart2js"]}
{"project": "snowplow_snowplow", "title": "Documentation: improve Redshift setup section", "description": "From Raul in snowplow-user: The instructions for setting up the storage loader user in Redshift are incorrect.  The storage loader runs Analyze on the atomic.events table.  That can only be run by a superuser or the Table owner. I resolved this by making the storage loader user  the owner of the events table.  Perhaps there is a better approach. ", "code": [], "labels": ["documentation"]}
{"project": "renovatebot_renovate", "title": "Support ssh for git-tags datasource", "description": "First of all i want to apologize if this issue is a bit messy, there are just so many points to consider. This issue emerges from Issue #3811 and PR #4019 What would you like Renovate to be able to do?\nI want the git-tags datasource to support getting info via ssh for improved integration with managers, in this case for composer (#3811) This is mostly applicable for self-hosted renovate. Describe the solution you'd like\nRefactor git-tags to use simple-git instead of isomorphic-git. simple-git is a wrapper around native git. isomorphic-git is a full javascript git implementation which is currently not supporting ssh Describe alternatives you've considered\nssh2 npm package instead of native ssh. Could tell git to use that package instead of native ssh and provide a ssh key via config? Additional context\nsimple-git will require the host system to provide git and ssh (the latter being required only for ssh calls with git@domain:repo) We can get around the requirement for ssh by using a regex with host rules. This would actually be easier with isomorphic-git, but will not work if the server has disabled https (might be an edge case?) When using ssh, we will be confronted with additional hurdles: As a result of the above mentioned points, git+ssh is probably only usable in self-hosted renovate. Alternatively, could a js based ssh client be used? The ssh2 npm package seems to support both password and ssh-key authentication. ", "code": [], "labels": ["released"]}
{"project": "saltstack_salt", "title": "New function to ensure file permissions are same as specified and change if different", "description": "There should be a new function (file.file or file.present) similar to`file.directory`` that ensures that the named file is present and has the right perms. Or at least there should be a function (file.permission) to ensure that the file permissions are same as specified. If not then the function should update the file permissions and or file owner/group. ", "code": [], "labels": ["Feature"]}
{"project": "PowerShell_PowerShell", "title": "\"\\u2026\" with a backslash appears instead of a Unicode ellipsis \"\u2026\"", "description": "Presumably caused by #8326 Unicode ellipsis <CODE> Backslash u 2026 <CODE> <CODE> ", "code": ["aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nAt line:1 char:1\n+ throw \"a\" * 44\n+ ~~~~~~~~~~~~~~\n+ CategoryInfo          : OperationStopped: (aaaaaaaaaaaaaaaaaaa\u2026aaaaaaaaaaaaaaaaaaa:String) [], RuntimeException\n+ FullyQualifiedErrorId : aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nAt line:1 char:1\n+ throw \"a\" * 44\n+ ~~~~~~~~~~~~~~\n+ CategoryInfo          : OperationStopped: (aaaaaaaaaaaaaaaaaaa\\u2026aaaaaaaaaaaaaaaaaaa:String) [], RuntimeException\n+ FullyQualifiedErrorId : aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n", "Name                           Value\n----                           -----\nPSVersion                      6.2.0\nPSEdition                      Core\nGitCommitId                    6.2.0\nOS                             Microsoft Windows 10.0.17763\nPlatform                       Win32NT\nPSCompatibleVersions           {1.0, 2.0, 3.0, 4.0\u2026}\nPSRemotingProtocolVersion      2.3\nSerializationVersion           1.1.0.1\nWSManStackVersion              3.0\n"], "labels": ["Resolution-Fixed", "Issue-Bug"]}
{"project": "microsoft_WSL", "title": "Docker does not starts automaticity after installation and containers cannot access the internet nor DNS from docker0 interface (bridged network).", "description": "<CODE> or <CODE> After logout&login or reboot: has been tested on WSL2: Debian 9.9, Ubuntu 18.04 and Ubuntu 19.04 with both ways of installing docker ", "code": ["curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable edge test\"\nsudo apt-get update\nsudo apt-get install -y docker-ce #installs 19.03.0-rc2\n", "curl https://get.docker.com/ | bash\n"], "labels": ["duplicate"]}
{"project": "npgsql_npgsql", "title": "Cannot use IEnumberable<T> parameters", "description": "We're looking at upgrading from a custom built 2.0.11 version of Npgsql to the latest and greatest and we ran in to this issue: Previously this would work, now it generates invalid SQL for the parameter. I might take a quick look through to see if I can fix this, no promises however :) ", "code": [], "labels": ["bug"]}
{"project": "fish-shell_fish-shell", "title": "Variable-as-command bug", "description": "fish, version 2.7.1-1452-ga4836436 There seems to be a bug when setting a variable to command and using it as a command. It will print the help for command rather than run a command: ...will print the help.  Interestingly, using flags works fine: I played around with a few other fish builtins and it seems this is specific to command. I didn't test them all, however. Just test, echo, random, set_color, and string. All of those worked normally. ", "code": [], "labels": ["bug"]}
{"project": "aws_aws-sdk-js", "title": "SQS, addPermission wildcard", "description": "I'm trying to set a SQS queue to allow anyone to receive a messages. I'm using this code: <CODE> I get this error: <CODE> Am I missing something in how to set the permission for all? (* works in the console) This is with SDK version 2.1.20 and using node v0.10.36 ", "code": ["  sqs.addPermission({\n    AWSAccountIds : ['*'],\n    Actions : ['ReceiveMessage'],\n    Label : 'mylabel',\n    QueueUrl : queueUrl\n  }, function(err,data) {\n    if (err) {\n      cb(err);\n    } else {\n      cb(null,inObj);\n    }\n  });\n", "{ [InvalidParameterValue: Value [*] for parameter PrincipalId is invalid. Reason: Unable to verify.]\n  message: 'Value [*] for parameter PrincipalId is invalid. Reason: Unable to verify.',\n  code: 'InvalidParameterValue',\n  time: Tue Apr 07 2015 15:19:19 GMT-0500 (CDT),\n  statusCode: 400,\n  retryable: false,\n  retryDelay: 30 }\n"], "labels": ["guidance"]}
{"project": "kubernetes_kubernetes", "title": "Isolate backend services from load balancer", "description": "Is this a BUG REPORT or FEATURE REQUEST?: /kind feature\n/sig network What happened:\nWhen I setup a loadbalancer to my frontend service, I notice it's forwarding traffic to each of my nodes. In case of possible DDoS attack, I'd like the front end nodes to be isolated to prevent the back end nodes from being overloaded as well. What you expected to happen:\nWhen setting up a LoadBalancer service, I should be able to setup a nodeSelector (Or it should read from the deployment associated with the service), and understand what nodes should receive traffic, and only route to nodes of that type. Anything else we need to know?: Environment: ", "code": [], "labels": ["lifecycle/rotten", "sig/network", "kind/feature"]}
{"project": "ramboxapp_community-edition", "title": "Share Screen not available", "description": "On both Slack and Hangouts, share screen does not function. Not sure if there is a way to fix this or not, but thought I would report it.\n-\n> Rambox 0.5.10\n> Electron 1.7.4\n> win32 x64 10.0.15063 ", "code": [], "labels": ["investigate", "bug"]}
{"project": "bazelbuild_bazel", "title": "Random overhead with Bazel @HEAD on null build under OS X", "description": "There seems to be a random overhead per Bazel invocation on my OS X laptop: <CODE> It usually happens at the end of the build. This make interactive build really slow. It seems like we don't have this overhead on linux ", "code": ["arting-macbookair:bazel dmarting$ time ./output/bazel build src/test/java/... src/main/java/com/google/devtools/build/lib:bazel/BazelServer\nINFO: Found 55 targets...\nINFO: Elapsed time: 0.242s, Critical Path: 0.00s\n\nreal    0m0.891s\nuser    0m0.011s\nsys 0m0.016s\ndmarting-macbookair:bazel dmarting$ time ./output/bazel build src/test/java/... src/main/java/com/google/devtools/build/lib:bazel/BazelServer\nINFO: Found 55 targets...\nINFO: Elapsed time: 0.159s, Critical Path: 0.00s\n\nreal    0m0.664s\nuser    0m0.011s\nsys 0m0.017s\ndmarting-macbookair:bazel dmarting$ time ./output/bazel build src/test/java/... src/main/java/com/google/devtools/build/lib:bazel/BazelServer\nINFO: Found 55 targets...\nINFO: Elapsed time: 0.194s, Critical Path: 0.02s\n\nreal    0m0.379s\nuser    0m0.012s\nsys 0m0.017s\n"], "labels": ["type: bug", "P2"]}
{"project": "kubernetes_kubernetes", "title": "kubernetes/cluster/log-dump.sh appears to be broken on G{C,K}E", "description": "The end of passing GKE runs shows stuff like <CODE> and there are no node logs being saved. It appears to be working on clusters that failed to fully start up, though. @spxtr @fejta ", "code": ["Dumping master and node logs to /var/lib/jenkins/jobs/kubernetes-e2e-gke/workspace/_artifacts\nMaster SSH not supported for gke\nERROR: (gcloud.compute.copy-files) Could not fetch instance:\n - The resource 'projects/k8s-jkns-e2e-gke-ci/zones/us-central1-f/instances/https' was not found\nERROR: (gcloud.compute.copy-files) Could not fetch instance:\n - The resource 'projects/k8s-jkns-e2e-gke-ci/zones/us-central1-f/instances/https' was not found\nERROR: (gcloud.compute.copy-files) Could not fetch instance:\n - The resource 'projects/k8s-jkns-e2e-gke-ci/zones/us-central1-f/instances/https' was not found\n"], "labels": ["area/test-infra", "priority/important-soon"]}
{"project": "moby_moby", "title": "panic: standard_init_linux.go:175: exec user process caused \"no such file or directory\" [recovered]", "description": "When I build image, and Dockerfile: <CODE> and then , throw exception\uff1a <CODE> Output of docker version: <CODE> Output of docker info: <CODE> Additional environment details (AWS, VirtualBox, physical, etc.):\ncustom physical , centos 7.2 ", "code": ["FROM centos:6.8\nRUN adduser tomcat\nRUN usermod -G tomcat tomcat\n\nWORKDIR /home/tomcat\nENV RMI_SERVER_NAME=localhost \\\nSET_JVM_Xms=2048m \\\nSET_JVM_Xmx=2048m \\\nSET_JVM_Xmn=268m \\\nSET_JVM_Xss=256k \\\nSET_JVM_XXPermSize=64m \\\nSET_JVM_XXMaxPermSize=256m\n#\u5916\u754c\u5f97\u8986\u76d6\u8be5\u73af\u5883\u53d8\u91cf\n#ENV APPNAME=APP\n\n#\u67e5\u770b\u4ed3\u5e93\u662f\u5426\u6709\u4e2d\u6587\u5305\nRUN yum grouplist |grep -i chinese\n#\u5b89\u88c5\u4e2d\u6587\u8bed\u8a00\u5305\nRUN yum groupinstall Chinese-support -y\n\n#\u8bbe\u7f6e\u652f\u6301\u4e2d\u6587\u8bed\u8a00\nENV LANG=zh_CN.utf8\n\n\nCOPY jdk1.6.0_38/ /usr/local/java/\n\nRUN echo \"\u5f00\u59cb\u5b89\u88c5zip\" && \\\nyum install unzip -y && \\\necho \"\u5b89\u88c5\u6210\u529f\"\n\nRUN echo \"\u5f00\u59cb\u5b89\u88c5git\" && \\\nyum install git -y && \\\necho \"git \u5b89\u88c5\u5b8c\u6210\"\n\nRUN mkdir -p /data/www/ROOT/\n\nCOPY tomcat/ /home/tomcat/tomcat/\nCOPY static/ /data/www/ROOT/\nCOPY java.sh /etc/profile.d\n\n#\u8fdc\u7a0bdebug \u7aef\u53e3\nEXPOSE 5801\nEXPOSE 80\n\n", "Sending build context to Docker daemon 221.8 MB\nStep 1 : FROM centos:6.8\n ---> 0cd976dc0a98\nStep 2 : MAINTAINER yeruisen <yeruisen@sina.cn>\n ---> Using cache\n ---> 6e456ba49dcd\nStep 3 : RUN adduser tomcat\n ---> Using cache\n ---> eaf24eac672e\nStep 4 : RUN usermod -G tomcat tomcat\n ---> Using cache\n ---> 29dea361c5ed\nStep 5 : WORKDIR /home/tomcat\n ---> Using cache\n ---> 3e921c5b824a\nStep 6 : ENV RMI_SERVER_NAME localhost SET_JVM_Xms 2048m SET_JVM_Xmx 2048m SET_JVM_Xmn 268m SET_JVM_Xss 256k SET_JVM_XXPermSize 64m SET_JVM_XXMaxPermSize 256m\n ---> Using cache\n ---> 9e4a2edace24\nStep 7 : RUN yum grouplist |grep -i chinese\n ---> Using cache\n ---> bd9fe81590b7\nStep 8 : RUN yum groupinstall Chinese-support -y\n ---> Using cache\n ---> 5b621dcd5b2b\nStep 9 : ENV LANG zh_CN.utf8\n ---> Using cache\n ---> aba17c6ec872\nStep 10 : COPY jdk1.6.0_38/ /usr/local/java/\n ---> Using cache\n ---> 4fd2632a2ed5\nStep 11 : RUN echo \"\u5f00\u59cb\u5b89\u88c5zip\" && yum install unzip -y && echo \"\u5b89\u88c5\u6210\u529f\"\n ---> Using cache\n ---> 5f56d4c9156d\nStep 12 : RUN echo \"\u5f00\u59cb\u5b89\u88c5git\" && yum install git -y && echo \"git \u5b89\u88c5\u5b8c\u6210\"\n ---> Using cache\n ---> 506b2cefc345\nStep 13 : RUN mkdir -p /data/www/ROOT/\n ---> Running in 2408c17fde9c\npanic: standard_init_linux.go:175: exec user process caused \"no such file or directory\" [recovered]\n        panic: standard_init_linux.go:175: exec user process caused \"no such file or directory\"\n\ngoroutine 1 [running, locked to thread]:\npanic(0x7e9de0, 0xc8201682a0)\n        /usr/local/go/src/runtime/panic.go:481 +0x3e6\ngithub.com/urfave/cli.HandleAction.func1(0xc8201292e8)\n        /go/src/github.com/opencontainers/runc/Godeps/_workspace/src/github.com/urfave/cli/app.go:478 +0x38e\npanic(0x7e9de0, 0xc8201682a0)\n        /usr/local/go/src/runtime/panic.go:443 +0x4e9\ngithub.com/opencontainers/runc/libcontainer.(*LinuxFactory).StartInitialization.func1(0xc820128bf8, 0xc8200420c8, 0xc820128d08)\n        /go/src/github.com/opencontainers/runc/Godeps/_workspace/src/github.com/opencontainers/runc/libcontainer/factory_linux.go:259 +0x136\ngithub.com/opencontainers/runc/libcontainer.(*LinuxFactory).StartInitialization(0xc820081630, 0x7f56f36c0728, 0xc8201682a0)\n        /go/src/github.com/opencontainers/runc/Godeps/_workspace/src/github.com/opencontainers/runc/libcontainer/factory_linux.go:277 +0x5b1\nmain.glob.func8(0xc8200a2a00, 0x0, 0x0)\n        /go/src/github.com/opencontainers/runc/main_unix.go:26 +0x68\nreflect.Value.call(0x74e5e0, 0x8ffda0, 0x13, 0x846308, 0x4, 0xc820129268, 0x1, 0x1, 0x0, 0x0, ...)\n        /usr/local/go/src/reflect/value.go:435 +0x120d\nreflect.Value.Call(0x74e5e0, 0x8ffda0, 0x13, 0xc820129268, 0x1, 0x1, 0x0, 0x0, 0x0)\n        /usr/local/go/src/reflect/value.go:303 +0xb1\ngithub.com/urfave/cli.HandleAction(0x74e5e0, 0x8ffda0, 0xc8200a2a00, 0x0, 0x0)\n        /go/src/github.com/opencontainers/runc/Godeps/_workspace/src/github.com/urfave/cli/app.go:487 +0x2ee\ngithub.com/urfave/cli.Command.Run(0x8491b8, 0x4, 0x0, 0x0, 0x0, 0x0, 0x0, 0x8df0e0, 0x51, 0x0, ...)\n        /go/src/github.com/opencontainers/runc/Godeps/_workspace/src/github.com/urfave/cli/command.go:191 +0xfec\ngithub.com/urfave/cli.(*App).Run(0xc820001b00, 0xc82000a100, 0x2, 0x2, 0x0, 0x0)\n        /go/src/github.com/opencontainers/runc/Godeps/_workspace/src/github.com/urfave/cli/app.go:240 +0xaa4\nmain.main()\n        /go/src/github.com/opencontainers/runc/main.go:137 +0xe24\nThe command '/bin/sh -c mkdir -p /data/www/ROOT/' returned a non-zero code: 2\n", "Client:\n Version:      1.12.3\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   6b644ec\n Built:        \n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.12.3\n API version:  1.24\n Go version:   go1.6.3\n Git commit:   6b644ec\n Built:        \n OS/Arch:      linux/amd64\n", "Containers: 22\n Running: 19\n Paused: 0\n Stopped: 3\nImages: 202\nServer Version: 1.12.3\nStorage Driver: devicemapper\n Pool Name: docker-253:0-8594930304-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 34.81 GB\n Data Space Total: 107.4 GB\n Data Space Available: 72.57 GB\n Metadata Space Used: 64.86 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.083 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.107-RHEL7 (2015-10-14)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: host null overlay bridge\nSwarm: active\n NodeID: 0ucr4iuloh1yydwe6oydplq4k\n Is Manager: false\n Node Address: 192.168.1.38\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.9.0-1.el7.elrepo.x86_64\nOperating System: CentOS Linux 7 (Core)\nOSType: linux\nArchitecture: x86_64\nCPUs: 32\nTotal Memory: 62.87 GiB\nName: 1.38\nID: ZPCQ:YE7G:IVZD:J7MT:5C2X:EXZU:VOOW:77AF:CCP2:W6LA:I5RY:SQOJ\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nWARNING: bridge-nf-call-ip6tables is disabled\nInsecure Registries:\n 127.0.0.0/8\n"], "labels": ["area/builder", "version/1.12"]}
{"project": "spring-cloud_spring-cloud-config", "title": "Some suggestions for Refresh.refreshAll()", "description": " tag1. refreshes the common configuration for a single project, such as some constants, mappings, etc. tag2.  write component configuration for redis/datasource. Since 1 tends to have a lot of k, v .then I don't confirm where the bean refresh, I have to choose refreshAll but this will refresh redis/datasource etc. But I don't want to refresh redis/datasource I hope to consider adding the excloude(\"beanName\") method to support it. as follows:\nrefreshScope.refreshAll().exclude({'redis','datasource'}); ", "code": [], "labels": ["help wanted", "enhancement"]}
{"project": "clappr_clappr", "title": "hideMediaControl:false option does not work when using autoPlay:true", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug", "wontfix"]}
{"project": "mautic_mautic", "title": "Citrix Segments Error", "description": "What type of report is this: When creating a segment using Citrix filters, the operators in the combobox are wrong.  Please check for related errors in the latest log file in [mautic root]/app/log/ and/or the web server's logs and post them here. Be sure to remove sensitive information if applicable. ", "code": [], "labels": ["P1", "Ready To Test", "Bug"]}
{"project": "aio-libs_aiohttp", "title": "Enable stdout logging in run_app by default", "description": "Flask adds StreamHandler to application logger if the logger has no handlers at the moment of application startup.\nWe should do the same in web.run_app. AppRunner should be configured explicitly. <URL> See #2952 (comment) for motivation ", "code": [], "labels": ["outdated", "easy"]}
{"project": "NodeBB_NodeBB", "title": "opening multiple chats on mobile doesn't work", "description": "", "code": [], "labels": ["bug"]}
{"project": "cleanflight_cleanflight", "title": "Flying Wing servo moves while throttleling", "description": "Hi you guys out there. I just finished building a new Mini Racing Wing which I wanted to stabilize with a CC3D flashed with BetaFlight I had laying around. So I put it in and everything looked fine (servos moved in the right direction, stabilization looked good too). But as I was at the field and gave it a little test thrust, I noticed that as I moved the throttle stick, the left servo would start moving upwards with a constant speed till it reached it maximum angle it then stayed there till I zeroed the throttle again. Doesnt matter how much throttle I give, till there is a tiny little bit the servo starts moving.\nAt home I checked wether I did anything wrong in the configuration tab at the mixers, but everything looked fine to me since I had flying_wing selected. So I moved on to the motors tab to see what's going on with that servo. Now the weird things begin: As I was in the motors tab in Cleanflight with the craft connected the servo didn't move anymore while I was rising the throttle stick. But as I moved out of the motors tab and tried the same thing again, the same problematic happend.\nThat indicated to me, that the reason for the problem has to be anything with the software and not with the hardware. Because of that I started thinking about what could cause that kind of a problem and first thing that came in my mind was that there is anything wrong with the mixers, so I read this page (<URL> and tried to write my own mixer in the CLI. I'm quiet unsure if mine is working, but that doesn't matter anyway because the same problem happened again, but not only with one servo, now both servos are moving as I'm rising the throttle. I'm really done, please help me!\nBest Regards, Zomhad ", "code": [], "labels": ["invalid", "support"]}
{"project": "Ultimaker_Cura", "title": "XY corodinates of Move don't match home position of printer", "description": "The XY move coordinates don't start at 0 for X and Y where the home marker is located. The 0,0,0, point is the middle of the bed by default.  If a printer is selected with a home marker in the lower left corner (pretty much the standard for most printers) the coordinates of the position of the object don't match or get updated. ", "code": [], "labels": ["Type: Improvement"]}
{"project": "gorhill_uBlock", "title": "Add explanation of logger output to documentation", "description": "This page\n<URL> is pretty good at describing everything except the main content of the logger output. What are those columns? What are those values? What do the colors mean? ", "code": [], "labels": ["accepted"]}
{"project": "godotengine_godot", "title": "ParallaxLayer mirroring", "description": "I can't get the ParallaxLayer mirroring property to work as it is documented. Setting an offset to ParallaxLayer - Motion - Mirroring creates a second version of the child texture but the image is in the same orientation - not reflected. I found a workaround by manually adding another copy of the texture and flipping it with sprite offset. Also the API documentation for ParallaxLayer is worded in such a way it implies that if either Mirroring axis is set to zero no mirroring whatsoever will take place. Godot V3.0.6.stable.official.8314054\nWindows 10 Home V 1803 build 17134.345 Intel Pentium CPU G2030 @ 3.00GHz 3.00GHz ASUS desktop with CM6730 motherboard with onboard GPU running Intel HD Graphics drivers screenshot shows minimal tree to reproduce the issue.  ", "code": [], "labels": ["documentation", "enhancement"]}
{"project": "openshift_origin", "title": "Djnago SETTINGS_MODULE not found while deploying application", "description": "[provide a description of the issue]\nI'm trying to deploy a Django application to OpenShift. I'm using kompse to use the docker-compose.yml1 file to deploy the application. My web application container is failing with the ModuleNotFoundError: No module named 'happinesspackets.settings' as seen from the web console error logs2. [provide output of the openshift version or oc version command]\noc v3.11.0+0cbc58b\nkubernetes v1.11.0+d4cacc0\nfeatures: Basic-Auth GSSAPI Kerberos SPNEGO Server <URL>\nkubernetes v1.11.0+d4cacc0 Web container crashing frequently. Web container deployed successfully. ", "code": [], "labels": ["lifecycle/rotten"]}
{"project": "microsoft_vcpkg", "title": "How to install the old version of the library", "description": "How do I install the old version of the library? For example: tesseract3.0.5 tesseract4.1.0. I want to use 3.0.5, which was available before, but it has been updated to 4.1.0 recently. ", "code": [], "labels": ["Question"]}
{"project": "grails_grails-core", "title": "GRAILS-10180: Add support @CompileStatic across the framework", "description": "Original Reporter: graemerocher\nEnvironment: Not Specified\nVersion: Not Specified\nMigrated From: <URL> ", "code": [], "labels": ["Major", "New Feature", "Fixed"]}
{"project": "dart-lang_sdk", "title": "Paste keybinding not working in omni box (64bit GTK)", "description": "[ed note: I suspect something change with the move to 3.8] You can no longer paste into the corner search box (the one on the top left, next to the \"SEND FEEDBACK\" button). When you focus the search bar and hit Ctrl-V to paste, it just pastes into the file that you were editing. In the screenshot provided, I highlighted the text table-panel, focused the search box, and hit paste. As you can see, I now have the text: table-paneltable-panel Because the paste happened in the editor window, not in the search box. ////////////////////////////////////////////////////////////////////////////////////\nEditor: 0.7.5_r27776 (2013-09-23)\nOS: Linux - amd64 (3.2.5-gg1236)\nJVM: 1.7.0-google-v5 auto-run pub: false\nlocalhost resolves to: 127.0.0.1\nmem max/total/free: 1778 / 1007 / 759 MB\nthread count: 26\nindex: 570413 relationships in 112216 keys in 683 sources SDK installed: true\nDartium installed: true ", "code": [], "labels": ["os-linux", "Type-Defect"]}
{"project": "istio_istio", "title": "Can we change default istio deployment replicator from 1 to 2?", "description": "By default, the replicator is only 1 for all istio deployment, which will bring \u201csingle point failure\u201d issue.\nOne quick question, can I change their replicator to 2, and minpods of HPA to 2, as below? I am doubt it especially for istio-pilot. ", "code": [], "labels": ["stale"]}
{"project": "hashicorp_terraform", "title": "Interpolation should only evaluate one branch of a condition", "description": "Conditionals are handy, but it looks like both branches are always evaluated. My specific use case is that I want to have a variable that may or may not point to a file: However I always get the \"file: open : no such file or directory in:\" error, even if I change conditional to: ", "code": [], "labels": ["config", "bug"]}
{"project": "saltstack_salt", "title": "Salt returns wrong error message after pkg installed properly.", "description": "After installation, salt returns wrong error message. <CODE> <CODE> <CODE> I tried with several other rpms, but salt returns the same wrong error message above. ", "code": ["ID: robot\nFunction: pkg.installed\nResult: False\nComment: The following packages failed to install/update: robotfw\nChanges: \n                -------------------\n                robotframework:\n                         ------------\n                         new:\n                               2.7.7-1\n                         old:\n", "robot.sls\nrobot:\n     pkg.installed:\n         - sources:\n               - robotfw: salt://robotrpm/robotframework-2.7.7-1.noarch.rpm\n", "Salt master & minion version\nSalt: 2014.1.4\n"], "labels": ["Expected Behavior"]}
{"project": "microsoft_TypeScript", "title": "Compiler option for stricter implicit truthy and falsy checks", "description": "We have a large Typescript application, and sometimes we have code like if (shouldFireNuclearMissiles)... while we should have written if (shouldFireNuclearMissiles())... (pun intended). So forgetting to evaluate a function results in a truthy value. I forked the tsc compiler to add basic checks for this in the conditional operator, the if-then-else, while, do and for statements, and that was very easy. We found several bugs in our large code using this forked compiler. Would such a stricter compiler option (maybe even emitting warnings) be a sound idea? These automatic truthy and falsy conversions are very handy, but IMHO, for large projects, the comfort they bring does not outweigh the dangers. Most likely this idea is too much non-Javascript-like, but we're coming from sharp & strongly-typed languages, so I must make this suggestion ;-) Thanks,\nPeter PS: I first suggested this as a TSLINT rule , but from the friendly feedback I got, it seems this belongs in the compiler instead. ", "code": [], "labels": ["Duplicate"]}
{"project": "hashicorp_packer", "title": "User variables specified with -var doesn't have to be declared in the variables block", "description": "Example template: <URL> This contradicts what the documentation says: See User Variables - Usage ", "code": [], "labels": ["bug", "docs", "core"]}
{"project": "DynamoRIO_dynamorio", "title": "drcontainers hashtable_add() lookup isn't atomic: could add twice", "description": "From bruen...@google.com on May 24, 2011 09:29:42 hashtable_add() lookup isn't atomic: could add twice for users who don't have own synch and rely on internal synch Original issue: <URL> ", "code": [], "labels": ["Status-Fixed", "Type-Bug", "Priority-Medium", "Migrated"]}
{"project": "saltstack_salt", "title": "Feature Request: Run Certain States As A User", "description": "So I understand that the salt-minion process can be run as a non-root user and can leverage sudo for certain functions; however what I would request is that the salt-minion process still runs as root but that certainly salt-formulas are executed as a specific user. The reason for this request is that we want to open up the ability for developers inside of our organization to build salt formulas but we want to make sure the formulas they write are all executed as a non-privileged user but the salt formula the infrastructure team writes are all executed with root privileges. I didn't see current support for this in any of the documentation. ", "code": [], "labels": ["stale", "Feature"]}
{"project": "gwtproject_gwt", "title": "ddfdf", "description": "Originally reported on Google Code with ID 903 <CODE> Reported by bruno.nogent@metaxis.fr on 2007-04-10 14:35:03 ", "code": ["Found in GWT Release:\n\nDetailed description:\n\n\nWorkaround if you have one:\n\n\nLinks to the relevant GWT Developer Forum posts:\n\n"], "labels": ["Priority-Medium", "Type-Defect"]}
{"project": "iron-meteor_iron-router", "title": "`Router.current().template` value is wrong", "description": "If data function returns null, Router automatically renders a not found template but the value of Router.current().template doesn't change to notFoundTemplate. ", "code": [], "labels": ["bug"]}
{"project": "ShareX_ShareX", "title": "Allow FTP to only be set for image uploading", "description": "Right now, you have to have the upload destination set to the FTP server if you want your images to be uploaded to the FTP server as well. It'd be nice to be able to upload images to the FTP server and files to somewhere like Mega.co.nz, for example.  ", "code": [], "labels": ["Enhancement"]}
{"project": "keepassxreboot_keepassxc", "title": "Add an \"include\" directive to keepassxc.ini", "description": "Even better: and an include directive in ~\\.config\\keepassxc.ini like many softwares like git, fish, tmux, vim, or ssh. Really handy for dotfiles repositories where we don't want to publish secret parts, or to manage specific cases by machines like here. In my case, I would like to make a reference to a tracked ~\\.config\\keepassxc_common.ini in my not-tracked ~\\.config\\keepassxc.ini. In ~\\.config\\keepassxc_common.ini, I would have a common configuration through my devices (like [General] LastOpenedDatabases or [security] lockdatabaseidlesec), but in ~\\.config\\keepassxc.ini, I would have everything else (for instance, options related to GUI that changes all the time). Originally posted by @nagromc in #1284 (comment) ", "code": [], "labels": ["new feature"]}
{"project": "npm_npm", "title": "I need your help", "description": "<CODE> ", "code": ["G:\\Users\\Shimh\\WebstormProjects\\Nodejs\\gulp_test>npm install graceful-fs@^4.0.0\nnpm WARN package.json gulp_test@1.0.0 No description\nnpm WARN package.json gulp_test@1.0.0 No repository field.\nnpm WARN package.json gulp_test@1.0.0 No README data\nnpm ERR! Windows_NT 6.1.7601\nnpm ERR! argv \"F:\\Program Files\\nodejs\\node.exe\" \"F:\\Program Files\\nodejs\\\nnode_modules\\npm\\bin\\npm-cli.js\" \"install\" \"graceful-fs@4.0.0\"\nnpm ERR! node v4.2.1\nnpm ERR! npm  v2.14.7\n\nnpm ERR! version not found: graceful-fs@4.0.0\nnpm ERR!\nnpm ERR! If you need help, you may report this error at:\nnpm ERR!     https://github.com/npm/npm/issues\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     G:\\Users\\Shimh\\WebstormProjects\\Nodejs\\gulp_test\\npm-debug.log\n"], "labels": ["bot-closed", "support"]}
{"project": "gohugoio_hugo", "title": "Add support for pre-compressed gzip files", "description": " Most of the discussion around this has been in #1251. It seems these should be broken up into different parts, so this is the one I care the most about. This is a feature request to have gzip -9'ed files generated along side the finished HTML, CSS, JS, etc. ", "code": [], "labels": ["Stale"]}
{"project": "arduino_Arduino", "title": "New CONTROLLINO-PLC library", "description": "Hello,\nwe prepared a new Arduino library for Arduino compatible device-CONTROLLINO.\nWe would like to add it to the Arduino IDE Library Manager. Would it be possible to check if the GitHub repository is in correct format and add it to the Library Manager please? Our GitHub repository: <URL> Thank you,\nCONTROLLINO team ", "code": [], "labels": ["Component: Board/Lib Manager"]}
{"project": "spring-projects_spring-security", "title": "Update to jackson-databind:2.8.11.2", "description": "\nNo description provided.\n ", "code": [], "labels": ["type: enhancement", "in: build"]}
{"project": "iview_iview", "title": "iviewadmin\u6f14\u793a\u73af\u5883", "description": "\u767b\u5f55\u63d0\u793a\u8bf7\u8f93\u5165\u4efb\u610f\u7528\u6237\u540d\u548c\u5bc6\u7801 \u5b9e\u9645\u4e0a\u4efb\u610f\u8f93\u5165\u5bc6\u7801\u53ef\u4ee5 \u4efb\u610f\u8f93\u5165\u7528\u6237\u540d\u5c31\u4f1a\u63d0\u793atoken\u95ee\u9898 ", "code": [], "labels": ["invalid"]}
{"project": "owncloud_core", "title": "Shared file notifications", "description": "Following issue  #4499 everything works fine if the file is shared with a single user or a group with users that are only in that group. When users are in multiple groups notification fail: the email doesn't contain che file name. The problem is in lib/private/share/share.php file:\n$result = \\OC_DB::executeAudited($query, array($itemSource, $itemType, implode(',', $groups))); Parameters to the query  $query = \\OC_DB::prepare(\n'SELECT file_target, permissions, expiration\nFROM\n*PREFIX*share\nWHERE\nitem_source = ? AND item_type = ? AND share_with in (?)'\n); are correct (i tryed executing it via sql prompt) but malformed, I suppose.\nI don know how to get rid of it. Any help?\nA. ", "code": [], "labels": ["Duplicate", "bug"]}
{"project": "sqlalchemy_sqlalchemy", "title": "Multiplying CASE statement by field generates TypeError: can only concatenate list (not \"itertools.chain\") to list", "description": "Migrated issue, originally created by Anonymous The following code works under 0.5.2 but produces an error under 0.5.3: <CODE> The desired SQL is: <CODE> ", "code": ["from sqlalchemy import Table, Column, Integer, MetaData, create_engine, case, select\n\nengine = create_engine('sqlite:///:memory:')\n\nmetadata = MetaData()\nusers_table = Table('users', metadata,\n     Column('id', Integer, primary_key=True),\n     Column('foo', Integer),\n)\n\nmetadata.create_all(engine)\n\nprint select([(users_table.c.foo)*case([(users_table.c.id>10, 1), (users_table.c.id<10, 2)](users_table.c.id,))])\n", "SELECT users.id, users.foo * CASE WHEN (users.id > 10) THEN 1 WHEN (users.id < 10) THEN 2 END AS anon_1\nFROM users\n"], "labels": ["high priority", "bug", "sql"]}
{"project": "lodash_lodash", "title": "lodash-es/find import side effects with Rollup", "description": "I've been working on a library that depends on specific functions from lodash-es \u2014 and every thing gets compiled via Rollup. And overall it has worked great! However, I've noticed a side effect of using the lodash-es/find import. I understand that some portions of lodash aren't fully amendable to \"tree-shaking\" yet, so this may just be a manifestation of that. Even if the find function is not used (which would cause Rollup to not include it \u2014 which is does do successfully!), there are imports throughout its dependency chain that add variables and functions. So even if you don't use find, you end up with around 800 lines of code that Rollup doesn't know it does not need. A test case: So it doesn't dominate the page, I've created a gist. Is there something I'm missing? Or is it still a work in progress? (Not sure if this may be on the Rollup side of things, but I figured I'd start here.) Thank you! ", "code": [], "labels": ["invalid"]}
{"project": "phpmyadmin_phpmyadmin", "title": "Export database with empty table as a php array, does not produce valid PHP.", "description": "Exporting a database with empty tables to a PHP array creates a PHP parse error in the code. It seems that empty tables print a closing paren \");\". I have created this in PMA 4.0.0, and the 4 RC's before it. ", "code": [], "labels": ["bug"]}
{"project": "wordpress-mobile_WordPress-iOS", "title": "Stats: Abrupt/jarring transition the first time refreshing.", "description": "View stats for a post / page.\nWhen the detail loads the refresh does not have a smooth transition.  Subsequent pull-to-refresh gestures do have a smooth transition.   See the demo:\n<URL> ", "code": [], "labels": ["Stats", "[Type] Bug", "[Pri] Low"]}
{"project": "firefly-iii_firefly-iii", "title": "[Sandstorm] Firefly III creates more than one user instead of using the main user", "description": "Bug description\nI am running Firefly III version 4.7.5.1 on Sandstorm I've noticed since the lastest update that users with whom they've shared a Firefly III grain can't access the account's data, and are shown the interface as if nothing was present. Steps to reproduce\nCreate a Firefly III grain on Sandstorm, share it to another user, the new user won't be able access the data created by the first and his profile will show an ID of 2 or more.\nI managed to reproduce the bug on Sandstorm Oasis in demo mode Extra Info\nI've found the root cause as being an old version of app/Http/Middleware/Sandstorm.php being packaged inside the spk.\nOur installed version comes from here\n<URL>\nThe spk package being <URL>\nWhen I checked the contents of the file using spk unpack on the package that I've downloaded from there, I found out that it didn't handle multiple users gracefully. This is a snippet taken from the file extracted I tried updating the file but it didn't work without overriding the checks on $count as the database now contains more than one user (making the latest code throw an exception saying Your Firefly III installation has more than one user, which is weird.) ", "code": [], "labels": ["bug", "fixed"]}
{"project": "eclipse_che", "title": "Investigate the failing selenium test 'RenamePackageSpringTest' on CI job", "description": "Che version: 6.12.0 See the report:\n<URL> ", "code": [], "labels": ["kind/task", "team/che-qe"]}
{"project": "quasarframework_quasar", "title": "Exposing build.appBase variables for user-defined configuration", "description": "Is your feature request related to a problem? Please describe.\nYes. I'm developing a SPA website. After building, all files (includes js, css, img, statics, fonts, index.html and so on) are hosted on a CDN server like <URL>**/ However, the address of the website is different from the CDN server, it's like <URL> So when you want to replace or push a router like <URL> with <URL>, it will redirect to <URL>**/home, which is wrong.\nAnd it seems caused by some code in quasar-config.js:\ncfg.build.appBase = cfg.build.vueRouterMode === 'history' ? cfg.build.publicPath : '' \nAnd it will also cause a replaceState error when enable scrollBehavior in vue-router. Describe the solution you'd like\nWhen replacing cfg.build.publicPath above with '/', the problem is disappeared.\nSo currently, I'm using 'history' in /router/index.js like new VueRouter( mode: 'history', routes: [...]}), not the example in the quasar.config.js like build: { vueRouterMode: 'history' }, to avoid appBase be assigned to a value like <URL>**/ .\nHowever, the appBase is empty '' now, when website has subroute like <URL>, it crashed.\nI also tried <base href=\"/\"> in index.template.html, but it will cause an error when building.\nI'm hoping a clearer way to achieve this like build: { appBase: '/' } or something better. Describe alternatives you've considered\nDistinguish publicPath with CDN and the website's real host. And files may be host on website's domain or CDN or both at the same time. Additional context\nIn addition, none statics file is used in this project, all static file like img file is process as assets, and is hosted on <URL>**/ . ", "code": [], "labels": ["feature request"]}
{"project": "rest-assured_rest-assured", "title": "Add printing of headers in Response", "description": "<CODE> Original issue reported on code.google.com by johan.ha...@gmail.com on 26 Jan 2012 at 8:15 ", "code": ["E.g.\n\nresponse.print(); // Prints everything\n\nresponse.printBody(); // print body\n"], "labels": ["Priority-Low", "auto-migrated", "Duplicate", "Type-Enhancement"]}
{"project": "microsoft_LightGBM", "title": "Data loading errors with extremely sparse datasets", "description": "I'm trying out training on a couple of the datasets that @Laurae2 reported in #536 (url and kdda) using the LibSVM data available here. Operating System: Ubuntu 16.04 CPU/GPU model: Training on an MPI cluster of 3 m4.xlarge instances C++/Python/R version: Latest master built with GCC 5.4 <CODE> I've traced the error to L1019 of dataset_loader.cpp. This is an overflow issue as evidenced when I was logging the two values being multiplied: <CODE> I tried a quick fix to change comm_size_t to int64_t: Which fixed the calculation of buffer_size: <CODE> But this led to a segfault later on: <CODE> Any ideas? Need to launch an MPI cluster, the easiest way I've found is using AWS ParallelCluster with the following config: <CODE> Once the cluster is up and running we install CMake: Get the data <CODE> Then build LightGBM Finally we can run the job: <CODE> which leads to the above error for the kdda dataset (~20M features) and the url data (~3.2M features). ", "code": ["> salloc -N 3 mpiexec --machinefile hostnames.txt ../../lightgbm config=train.conf\n\nsalloc: Granted job allocation 11\n[LightGBM] [Info] Finished loading parameters\n[LightGBM] [Info] Finished loading parameters\n[LightGBM] [Info] Finished loading parameters\n[LightGBM] [Info] Local rank: 2, total number of machines: 3\n[LightGBM] [Info] Finished initializing network\n[LightGBM] [Info] Local rank: 0, total number of machines: 3\n[LightGBM] [Info] Finished initializing network\n[LightGBM] [Info] Local rank: 1, total number of machines: 3\n[LightGBM] [Info] Finished initializing network\n[LightGBM] [Fatal] Check failed: buffer_size >= 0 at /shared/LightGBM/src/io/dataset_loader.cpp, line 1019 .\n\n[LightGBM] [Fatal] Check failed: buffer_size >= 0 at /shared/LightGBM/src/io/dataset_loader.cpp, line 1019 .\n\n[LightGBM] [Fatal] Check failed: buffer_size >= 0 at /shared/LightGBM/src/io/dataset_loader.cpp, line 1019 .\n", "[LightGBM] [Warning] type_size: 1345, num_total_features: 2014668\n[LightGBM] [Fatal] Overflow during buffer_size calculation: -1585238836l\n", "type_size: 1345, num_total_features: 2014668\n[LightGBM] [Warning] buffer_size: 2709728460\n", "*** Process received signal ***\n[<ip-redacted>] Signal: Segmentation fault (11)\n[<ip-redacted>] Signal code: Address not mapped (1)\n[<ip-redacted>] Failing at address: 0x7f5667a804b3\n[<ip-redacted>] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7f585314a390]\n[<ip-redacted>] [ 1] ../../lightgbm(_ZN8LightGBM9BinMapper8CopyFromEPKc+0x8)[0x4b22e8]\n[<ip-redacted>] [ 2] ../../lightgbm(_ZN8LightGBM13DatasetLoader31ConstructBinMappersFromTextDataEiiRKSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS7_EEPKNS_6ParserEPNS_7DatasetE+0x1e15)[0x528dc5]\n[<ip-redacted>] [ 3] ../../lightgbm(_ZN8LightGBM13DatasetLoader12LoadFromFileEPKcS2_ii+0x1ed)[0x52c34d]\n[<ip-redacted>] [ 4] ../../lightgbm(_ZN8LightGBM11Application8LoadDataEv+0x24a)[0x4447ca]\n[<ip-redacted>] [ 5] ../../lightgbm(_ZN8LightGBM11Application9InitTrainEv+0x181)[0x4459f1]\n[<ip-redacted>] [ 6] ../../lightgbm(main+0x49)[0x440a19]\n[<ip-redacted>] [ 7] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f5852d8f830]\n[<ip-redacted>] [ 8] ../../lightgbm(_start+0x29)[0x442ff9]\n[<ip-redacted>] *** End of error message ***\n", "[aws]\naws_region_name = us-east-1\n\n[cluster default]\nkey_name = <your-key-name-here>\ninitial_queue_size = 3\nmax_queue_size = 3\nmaintain_initial_size = 3\nmaster_instance_type = m4.xlarge\ncompute_instance_type = m4.xlarge\ncluster_type = spot\nvpc_settings = public\nbase_os = ubuntu1604\nscheduler = slurm\nplacement_group = DYNAMIC\n\n[vpc public]\nvpc_id = vpc-56fd132f\nmaster_subnet_id = subnet-10683d2c\n\n[global]\ncluster_template = default\nupdate_check = true\nsanity_check = true\n\n[aliases]\nssh = ssh {CFN_USER}@{MASTER_IP} {ARGS}\n", "# ParallelCluster sets up a shared NFS under /shared\ncd /shared/\nmkdir data\ncd data\nwget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/kdda.t.bz2\nbunzip2 kdda.t.bz2\n", "cd /shared/LightGBM\n# Get the hostnames in a file\nsrun -N 3 -n 3 hostname > hostnames.txt\nsalloc -N 3 mpiexec --machinefile hostnames.txt ./lightgbm config=train.conf data=/shared/data/kdda.t num_trees=3 tree_learner=data\n"], "labels": ["bug"]}
{"project": "ntop_ntopng", "title": "Double nDPI reload", "description": "Enabling tracings such it is easy to check that  lists_utils.checkReloadLists()  has been called twice (double reload). This is not necessary Tested with ntopng -i lo -i tcp://127.0.0.1:1234c -i syslog://127.0.0.1:9999  -i eth0 -i enp5s0 Note that you need at least two (-i) interfaces to reproduce it ", "code": [], "labels": ["bug"]}
{"project": "joomla_joomla-cms", "title": "[4.0] CLI Joomla Console fatal error", "description": "Install the latest nightly build of Joomla 4 (alpha11).\n<URL> Open a terminal, go to the Joomla root folder, and type:\nphp cli/joomla/php list Something like that: It worked fine with Joomla! 4.0.0-alpha10 ", "code": [], "labels": ["No Code Attached Yet", "J4 Issue"]}
{"project": "timgrossmann_InstaPy", "title": "I_a2", "description": "", "code": [], "labels": ["wontfix"]}
{"project": "microsoft_nodejstools", "title": "'Newtonsoft.Json.Linq.JObject' does not contain a definition for 'name'", "description": "I get this error everytime I install a package or open the solution : <CODE> I'm working with the latest versions of VS 2015, NTVS, and NodeJS. I tryed reinstalling all of them without success. I have read these related issues, but they didn't help :\n#533\n#208\n<URL> Edit: my package.json file does have a name property : <CODE> ", "code": ["System.AggregateException: One or more errors occurred. ---> Microsoft.CSharp.RuntimeBinder.RuntimeBinderException: 'Newtonsoft.Json.Linq.JObject' does not contain a definition for 'name'\n   at CallSite.Target(Closure , CallSite , Object )\n   at Microsoft.NodejsTools.Npm.SPI.PackageJson.get_Name()\n   at Microsoft.NodejsTools.Npm.SPI.RootPackage.get_Name()\n   at Microsoft.NodejsTools.Npm.SPI.AbstractNodeModules.AddModule(IPackage package)\n   at Microsoft.NodejsTools.Npm.SPI.NodeModules..ctor(IRootPackage parent, Boolean showMissingDevOptionalSubPackages)\n   at Microsoft.NodejsTools.Npm.SPI.RootPackage..ctor(String fullPathToRootDirectory, Boolean showMissingDevOptionalSubPackages)\n   at Microsoft.NodejsTools.Npm.SPI.NpmController.<RefreshAsync>d__1.MoveNext()\n   --- End of inner exception stack trace ---\n---> (Inner Exception #0) Microsoft.CSharp.RuntimeBinder.RuntimeBinderException: 'Newtonsoft.Json.Linq.JObject' does not contain a definition for 'name'\n   at CallSite.Target(Closure , CallSite , Object )\n   at Microsoft.NodejsTools.Npm.SPI.PackageJson.get_Name()\n   at Microsoft.NodejsTools.Npm.SPI.RootPackage.get_Name()\n   at Microsoft.NodejsTools.Npm.SPI.AbstractNodeModules.AddModule(IPackage package)\n   at Microsoft.NodejsTools.Npm.SPI.NodeModules..ctor(IRootPackage parent, Boolean showMissingDevOptionalSubPackages)\n   at Microsoft.NodejsTools.Npm.SPI.RootPackage..ctor(String fullPathToRootDirectory, Boolean showMissingDevOptionalSubPackages)\n   at Microsoft.NodejsTools.Npm.SPI.NpmController.<RefreshAsync>d__1.MoveNext()<---\n", "{\n   \"version\": \"1.0.0\",\n   \"name\": \"test\",\n   \"private\": true,\n  \"devDependencies\": {\n    \"gulp\": \"3.9.1\",\n    \"gulp-sass\": \"3.1.0\",\n    \"run-sequence\": \"1.2.2\",\n    \"del\": \"2.2.2\",\n    \"gulp-uglify\": \"2.0.1\",\n    \"gulp-imagemin\": \"3.1.1\",\n    \"gulp-util\": \"3.0.8\",\n    \"node-sass\": \"4.5.0\",\n    \"imagemin\": \"5.2.2\",\n    \"uglify-js\": \"2.7.5\",\n    \"gulp-sourcemaps\": \"2.4.0\"\n  }\n}\n"], "labels": ["fixed"]}
{"project": "mochajs_mocha", "title": "--config does not resolve paths relative to CWD", "description": ".js config loading with --config does not handle relative paths correctly, because it calls require() with a relative path. Here's the problem: <URL> cd to an empty directory.  touch foo.js <CODE> Expected behavior: [What you expect to happen] mocha loads config from foo.js Actual behavior: [What actually happens] <CODE> Reproduces how often: [What percentage of the time does it reproduce?] All the time Mocha 6.0.2\nWSL WLinux bash Issue #3818 ", "code": ["mocha --config foo.js\n", "/c/Users/cspotcode/Documents/Personal-dev/@mochajs/mocha/lib/cli/config.js:64\n    throw new Error(`failed to parse ${filepath}: ${err}`);\n    ^\n\nError: failed to parse foobar.js: Error: Cannot find module 'foo.js'\n"], "labels": ["confirmed-bug"]}
{"project": "ionic-team_ionic", "title": "feat: Image source management - Image Placeholder", "description": "Type: feat Ionic Version: 2.x Platform: all Mission:\nDisplay an image from a remote server, if image is not found on server or you got a positive status code like(205, 206, 301, 307) but without image then display a default image.\nwith javascript, you can catch and treat such a case, if image not found:\n<img src=\"http://remote/image.png\" onerror=\"javascript:this.src='default.png'\"/> A response without image but with success code can be caught in a method but you should to make another call to remote server, it's to expensive when you need performance.. We need such a feature in ionic, which can ensure that we got the picture(based on status code, image size,..), taking in consideration the performance(imagine you have an autocomplete box that returns a list of images at each typed letter) It intends to be an image placeholder, so we'll be able to write something like this:\n<ion-img placeholder=\"default.png\" src=\"remote/image.png\" />\n  ", "code": [], "labels": ["feature"]}
{"project": "ReactiveX_RxJava", "title": "2.x - bufferSize of Observable#flatMapIterable(mapper, bufferSize)", "description": "[RxJava 2.0.0-RC4]\nIt seems that bufferSize became maxConcurrency. I checked the Observable.java source. <CODE> I'm not sure whether the param's name is wrong or the source is wrong. ", "code": [" public final <U> Observable<U> flatMapIterable(\n    Function<? super T, ? extends Iterable<? extends U>> mapper, int bufferSize) {\n  return flatMap(ObservableInternalHelper.flatMapIntoIterable(mapper), false,\n      bufferSize);\n}\npublic final <R> Observable<R> flatMap(\n    Function<? super T, ? extends ObservableSource<? extends R>> mapper, \n    boolean delayErrors, \n    int maxConcurrency) {\n  return flatMap(mapper, delayErrors, maxConcurrency, bufferSize());\n}\n"], "labels": ["Question"]}
{"project": "graphhopper_graphhopper", "title": "Cleanup the DataFlagEncoder", "description": "As mentioned by @karussell, the DataFlagEncoder contains too much information right now. My proposal would be to use a plugin mechanism. We have the DataFlagEncoder, that on it's own does not do anything, it is just a container for MicroFlagEncoder/FlagEncoderPlugins. Every MicroFlagEncoder handles a single purpose, maybe handling truck attributes or even finer grained, handling one MicroFlagEncoder for each of the attributes width, height, weight. We might also create a MicroFlagEncoder for the MaxSpeed. Not everyone wants to save speed, maybe for foot routing, one does not care about speed and could disable saving it. How this would work:\nEvery MicroFlagEncoder has acceptWay, handleWayTags, and a way to extract the stored data. Maybe we keep the extraction part generic, similar to the ConfigMap.get. In the GenericWeighting we could do something like: <CODE> We might be even able to skip the supports part, by defining, if the value is not supported we also return the requested default value, in the above case -1. This would lead to cleaner code, but adds some \"magic\". This would also require a building mechanism. The best would be to be able to define the properties that should be saved in the config. We read the config and initialize the required MicroFlagEncoders. ", "code": ["if(encoder.supports(MaxSpeedMicroFlagEncoder.class))\n   double maxSpeed = encoder.get(MaxSpeedMicroFlagEncoder.class)).getDouble(\"max_speed\", -1);\n"], "labels": ["improvement"]}
{"project": "neovim_neovim", "title": "Please consider adding support for the XDG Base Directory spec", "description": "Vim should source vimrc from the $XDG_CONFIG_HOME/vim, temp files in $XDG_CACHE_HOME, etc. Please look at this: <URL> Of course, it should gracefully fall-back to normal locations, but this check up wouldn't cost much for end users and is a good step for consolidating all the settings into the .config folder for easier migration and cross-compatibility. ", "code": [], "labels": ["duplicate"]}
{"project": "keras-team_keras", "title": "Feature Request: Not too verbose during model.fit", "description": "I wonder if it's possible that model.fit can print epochs once we have finished every 10% (of course this 10% can be a variable) of nb_epoches rather than every one single epoch. For example, when we have model.fit(x, y, verbose=2, nb_epochs=1000), the output will be something like: This is what I want: ", "code": [], "labels": ["stale"]}
{"project": "golang_go", "title": "doc: more detailed description of -tags option", "description": "Please answer these questions before submitting your issue. Thanks! <CODE> The description -tags option is: <CODE> tag list needs to be separated by spaces. And <URL> talks about using spaces or commas to separate tags. I think that it will be clearer if a list of build tags is changed to a list of space-separated build tags. ", "code": ["go version go1.7.1 linux/amd64\n", "-tags 'tag list'\n    a list of build tags to consider satisfied during the build.\n    For more information about build tags, see the description of\n    build constraints in the documentation for the go/build package.\n"], "labels": ["FrozenDueToAge"]}
{"project": "nextcloud_server", "title": "File replacement modal too wide on mobile", "description": "Uploading multiple images with iPhone in Files is not possible because the confirmation dialog for overwriting files cannot be used as expected. There's not enough room for seeing the full dialog box.  cc @nextcloud/designers @nextcloud/mac ", "code": [], "labels": ["bug", "design"]}
{"project": "ant-design_ant-design", "title": "\u5173\u4e8eant-design 2.13.10\u7248\u672c\u4f7f\u7528Upload\u7ec4\u4ef6\u7f16\u8bd1\u6253\u5305\u62a5\u9519\u7684\u95ee\u9898", "description": "2.13.10 win7 #7515 import { Breadcrumb, Icon, message ,Upload} from 'antd';\n \u80fd\u6253\u5305\u6210\u529f \u6253\u5305\u7f16\u8bd1\u5931\u8d25 ERROR in ./node_modules/_attr-accept@1.1.0@attr-accept/dist/index.js\nModule build failed: ReferenceError: [BABEL] C:\\Users\\Administrator\\Desktop\\FEK\\node_modules_attr-accept@1.1.0@attr-accept\\dist\\index.js: Using removed Babel 5 o\nption: C:\\Users\\Administrator\\Desktop\\FEK\\node_modules_attr-accept@1.1.0@attr-accept.babelrc.stage - Check out the corresponding stage-x presets http://babeljs.\nio/docs/plugins/#presets\nat Logger.error (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules_babel-core@6.26.0@babel-core\\lib\\transformation\\file\\logger.js:41:11)\nat OptionManager.mergeOptions (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules_babel-core@6.26.0@babel-core\\lib\\transformation\\file\\options\\option-manager.js\n:220:20)\nat OptionManager.init (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules_babel-core@6.26.0@babel-core\\lib\\transformation\\file\\options\\option-manager.js:368:12) <CODE> @ ./node_modules/_rc-upload@2.4.3@rc-upload/es/AjaxUploader.js 51:18-40\n@ ./node_modules/_rc-upload@2.4.3@rc-upload/es/Upload.js\n@ ./node_modules/_rc-upload@2.4.3@rc-upload/es/index.js\n@ ./node_modules/_antd@2.13.10@antd/lib/upload/Upload.js\n@ ./node_modules/_antd@2.13.10@antd/lib/upload/index.js\n@ ./src/detail/index.js\n@ ./src/routes/route.js\n@ ./src/app/index.js\n@ ./src/home/home.js\n@ ./src/routes/index.js\n@ ./src/index.js\n@ multi ./node_modules/_webpack-dev-server@2.9.4@webpack-dev-server/client?http://localhost:3002 ./src/index.js ", "code": ["at File.initOptions (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules\\_babel-core@6.26.0@babel-core\\lib\\transformation\\file\\index.js:212:65)\nat new File (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules\\_babel-core@6.26.0@babel-core\\lib\\transformation\\file\\index.js:135:24)\nat Pipeline.transform (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules\\_babel-core@6.26.0@babel-core\\lib\\transformation\\pipeline.js:46:16)\nat transpile (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules\\_babel-loader@7.1.2@babel-loader\\lib\\index.js:50:20)\nat Object.module.exports (C:\\Users\\Administrator\\Desktop\\FEK\\node_modules\\_babel-loader@7.1.2@babel-loader\\lib\\index.js:175:20)\n"], "labels": [" Need Reproduce"]}
{"project": "yiisoft_yii2", "title": "Losing data when use \"joinWith()\"", "description": "When I get data as\n$query =  Store::find()->with('nomenclature')->asArray()->limit(100)->all();\necho count($query); //100\nthis normal result but i can't sorting my records. When  i use this variant i can sorting my records\n$query =  Store::find()->joinWith('nomenclature')->asArray()->limit(100)->all();\necho count($query); //93\nWhy 93? where I lost data Store have record with the same nomenclature_id Yii 2.0.7\nPHP 5.6.16-2\nUbuntu\nPostgresql 9.4 ", "code": [], "labels": ["question"]}
{"project": "keepassxreboot_keepassxc", "title": "Unable to write to the database with an access denied message.", "description": "When a save (or auto-save) is attempted; there will be a banner message saying \"writing to the database failed. Access is denied\" This is happening on my work PC, using GoogleDrive. I share the database with my Macbook at home (which is currently off) Database should be able to be saved. The database cannot be saved to the current file. It must be saved to a new file name, and then merged back with the previous version. There aren't any specific steps to reproduce this.  It just occurs. The second time it happened today, i had merged two databases together. I went to merge into with another older one, and then the message appeared again. KeePassXC - Version 2.2.4\nRevision: 4723f66 Libraries: Operating system: Windows 8.1 (6.3)\nCPU architecture: x86_64\nKernel: winnt 6.3.9600 Enabled extensions: ", "code": [], "labels": ["duplicate"]}
{"project": "agda_agda", "title": "Double solving of meta", "description": "The problematic code:\n We need to check if the low priority meta has been instantiated before assigning the other way around! ", "code": [], "labels": ["meta", "type: bug"]}
{"project": "dvajs_dva", "title": "dva-core\u91cc\u7684REDEX_DEVTOOLS\u4e0d\u80fd\u4f7f\u7528", "description": "\u6211\u4e0d\u77e5\u9053REDEX_DEVTOOLS\u662f\u4e0d\u662f\u7248\u672c\u5347\u7ea7\u4e86\uff0c\u5bfc\u81f4\u4e86dva-core\u4e2d\u7684\u5173\u4e8edevtools\u7684\u4ee3\u7801\u4e0d\u80fd\u8d77\u4f5c\u7528\u4e86\n\u539f\u59cb\u4ee3\u7801\u5982\u4e0b\uff1a\nlet devtools = () => noop => noop;\nif (process.env.NODE_ENV !== 'production' && window.REDUX_DEVTOOLS_EXTENSION) {\ndevtools = window.REDUX_DEVTOOLS_EXTENSION;\n} const enhancers = [\napplyMiddleware(...middlewares),\n...extraEnhancers,\ndevtools(window.__REDUX_DEVTOOLS_EXTENSION__OPTIONS),\n]; \u73b0\u5728\u51fa\u73b0\u95ee\u9898\n\u6211\u67e5\u770b\u4e86REDEX_DEVTOOLS\u7684git\n\u8fd9\u73b0\u5728\u662f\nimport { createStore, applyMiddleware, compose } from 'redux'; ", "code": [], "labels": ["question"]}
{"project": "vitessio_vitess", "title": "Support for cross shard transaction", "description": "It seems that Vitess has 2P commit to support cross shard transaction. Is this battle tested feature? Or should we avoid it? ", "code": [], "labels": ["Type: Question"]}
{"project": "emacs-helm_helm", "title": "Please, add a refresh command in the saved grep buffer", "description": "It would be really handy to be able to refresh the saved buffer by pressing  g. ", "code": [], "labels": ["enhancement"]}
{"project": "joomla_joomla-cms", "title": "Malformed menuitem allows article and category creation - Require category selction if Create Article in specific category in selected", "description": "In J!3.7.5 one can save a Create Article menu item, settting \"Default Category\" to Yes and NOT filling the \"Choose a Category\" field. Joomla! refuses to save menu item. Joomla! saves the menu item.\nIn frontend, using that menu with such a setting, forces to save the article in a newly created category with name '1' ! J!3.7.5 (and probably all previous versions) Bug detected thanks by @infograf768  while testing PR #17674 . We need a way to make 'catid' (Choose a Category) form field param required (\\components\\com_content\\views\\form\\tmpl\\edit.xml) when enable_category param (Default/Specific category) is active.\nA new \"requiredon:...\" attribute, working like \"showon:...\" ?\nA way to require validation of that attribute in the backend from ? ", "code": [], "labels": ["No Code Attached Yet", "J3 Issue"]}
{"project": "ytdl-org_youtube-dl", "title": "ARD Mediathek is not working", "description": "youtube-dl \"<URL>\" --> <CODE> ", "code": ["[debug] System config: []\n[debug] User config: []\n[debug] Custom config: []\n[debug] Command-line args: [u'-v', u'https://www.ardmediathek.de/tv/FilmDeb%C3%BCt-im-Ersten/Verfehlung/Das-Erste/Video?bcastId=10317610&documentId=53435326']\n[debug] Encodings: locale UTF-8, fs utf-8, out UTF-8, pref UTF-8\n[debug] youtube-dl version 2018.06.25\n[debug] Python version 2.7.15 (CPython) - Darwin-17.6.0-x86_64-i386-64bit\n[debug] exe versions: avconv 12.3, avprobe 12.3, ffmpeg 4.0.1, ffprobe 4.0.1, rtmpdump 2.4\n[debug] Proxy map: {}\n[ARD:mediathek] 53435326: Downloading webpage\n[ARD:mediathek] 53435326: Downloading media JSON\n[ARD:mediathek] 53435326: Downloading f4m manifest\n[ARD:mediathek] 53435326: Downloading m3u8 information\n[debug] Default format spec: bestvideo+bestaudio/best\n[debug] Invoking downloader on u'https://dasersteuni-vh.akamaihd.net/i/int/2018/06/22/5167d480-53d9-4d48-aff8-912a0a3ba490/,320-1,512-1,960-1,480-1,640-1,.mp4.csmil/index_2_av.m3u8?null=0'\n[download] Destination: Verfehlung-53435326.mp4\n[debug] avconv command line: avconv -y -loglevel verbose -headers 'Accept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip, deflate\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:59.0) Gecko/20100101 Firefox/59.0 (Chrome)\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nCookie: _alid_=uKvrf+YRUoZwiC09xm07gw==\n' -i 'https://dasersteuni-vh.akamaihd.net/i/int/2018/06/22/5167d480-53d9-4d48-aff8-912a0a3ba490/,320-1,512-1,960-1,480-1,640-1,.mp4.csmil/index_2_av.m3u8?null=0' -c copy -f mp4 'file:Verfehlung-53435326.mp4.part'\navconv version 12.3, Copyright (c) 2000-2018 the Libav developers\n  built on Feb 13 2018 11:17:07 with Apple LLVM version 9.0.0 (clang-900.0.39.2)\n  configuration: --disable-debug --disable-shared --disable-indev=jack --prefix=/usr/local/Cellar/libav/12.3 --enable-gpl --enable-nonfree --enable-version3 --enable-vda --cc=clang --host-cflags= --host-ldflags= --enable-libfaac --enable-libfdk-aac --enable-libfreetype --enable-libmp3lame --enable-libopus --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libxvid\n  libavutil     55. 20. 0 / 55. 20. 0\n  libavcodec    57. 25. 0 / 57. 25. 0\n  libavformat   57.  7. 2 / 57.  7. 2\n  libavdevice   56.  1. 0 / 56.  1. 0\n  libavfilter    6.  7. 0 /  6.  7. 0\n  libavresample  3.  0. 0 /  3.  0. 0\n  libswscale     4.  0. 0 /  4.  0. 0\nhttps://dasersteuni-vh.akamaihd.net/i/int/2018/06/22/5167d480-53d9-4d48-aff8-912a0a3ba490/,320-1,512-1,960-1,480-1,640-1,.mp4.csmil/index_2_av.m3u8?null=0: Protocol not found\n\n\nERROR: ffmpeg exited with code 1\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/bin/youtube-dl/__main__.py\", line 19, in <module>\n    youtube_dl.main()\n  File \"/usr/local/bin/youtube-dl/youtube_dl/__init__.py\", line 472, in main\n    _real_main(argv)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/__init__.py\", line 462, in _real_main\n    retcode = ydl.download(all_urls)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 2001, in download\n    url, force_generic_extractor=self.params.get('force_generic_extractor', False))\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 803, in extract_info\n    return self.process_ie_result(ie_result, download, extra_info)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 857, in process_ie_result\n    return self.process_video_result(ie_result, download=download)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 1635, in process_video_result\n    self.process_info(new_info)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 1908, in process_info\n    success = dl(filename, info_dict)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 1847, in dl\n    return fd.download(name, info)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/downloader/common.py\", line 364, in download\n    return self.real_download(filename, info_dict)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/downloader/external.py\", line 64, in real_download\n    self.get_basename(), retval))\n  File \"/usr/local/bin/youtube-dl/youtube_dl/downloader/common.py\", line 165, in report_error\n    self.ydl.report_error(*args, **kargs)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 620, in report_error\n    self.trouble(error_message, tb)\n  File \"/usr/local/bin/youtube-dl/youtube_dl/YoutubeDL.py\", line 582, in trouble\n    tb_data = traceback.format_list(traceback.extract_stack())\n"], "labels": ["invalid"]}
{"project": "cherrypy_cherrypy", "title": "Suggestion for enhancement of _checkBasicResponse()", "description": "Originally reported by: Anonymous I would like to suggest an enhancement of _checkBasicResponse() as\nshown by the following diff: <CODE> The addition of a second parameter providing the user name to\nencrypt() would ease the life of cherrypy users writing an encryption\nfunction for basic http authentication. Because sometimes the\nencryption function needs additional information on how to encrypt the\npassword, for example think about encrypting a password like Unix/\nLinux does: crypt.crypt(password, salt) in which salt is the encrypted password which cannot guessed in the\nencryption function unless additional information is available like\nthe corresponding user name. Best regards,\nSven Reported by fischer@snom.com ", "code": ["--- a/PyLib/CherryPy-3.1b1-py2.5.egg/cherrypy/lib/httpauth.py\n+++ b/PyLib/CherryPy-3.1b1-py2.5.egg/cherrypy/lib/httpauth.py\n@@ -309,7 +309,7 @@ def _checkDigestResponse(auth_map, password,\nmethod = \"GET\", A1 = None, **kwargs\n     return response == auth_map[\"response\"]\n\n def _checkBasicResponse (auth_map, password, method='GET',\nencrypt=None, **kwargs):\n-    return encrypt(auth_map[\"password\"]) == password\n+    return encrypt(auth_map[\"password\"], auth_map[\"username\"]) ==\npassword\n\n AUTH_RESPONSES = {\n     \"basic\": _checkBasicResponse,\n"], "labels": ["major", "enhancement", "CherryPy code"]}
{"project": "OrchardCMS_Orchard", "title": "When presenting the Editor and hiding shapes, when then updating that editor, all information pertaining to that is lost", "description": "@Jetski5822 created:\n<URL> As Title says there seems to be a major flaw in updating user details from the front end\nSo, If I render out a user profile with a bunch of fields and parts and use the placement.info file to hide certain parts and then save the profile. Those hidden parts get wiped. any ideas on how to stop that? Fix:\nbool IUpdateModel.TryUpdateModel(\nTModel model, string prefix, string[] includeProperties, string[] excludeProperties)\n{\nvar keys = this.Request.Params.Keys.Cast();\nreturn keys.Any(k => k.StartsWith(prefix))\n? this.TryUpdateModel(model, prefix, includeProperties, excludeProperties)\n: false;\n} But there has to be a better way! ", "code": [], "labels": ["resolved"]}
{"project": "agda_agda", "title": "Instance argument mechanism ignores let-bound variables", "description": "<CODE> Original issue reported on code.google.com by nils.anders.danielsson on 10 Jan 2012 at 4:05 ", "code": ["module Bug where\n\ndata Box (A : Set) : Set where\n  [_] : A \u2192 Box A\n\npostulate\n  A : Set\n\n\u22ef : {{a : A}} \u2192 A\n\u22ef {{a = a}} = a\n\nworks : Box A\nworks = [ \u22ef ]\n  where postulate a : A\n\nfails : Box A\nfails =\n  let a : A\n      a = ?\n  in [ \u22ef ]\n\n-- Bug.agda:20,8-9\n-- No variable of type A was found in scope.\n-- when checking that the expression \u22ef has type A\n\n"], "labels": ["auto-migrated", "type: bug"]}
{"project": "matomo-org_matomo", "title": "archive.php should only process websites which exist", "description": "If a website data was invalidated, archive.php will try to process it next time it runs. If a website data was invalidated and then the website deleted, the archive.php will partially fail trying to process a non existing website. ", "code": [], "labels": ["T: Bug"]}
{"project": "vnpy_vnpy", "title": "ImportError: No module named strategyAtrRsi", "description": "Question \u9884\u671f\u4f7f\u7528 import vnpy.trader.app.ctaStrategy.strategy as cta \u53ef\u4ee5\u6b63\u5e38\u5f15\u5165\u5305 \u62a5\u9519\uff1a\u63d0\u793a /anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py \u6587\u4ef6\u65e0\u6cd5\u5f15\u5165\u76f8\u540c\u76ee\u5f55\u4e0b\u7684\u5176\u4ed6\u7b56\u7565\u6587\u4ef6\uff0c\u5982\u4e0b\uff1a <CODE> \u6211\u5728 anaconda python 2.7x \u548c\u672c\u673a\u81ea\u5e26\u7684 python \u90fd\u5c1d\u8bd5\u4e86\uff0c\u95ee\u9898\u76f8\u540c\u3002 \u8ba9\u670b\u53cb\u5728\u5176 Windows \u7535\u8111\u4e0b\u8fdb\u884c\u76f8\u540c\u5c1d\u8bd5\u6ca1\u6709\u95ee\u9898\u3002 \u770b\u4e86 issues \u91cc\u9762\u5176\u4ed6\u7684 ImportError: No module named XXX \u95ee\u9898\u8c8c\u4f3c\u90fd\u4e0e\u6211\u7684\u4e0d\u592a\u76f8\u540c\uff0c \u8bf7\u5927\u795e\u6307\u70b9~ ", "code": ["--------------------\nFailed to import strategy file strategyAtrRsi:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyAtrRsi\n--------------------\nFailed to import strategy file strategyBollChannel:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyBollChannel\n--------------------\nFailed to import strategy file strategyDoubleMa:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyDoubleMa\n--------------------\nFailed to import strategy file strategyMultiTimeframe:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyMultiTimeframe\n--------------------\nFailed to import strategy file strategyMultiSignal:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyMultiSignal\n--------------------\nFailed to import strategy file strategyTurtleTrading:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyTurtleTrading\n--------------------\nFailed to import strategy file strategyKingKeltner:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyKingKeltner\n--------------------\nFailed to import strategy file strategyDualThrust:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyDualThrust\n--------------------\nFailed to import strategy file strategyAtrRsi:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyAtrRsi\n--------------------\nFailed to import strategy file strategyBollChannel:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyBollChannel\n--------------------\nFailed to import strategy file strategyDoubleMa:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyDoubleMa\n--------------------\nFailed to import strategy file strategyMultiTimeframe:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyMultiTimeframe\n--------------------\nFailed to import strategy file strategyMultiSignal:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyMultiSignal\n--------------------\nFailed to import strategy file strategyTurtleTrading:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyTurtleTrading\n--------------------\nFailed to import strategy file strategyKingKeltner:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyKingKeltner\n--------------------\nFailed to import strategy file strategyDualThrust:\nTraceback (most recent call last):\n  File \"/anaconda3/envs/Python27/lib/python2.7/site-packages/vnpy/trader/app/ctaStrategy/strategy/__init__.py\", line 20, in loadStrategyModule\n    module = importlib.import_module(moduleName)\n  File \"/anaconda3/envs/Python27/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named strategyDualThrust\n"], "labels": ["help wanted"]}
{"project": "museui_muse-ui", "title": "Date Picker\u7ec4\u4ef6 \u9009\u62e9\u5e74\u4efd\u540e\u4e0d\u8df3\u8f6c\u5230\u9009\u62e9\u65e5\u671f\u7684\u754c\u9762", "description": "\u7528\u6237\u6253\u5f00\u63a7\u4ef6\uff0c\u70b9\u51fb\u9009\u62e9\u5e74\u4efd\u540e\u4e0d\u8df3\u8f6c\u5230\u9009\u62e9\u65e5\u671f\u7684\u754c\u9762 \uff0c\n\u4e0d\u77e5\u9053\u7b97\u4e0d\u7b97BUG \uff0c \u611f\u89c9\u4f7f\u7528\u4e0a\u6709\u70b9\u4e0d\u4fbf\u5427\u3002\nmaterial-ui \u7f51\u7ad9\u7684 \u6ca1\u6709\u8fd9\u4e2a\u95ee\u9898 date-picker\u3002 ", "code": [], "labels": ["enhancement"]}
{"project": "ant-design_ant-design", "title": "\u4f7f\u7528react-contexify\u521b\u5efatreenode\u53f3\u952e\u83dc\u5355\uff0c\u70b9\u51fb\u83dc\u5355\u65f6\uff0c\u5982\u4f55\u83b7\u53d6\u9009\u4e2d\u7684treeNode\uff1f", "description": "\nNo description provided.\n ", "code": [], "labels": ["Invalid"]}
{"project": "ionic-team_ionic", "title": "Sample app doesn't work with es6 target", "description": "Steps to reproduce: Ionic info\nCordova CLI: 6.0.0 Ionic Version: 2.0.0-alpha.57 Ionic CLI Version: 2.0.0-beta.17 Ionic App Lib Version: 2.0.0-beta.8 ios-deploy version: 1.8.5  ios-sim version: 5.0.6  OS: Mac OS X El Capitan Node Version: v5.6.0 Xcode version: Xcode 7.3 Build version 7D111g ", "code": [], "labels": ["build"]}
{"project": "OpenRA_OpenRA", "title": "Merging the tabs graphic into the team chrome graphic.", "description": "There is a lot of negative space in the allied/soviet chrome image files, and the tabs being in a separate file where all teams are together seems less modular. Limitation coming from only being able to have one set of Tabs nodes available to represent all teams instead of for each team. ", "code": [], "labels": ["Refactor"]}
{"project": "jOOQ_jOOQ", "title": "NullPointerException in DefaultRecordMapperProvider when setting a new instance to a Configuration", "description": "When using the following kind of Configuration: A NullPointerException may occur when calling Result.into(Class): <CODE> See also:\n<URL> ", "code": ["java.lang.NullPointerException\n    at org.jooq.impl.DefaultRecordMapperProvider.provide(DefaultRecordMapperProvider.java:83)\n    at org.jooq.impl.ResultImpl.into(ResultImpl.java:1369)\n"], "labels": ["E: All Editions", "R: Fixed", "C: Functionality", "P: High", "T: Defect"]}
{"project": "serverless_serverless", "title": "application/json not being converted into a dictionary", "description": "I have created an POST API Endpoint + Lambda function. Although when I send \"content-type\": \"application/json\" with raw body as { \"name\": \"Prakash Raman\" } I get the following in the \"event\" object. \"input\": { \"body\": \"{\\n\\t\\\"name\\\": \\\"Prakash Raman\\\"\\n}\", The documentation says Was wondering what I am doing wrong. Thanks! ", "code": [], "labels": ["more-info-needed", "question"]}
{"project": "cherrypy_cherrypy", "title": "Correct content-type leads to ValueError (unicode)", "description": "My application returns data that is ASCII Text however this text has a special meaning and custom mime type. (It's chemical data:  <URL> If I don't set a content-type (defaults to html)  or set it to text/plain but works but is semantically incorrect.  If I set content type to one of the aboves, say for example chemical/x-mdl-molfile I get an error: Set the content-type of a response: cherrypy.response.headers['Content-Type'] = 'chemical/x-mdl-molfile' Same output as with content-type text/plain Correctness. ", "code": [], "labels": ["duplicate"]}
{"project": "eclipse-theia_theia", "title": "Intermittent problem where new folder not shown", "description": "With 0.3.10 browser-based Theia, we are seeing an intermittent problem where a new folder created in the workspace from outside Theia isn't automatically being shown in the tree files view. To get it to show requires refreshing the browser. ", "code": [], "labels": ["bug"]}
{"project": "kivy_kivy", "title": "SDL2: Unable to load image [solved]", "description": "<URL> ", "code": [], "labels": ["awaiting-reply"]}
{"project": "Maatwebsite_Laravel-Excel", "title": "function dispatch_now don't exist", "description": "When use \"Chunk reading\",  unfortunately cause to exception as follows ", "code": [], "labels": ["enhancement"]}
{"project": "ansible_ansible", "title": "Ansible hangs indefinitely on password age prompt", "description": "<CODE> N/A ansible will hang indefinitely on hosts that require a password change on connect ansible exits with a failure ansible hangs forever <CODE> If I ssh manually to the host I get the following: <CODE> ", "code": ["ansible 2.0.0.2\n", "Loaded callback default of type stdout, v2.0\n1 plays in global-rcfiles.yml\n\nPLAY ***************************************************************************\n\nTASK [copy rcfiles] ************************************************************\ntask path: /home/sec/Projects/ansible/global-rcfiles.yml:4\n<munnvinfpapc03> ESTABLISH SSH CONNECTION FOR USER: None\n<munnvinfpapc03> SSH: EXEC ssh -C -vvv -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o ControlPath=/home/sec/.ansible/cp/ansible-ssh-%h-%p-%r -tt hostname 'echo ~'\n", "+------------------------------------------------------------+\n| The use of this system is restricted to authorised users.  |\n| Unauthorised users will be prosecuted without hesitation!! |\n+------------------------------------------------------------+\nYou are required to change your password immediately (password aged)\nLast login: Thu Jul  6 16:21:51 2017 from 10.0.0.1\n \nCentOS release 6.9 (Final)\n[...]\n\nWARNING: Your password has expired.\nYou must change your password now and login again!\nChanging password for user szehl.\nChanging password for szehl.\n(current) UNIX password: \n"], "labels": ["support:core", "bug", "affects_2.0"]}
{"project": "matrix-org_synapse", "title": "Syncrotron worker fail", "description": "We would like horizontal scaling for synapse. We have one virtual machine private synapse running almost without problems.\nWe have found this url where it expain this:\n<URL> But we have many problems when we configure workers with syncrotron. Our idea is add several virtual machines and then load balance with haproxy among them. Is it possible? We have created second virtualmachine, and cloning actual private synapse server. We add listeners to /etc/matrix-synapse/homeserver.yaml and restarting \"systemctl restart matrix-synapse\" up new ports without problem. Then we add new configuration file /etc/matrix-synapse/conf.d/syncrotron.yaml with next content: <CODE> Then we restart service with \"systemctl restart matrix-synapse\" but no start synapse service.\nLog output is next (/var/log/matrix-synapse/homeserver.log): <CODE> Maybe we have misunderstood the documentation If not matrix.org: ", "code": ["worker_app: synapse.app.synchrotron\nserver_name: matrix.example.com\nreport_stats: false\n\nworker_replication_host: 127.0.0.1\nworker_replication_port: 9092\nworker_replication_http_port: 9093\n\nworker_listeners:\n - type: http\n   port: 8083\n   resources:\n     - names:\n       - client\n\nworker_daemonize: True\nworker_pid_file: /var/lib/matrix-synapse/synchrotron.pid\nworker_log_config: /var/log/matrix-synapse/synchrotron_log_config.yaml\n", "2018-07-12 09:36:40,332 - twisted - 131 - ERROR - - Traceback (most recent call last):\n2018-07-12 09:36:40,333 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n2018-07-12 09:36:40,333 - twisted - 131 - ERROR - -     \"__main__\", fname, loader, pkg_name)\n2018-07-12 09:36:40,334 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n2018-07-12 09:36:40,335 - twisted - 131 - ERROR - -     exec code in run_globals\n2018-07-12 09:36:40,336 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/app/homeserver.py\", line 537, in <module>\n2018-07-12 09:36:40,336 - twisted - 131 - ERROR - -     main()\n2018-07-12 09:36:40,337 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/app/homeserver.py\", line 532, in main\n2018-07-12 09:36:40,338 - twisted - 131 - ERROR - -     hs = setup(sys.argv[1:])\n2018-07-12 09:36:40,339 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/app/homeserver.py\", line 361, in setup\n2018-07-12 09:36:40,339 - twisted - 131 - ERROR - -     hs.start_listening()\n2018-07-12 09:36:40,340 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/app/homeserver.py\", line 243, in start_listening\n2018-07-12 09:36:40,341 - twisted - 131 - ERROR - -     self._listener_http(config, listener)\n2018-07-12 09:36:40,342 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/app/homeserver.py\", line 113, in _listener_http\n2018-07-12 09:36:40,342 - twisted - 131 - ERROR - -     config, name, res.get(\"compress\", False),\n2018-07-12 09:36:40,343 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/app/homeserver.py\", line 173, in _configure_named_resource\n2018-07-12 09:36:40,344 - twisted - 131 - ERROR - -     client_resource = ClientRestResource(self)\n2018-07-12 09:36:40,345 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/rest/__init__.py\", line 66, in __init__\n2018-07-12 09:36:40,345 - twisted - 131 - ERROR - -     self.register_servlets(self, hs)\n2018-07-12 09:36:40,346 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/rest/__init__.py\", line 73, in register_servlets\n2018-07-12 09:36:40,347 - twisted - 131 - ERROR - -     room.register_servlets(hs, client_resource)\n2018-07-12 09:36:40,347 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/rest/client/v1/room.py\", line 833, in register_servlets\n2018-07-12 09:36:40,348 - twisted - 131 - ERROR - -     RoomTypingRestServlet(hs).register(http_server)\n2018-07-12 09:36:40,349 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/rest/client/v1/room.py\", line 714, in __init__\n2018-07-12 09:36:40,350 - twisted - 131 - ERROR - -     self.presence_handler = hs.get_presence_handler()\n2018-07-12 09:36:40,350 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/server.py\", line 449, in _get\n2018-07-12 09:36:40,351 - twisted - 131 - ERROR - -     dep = builder()\n2018-07-12 09:36:40,352 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/server.py\", line 249, in build_presence_handler\n2018-07-12 09:36:40,352 - twisted - 131 - ERROR - -     return PresenceHandler(self)\n2018-07-12 09:36:40,353 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/handlers/presence.py\", line 105, in __init__\n2018-07-12 09:36:40,354 - twisted - 131 - ERROR - -     self.federation = hs.get_federation_sender()\n2018-07-12 09:36:40,354 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/server.py\", line 449, in _get\n2018-07-12 09:36:40,355 - twisted - 131 - ERROR - -     dep = builder()\n2018-07-12 09:36:40,356 - twisted - 131 - ERROR - -   File \"/usr/lib/python2.7/dist-packages/synapse/server.py\", line 368, in build_federation_sender\n2018-07-12 09:36:40,357 - twisted - 131 - ERROR - -     raise Exception(\"Workers cannot send federation traffic\")\n2018-07-12 09:36:40,357 - twisted - 131 - ERROR - - Exception: Workers cannot send federation traffic\n"], "labels": ["question"]}
{"project": "twbs_bootstrap", "title": "Firefox Issue: On click of element which has tooltip, Tooltip is not removed from the element", "description": "Firefox Issue: On click of element which has tooltip, Tooltip is not removed from the element Using the default settings to Initialise the Tooltip.\nUsing Bootstrap version: ^4.1.3 ", "code": [], "labels": ["awaiting reply"]}
{"project": "composer_composer", "title": "php extension requirement handling", "description": "With the following command <CODE> on a plain ubuntu14 vm with php7 I got <CODE> after solving this problem by installing php-ast I now get <CODE> couldnt composer check all required extensions at once and give me information about all required extensions?\nespecially in a workflow where the person who installs the missing extensions is not the one who runs the CLI command this kind of single-cause error messages render the process time-comsuming. <CODE> ", "code": ["composer global require \"etsy/phan:dev-master\"\n", "  Problem 1\n    - Installation request for etsy/phan dev-master -> satisfiable by etsy/phan[                                                                                                     dev-master].\n    - etsy/phan dev-master requires ext-ast * -> the requested PHP extension ast                                                                                                      is missing from your system.\n", "  Problem 1\n    - Installation request for etsy/phan dev-master -> satisfiable by etsy/phan[dev-master].\n    - etsy/phan dev-master requires ext-sqlite3 0.7-dev -> the requested PHP extension sqlite3 is missing from your system.\n", "composer --version\nComposer version 1.1.3 2016-06-26 15:42:08\n\nphp --version\nPHP 7.0.8-4+deb.sury.org~trusty+1 (cli) ( NTS )\nCopyright (c) 1997-2016 The PHP Group\nZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies\n    with Zend OPcache v7.0.8-4+deb.sury.org~trusty+1, Copyright (c) 1999-2016, by Zend Technologies\n"], "labels": ["Question"]}
{"project": "ansible_ansible", "title": "ecs_service.py: \"network_configuration\" for \"awsvpc\" is missing \"assign_public_ip\"", "description": "Cannot assign public IP to an ECS container running with awsvpc network_configuration mode (also affects fargate probably).\n<URL>\nThe subnet and security group options are OK but the 3rd option is missing from the code. amazon/ecs_service latest development assignPublicIp should be ENABLED launchType: EC2\n02:11:29       networkConfiguration:\n02:11:29         awsvpcConfiguration:\n02:11:29           assignPublicIp: DISABLED\n02:11:29           securityGroups:\n02:11:29           - sg-a89fc1d6\n02:11:29           subnets:\n02:11:29           - subnet-6c9c4d42\n02:11:29       pendingCount: 1\n02:11:29       runningCount: 0\n02:11:29       status: ACTIVE ", "code": [], "labels": ["waiting_on_contributor", "support:community", "affects_2.7", "module", "aws", "bug", "cloud"]}
{"project": "Homebrew_homebrew-science", "title": "Octave 3.8 failed to build on 10.9.1", "description": "Octave suddenly didn't work properly anymore (hang and crash on startup). So I decided\nto reinstall it. After running brew update and brew update I ran: <CODE> Please review the gist for a more detailed output (put up using brew gist-logs --config --doctor octave). ", "code": ["$ brew install octave\n==> Using Homebrew-provided fortran compiler.\nThis may be changed by setting the FC environment variable.\n==> Building with an alternative Fortran compiler\nThis is unsupported.\n==> Building with an alternative Fortran compiler\nThis is unsupported.\n==> Building with an alternative Fortran compiler\nThis is unsupported.\n==> Downloading http://ftpmirror.gnu.org/octave/octave-3.8.0.tar.bz2\nAlready downloaded: /Library/Caches/Homebrew/octave-3.8.0.tar.bz2\n==> autoreconf -ivf\n==> ./configure --prefix=/usr/local/Cellar/octave/3.8.0 --with-blas=-Wl,-framework,Accelerate --with-lapack=-Wl,-framework,Accelerate \n==> make all\n7 errors\n1 warning\nmake[2]: *** [java/org/octave/ClassHelper.class] Error 1\nmake[1]: *** [all-recursive] Error 1\nmake: *** [all] Error 2\n\nREAD THIS: https://github.com/Homebrew/homebrew/wiki/troubleshooting\nIf reporting this issue please do so at (not Homebrew/homebrew):\n  https://github.com/homebrew/homebrew-science/issues\n\nThese open issues may also help:\nFormula for octave (https://github.com/Homebrew/homebrew/pull/2914)\noctave failed to build on 10.8.5 (https://github.com/Homebrew/homebrew/issues/24804)\noctave 3.8 failed to build on 10.9.1 (https://github.com/Homebrew/homebrew/issues/25593)\noctave failed to build on 10.9 (https://github.com/Homebrew/homebrew/issues/23611)\n"], "labels": ["build-error"]}
{"project": "saltstack_salt", "title": "minion runs highstate on start if schedule set in pillar", "description": "This is either a bug with the minion or a bug in the documentation and I wanted to clarify if this expected behaviour. With a schedule in the pillar it triggers the function on salt-minion start: This will trigger a highstate when the minion starts which is (to me) slightly unexpected behaviour, I can understand why it would do it but I can't see it documented (which has lead to a few head/table interfaces during state development). ", "code": [], "labels": ["Documentation", "Bug", "Fixed Pending Verification", "Medium Severity", "P4", "TEAM Core"]}
{"project": "microsoft_CNTK", "title": "Does parallel train support sparse matrix?", "description": "Hi all, When I tried to run CNTK with multiple GPU machines on sparse input data, I meet the error below. But for dense input data, it seems worked fine. Dose it mean CNTK do not support parallel train with GPU sparse matrix now? [CALL STACK]\n>Microsoft::MSR::CNTK::TensorView::DoTernaryOpOf\n-Microsoft::MSR::CNTK::GPUSparseMatrix::Reshape\n-Microsoft::MSR::CNTK::Matrix::Reshape\n-Microsoft::MSR::CNTK::Matrix::Reshaped\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-Microsoft::MSR::CNTK::TracingGPUMemoryAllocator::operator=\n-BaseThreadInitThunk\n-RtlUserThreadStart EXCEPTION occurred: GPUSparseMatrix::Reshape: Cannot Reshape since the buffer is managed externally. I add ParallelTrain=true in the command line the add below parameter in SGD section in config file.\nParallelTrain=[\nparallelizationMethod=DataParallelSGD\n] @bmitra-msft @frankseide ", "code": [], "labels": ["question"]}
{"project": "hashicorp_terraform", "title": "aliased providers do not get merged from override files.", "description": "When attempting to validate terraform provider config with an aliased provider in an override file, the aliased provider does not get merged correctly, resulting in duplicate provider errors. <CODE> NOTE: un-aliased providers are merged fine. v0.10.7 cd_override.tf main.tf <CODE> <URL> aliased provider should get merged before validate is called and only a single instance of the provider should exist at this point. Validate fails as two instances of the provider are found in the resources, somehow I am guessing that when it merges the overrides it does not match the alias key and merge it? I cant seem to figure that one out. I suspect around here it should look for the alias key and decide to merge it. Please list the full steps required to reproduce the issue, for example: I am using the cd override to assume a role when working in a cd env. Usually we use aws-vault locally so no need to specify roles. Secondly, the reason I am trying to use two AWS providers is because I need to fetch an aws acm resource arn using a data source from a aws provider set to us-east-1. I need to do this as aws_api_gateway can only use certs from us-east-1, regardless of what region it is in. This is because under the hood api gateway sets up a cloudfront distribution. Fetching the cert arn using a provider in a different region with an alias is less than ideal, but I don't have much choice here. Ergh! None that i can find. ", "code": ["Error validating: 1 error(s) occurred:                                                                                               \n                                                                                                                                     \n* provider.aws.us-east-1: declared multiple times, you can only declare a provider once  \n", "provider \"aws\" {\n  // this is the test account id\n  allowed_account_ids = [\"123456789111\"]\n  region              = \"eu-west-1\"\n}\n\nprovider \"aws\" {\n  alias = \"us-east-1\"\n\n  // this is the test account id\n  allowed_account_ids = [\"123456789111\"]\n  region              = \"us-east-1\"\n}\n"], "labels": ["config", "bug"]}
{"project": "mikepenz_MaterialDrawer", "title": "Get instance of current drawer", "description": "Hey! I wanna use your drawer in my project, but i have a question: how to get instance of current drawer, from fragment, to change counters for example, or listen for open/close state Thanks in advance! ", "code": [], "labels": ["question"]}
{"project": "samaaron_sonic-pi", "title": "[Feature] Solo mode", "description": "A solo function which silences all but the selected named thread A very quick way to transition to a new melody within other silenced threads or simply to add some variation while live coding. Happy to implement if its deemed useful. ", "code": [], "labels": ["Feature Request"]}
{"project": "TeamNewPipe_NewPipe", "title": "[meta] Wikipedia article", "description": "I'd love to see a Wikipedia article (or even localized ones) for NewPipe. I assume the app is mature enough by now, and there's enough references one could use in my opinion. I'd love to see our contributors compose an article about this really awesome piece of software. @theScrabi and I put a list of references together you might use (a few are in German, and it would be awesome to see those magazine articles as references): ", "code": [], "labels": ["meta"]}
{"project": "saltstack_salt", "title": "Salt-Master 2014.7 network.py lsof command returns non-zero on SmartOS base64 14.2.0", "description": "Salt was installed on SmartOS base64 14.2.0 with:\nwget -O bootstrap.sh bootstrap.saltstack.org\nsh bootstrap.sh git v2014.7 separate issue, \"svccfg export salt-master\" shows config_dir expected to be in /opt/local/etc/, had to also do \"mv /etc/salt /opt/local/etc/\" On SmartOS base64 14.2.0, lines 930-934 of /opt/local/lib/python2.7/site-packages/salt/utils/network.py <URL> show what appears to be the \"Linux lsof\" that differs from the illumos lsof shown here <URL> A snippet of /var/log/salt/master shows <URL> shows an lsof command that won't run on base64 14.2.0 <URL> ", "code": [], "labels": ["Duplicate", "Bug", "Pending Discussion", "Fixed Pending Verification", "Medium Severity"]}
{"project": "RocketChat_Rocket.Chat", "title": "Hide Flextab Preference Bug", "description": "When the hide right side bar with click user preference is set to true the flex tabs doesn't open. ", "code": [], "labels": ["subj: ui/ux", "type: bug"]}
{"project": "cdnjs_cdnjs", "title": "[Request] Add nipplejs", "description": "Library name: nipplejs\nGit repository url: <URL>\nnpm package name or url (if there is one): nipplejs\nLicense (List them all if it's multiple): MIT\nOfficial homepage: <URL>\nWanna say something? Leave message here: ", "code": [], "labels": [" Library Request"]}
{"project": "ionic-team_ionic", "title": "error :  ionc build ios or android, uglifyjs failed: SyntaxError: Unexpected token: operator (>)", "description": "when i run ionic build ios. will display fllow errror\uff0cuglifyjs cannot support es6 feature arrow function\n]  ngc finished in 32.81 s\n[19:52:49]  bundle started ...\n[19:53:01]  bundle finished in 12.33 s\n[19:53:01]  uglifyjs started ...\n[19:53:01]  sass started ...\n[19:53:02]  uglifyjs failed: SyntaxError: Unexpected token: operator (>)\n[19:53:02]  ionic-app-script task: \"build\"\n[19:53:02]  Error: SyntaxError: Unexpected token: operator (>) ", "code": [], "labels": ["needs: reply", "v2"]}
{"project": "openMVG_openMVG", "title": "[question] Using EXR / HDR as input files ?", "description": "Good afternoon everyone, I would like to know if anyone made any tests to use EXR or other kind of HDR image to rebuild an asset ?\nIs that something do able ? Or  does the main strategy should be to use one exposure, and then interpolate the texture ? I think that would be really interesting, because you are working on fisheye camera, so why we should not get 3D environment map for example or to acquire material/BRDF from asset ? Thanks for your replies, Have a great day, Stephane ", "code": [], "labels": ["question"]}
{"project": "jeremylong_DependencyCheck", "title": "old NVD CVE 2019 in the report while updates done before", "description": "using docker image dependency-check version: 4.0.2 In the log I see that there was a check for updates and that there are updates downloaded and processed: 03:11:56 [INFO] Checking for updates\n03:11:56 [INFO] starting getUpdatesNeeded() ...\n03:11:59 [INFO] Download Started for NVD CVE - Modified\n03:12:02 [INFO] Download Complete for NVD CVE - Modified  (2875 ms)\n03:12:02 [INFO] Processing Started for NVD CVE - Modified\n03:12:05 [INFO] Processing Complete for NVD CVE - Modified  (3577 ms)\n03:12:05 [INFO] Begin database maintenance.\n03:12:07 [INFO] End database maintenance.\n03:12:07 [WARN] A new version of dependency-check is available. Consider updating to version 5.0.0.m1.\n03:12:09 [INFO] Check for updates complete (12393 ms) But in the report the data for NVD CVE 2019 are old (from March):\n...\nNVD CVE 2016: 02/03/2019 03:57:16\nNVD CVE 2017: 02/03/2019 03:57:15\nNVD CVE 2018: 02/03/2019 03:57:14\nNVD CVE 2019: 01/03/2019 08:01:31\nNVD CVE Checked: 14/05/2019 08:13:46\nNVD CVE Modified: 14/05/2019 05:15:33\nVersionCheckOn: 1556717936668 ", "code": [], "labels": ["bug"]}
{"project": "cake-build_cake", "title": "Space in Reference Preprocessor Directive Throws Illegal characters in path", "description": "adding a preprocessor directive like this:\n#r \"path to/assembly.dll\"\nor:\n#reference \"path to/assembly.dll\"\nresults in: <CODE> Assuming the path is valid, the reference should be loaded, if the path is invalid, a file not found exception. First saw with 0.11.0, updated to 0.17.0 same issue. 64 bit Windows 10 Enterprise No A single line .cake file with a reference as described above can reproduce the problem. ", "code": ["    Error: System.ArgumentException: Illegal characters in path.\n       at System.IO.Path.CheckInvalidPathChars(String path, Boolean checkAdditional)\n       at System.IO.Path.IsPathRooted(String path)\n       at Cake.Core.IO.Path..ctor(String path)\n       at Cake.Core.IO.FilePath..ctor(String path)\n       at Cake.Core.Scripting.Processors.ReferenceDirectiveProcessor.Process(IScriptAnalyzerContext context, String line, String& replacement)\n       at Cake.Core.Scripting.Analysis.ScriptAnalyzer.<>c__DisplayClass6_2.<AnalyzeCallback>b__0(LineProcessor p)\n       at System.Linq.Enumerable.Any[TSource](IEnumerable`1 source, Func`2 predicate)\n       at Cake.Core.Scripting.Analysis.ScriptAnalyzer.AnalyzeCallback(IScriptAnalyzerContext context)\n       at Cake.Core.Scripting.Analysis.ScriptAnalyzerContext.Analyze(FilePath path)\n       at Cake.Core.Scripting.Analysis.ScriptAnalyzer.Analyze(FilePath path)\n       at Cake.Core.Scripting.ScriptRunner.Run(IScriptHost host, FilePath scriptPath, IDictionary`2 arguments)\n       at Cake.Commands.BuildCommand.Execute(CakeOptions options)\n       at Cake.CakeApplication.Run(CakeOptions options)\n       at Cake.Program.Main()\n"], "labels": ["Bug"]}
{"project": "dart-lang_sdk", "title": "Not initializing static final and spec", "description": "This issue was originally filed by Ilya.V...@gmail.com co19 test fails Language/05_Variables/05_Variables_A06_t02.dart cause an error is issued for class C {\n\u00a0\u00a0static final v;\n} not static warning as the test expects. Formally the test adheres to spec because, However, I think the spec should list this as an error, cause where else final class static will be initialized. ", "code": [], "labels": ["area-language", "Type-Defect", "closed-as-intended"]}
{"project": "surveyjs_survey-library", "title": "Survey Editor returns 404 on a couple of assets", "description": "Hi,\nJust noticed when using the Survey Editor on the site that it returns 404 status for the following items: ", "code": [], "labels": ["bug", "fixed"]}
{"project": "rust-lang_rfcs", "title": "Add a type which is equivalent to _Bool in C99", "description": "Postponed RFC This type would have to ensure two aspects: This could possibly be done through a new c_bool primitive type in liblibc (not an alias) or perhaps a wrapper struct/wrapper newtype if we're able to enhance as semantics enough (for example). ", "code": [], "labels": ["T-libs"]}
{"project": "rust-lang_rust", "title": "ICE when trying to tame std: failed at 'lookup_item: id not found: 148798'", "description": "I made a ~150 line usb footpedal library and I'm trying to link it against a tamed subset of std (cf #3094): I ran into an ICE: <CODE> I haven't made an isolated test case, but it doesn't take much code to trigger the bug: <CODE> The code is fpscribe rev 98b0e0cdbb. I'm using the current nightly on linux (Ubuntu 12.04): <CODE> I got it from the ppa. ", "code": ["fpscribe$ RUST_BACKTRACE=1 make\nrustc   -O footpedal.rs -L .\nerror: internal compiler error: unexpected failure\nnote: the compiler hit an unexpected failure path. this is a bug.\nnote: we would appreciate a bug report: http://static.rust-lang.org/doc/master/complement-bugreport.html\nnote: run with `RUST_BACKTRACE=1` for a backtrace\ntask 'rustc' failed at 'lookup_item: id not found: 148798', /build/buildd/rust-nightly-201404060405~0651d27~precise/src/librustc/metadata/decoder.rs:95\nstack backtrace:\n   1:     0x2b692cf2fb00 - rt::backtrace::imp::write::h5f2f567c302aceb38Mb::v0.11.pre\n   2:     0x2b692ce917f0 - rt::unwind::begin_unwind_inner::h020e2bd5484a13f9Bnb::v0.11.pre\n   3:     0x2b692ce91470 - rt::unwind::begin_unwind_fmt::had2edc00130e15ecLmb::v0.11.pre\n   4:     0x2b692aef2c60 - <unknown>\n   5:     0x2b692aef9030 - metadata::decoder::maybe_get_item_ast::hb969df0f249f5979bda::v0.11.pre\n   6:     0x2b692a79fd90 - metadata::csearch::maybe_get_item_ast::h54e9a0b7f74b5af2Z8b::v0.11.pre\n   7:     0x2b692ac599c0 - middle::const_eval::lookup_variant_by_id::hfce98df3ad93b884L4P::v0.11.pre\n   8:     0x2b692a8bd840 - middle::const_eval::lookup_const::h17cb5423bf10a1f4S3P::v0.11.pre\n   9:     0x2b692ac5c430 - <unknown>\n  10:     0x2b692ac5e700 - <unknown>\n  11:     0x2b692ac5e700 - <unknown>\n  12:     0x2b692ac5f470 - <unknown>\n  13:     0x2b692ac5e700 - <unknown>\n  14:     0x2b692ac5f470 - <unknown>\n  15:     0x2b692ac5e700 - <unknown>\n  16:     0x2b692ac5f470 - <unknown>\n  17:     0x2b692ac605a0 - <unknown>\n  18:     0x2b692ac5fcd0 - <unknown>\n  19:     0x2b692ac5ddd0 - middle::const_eval::process_crate::h85e49642fdbc647csfQ::v0.11.pre\n  20:     0x2b692ab6b350 - <unknown>\n  21:     0x2b692af9cc20 - driver::driver::phase_3_run_analysis_passes::h56874d2a6b937793Ere::v0.11.pre\n  22:     0x2b692afa3650 - driver::driver::compile_input::h108fdc2cbeadd60aBQe::v0.11.pre\n  23:     0x2b692afc6530 - run_compiler::h82f4eda38ece6fe2Jim::v0.11.pre\n  24:     0x2b692afdd8e0 - <unknown>\n  25:     0x2b692afdc210 - <unknown>\n  26:     0x2b692afd7b40 - <unknown>\n  27:     0x2b692a25c3f0 - <unknown>\n  28:     0x2b692cf2af90 - <unknown>\n  29:     0x2b692cf365b0 - rust_try\n  30:     0x2b692cf2add0 - rt::task::Task::run::hd22104201ff3b8d47f9::v0.11.pre\n  31:     0x2b692a25c1c0 - <unknown>\n  32:     0x2b692cf2e640 - <unknown>\n  33:     0x2b692ff97dc0 - start_thread\n  34:                0x0 - <unknown>\n\nmake: *** [libfootpedal-77ad9f83-0.0.rlib] Error 101\n", "fpscribe$ wc tame.rs footpedal.rs \n  10   22  245 tame.rs\n 147  393 3598 footpedal.rs\n 157  415 3843 total\n", "$ apt-cache policy rust-nightly\nrust-nightly:\n  Installed: 201404060405~0651d27~precise\n  Candidate: 201404060405~0651d27~precise\n"], "labels": ["I-ICE"]}
{"project": "aircrack-ng_aircrack-ng", "title": "Placeholder", "description": "This is a placeholder created during migration to preserve original issue numbers. ", "code": [], "labels": ["invalid"]}
{"project": "vuejs_vuepress", "title": "Request: Render $page.excerpt markdown", "description": "Currently $page.excerpt is rendered as plain text, without markdown parsing. ", "code": [], "labels": ["type: feature request"]}
{"project": "googleapis_google-cloud-python", "title": "[Request] Verify User Project methods comments are not ambiguous", "description": "General Request: Verify that the comments are clear for methods which accept User Project with and without Requester Pays. Here's a distinction between Requester Pays and User Project:\nUser Project: Is a request metadata field that is used to assign Storage operational costs to a specified project. Requester Pays: Is a bucket-level metadata field that is used to enforce the use of the User Project metadata field to assign operational costs when an operation is made on a Bucket and its objects. ", "code": [], "labels": ["api: storage", "type: question"]}
{"project": "frappe_erpnext", "title": "Cancelled Enteries should appear red/gray in Ledger so user is not confused", "description": "@netchampfaris use case for new datatable! ", "code": [], "labels": ["user-interface"]}
{"project": "grails_grails-core", "title": "GRAILS-6570: Named queries should support all standard list() parameters", "description": "Original Reporter: manuelvio\nEnvironment: Not Specified\nVersion: 1.3.3\nMigrated From: <URL> Named queries list() method supports \"max\" and \"offset\" parameters only. It should support sorting parameters (\"sort\", \"order\" and \"ignoreCase\") and \"fetch\" Map like standard domain classes .list() method does.\nThis would enhanche interchangeability between standard and namedquery .list() methods e.g. in controller actions. A similar behaviour now can be achieved chaining two named queries, one with the results, and another with a params argument: {code:title=SomeDomain.groovy|borderStyle=solid}\n...\nstatic namedQueries = {\nlistByOrganization { org ->\neq('organization', org)\n} //named query for pagination\npaginate{ params ->\nif (params?.sort){\norder(params.sort, params.order)\n} <CODE> }\n}\n...\n{code} {code}\n// This line should be : SomeDomain.listByOrganization.list(params)\nSomeDomain.listByOrganization.paginate(params).list()\n{code} ", "code": ["// max and offset are supported by list() method, but they're included here to manage them together with sorting\nif (params?.max){\n  maxResults(params?.max)\n}\nif (params?.offset){\n  firstResult(params?.offset)\n}\n"], "labels": ["Improvement", "Minor", "Fixed"]}
{"project": "shadowsocks_shadowsocks-libev", "title": "Server always prefer IPv4 over IPv6 for domain request", "description": "\u670d\u52a1\u5668\u5728\u6536\u5230\u7c7b\u578b\u4e3a3\uff08domain\uff09\u7684\u8bf7\u6c42\u540e\uff0c\u603b\u662f\u4f1a\u4f18\u5148\u89e3\u6790IPv4\u5730\u5740\uff0c\u800c\u4e0d\u662f\u4f7f\u7528getaddrinfo\u7684\u987a\u5e8f\u3002 \u4e4b\u524d-go\u7684\u670d\u52a1\u5668\u4e5f\u662f\u8fd9\u6837\uff0c\u4f46\u662f\u5728golang\u4fee\u590d\u4e86golang/go#8453 \uff08<URL>\uff09 \u4e4b\u540e\u5c31\u53d8\u6210\u4e86\u9075\u5b88\u7cfb\u7edf\u7684getaddrinfo\u4f18\u5148\u7ea7\uff0c\u53ef\u4ee5\u901a\u8fc7/etc/gai.conf \u63a7\u5236\u987a\u5e8f\u3002 \u6211\u4e5f\u4e0d\u662f\u5f88\u6e05\u695a\u8fd9\u662f\u4e0d\u662f\u6807\u51c6\uff0c\u4e0a\u9762\u7684issue\u91cc\u8bf4\u662fRFC 6555\u6216\u80056724\u2026\u2026\u4f46\u662f\u9ed8\u8ba4IPv4\u8fd9\u79cd\u8bbe\u5b9a\u5b9e\u5728\u4e0d\u592a\u65b9\u4fbf\uff0c\u5728DigitalOcean\u67d0\u4e9b\u673a\u5668\u4e0a\u53ea\u6709IPv6\u80fd\u4e0aGoogle\u2026\u2026 \u7c97\u7565\u770b\u4e86\u4e00\u4e0b\u4ee3\u7801\uff0c src/server.c#L602 \u8868\u793a\u4f7f\u7528\u4e86libcork\uff0c\u8ddf\u8fdb\u53bb\u4e4b\u540e libcork/core/ip-address.c#L472 \u76f4\u63a5\u5199\u4e86\"Try IPv4 first\"\uff0c\u8fd9\u4e5f\u2026\u2026 \u4e0d\u77e5\u9053\u5f00\u53d1\u8005\u600e\u4e48\u770b\u5462\uff1f ", "code": [], "labels": ["wontfix"]}
{"project": "tidusjar_Ombi", "title": "Newsletter Customization", "description": "Newsletter needs customization in options (How often it goes out, Content to Show, etc.)? Also the posters are all different sizes, especially the TV shows. Which makes the email scroll forever, even more so when a lot of content was added recently. The Newsletter should also remember what it sent out prior as newly added content to not show it again. This will help it not scroll forever as well. Need to have 2 formats for email. Poster View and Summary View. This way we can just send out a summary of listings without them having to scroll through the list. Great work though, keep it up. ", "code": [], "labels": ["enhancement"]}
{"project": "foosel_OctoPrint", "title": "usb_device_path validation in webcamd script needlessly strict", "description": "When using udev rules to create unique symlinks for specific usb cameras, it is customary to use a descriptive symlink, or at any rate, it appears to be preferred to avoid specifying symlinks that may collide with automatically generated devices. The regex of /dev/video[0-9]+\\ only finds numbered video devices, which may be randomly reassigned on reboot, particularly if devices have been plugged into different usb ports or moved to a powered hub. If a determined user has read through webcamd far enough to discover the undocumented usb_device_path option, it's unfortunate that usb_device_path can only be a numbered video device, rather than something like a /dev/videoC310 symlink created by a udev rule. For ease of use, i suggest a more general regex of /dev/video\\w+\\ ", "code": [], "labels": ["type:incomplete ticket"]}
{"project": "swaywm_sway", "title": "Toggling dpms changes output layout", "description": "Run the following: swaymsg \"output * dpms off\"; sleep 3; swaymsg \"output * dpms on\". On resume, my output layout is changed to an automatically generated one. The positioning I have in my config is ignored but transformations are preserved. Running swaymsg reload makes it re-apply the positioning from my config. ", "code": [], "labels": ["bug"]}
{"project": "nestjs_nest", "title": "@Query() does not transform to DTO", "description": "I have a controller that needs to recive data from the request query and I want to put that data into a DTO using @query() but it does not properly transform the DTO to the target interface If I call http://localhost:3000/?field1=10&field2=true&field3=test I get But the expected result is: <CODE> ", "code": ["\nNest version: 5.7.4\nNode version: 10.9.0\nclass-transformer: 0.2.3\nclass-validator: 0.10.1\ntsc version: 1.8.10\nPlatform: Ubuntu 18.10\n\n"], "labels": ["needs triage"]}
{"project": "odoo_odoo", "title": "[12.0] picking validate return nothing", "description": " ", "code": [], "labels": ["Need information"]}
{"project": "hashicorp_nomad", "title": "Clients working behind NAT", "description": "Last time I checked nomad had issues running worker nodes behind NAT. My usecase: I'd like nomad servers to run in the cloud, but nomad clients to run on my machine and execute tasks. This is a model that new docker swarm model allows in docker 1.12, but I'd like to nomad without docker installed (many clouds don't allow it, e.g. because there's missing TUN interface, or cgroups is not available). Is it currently possible to run worker nodes behind NAT? Are there plans to support it? ", "code": [], "labels": ["networking", "enhancement"]}
{"project": "grpc_grpc", "title": "yapf_code.sh failing", "description": "Failed in test <URL>\nand Linux master ", "code": [], "labels": ["priority/P0", "infra/BUILDPONY", "area/tools", "lang/Python"]}
{"project": "mapbox_mapbox-gl-native", "title": "Narrow but high viewport does not fit into area constrained by map.setPadding", "description": "In our app, we show a screen with a map on it, which has a bottom overlay. This overlay can be dragged over the screen and snaps to certain positions. When the overlay is pulled all the way down, the map has a relatively small bottom padding that allows the drag handler to be visible. Using this small padding of 120, the bounds of the viewport are correctly centered and the whole viewport is visible.\nIf we now drag the panel up, we set a higher bottom padding of the 50% of the map height and expect the viewport to still be visible in the now smaller area of the map, e.g. by zooming out.\nWhat actually happens is that the whole viewport is only shifted up slightly, not even in a way that the center would be correct, and no zooming out happens. The viewport is visible in the now smaller area of the map. The viewport is shifted up slightly. \nIn the bottom position, padding is applied correctly and the whole viewport is visible \nWith the panel in the center position, the viewport is not shown correctly We use the following code to set the bottom padding: Android versions: 8/9\nDevice models: Pixel2/3, One Plus 5\nMapbox SDK versions: 8.0.1 ", "code": [], "labels": ["Android"]}
{"project": "matomo-org_matomo", "title": "Calculation All Websites dashboard wrong", "description": "After upgrading Piwik the calculation for all dashboards is wrong see attached file, i have seen this after upgrading from piwik. Actually you can see this in the demo.piwik.org <URL> The total calculation of Pageviews is wrong you can also see my post in the forum: <URL>,115242,116586 Thank you ", "code": [], "labels": ["T: Bug"]}
{"project": "dotnet_roslyn", "title": "Roslyn ignores IVSSymbolicNavigationNotify and IVSRefactorNotify for CPS projects", "description": "Version Used: 15.7-preview1 Steps to Reproduce: Expected Behavior:\nRoslyn calls the implementation of IVsSymbolicNavigationNotify so that I can implement go to definition from C# -> Razor Actual Behavior:\nIt doesn't \ud83d\ude22 What's going wrong here is that at this location: <URL> hierarchy is the .NET object for ConfiguredProjectHostObject and not the COM wrapper. This means that the cast is a normal .NET cast, and not a QueryInterface. This means that my service (exported through CPS) aspnet/Razor@91b3b22#diff-4f1af834b38be73a1ebbffeffbde7bffR40 is not called. I'm honestly not sure what the right fix is for this, or whether it should come from Roslyn or the project system. I used the power of HAXXX to create a non-production-quality workaround in my local install and then everything functions as desired. rynowak@40a1e6e ", "code": [], "labels": ["Area-IDE", "Bug"]}
{"project": "Ultimaker_Cura", "title": "Super-fat infill lines leaves gaps, how to fill those?", "description": " I do all my prints 100% infilled. Meaning the infilling is the most time consuming part of most prints. It turns out my nozzle can do quite a lot fatter lines than one would imagine, BUT cura leaves gaping holes where it thinks the infill-lines dont fit. They would, in most cases if they were single-lines Is there a way to fill those holes with some other form of infill? Skin/top/bottom? Is there a way to tell the system to lower the height and width of the infill-line \"where needed\" ? ", "code": [], "labels": ["Type: Question"]}
{"project": "bisq-network_bisq", "title": "Fraud report", "description": "\nNo description provided.\n ", "code": [], "labels": ["0 - Backlog"]}
{"project": "duplicati_duplicati", "title": "OutOfMemory error on OS-X", "description": "", "code": [], "labels": ["bug"]}
{"project": "matomo-org_matomo", "title": "Visual Menu bug in IE7", "description": "See report and screenshot in <URL>,77718 ", "code": [], "labels": ["T: Bug"]}
{"project": "shadowsocks_shadowsocks-libev", "title": "Build error with dpkg-buildpackage", "description": "<CODE> and it seems dh_auto_clean returns errors in doc folder as well. ", "code": ["Making check in src\nmake[2]: Entering directory `/root/shadowsocks-libev/src'\nmake[2]: Nothing to be done for `check'.\nmake[2]: Leaving directory `/root/shadowsocks-libev/src'\nMaking check in doc\nmake[2]: Entering directory `/root/shadowsocks-libev/doc'\nmake[2]: *** No rule to make target `check'.  Stop.\nmake[2]: Leaving directory `/root/shadowsocks-libev/doc'\nmake[1]: *** [check-recursive] Error 1\nmake[1]: Leaving directory `/root/shadowsocks-libev'\ndh_auto_test: make -j1 check returned exit code 2\nmake: *** [build] Error 29\ndpkg-buildpackage: error: debian/rules build gave error exit status 2\n"], "labels": ["enhancement"]}
{"project": "CachetHQ_Cachet", "title": "Component's updated_at field not updating", "description": "When I make an API call to a component the updated_at field only updates to the current time if the status actually changes - i.e. If I send a request to update a component from Operational to Operational the update_at timestamp does not change. I have automated monitoring setup to update the components status regularly, and I want the timestamp to reflect the most recent time the component was checked. The other option would be to send a PUT request to manually change the updated_at field with the current time, however when I do this it causes the status to be set to 'cachet.components.status.0' and doesn't even update the time field. Example:\nCall: [2018-12-13 13:22.54] curl -X PUT <URL> -H \"Content-type: application/json\" -H \"X-Cachet-Token: <token omitted>\" -d \"{\\\"updated_at\\\":date +%s}\"\nResult:\n{\"data\":{\"id\":4,\"name\":\"Component Four\",\"description\":\"\",\"link\":\"https:\\/\\/www.component-four.com\",\"status\":0,\"order\":0,\"group_id\":1,\"created_at\":\"2018-12-12 15:13:15\",\"updated_at\":\"2018-12-13 13:22:42\",\"deleted_at\":null,\"enabled\":true,\"status_name\":\"cachet.components.status.0\",\"tags\":[]}}  EDIT: Already reached out on slack and was told to raise an issue, also I see there was a similar issue raised on here but it was closed with no resolution ", "code": [], "labels": ["API"]}
{"project": "mui-org_material-ui", "title": "examples Should Use Local, Not Install from npm", "description": "During development, I am attempting to utilize the local examples of this repo (and adding more components to them) in order to test / see changes I am creating. In order to do this sanely, I have removed material-ui from the package.json in each example directory and utilized local lib from project root. Is this something your team agrees with? It seems unconventional to me to do it that way it is currently. Note: React also should be used from root, otherwise you will end up with invariant issues from multiple instances of React. ", "code": [], "labels": ["wontfix"]}
{"project": "npm_npm", "title": "Can't install coffee script on windows 10", "description": "Can't install coffee script using \" npm install -g coffee-script \". ", "code": [], "labels": ["windows", "support"]}
{"project": "cakephp_cakephp", "title": "HtmlHelper::link fullBase option", "description": "This is a (multiple allowed): Used $options['fullBase' => true] in HtmlHelper::link().\nOutput linkdid not contain full base.\nMethod options are inconsistent as fullBase is accepted as an option in the rest of HtmlHelper/UrlHelper options. Output link did not contain full base. Output link contains full base. ", "code": [], "labels": ["enhancement", "defect"]}
{"project": "rest-assured_rest-assured", "title": "RA lost last slash", "description": "From twilig...@gmail.com on December 24, 2013 10:09:51 What steps will reproduce the problem? 1. given().log().all().expect().log().all().get(\"/bla/bla/\"); What is the expected output? What do you see instead? Request method:  GET\nRequest path:   http://localhost:8080/bla/bla/ Instead:\nRequest method: GET\nRequest path:   http://localhost:8080/bla/bla What version of the product are you using? On what operating system? 1.9.0, 1.8.2-SNAPSHOT, any OS. Please provide any additional information below. Error in this method:com/jayway/restassured/internal/RequestSpecificationImpl.groovy:1260 pathWithoutQueryParams = StringUtils.split(tempParams, \"/\").inject(\"\") { String acc, String subresource ->\n...\nformat(\"%s/%s\", acc, encode(subresource, EncodingTarget.QUERY)).toString()\n}\nAfter closure pathWithoutQueryParams has path without last slash Original issue: <URL> ", "code": [], "labels": ["wontfix", "Priority-Medium", "imported", "bug"]}
{"project": "keras-team_keras", "title": "Keras 1.2.2, TF 1.0, Windows10/64:", "description": "Noted this exception: Exception ignored in: <bound method BaseSession.del of <tensorflow.python.client.session.Session object at 0x0000025BCCD14550>>\nTraceback (most recent call last):\nFile \"lib\\tensorflow_gpu\\tensorflow\\python\\client\\session.py\", line 582, in del\nAttributeError: 'NoneType' object has no attribute 'TF_DeleteStatus' ", "code": [], "labels": ["stale"]}
{"project": "rust-lang_rust", "title": "Command::detach can cause zombie processes", "description": "Properly spawning a detached process requires double forking in order to avoid zombie processes: <URL> I did not see this happening in <URL> cc @aturon @alexcrichton ", "code": [], "labels": ["A-libs"]}
{"project": "doctrine_orm", "title": "DDC-1556: @PostLoad hook being executed more than once for the same entity when loaded through relationship", "description": "Jira issue originally created by user agvstin: Scenario: When I load both A's using the EntityManager, and access the instance of B (internally from each A), the @PostLoad hook is being triggered twice instead of once (as there is only one instance of A). I left an attachment with the code ready to run (please read the README.md to setup the environment). ", "code": [], "labels": ["Bug"]}
{"project": "ElemeFE_element", "title": "\u52a8\u6001\u589e\u51cf\u8868\u5355\u9879\u7684\u9a8c\u8bc1\u8be5\u600e\u4e48\u914d\u7f6e\uff1f", "description": "\u8868\u5355 <CODE> data <CODE> \u8be5\u5982\u4f55\u9a8c\u8bc1\u6bcf\u4e00\u884c\u7684money\uff0cdate\uff0cpayType\u5462\uff1f\u770b\u52a8\u6001\u6dfb\u52a0\u57df\u540d\u7684\u8868\u5355\uff0c\u597d\u50cf\u548c\u6211\u7684\u7ed3\u6784\u4e0d\u4e00\u6837\uff0c\u5c31\u4e0d\u61c2\u8be5\u5982\u4f55\u914d\u7f6e\u4e86 ", "code": [" <el-form :model=\"formData\" :inline=\"true\">\n      <el-row type=\"flex\" justify=\"center\" align=\"middle\"\n              v-for=\"(item, index) in formData.items\" :key=\"item.key\">\n        <el-col :span=\"24\">\n          <el-form-item\n            :prop=\"money\"\n            :rules=\"{\n      type: 'integer', required: true,\n      fields: {\n        value: { required: true, message: '\u91d1\u989d\u4e0d\u80fd\u4e3a\u7a7a', trigger: 'blur' }\n      }\n    }\">\n            <el-input v-model=\"item.money\" placeholder=\"\u8bf7\u8f93\u5165\u91d1\u989d\" auto-complete=\"off\"></el-input>\n          </el-form-item>\n          <el-form-item>\n            <el-date-picker\n              v-model=\"item.date\"\n              type=\"date\"\n              placeholder=\"\u9009\u62e9\u65e5\u671f\"\n              :picker-options=\"pickerOptions\">\n            </el-date-picker>\n          </el-form-item>\n          <el-form-item>\n            <el-select v-model=\"item.payType\" placeholder=\"\u8bf7\u9009\u62e9\u652f\u4ed8\u65b9\u5f0f\">\n              <el-option v-for=\"type in payTypes\" :label=\"type.label\" :value=\"type.label\"></el-option>\n            </el-select>\n          </el-form-item>\n          <el-button type=\"text\" @click.native.prevent=\"removeItem(item)\">-</el-button>\n        </el-col>\n      </el-row>\n      <el-row type=\"flex\" justify=\"center\" align=\"middle\">\n        <el-col :span=\"24\">\n          <el-button type=\"primary\" @click.native.prevent=\"addItem()\">\u6dfb\u52a0</el-button>\n          <el-button type=\"primary\" @click.native.prevent=\"save()\">\u4fdd\u5b58</el-button>\n        </el-col>\n      </el-row>\n    </el-form>\n", "formData: {\n          items: [{\n            key: 0,\n            money: '',\n            date: '',\n            payType: ''\n          }]\n        }\n"], "labels": ["type: question"]}
{"project": "nuxt_nuxt.js", "title": "svg can't be used in nuxt.js", "description": "2.export in 'components/common/index.js'\nexport { default as Iconsvg } from './Icon-svg' ", "code": [], "labels": ["cmty:question"]}
{"project": "kythe_kythe", "title": "JVM indexer: split off analyzer library [phab:D2158]", "description": "Created by schroederc at 2018-01-31 21:35:14: ", "code": [], "labels": ["phabricator diff"]}
{"project": "elastic_elasticsearch", "title": "SQL: floats precision and scale corrections", "description": "This issue is proposing to change the reported MAXIMUM_SCALE, MINIMUM_SCALE and potentially PRECISION values in SYS TYPES answer. Example: <CODE> <CODE> Above one can see that: For the PRECISION point[3]: <CODE> In this case, the PRECISION seems kept, but the scale (and thus float data type's precision, in non-SQL talk) is diminished, the type's reported scale then no longer being correct. An alternative implementation: <CODE> ", "code": ["DELETE floats\nPUT floats\n{\n  \"mappings\" : {\n    \"properties\": {\n      \"scaled_float\": {\n        \"type\": \"scaled_float\"\n        , \"scaling_factor\": 1000.0\n      },\n      \"half_float\": {\n        \"type\": \"half_float\"\n      },\n      \"float\": {\n        \"type\": \"float\"\n      },\n      \"double\": {\n        \"type\": \"double\"\n      }\n    }\n  }\n}\n\nPUT floats/_doc/1\n{\n  \"scaled_float\": 9223372036854775807,\n  \"half_float\": 1.98765432100123456789,\n  \"float\": 1.98765432100123456789,\n  \"double\": 1.98765432100123456789\n}\n", "sql> select * from floats;\n\n      double      |      float       |  half_float   |    scaled_float\n------------------+------------------+---------------+--------------------\n1.9876543210012345|1.9876543283462524|1.9873046875   |9.223372036854776E15\n", "sql> select 1000000+double from floats;\n 1000000+double\n-----------------\n1000001.987654321\n", "MariaDB [(none)]> select 1000000+1.98765432100123456789;\n+--------------------------------+\n| 1000000+1.98765432100123456789 |\n+--------------------------------+\n|   1000001.98765432100123456789 |\n+--------------------------------+\n1 row in set (0.00 sec)\n\n"], "labels": [":Search/SQL"]}
{"project": "golang_go", "title": "cmd/go: copy/delete instead of rename existing binaries on windows", "description": "A surprising behavior on Windows allows executable on disk associated with running processes to be renamed without error. This behavior only occurs for the rename or 'move' operation, and not 'delete' or 'write'. Currently, go build will move an old binary like main.exe out of the way by renaming it to main.exe~. However, main.exe may still be associated with a running process. Windows thinks this is OK, so it allows the rename operation to happen without error. This raises two issues: 1.) It is confusing when I terminate the original process (long after a build is finished), run the associated program again on disk, only to see the program is different in some way, because it has been replaced between executions. 2.) The call to os.Executable is wrong after a rename or move operation on Windows. This might be a separate issue, but its worth mentioning, because it may be unfixable. The userspace process environment block is not updated to reflect the change of the rename operation. My request is that go build instead copies main.exe -> main.exe~ and then attempts to delete the original main.exe. If that operation fails it can then delete main.exe~. To my knowledge this is compatible with the current behavior of go build on Windows systems. go version go1.9 windows/amd64 Yes One line reproduction for Windows <CODE> Copy main.exe -> ~main.exe\nDelete main.exe\nResume build Move main.exe -> ~main.exe\nResume build set GOARCH=amd64\nset GOBIN=C:\\gotools\nset GOEXE=.exe\nset GOHOSTARCH=amd64\nset GOHOSTOS=windows\nset GOOS=windows\nset GOPATH=C:\\g\nset GORACE=\nset GOROOT=C:\\Go\nset GOTOOLDIR=C:\\Go\\pkg\\tool\\windows_amd64\nset GCCGO=gccgo\nset CC=gcc\nset GOGCCFLAGS=-m64 -mthreads -fmessage-length=0\nset CXX=g++\nset CGO_ENABLED=1\nset CGO_CFLAGS=-g -O2\nset CGO_CPPFLAGS=\nset CGO_CXXFLAGS=-g -O2\nset CGO_FFLAGS=-g -O2\nset CGO_LDFLAGS=-g -O2\nset PKG_CONFIG=pkg-config ", "code": ["mkdir goissue21997 & cd goissue21997 && echo package main;import \"time\";import \"os\";import \"fmt\"; func main(){println(\"1\");for { time.Sleep(100e6); fmt.Println(os.Executable());};};|gofmt > main.go && go build main.go && start main.exe && echo package main;import \"time\";import \"os\";import \"fmt\"; func main(){println(\"2\");for { time.Sleep(100e6); fmt.Println(os.Executable());};};|gofmt > main.go && go build main.go && start main.exe && dir\n"], "labels": ["FrozenDueToAge"]}
{"project": "Kong_kong", "title": "0.14 /services PATCH Doesn't Unset Path Via Url Argument", "description": "When sending a PATCH payload to /services with an empty path for the url attribute, the path is not unset/emptied, but remains at the previous value. ", "code": [], "labels": ["good first issue"]}
{"project": "akka_akka", "title": "Optimize for method inlining (< 35 bytes) in the hot path", "description": "imported from <URL> ", "code": [], "labels": ["imported"]}
{"project": "ccrisan_motioneye", "title": "number of action buttons limited?", "description": "I can not add more than 7 action buttons, only 8 including the \"take snapshot\" button are shown. Is that correct? If yes - is there a config option to show more? PS. Great project, thank you so much for your work! :) ", "code": [], "labels": ["question"]}
{"project": "hashicorp_vault", "title": "Print server URL", "description": "It would be nice having a possibility to print the URL of the webserver depending on the config or run mode.\n$vault server -dev -print-url\nOutput:\n<URL>\nor\n$vault server -print-url -config=/path/to/vault.hcl\nOutput depending on the config:\n<URL> This would help to get the URL in a scriptable way. E.g.:\n.bashrc\nexport VAULT_ADDR='$(vault server -print-url -config=/path/to/vault.hcl)' It's also possible to add a separate command for this feature instead of an additional flag of the 'server' command. ", "code": [], "labels": ["enhancement"]}
{"project": "qgis_QGIS", "title": "Browser: cannot load WMS, due to missing value in FORMAT parameter", "description": "Author Name: luca76 - (luca76 -)\nOriginal Redmine Issue: 10519\nAffected QGIS version: master\nRedmine category:browser Hi, here's how to reproduce it in qgis master: If you add it with the normal menu Layer->Add WMS, it works perfectly. ", "code": [], "labels": ["Bug"]}
{"project": "rust-lang_cargo", "title": "Please publish 0.33 to crates.io", "description": "rustc 1.32.0 is out with cargo 0.33 but this is still not on crates.io d2acfb6 is the commit I believe Thanks in advance! ", "code": [], "labels": ["C-bug"]}
{"project": "ARMmbed_mbed-os", "title": "Timeout when running  IceTea test on CY8CKIT_062_WIFI_BT", "description": "The following command result in a timeout error.\nmbed test -m CY8CPROTO_062_4343W -t GCC_ARM --icetea -n test_cmdline -v -DICETEA_EXAMPLE_ENABLED It is a timing issue during startup.\nThere are 2 ways to run icetea. The first way is through mbed by calling mbed test -m CY8CPROTO_062_4343W -t GCC_ARM --icetea -n test_cmdline -DICETEA_EXAMPLE_ENABLED\nThis way compiles, flashs the application, and drives the icetea test. The fails because the test start driving the icetea test before the device's UART is ready. The test fails due to timeout waiting for a response to a command that the device never received. The second way is by manually programming the application and invoking icetea directly by calling icetea --tc test_cmdline\nThis assume that the application has already been flash and just drives the test. The test passes in this case. The only way I can find to fix the timing issue is to modify the mbed-os\\TEST_APPS\\testcases\\example\\test_cmdline.py file to add an ready trigger. The application send the text \"ARM Ltd\" when finishes initialization. \"application\": {\n\"name\": \"TEST_APPS-device-exampleapp\",\n\"cli_ready_trigger\": \"ARM Ltd\"\n} This wait cause the test to wait until it receives the text \"ARM Ltd\" from UART before it start driving the test. This fixing the case number 1 but breaks case number 2. In case number 2, the application was already flashed so icetea command fails during initialization waiting for a command sent long ago. I am not sure what the correct way to fix this bug is. <CODE> ", "code": ["[ ] Question\n[ ] Enhancement\n[X ] Bug\n"], "labels": ["Jira status: CLOSED", "mirrored", "type: bug"]}
{"project": "taichi-framework_TaiChi", "title": "Module not compatible: Edge Sense Plus", "description": "Title says it all, couldn't test with EdXposed. ", "code": [], "labels": ["bug"]}
{"project": "spyder-ide_spyder", "title": "Workspace should have filters", "description": "From tim.mich...@gmail.com on 2010-03-09T18:31:25Z worksspace should have filters since it gets cluttered quickly\nwhen working for quite some time in the spyder:\nfilters could select\n* all contents of namespace <CODE> Original issue: <URL> ", "code": ["* only current file namespace\n"], "labels": ["invalid", "type:Bug", "1 star"]}
{"project": "spring-projects_spring-boot", "title": "Switch `SpringApplication.run(...)` to not use varargs", "description": "It's easy to accidentally miss the args off the static SpringApplication.run() method. If we changed String... args to String[] args it would be harder to mess up. ", "code": [], "labels": ["status: declined"]}
{"project": "spring-projects_spring-boot", "title": "Upgrade to Spring Data Kay SR7", "description": "\nNo description provided.\n ", "code": [], "labels": ["type: dependency-upgrade"]}
{"project": "nicolargo_glances", "title": "Monitor list is bugged, not all processes are take into account", "description": "A big bug on the monitor list. It only search for process in the displayed processes list. If the monitored process is not display, it is display with the NOT RUNNING status...  ", "code": [], "labels": ["bug", "regression"]}
{"project": "hypothesis_h", "title": "Selection does not always result in the right quote", "description": "Select a line by doing a drag from the start of a line to the start of the next line.\nThe whole like will be selected (as expected), but the quote will be empty.\nStrange. ", "code": [], "labels": ["bug"]}
{"project": "notepad-plus-plus_notepad-plus-plus", "title": "Convert all XML files to similar encoding", "description": "Per the conversation with @donho on gitter --  converting all XML config and lang files to a similar encoding can do away with the two versions of tinyxml. No idea how to do this...yet. ", "code": [], "labels": ["enhancement"]}
{"project": "angular-ui_angular-google-maps", "title": "Write up migration path for ui-map users to new ui-gmap", "description": "As angular-google-maps is transferred under the angular-ui umbrella, a migration path for current ui-map users needs to be created for current ui-map users. ", "code": [], "labels": ["documentation"]}
{"project": "nwjs_nw.js", "title": "Distinguish click and hotkey for MenuItem", "description": "Let's say I have a MenuItem like this: <CODE> The click handler is triggered, if a user presses \u2318O. But it's not a click. It would be nice to distinguish between those two events either by using another handler as a sibling to click or by an event object passed to the click handler. Want to back this issue? Post a bounty on it! We accept bounties via Bountysource.\n ", "code": ["fileMenu.submenu.append(new gui.MenuItem({\n  label: 'Open...',\n  key: 'o',\n  modifiers: 'cmd',\n  click: function () {\n    console.log('open something.');\n  }\n}));\n"], "labels": ["stale"]}
{"project": "openseadragon_openseadragon", "title": "Uncaught TypeError: Cannot read property 'node' of undefined", "description": "our clients have an issue with drawing annotations in the screen. when their chrome version got updated to the recent one, they are not able to draw annotations. the chrome new version is 70.0.3538.77 and openseadragon seems not to be compatible with it. it was working in chrome version 69.0.3497.100.\nscripts.js:9 Uncaught TypeError: Cannot read property 'node' of undefined <CODE> and this is the script.js where shape is getting undefined and therefore the node can not be extracted from the undefined object.\ne=a.shape.node;a.shape.attr({id:\"shape_\"+a.shape.id});var g=a.shape.id,h=parseFloat(e.getAttribute(\"data-startx\")),j=parseFloat(e.getAttribute(\"data-starty\")),k=window.paper.select(\"g\"),l=k,m=l.text(h,j,\"--\"),p=.02,r=.08,A=h-p/1.7,B=j+r/9.8,C=l.circle(h,j,p),D=0,E=0;\"90\"==a.viewer.degrees&&(D=0,E=12),\"180\"==a.viewer.degrees&&(D=-11,E=8),\"270\"==a.viewer.degrees&&(D=-10,E=0),m.attr({fill:\"#000\",color:\"#fff\",\"data-type\":\"marker\",\"font-size\":\"0.8em\",\"font-weight\":\"bold\",\"min-height\":\"13px\",x:A,y:B,dx:D,dy:E,\"pointer-events\":\"none\",opacity:\"1\"});var F=new Snap.Matrix;if(F.translate(A,B).scale(.002,.002).rotate(-1*a.viewer.degrees),m.transform(F),C.attr({fill:\"yellow\",id:\"circle_for_\"+g,opacity:1,\"data-type\":\"marker\",\"class\":\"label-marker\"}),l.add(C),l.add(m),m.attr({id:\"label_for_\"+g,\"class\":\"label-marker\",\"data-anno-degrees\":a.viewer.degrees,\"data-init-transform\":\"0\"}),a.shape.attr({\"data-shape-id\":a.shape.node.id}),C.attr({\"data-circle-shape-id\":a.shape.node.id}),m.attr({\"data-label-shape-id\":a.shape.node.id}),a.shape&&a.shape.node&&!a.shape.node.getAttribute(\"data-label-shape-id\")&&!x.node.getAttribute(\"data-circle-shape-id\")){var G=a.shape.node.getAttribute(\"style\");G&&G.indexOf(\"cursor:default;\")<=-1&&(G+=\"; cursor:default;\"),a.shape.node.setAttribute(\"style\",G)}q(C,a.viewer,a),s(C,a),t=u=v=w=0,a.setCurrentDrawingMode(-1) unfortunately, the openseadragon version is 2.0.0. Thanks. ", "code": ["at SVGSVGElement.<anonymous> (scripts.js:9)\n\nat SVGSVGElement.dispatch (vendor.js:2)\n\nat SVGSVGElement.q.handle (vendor.js:2)\n"], "labels": ["question"]}
{"project": "NLog_NLog", "title": "Move files and namespaces", "description": "\nNo description provided.\n ", "code": [], "labels": ["refactoring"]}
{"project": "wenzhixin_bootstrap-table", "title": "Extension Editable - not working", "description": "Hi!\nI've just discovered that the editable plugin doesn't work as before updating to 1.9.1.\nIn my application the following config doesn't call the data-url anymore: Before the update it worked like expected. It called the data-url and sent the data.\nNow it just closes the overlay and does nothing (also no error)... only the classes change to \"editable editable-click editable-unsaved\" I have a second editable field with a data-type date and before the update there was also a datepicker...now its just an input field... Following versions I'm using:\nX-editable - v1.5.1\nBootstrap v3.3.2\nbootstrap-table - v1.9.1 - 2015-10-25\nbootstrap-table editable - v1.9.1 - 2015-10-25\njQuery v2.1.3 Can you please help me finding the problem ?\nThanks for your help!! regards Alex ", "code": [], "labels": ["awaiting reply"]}
{"project": "ionic-team_ionic-cli", "title": "ionic run ios --device", "description": "From @martyzz1 on April 6, 2016 13:25 Note: for support questions, please use one of these channels: <URL>\n<URL> ionic run ios  --device   doesn't work. Command halts without errors before copying to device\ncordova run ios works perfectly and deploys to the device ionic run ios --device should deploy my app to my ipad Steps to reproduce: <CODE> Other information: (e.g. stacktraces, related issues, suggestions how to fix, stackoverflow links, forum links, etc) relevant section of output from cordova run ios:- adding: Payload/PawSquad.app/www/templates/users/signup-thank-you.html    (in=188) (out=117) (deflated 38%)\nadding: Payload/PawSquad.app/www/templates/users/user-login.html  (in=715) (out=259) (deflated 64%)\nadding: Payload/PawSquad.app/www/templates/users/vet-needed.html  (in=71) (out=63) (deflated 11%)\nadding: Payload/PawSquad.app/www/templates/users/vet-urgent.html  (in=71) (out=63) (deflated 11%)\ntotal bytes=97295278, compressed=66204319 -> 32% savings\n]\nResults at '/Users/marty/pawztech/apps/client_app/platforms/ios/build/device/PawSquad.ipa'\n[....] Waiting up to 1 seconds for iOS device to be connected\n[....] Found J72AP 'iPad' (8680a7ef929d1fca2d261937459af65007e40904) connected through USB.\n[....] Waiting for iOS device to be connected\n[....] Using J72AP 'iPad' (8680a7ef929d1fca2d261937459af65007e40904).\n------ Install phase ------\n[  0%] Found J72AP 'iPad' (8680a7ef929d1fca2d261937459af65007e40904) connected through USB, beginning install\n[  5%] Copying /Users/marty/pawztech/apps/client_app/platforms/ios/build/device/PawSquad.app/META-INF/ to device\n[  5%] Copying /Users/marty/pawztech/apps/client_app/platforms/ios/build/device/PawSquad.app/META-INF/com.apple.ZipMetadata.plist to device\n[  5%] Copying /Users/marty/pawztech/apps/client_app/platforms/ios/build/device/PawSquad.app/_CodeSignature/ to device\n[  5%] Copying /Users/marty/pawztech/apps/client_app/platforms/ios/build/device/PawSquad.app/_CodeSignature/CodeResources to device\netc.... Same section from ionic run ios --device\nadding: Payload/PawSquad.app/www/lib/pawsquad/lib/bower_components/fullcalendar/dist/lang/fa.js   (in=2782) (out=1228) (deflated 56%)\nadding: Payload/PawSquad.app/www/lib/pawsquad/lib/bower_components/fullcalendar/dist/lang/fi.js   (in=2687) (out=1187) (deflated 56%)\nadding: Payload/PawSquad.app/www/lib/pawsquad/lib/bower_components/fullcalendar/dist/lang/fr-ca.js    (in=1909) (out=960) (deflated 50%)\nadding: Payload/PawSquad.app/www/lib/pawsquad/lib/bower_components/fullcalendar/dist/lang/fr.js   (in=1915) (out=965) (deflated 50%)\nadding: Payload/PawSquad.app/www/lib/pawsquad/lib/bower_components/fullcalendar/d ^^literaly clips the output like this.. Which Ionic Version? 1.x or 2.x\n1.7.14 Run ionic info from terminal/cmd prompt: (paste output below)\nYour system information: Cordova CLI: 6.1.1\nGulp version:  CLI version 3.9.1\nGulp local:   Local version 3.9.1\nIonic Version: 1.2.4-nightly-1917\nIonic CLI Version: 1.7.14\nIonic App Lib Version: 0.7.0\nios-deploy version: 1.8.5\nios-sim version: 5.0.8\nOS: Mac OS X El Capitan\nNode Version: v4.4.2\nXcode version: Xcode 7.2.1 Build version 7C1002 Cordova info Collecting Data... Node version: v4.4.2 Cordova version: 6.1.1 Config.xml file: <CODE> Plugins: cordova-plugin-compat,cordova-plugin-console,cordova-plugin-device,cordova-plugin-facebook4,cordova-plugin-geolocation,cordova-plugin-splashscreen,cordova-plugin-statusbar,cordova-plugin-whitelist,ionic-plugin-deploy,ionic-plugin-keyboard,mx.ferreyra.callnumber,pawsquad Android platform: id: 1 or \"android-21\"\nName: Android 5.0.1\nType: Platform\nAPI level: 21\nRevision: 2\nSkins: HVGA, QVGA, WQVGA400, WQVGA432, WSVGA, WVGA800 (default), WVGA854, WXGA720, WXGA800, WXGA800-7in, AndroidWearRound, AndroidWearSquare, AndroidWearRound, AndroidWearSquare id: 2 or \"android-22\"\nName: Android 5.1.1\nType: Platform\nAPI level: 22\nRevision: 2\nSkins: HVGA, QVGA, WQVGA400, WQVGA432, WSVGA, WVGA800 (default), WVGA854, WXGA720, WXGA800, WXGA800-7in, AndroidWearRound, AndroidWearRound400x400, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320, AndroidWearRound, AndroidWearRound400x400, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320 id: 3 or \"android-23\"\nName: Android 6.0\nType: Platform\nAPI level: 23\nRevision: 2\nSkins: HVGA, QVGA, WQVGA400, WQVGA432, WSVGA, WVGA800 (default), WVGA854, WXGA720, WXGA800, WXGA800-7in, AndroidWearRound, AndroidWearRound360x360, AndroidWearRound400x400, AndroidWearRound480x480, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320, AndroidWearRound, AndroidWearRound360x360, AndroidWearRound400x400, AndroidWearRound480x480, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320 id: 4 or \"Google Inc.:Google APIs:21\"\nName: Google APIs\nType: Add-On\nVendor: Google Inc.\nRevision: 1\nDescription: Android + Google APIs\nBased on Android 5.0.1 (API level 21)\nLibraries:\n* com.google.android.media.effects (effects.jar)\nCollection of video effects\n* com.android.future.usb.accessory (usb.jar)\nAPI for USB Accessories\n* com.google.android.maps (maps.jar)\nAPI for Google Maps\nSkins: HVGA, QVGA, WQVGA400, WQVGA432, WSVGA, WVGA800 (default), WVGA854, WXGA720, WXGA800, WXGA800-7in, AndroidWearRound, AndroidWearSquare, AndroidWearRound, AndroidWearSquare id: 5 or \"Google Inc.:Google APIs:22\"\nName: Google APIs\nType: Add-On\nVendor: Google Inc.\nRevision: 1\nDescription: Android + Google APIs\nBased on Android 5.1.1 (API level 22)\nLibraries:\n* com.google.android.media.effects (effects.jar)\nCollection of video effects\n* com.android.future.usb.accessory (usb.jar)\nAPI for USB Accessories\n* com.google.android.maps (maps.jar)\nAPI for Google Maps\nSkins: HVGA, QVGA, WQVGA400, WQVGA432, WSVGA, WVGA800 (default), WVGA854, WXGA720, WXGA800, WXGA800-7in, AndroidWearRound, AndroidWearRound400x400, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320, AndroidWearRound, AndroidWearRound400x400, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320 id: 6 or \"Google Inc.:Google APIs:23\"\nName: Google APIs\nType: Add-On\nVendor: Google Inc.\nRevision: 1\nDescription: Android + Google APIs\nBased on Android 6.0 (API level 23)\nLibraries:\n* com.google.android.media.effects (effects.jar)\nCollection of video effects\n* com.android.future.usb.accessory (usb.jar)\nAPI for USB Accessories\n* com.google.android.maps (maps.jar)\nAPI for Google Maps\nSkins: HVGA, QVGA, WQVGA400, WQVGA432, WSVGA, WVGA800 (default), WVGA854, WXGA720, WXGA800, WXGA800-7in, AndroidWearRound, AndroidWearRound360x360, AndroidWearRound400x400, AndroidWearRound480x480, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320, AndroidWearRound, AndroidWearRound360x360, AndroidWearRound400x400, AndroidWearRound480x480, AndroidWearRoundChin320x290, AndroidWearRoundChin360x325, AndroidWearRoundChin360x330, AndroidWearSquare, AndroidWearSquare320x320\nTag/ABIs : google_apis/armeabi-v7a, google_apis/x86, google_apis/x86_64 iOS platform: Xcode 7.2.1 Copied from original issue: ionic-team/ionic#6057 ", "code": ["insert any relevant code between the above and below backticks\n", "<?xml version='1.0' encoding='utf-8'?>\n<widget id=\"com.xxx.yyy\" version=\"1.0.0\" xmlns=\"http://www.w3.org/ns/widgets\" xmlns:cdv=\"http://cordova.apache.org/ns/1.0\" xmlns:gap=\"http://phonegap.com/ns/1.0\">\n    <name>xxxyyy</name>\n    <description>\n        xxxxxxx yyyyyyy\n    </description>\n    <author email=\"technology@xxxyyy.com\" href=\"http://www.xxxyyy.com/\">\n      Your Name Here\n    </author>\n    <content src=\"index.html\" />\n    <access origin=\"*\" />\n    <access launch-external=\"yes\" origin=\"tel:*\" />\n    <preference name=\"webviewbounce\" value=\"false\" />\n    <preference name=\"UIWebViewBounce\" value=\"false\" />\n    <preference name=\"DisallowOverscroll\" value=\"true\" />\n    <preference name=\"android-minSdkVersion\" value=\"16\" />\n    <preference name=\"BackupWebStorage\" value=\"none\" />\n    <preference name=\"SplashScreen\" value=\"screen\" />\n    <preference name=\"SplashScreenDelay\" value=\"3000\" />\n    <preference name=\"OpentokClientVersion\" value=\"v2.7.2\" />\n    <feature name=\"StatusBar\">\n        <param name=\"ios-package\" onload=\"true\" value=\"CDVStatusBar\" />\n    </feature>\n    <feature name=\"Geolocation\">\n        <param name=\"ios-package\" value=\"CDVLocation\" />\n    </feature>\n    <platform name=\"ios\">\n        <plugin name=\"cordova-plugin-googleplus\" spec=\"https://github.com/EddyVerbruggen/cordova-plugin-googleplus\">\n            <variable name=\"REVERSED_CLIENT_ID\" value=\"417008191229-ns8sechurs2nlh8irv8a72s21itl61qf.apps.googleusercontent.com\" />\n        </plugin>\n        <icon height=\"57\" src=\"resources/ios/icon/icon.png\" width=\"57\" />\n        <icon height=\"114\" src=\"resources/ios/icon/icon@2x.png\" width=\"114\" />\n        <icon height=\"40\" src=\"resources/ios/icon/icon-40.png\" width=\"40\" />\n        <icon height=\"80\" src=\"resources/ios/icon/icon-40@2x.png\" width=\"80\" />\n        <icon height=\"50\" src=\"resources/ios/icon/icon-50.png\" width=\"50\" />\n        <icon height=\"100\" src=\"resources/ios/icon/icon-50@2x.png\" width=\"100\" />\n        <icon height=\"60\" src=\"resources/ios/icon/icon-60.png\" width=\"60\" />\n        <icon height=\"120\" src=\"resources/ios/icon/icon-60@2x.png\" width=\"120\" />\n        <icon height=\"180\" src=\"resources/ios/icon/icon-60@3x.png\" width=\"180\" />\n        <icon height=\"72\" src=\"resources/ios/icon/icon-72.png\" width=\"72\" />\n        <icon height=\"144\" src=\"resources/ios/icon/icon-72@2x.png\" width=\"144\" />\n        <icon height=\"76\" src=\"resources/ios/icon/icon-76.png\" width=\"76\" />\n        <icon height=\"152\" src=\"resources/ios/icon/icon-76@2x.png\" width=\"152\" />\n        <icon height=\"29\" src=\"resources/ios/icon/icon-small.png\" width=\"29\" />\n        <icon height=\"58\" src=\"resources/ios/icon/icon-small@2x.png\" width=\"58\" />\n        <icon height=\"87\" src=\"resources/ios/icon/icon-small@3x.png\" width=\"87\" />\n        <splash height=\"1136\" src=\"resources/ios/splash/Default-568h@2x~iphone.png\" width=\"640\" />\n        <splash height=\"1334\" src=\"resources/ios/splash/Default-667h.png\" width=\"750\" />\n        <splash height=\"2208\" src=\"resources/ios/splash/Default-736h.png\" width=\"1242\" />\n        <splash height=\"1242\" src=\"resources/ios/splash/Default-Landscape-736h.png\" width=\"2208\" />\n        <splash height=\"1536\" src=\"resources/ios/splash/Default-Landscape@2x~ipad.png\" width=\"2048\" />\n        <splash height=\"768\" src=\"resources/ios/splash/Default-Landscape~ipad.png\" width=\"1024\" />\n        <splash height=\"2048\" src=\"resources/ios/splash/Default-Portrait@2x~ipad.png\" width=\"1536\" />\n        <splash height=\"1024\" src=\"resources/ios/splash/Default-Portrait~ipad.png\" width=\"768\" />\n        <splash height=\"960\" src=\"resources/ios/splash/Default@2x~iphone.png\" width=\"640\" />\n        <splash height=\"480\" src=\"resources/ios/splash/Default~iphone.png\" width=\"320\" />\n        <config-file parent=\"NSAppTransportSecurity\" platform=\"ios\" target=\"PawSquad-Info.plist\">\n            <dict>\n                <key>NSExceptionDomains</key>\n                <dict>\n                    <key>amazonaws.com</key>\n                    <dict>\n                        <key>NSThirdPartyExceptionMinimumTLSVersion</key>\n                        <string>TLSv1.0</string>\n                        <key>NSThirdPartyExceptionRequiresForwardSecrecy</key>\n                        <false />\n                        <key>NSIncludesSubdomains</key>\n                        <true />\n                    </dict>\n                    <key>amazonaws.com.cn</key>\n                    <dict>\n                        <key>NSThirdPartyExceptionMinimumTLSVersion</key>\n                        <string>TLSv1.0</string>\n                        <key>NSThirdPartyExceptionRequiresForwardSecrecy</key>\n                        <false />\n                        <key>NSIncludesSubdomains</key>\n                        <true />\n                    </dict>\n                </dict>\n            </dict>\n        </config-file>\n        <config-file platform=\"ios\" target=\"project.pbxproj\">\n            <build-property name=\"ENABLE_BITCODE\" value=\"NO\" />\n        </config-file>\n    </platform>\n    <platform name=\"android\">\n        <plugin name=\"cordova-plugin-googleplus\" spec=\"https://github.com/EddyVerbruggen/cordova-plugin-googleplus\">\n            <variable name=\"REVERSED_CLIENT_ID\" value=\"417008191229-vuk7vq09t4akeun07nthgsqjpv4fod5q.apps.googleusercontent.com\" />\n        </plugin>\n        <allow-navigation href=\"https://harryb.eu.ngrok.io/*\" />\n        <config-file parent=\"/*\" target=\"AndroidManifest.xml\">\n        </config-file>\n        <icon density=\"ldpi\" src=\"resources/android/icon/drawable-ldpi-icon.png\" />\n        <icon density=\"mdpi\" src=\"resources/android/icon/drawable-mdpi-icon.png\" />\n        <icon density=\"hdpi\" src=\"resources/android/icon/drawable-hdpi-icon.png\" />\n        <icon density=\"xhdpi\" src=\"resources/android/icon/drawable-xhdpi-icon.png\" />\n        <icon density=\"xxhdpi\" src=\"resources/android/icon/drawable-xxhdpi-icon.png\" />\n        <icon density=\"xxxhdpi\" src=\"resources/android/icon/drawable-xxxhdpi-icon.png\" />\n        <splash density=\"land-ldpi\" src=\"resources/android/splash/drawable-land-ldpi-screen.png\" />\n        <splash density=\"land-mdpi\" src=\"resources/android/splash/drawable-land-mdpi-screen.png\" />\n        <splash density=\"land-hdpi\" src=\"resources/android/splash/drawable-land-hdpi-screen.png\" />\n        <splash density=\"land-xhdpi\" src=\"resources/android/splash/drawable-land-xhdpi-screen.png\" />\n        <splash density=\"land-xxhdpi\" src=\"resources/android/splash/drawable-land-xxhdpi-screen.png\" />\n        <splash density=\"land-xxxhdpi\" src=\"resources/android/splash/drawable-land-xxxhdpi-screen.png\" />\n        <splash density=\"port-ldpi\" src=\"resources/android/splash/drawable-port-ldpi-screen.png\" />\n        <splash density=\"port-mdpi\" src=\"resources/android/splash/drawable-port-mdpi-screen.png\" />\n        <splash density=\"port-hdpi\" src=\"resources/android/splash/drawable-port-hdpi-screen.png\" />\n        <splash density=\"port-xhdpi\" src=\"resources/android/splash/drawable-port-xhdpi-screen.png\" />\n        <splash density=\"port-xxhdpi\" src=\"resources/android/splash/drawable-port-xxhdpi-screen.png\" />\n        <splash density=\"port-xxxhdpi\" src=\"resources/android/splash/drawable-port-xxxhdpi-screen.png\" />\n        <plugin name=\"phonegap-plugin-push\" spec=\"~1.6.1\">\n            <variable name=\"SENDER_ID\" value=\"417008191229\" />\n        </plugin>\n    </platform>\n    <engine name=\"android\" spec=\"4.0.2\" />\n    <engine name=\"browser\" spec=\"3.6.0\" />\n    <allow-intent href=\"http://*/*\" />\n    <allow-intent href=\"https://*/*\" />\n    <allow-intent href=\"tel:*\" />\n    <allow-intent href=\"sms:*\" />\n    <allow-intent href=\"mailto:*\" />\n    <allow-intent href=\"geo:*\" />\n    <plugin name=\"cordova-plugin-whitelist\" spec=\"~1.2.1\" />\n    <plugin name=\"cordova-plugin-splashscreen\" spec=\"~3.1.0\" />\n    <plugin name=\"cordova-plugin-device\" spec=\"^1.0.1\" />\n    <plugin name=\"pawsquad\" spec=\"../opentok-cordova\" />\n    <plugin name=\"cordova-plugin-geolocation\" spec=\"https://github.com/apache/cordova-plugin-geolocation.git\" />\n    <plugin name=\"cordova-plugin-facebook4-custom\" spec=\"../cordova-plugin-facebook4\">\n        <variable name=\"APP_ID\" value=\"1036709146374432\" />\n        <variable name=\"APP_NAME\" value=\"PawSquad\" />\n    </plugin>\n    <plugin name=\"mx.ferreyra.callnumber\" spec=\"https://github.com/Rohfosho/CordovaCallNumberPlugin.git\" />\n    <icon src=\"resources/android/icon/drawable-xhdpi-icon.png\" />\n    <plugin name=\"ionic-plugin-deploy\" spec=\"~0.5.0\" />\n    <engine name=\"ios\" spec=\"~4.1.0\" />\n</widget>\n\n\n"], "labels": ["platform:ios"]}
{"project": "ossrs_srs", "title": "Convert raw h264 to flv stream", "description": "<URL> ", "code": [], "labels": ["wontfix", "question"]}
{"project": "MicrosoftDocs_azure-docs", "title": "OSBA is not supported despite FAQ?", "description": "Following the directions here: <URL> causes an error: clusterservicebrokers.servicecatalog.k8s.io at the cluster scope: no RBAC policy matched secret/osba-redis created\nsecret/osba-open-service-broker-azure-auth created\nsecret/osba-open-service-broker-azure created\nservice/osba-redis created\nservice/osba-open-service-broker-azure created\npersistentvolumeclaim/osba-redis-pv-claim created\ndeployment.extensions/osba-redis created\ndeployment.extensions/osba-open-service-broker-azure created\nError from server (Forbidden): clusterservicebrokers.servicecatalog.k8s.io is forbidden: User \"me@xxxx.com\" cannot create clusterservicebrokers.servicecatalog.k8s.io at the cluster scope: no RBAC policy matched \u26a0 Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking. ", "code": [], "labels": ["triaged", "in-progress", "container-service/svc", "product-question", "cxp"]}
{"project": "tensorflow_tensorflow", "title": "segfaults in GPU tf.matrix_inverse", "description": "I'm running into segfaults in tf.matrix_inverse\nI'm adding identity*0.001 so matrices should be invertible, and same procedure works fine in numpy and in TensorFlow CPU version. <URL>\npython inverse_segfault.py This non-deterministically crashes after 1-2 seconds with various backtraces. IE <CODE> or this <CODE> TensorFlow commit: 22a886b\nNVIDIA-SMI 381.09\nlibcudart.so.8.0.44\nlibcudnn.so.6.0.21\nNvidia GTX 1080 ", "code": ["#0  0x0000000000000001 in ?? ()\n#1  0x00007fe90ed9c652 in tensorflow::Tensor::TotalBytes() const ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n#2  0x00007fe90ed9c7d6 in tensorflow::Tensor::tensor_data() const ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n#3  0x00007fe9137adda3 in bool tensorflow::internal::TransposeUsingTile<unsigned int>(Eigen::GpuDevice const&, tensorflow::Tensor const&, tensorflow::gtl::ArraySlice<int>, tensorflow::Tensor*) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#4  0x00007fe9137a696c in tensorflow::Status tensorflow::DoTranspose<Eigen::GpuDevice>(Eigen::GpuDevice const&, tensorflow::Tensor const&, tensorflow::gtl::ArraySlice<int>, tensorflow::Tensor*) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#5  0x00007fe911ada0fd in tensorflow::SvdOpGpu<float>::PerformSVD_MgeqN(tensorflow::OpKernelContext*, std::function<void ()>, long long, long long, long long, tensorflow::gtl::ArraySlice<int> const&, tensorflow::Tensor const&, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#6  0x00007fe911ade897 in tensorflow::SvdOpGpu<float>::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#7  0x00007fe90f20790b in tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n#8  0x00007fe90f23cf37 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)\n    ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n", "#0  0x00007fa89090686a in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1\n#1  0x00007fa89091b074 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1\n#2  0x00007fa890826e2c in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1\n#3  0x00007fa890978880 in cuLaunchKernel ()\n   from /usr/lib/x86_64-linux-gnu/libcuda.so.1\n#4  0x00007fa891bf1dc1 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#5  0x00007fa891c0f9cd in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#6  0x00007fa891aa1132 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#7  0x00007fa891aa2b72 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#8  0x00007fa891aa32e3 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#9  0x00007fa891aa36fa in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#10 0x00007fa89190f5f3 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#11 0x00007fa891912375 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0\n#12 0x00007fa89aa82c50 in tensorflow::Status tensorflow::CudaSolver::Getrf<float>(int, int, float*, int, int*, int*) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#13 0x00007fa89a55f5d6 in tensorflow::MatrixInverseOpGpu<float>::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#14 0x00007fa897dce90b in tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n#15 0x00007fa897e03f37 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)\n    ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n#16 0x00007fa897df1ec5 in std::_Function_handler<void (), std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> (tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> >::_M_invoke(std::_Any_data const&) ()\n   from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n\n"], "labels": ["type:bug", "stat:awaiting tensorflower"]}
{"project": "cdnjs_cdnjs", "title": "[Request] Add aui", "description": "Library name:  aui\nGit repository url: <URL>\nnpm package url(optional): @atlassian/aui ", "code": [], "labels": [" Library Request"]}
{"project": "square_okhttp", "title": "AsyncCall NPE's if an interceptor throws before the call is attempted.", "description": "AsyncCall throws an uncaught NullPointerException here because engine is null, having never been initialized, if the call was never attempted.  For example, this can happen if an (\"application-level\") interceptor aborted the call by throwing an IOException before the call was ever attempted. I suggest that it could simply pass a null request to the callback in this case instead. ", "code": [], "labels": ["bug"]}
{"project": "aio-libs_aiohttp", "title": "wheel", "description": "Hi, would you mind uploading a wheel file of aiohttp to PyPI?  They have smaller downloads and faster installs (they don't run setup.py on install). All you have to do is: Add <CODE> to your setup.cfg (it tells wheel that you\u2019re python-only and that you need only one wheel file that works on all architectures) and then installing the wheel package + running python setup.py bdist_wheel.  More details in my blog post. :) Thanks for the consideration! ", "code": ["[wheel]\nuniversal = 1\n"], "labels": ["outdated"]}
{"project": "bilibili_ijkplayer", "title": "ff_read \u5d29\u6e83\u4fe1\u606f", "description": "<CODE> \u64ad\u653e\u89c6\u9891\u4f1a\u5d29\u6e83 \u63d0\u793a ff_read(21) http_open ", "code": ["   \u5f53 self.player = [[IJKFFMoviePlayerController alloc]initWithContentURL:vidoUrl withOptions:options];\n"], "labels": ["need-more-information"]}
{"project": "nasa_openmct", "title": "[Mobile] Smaller-screen laptop treated as mobile device", "description": "Laptops with small screens can display Open MCT Web incorrectly due to CSS rules which detect small screens as mobile devices. Known cases where this occurs: ", "code": [], "labels": ["bug"]}
{"project": "thinkjs_thinkjs", "title": "\u5b9e\u4f8b\u5316\u6a21\u578b\u65f6\uff0c\u53ef\u4ee5\u76f4\u63a5\u5b9e\u4f8b\u5316\u4e2a\u9ad8\u7ea7\u6a21\u578b", "description": "\nNo description provided.\n ", "code": [], "labels": ["enhancement"]}
{"project": "OptimalBits_bull", "title": "Question: difference in configurations and job states", "description": "So in short, what is the difference between \"maxStalledCount\" and \"attempts\" configurations? It seems only the attempts actually determines anything. If attempts it 3 and maxStalledCount is 1, it will still try to do a failed job 3 times before moving it to failed. While if attempts is 1 and maxStalledCount is 3, it will only do it once and upon failing move it to failed. So what do these things mean? what's the difference between stalled and failed? is stalled = waiting on the getJobCounts() result object? Ultimately I want my queue to try a job up to 5 times and if it failed all 5 times, only then move it to failed status. how would i go about configuring my queue to do that? Thanks. ", "code": [], "labels": ["question"]}
{"project": "libretro_RetroArch", "title": "Please help.... Games all too fast and no sound.", "description": "Hi. I am completely new a this. Even still I worked out everything according to your Forums and have been successful with all but two items before I can go ahead and enjoy retro gaming. I have read through many FAQ and FORUMS on this. Can't get it fixed. Any support would be appreciated. ", "code": [], "labels": ["invalid"]}
{"project": "netdata_netdata", "title": "MySQL chart not showing up", "description": "I have mysql enabled and would like it to show up on the netdata page. I get this output, which should mean I am connected and getting data back from MySQL, but no charts are actually showing up on the dashboard. <CODE> Any help would be appreciated. Thank you! ", "code": ["root@localhost:/etc/netdata/python.d# /usr/libexec/netdata/plugins.d/python.d.plugin 1 mysql\n16-10-10 23:31:19:  INFO: Using python v2\n16-10-10 23:31:19: python.d INFO: reading configuration file: /etc/netdata/python.d.conf\n16-10-10 23:31:19: python.d INFO: MODULES_DIR='/usr/libexec/netdata/python.d/', CONFIG_DIR='/etc/netdata/', UPDATE_EVERY=1, ONLY_MODULES=['mysql']\n16-10-10 23:31:19: python.d INFO: using MySQLdb\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv6_root Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv6_root check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/tcpipv6_root\n16-10-10 23:31:19: python.d ERROR: local already exists. Stopping 'mycnf1_root'\n16-10-10 23:31:19: python.d INFO: Disabled mysql/mycnf1_root\n16-10-10 23:31:19: python.d ERROR: local already exists. Stopping 'tcp_root'\n16-10-10 23:31:19: python.d INFO: Disabled mysql/tcp_root\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv6 Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv6 check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/tcpipv6\n16-10-10 23:31:19: python.d ERROR: local already exists. Stopping 'mycnf2'\n16-10-10 23:31:19: python.d INFO: Disabled mysql/mycnf2\n16-10-10 23:31:19: python.d ERROR: mysql_socket2 Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_socket2 check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/socket2\n16-10-10 23:31:19: python.d ERROR: mysql_socket3 Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_socket3 check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/socket3\n16-10-10 23:31:19: python.d ERROR: local already exists. Stopping 'socket1'\n16-10-10 23:31:19: python.d INFO: Disabled mysql/socket1\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv4 Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv4 check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/tcpipv4\n16-10-10 23:31:19: python.d ERROR: local already exists. Stopping 'socket1_root'\n16-10-10 23:31:19: python.d INFO: Disabled mysql/socket1_root\n16-10-10 23:31:19: python.d ERROR: local already exists. Stopping 'mycnf1'\n16-10-10 23:31:19: python.d INFO: Disabled mysql/mycnf1\n16-10-10 23:31:19: python.d ERROR: local already exists. Stopping 'mycnf2_root'\n16-10-10 23:31:19: python.d INFO: Disabled mysql/mycnf2_root\n16-10-10 23:31:19: python.d ERROR: mysql_socket2_root Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_socket2_root check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/socket2_root\n16-10-10 23:31:19: python.d ERROR: mysql_socket3_root Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_socket3_root check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/socket3_root\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv4_root Cannot establish connection to MySQL.\n16-10-10 23:31:19: python.d ERROR: mysql_tcpipv4_root check function failed.\n16-10-10 23:31:19: python.d INFO: Disabled mysql/tcpipv4_root\nCHART mysql_local.net '' 'mysql Bandwidth' kilobits/s bandwidth mysql.net area 90000 1\nDIMENSION Bytes_received in incremental 8 1024\nDIMENSION Bytes_sent out incremental -8 1024\nCHART mysql_local.queries '' 'mysql Queries' queries/s queries mysql.queries line 90001 1\nDIMENSION Queries queries incremental 1 1\nDIMENSION Questions questions incremental 1 1\nDIMENSION Slow_queries slow_queries incremental 1 1\n"], "labels": ["question"]}
{"project": "angular-fullstack_generator-angular-fullstack", "title": "run-sequence error", "description": "Hi all!\nAfter executing the command \"gulp serve\" i get this error: <CODE> Could you help me?\nThanks, ", "code": ["[11:04:07] Requiring external module babel-core/register\n[11:04:07] Using gulpfile ~/Dropbox/Node_Angular/***/gulpfile.babel.js\n[11:04:07] Starting 'serve'...\n[11:04:07] Starting 'clean:tmp'...\n[11:04:07] Starting 'constant'...\n[11:04:07] Finished 'constant' after 62 ms\n[11:04:07] Finished 'clean:tmp' after 73 ms\n[11:04:07] Starting 'lint:scripts'...\n[11:04:07] Starting 'lint:scripts:client'...\n[11:04:07] Starting 'lint:scripts:server'...\n[11:04:07] Starting 'inject'...\n[11:04:07] 'inject' errored after 80 \u03bcs\n[11:04:07] Error: Task inject:css is listed more than once. This is probably a typo.\nat /home/***/Dropbox/Node_Angular/***/node_modules/run-sequence/index.js:24:11\nat Array.forEach (native)\nat verifyTaskSets (/home/***/Dropbox/Node_Angular/***/node_modules/run-sequence/index.js:13:11)\nat /home/***/Dropbox/Node_Angular/***/node_modules/run-sequence/index.js:32:4\nat Array.forEach (native)\nat verifyTaskSets (/home/***/Dropbox/Node_Angular/***/node_modules/run-sequence/index.js:13:11)\nat runSequence (/home/***/Dropbox/Node_Angular/***/node_modules/run-sequence/index.js:94:2)\nat Gulp.<anonymous> (/home/***/Dropbox/Node_Angular/***/gulpfile.babel.js:148:5)\nat module.exports (/home/***/Dropbox/Node_Angular/***/node_modules/orchestrator/lib/runTask.js:34:7)\nat Gulp.Orchestrator._runTask (/home/***/Dropbox/Node_Angular/***/node_modules/orchestrator/index.js:273:3)\n[11:04:07] 'serve' errored after 142 ms\n[11:04:07] Error in plugin 'run-sequence'\nMessage:\n    An error occured in task 'inject'.\n[11:04:07] 'lint:scripts' errored after 69 ms\n[11:04:07] Error in plugin 'run-sequence'\nMessage:\n    An error occured in task 'serve'.\n[11:04:07] 'lint:scripts' errored after 69 ms\n[11:04:07] Error in plugin 'run-sequence'\nMessage:\n    An error occured in task 'inject'.\n\nclient/app/app.constant.js\n  line 2  col 3   Missing \"use strict\" statement.\n  line 2  col 46  Strings must use singlequote.\n  line 4  col 22  Strings must use singlequote.\n  line 5  col 16  Strings must use singlequote.\n  line 6  col 16  Strings must use singlequote.\n  line 7  col 15  Strings must use singlequote.\n  line 8  col 16  Strings must use singlequote.\n\n  \u2716  1 error\n  \u26a0  6 warnings\n\n[11:04:08] Finished 'lint:scripts:client' after 506 ms\n[11:04:08] Finished 'lint:scripts:server' after 501 ms\n"], "labels": ["bug"]}
{"project": "zaproxy_zaproxy", "title": "AJAX Spider should honour global excluded URLs", "description": "Change AJAX Spider to honour global excluded URLs (Options > Global Excluded URL), as the normal spider does. Add-on\nAjax Spider ", "code": [], "labels": ["add-on", "historic", "enhancement"]}
{"project": "ionic-team_ionic", "title": "bug: no-padding / no-margin not working on toolbar", "description": "If the attribute is added to a toolbar the padding on the toolbar takes precedence: <CODE> A simple solution to this is moving the styles to the end of the css so they take precedence over toolbar, but this could always get messed up again in the future, and it probably doesn't work on some components. This is just a thought, but what if we add a utility mixin that automatically added all of these attributes to the main component class. So it would be like: <CODE> and then the mixin could be: <CODE> None of the above was tested so it could not be functional currently. What do you think @manucorporat @adamdbradley @bensperry ? ", "code": ["<ion-toolbar no-padding>\n", ".toolbar-md {\n  @include util();\n\n  // all the other toolbar stuff\n}\n", "@mixin util() {\n  &[no-padding] {\n    padding: 0;\n  }\n\n  // all of the other padding attributes\n\n  &[no-margin] {\n    margin: 0;\n  }\n\n  // all of the other margin attributes\n\n  // any other util attributes\n}\n"], "labels": ["v2"]}
{"project": "glpi-project_glpi", "title": "update log event for reservation", "description": "<URL> Information are not enough to see if a reservation was deleted from the requester ", "code": [], "labels": ["enhancement"]}
{"project": "styled-components_styled-components", "title": "[v2] [optimization] do not output empty classes for SSR", "description": "While prerendering I get a lot of empty classes: <CODE> it would be nice if fetching the styles for SSR removed those. ", "code": ["            .AddTextInput__InputField-lew40i {\n            }\n\n            .AddTextInput__PlusBtn-1yatb23 {\n            }\n\n            .ColumnsLayout__ColumnsWrapper-1u3y8xp {\n            }\n\n            .ColumnsLayout__Column-1he5qfk {\n            }\n\n            .ArrayInput__HorizLineBetween-1k50h5d {\n"], "labels": ["enhancement "]}
{"project": "dart-lang_sdk", "title": "Frequent timeouts of precompilation_test on the buildbot only", "description": "For example:\n<URL>\n<URL> ", "code": [], "labels": ["area-vm"]}
{"project": "grafana_grafana", "title": "Upper case K used in short units", "description": "Grafana v5.2.3 Ubuntu When using the \"short\" unit representation, kilos are displayed with upper K. Following the \"International System of Units\" [1] kilos should be displayed with a lower k.\n[1] <URL> ", "code": [], "labels": ["type/feature-request"]}
{"project": "kythe_kythe", "title": "Setup release v0.0.11 [phab:D488]", "description": "Created by schroederc at 2015-09-01 22:37:47: ", "code": [], "labels": ["phabricator diff"]}
{"project": "ansible_ansible", "title": "Allow Excluding and/or overriding transitive role dependencies", "description": "I'm just hitting more and more often a serious limitation in the 'role dependencies',\nthat especially restrain the potential to re-use opensource roles, that contain transitive dependencies. The problem: Quite a number of quality roles are split into multiple roles,\nin a way that currently we have no control over the lower level dependencies.\nBut sometimes you want to not use/run transitive role(s).\nOr more often, replace/override that lower-level (transitive) role with a different role\n(either you own, or better, another opensource role that is better suited for this task).\nA good example for this case is a very low-level role (app dependency) like java/jdk. An example illustrates this best:\n- myRole (private)  depends on:\n|\n---  OS role $osUser.$role2a (for ex. azavea.spark) ..depends on:\n|\n--- OS role $osUser.$role2b (for ex. azavea.java) but myRole would prefer to not run $osUser.$role2b, but rather replace it by an alternative\n$osUser2.role2b. As far as I see, there's no features yet neither in ansible 1.x  nor in the 2.x branch,\nbut would be really awesome, to have at least a minimal solution in upcoming v2\n(like '--disable-transitive-deps'), to easier re-use original roles without the hassle: Possible solutions I see (but Im very open for alternative solutions): Reference:\nI searched the mail list for:  transitive role (dependencies)\n<URL>!searchin/ansible-project/$20transitive$20role$20dependencies <URL> Related issues: ", "code": [], "labels": ["feature", "support:core", "affects_2.3", "affects_2.2"]}
{"project": "dart-lang_sdk", "title": "Editor's context suggest ignores private members", "description": "This issue was originally filed by naddise...@gmail.com What steps will reproduce the problem? What is the expected output? What do you see instead?\nThe private member _private should show up on the content assist. What version of the product are you using? On what operating system?\nDart Editor version 0.5.11_r23200\nDart SDK version 0.5.11.1_r23200 Please provide any additional information below. ", "code": [], "labels": ["Type-Defect"]}
{"project": "Azure_azure-cli", "title": "Very long running commands time out with login token expired", "description": "Delete a large resource group\nIf large enough, the delete command will time out and say that login is required because the expiry time of the token if before the current time.  However, the token is not timed out, I can still execute other commands. ", "code": [], "labels": ["Bug"]}
{"project": "aws_aws-cdk", "title": "CfnInstance fails in C# with complex properties (Tags, SecurityGroupIds) set", "description": "Note: for support questions, please first reference our documentation, then use Stackoverflow. This repository's issues are intended for feature requests and bug reports. Trying to deploy/diff a stack with a CfnInstance with Tags or Security groups set, fails To diff or deploy the CfnInstance It worked in 0.28 An app like this: Throws the following error: <CODE> ", "code": ["Amazon.JSII.Runtime.JsiiException: Resolution error: System.ArgumentException: Could not infer JSII type for .NET type 'JArray'\nParameter name: type\n   at Amazon.JSII.Runtime.Services.Converters.FrameworkToJsiiConverter.InferType(IReferenceMap referenceMap, Type type)\n   at Amazon.JSII.Runtime.Services.Converters.ValueConverter.ConvertAny(IReferenceMap referenceMap, Object value)\n   at Amazon.JSII.Runtime.Services.Converters.ValueConverter.TryConvertPrimitive(IReferenceMap referenceMap, Object value, Boolean isOptional, PrimitiveType primitiveType, Object& result)\n   at Amazon.JSII.Runtime.Services.Converters.ValueConverter.TryConvert(IOptionalValue optionalValue, IReferenceMap referenceMap, Object value, Object& result)\n   at Amazon.JSII.Runtime.Services.Converters.FrameworkToJsiiConverter.TryConvertMap(IReferenceMap referenceMap, TypeReference elementType, Object value, Object& result)\n   at Amazon.JSII.Runtime.Services.Converters.ValueConverter.TryConvert(IOptionalValue optionalValue, IReferenceMap referenceMap, Object value, Object& result)\n   at Amazon.JSII.Runtime.Deputy.DeputyBase.<>c__DisplayClass20_0.<ConvertArguments>b__0(Parameter parameter, Object frameworkArgument)\n   at System.Linq.Enumerable.ZipIterator[TFirst,TSecond,TResult](IEnumerable`1 first, IEnumerable`1 second, Func`3 resultSelector)+MoveNext()\n   at System.Collections.Generic.LargeArrayBuilder`1.AddRange(IEnumerable`1 items)\n   at System.Collections.Generic.EnumerableHelpers.ToArray[T](IEnumerable`1 source)\n   at System.Linq.Enumerable.ToArray[TSource](IEnumerable`1 source)\n   at Amazon.JSII.Runtime.Deputy.DeputyBase.<InvokeMethodCore>g__GetResult|18_0[T](<>c__DisplayClass18_0`1& )\n   at Amazon.JSII.Runtime.Deputy.DeputyBase.InvokeMethodCore[T](JsiiMethodAttribute methodAttribute, Object[] arguments, Func`3 beginFunc, Func`3 invokeFunc)\n   at Amazon.JSII.Runtime.Deputy.DeputyBase.InvokeInstanceMethod[T](Object[] arguments, String methodName).\nObject creation stack:\n  at new Intrinsic (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\private\\intrinsic.js:20:44)\n  at new PostResolveToken (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\util.js:72:9)\n  at CfnInstance._toCloudFormation (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\cfn-resource.js:167:39)\n  at node.addReference.resolve_1.findTokens (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\cfn-element.js:84:77)\n  at Object.findTokens (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\private\\resolve.js:126:13)\n  at CfnInstance.prepare (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\cfn-element.js:84:49)\n  at _wrapSandboxCode (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6498:51)\n  at Kernel._wrapSandboxCode (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:7131:20)\n  at ret._ensureSync (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6498:25)\n  at Kernel._ensureSync (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:7102:20)\n  at Kernel.invoke (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6497:26)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6191:28)\n  at completeCallback (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6164:25)\n  at KernelHost.callbackHandler (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6145:16)\n  at KernelHost.kernel.jsii_kernel_1.Kernel.cb [as callbackHandler] (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6129:59)\n  at CfnInstance.value (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6848:41)\n  at Function.prepare (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\construct.js:89:27)\n  at Function.synth (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\construct.js:52:14)\n  at App.synth (C:\\Users\\username\\AppData\\Local\\Temp\\jsii-kernel-E0rbbc\\node_modules\\@aws-cdk\\core\\lib\\app.js:67:52)\n  at _wrapSandboxCode (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6498:51)\n  at Kernel._wrapSandboxCode (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:7131:20)\n  at ret._ensureSync (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6498:25)\n  at Kernel._ensureSync (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:7102:20)\n  at Kernel.invoke (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6497:26)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6191:28)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at KernelHost.processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6233:16)\n  at KernelHost.run (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:14)\n  at processRequest (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6137:45)\n  at promise.then.val (C:\\Users\\username\\AppData\\Local\\Temp\\1fy2x0ks.smv\\jsii-runtime.js:6218:21)\n   at Amazon.JSII.Runtime.Services.Client.TryDeserialize[TResponse](String responseJson)\n   at Amazon.JSII.Runtime.Services.Client.ReceiveResponse[TResponse]()\n   at Amazon.JSII.Runtime.Services.Client.TryDeserialize[TResponse](String responseJson)\n   at Amazon.JSII.Runtime.Services.Client.ReceiveResponse[TResponse]()\n   at Amazon.JSII.Runtime.Deputy.DeputyBase.<InvokeMethodCore>g__GetResult|18_0[T](<>c__DisplayClass18_0`1& )\n   at Amazon.JSII.Runtime.Deputy.DeputyBase.InvokeMethodCore[T](JsiiMethodAttribute methodAttribute, Object[] arguments, Func`3 beginFunc, Func`3 invokeFunc)\n   at Amazon.JSII.Runtime.Deputy.DeputyBase.InvokeInstanceMethod[T](Object[] arguments, String methodName)\n   at Amazon.CDK.CfnElement.Prepare()\n"], "labels": ["duplicate"]}
{"project": "wavebox_waveboxapp", "title": "Conflicting keyboard shortcuts on Azerty (Belgian) keyboard", "description": "On a Azerty keyboard (Belgian - period) the AltGr + 2 shortcut is used for the  symbol.\nIn Wavebox, this is however also mapped to moving to another \"tab\". This makes it impossible to type the  symbol in Google Inbox without copy-pasting it from another program. A switch to disable the switching tab behavior would be nice. (Maybe it is already in there, but I wasn't able to find it). Thanks for making a great desktop mail client! Tim Encountered in Wavebox 3.1.5 on Windows 10 ", "code": [], "labels": ["feature"]}
{"project": "material-components_material-components-ios", "title": "Internal issue: b/130286292", "description": "This was filed as an internal issue. If you are a Googler, please visit b/130286292 for more details. ", "code": [], "labels": ["type:Feature request"]}
{"project": "biolab_orange3", "title": "Survival analysis", "description": "It would be great if Orange included survival analysis tools such as Kaplan-Meier plots and Cox proportional hazards model. ", "code": [], "labels": ["enhancement"]}
{"project": "godotengine_godot", "title": "Add predelete signal to Object", "description": "Using the Mono version I have an extension method that needs to perform some cleanup steps when an Object is freed. However there doesn't seem to be any way to know when an Object has been freed from outside of the Object. If we think this is useful I believe I could follow this to create a PR: #15911 Note: I tried using a Reference for this but as far as I can tell References in the Mono version aren't freed by Godot but instead are disposed by the garbage collector? Which means the predelete notification on the Reference isn't sent. ", "code": [], "labels": ["topic:core", "discussion", "archived", "enhancement"]}
{"project": "ytdl-org_youtube-dl", "title": "Unable to download JSON metadata: HTTP Error 418", "description": "Getting the following:\nERROR: Unable to download JSON metadata: HTTP Error 418:  (caused by <HTTPError 418: ''>); please report this issue on <URL> . Make sure you are using the latest version; see  <URL>  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output. ", "code": [], "labels": ["incomplete"]}
{"project": "golang_go", "title": "x/build/cmd/gopherbot: assist with cherry picks based on Milestones", "description": "As @rsc writes: Do that. ", "code": [], "labels": ["Builders", "FrozenDueToAge"]}
{"project": "NixOS_nixpkgs", "title": "pythonPackages.basemap: Python interpreter cannot import basemap", "description": "I'm trying to run a nix-shell with several python packages. One of them is basemap.\nI cannot successfully import basemap however.\nOddly enough it works when using ipython as REPL. <CODE> outputs: ImportError: No module named basemap However if we use ipython it works: <CODE> ", "code": ["nix-shell -p pythonPackages.basemap  --pure --run \"python -c 'import mpl_toolkits.basemap'\"\n", "nix-shell -p pythonPackages.basemap pythonPackages.ipython --pure --run \"ipython -c 'import mpl_toolkits.basemap'\"\n"], "labels": ["6.topic: python", "0.kind: bug"]}
{"project": "dotnet_coreclr", "title": "JIT should suppress zero-extending same-register moves in more scenarios", "description": "Related to #22454. An optimization was previously introduced in coreclr which eliminates unnecessary mov instructions when zero-extending registers. However, that optimization only looks back one instruction to determine if the elimination is worthwhile. Per #23665, we have evidence that there's benefit to be realized from looking back more than one instruction when performing this optimization. We should be more aggressive about eliminating these mov instructions. category:cq\ntheme:basic-cq\nskill-level:intermediate\ncost:medium ", "code": [], "labels": ["area-CodeGen", "optimization"]}
{"project": "gatsbyjs_gatsby", "title": "Returning a <Redirect /> within render() leads to a broken page", "description": "Using @reach/router, if I send a redirect from within a page's render(), the target page loads but then crashes. If I go directly to the target page, it loads fine. The code is currently on GitHub, so I can show it. This is the current color.js file. The use of  is on line 59. If the URL does not include an id parameter, then it sets the state value redirect to true. When that is true, render() sends a redirect to /colors. For reference, here is an earlier version of color.js. In this earlier version, I was passing the ID to the page as path info (i.e., /color/1 instead of /color/?id=1). However, this didn't work in production and I had to switch to query parameters instead. In this version of the component, I am using the router in lines 11-14. I am able to route requests with an ID to the main component (line 12) and redirect requests that are missing the ID (line 13). I would try the full-on router approach, but I'm not clear on how I can get the path to be sensitive to query parameters. To see this without the stack-trace, go to this link, then edit the URL to remove the ?id=5. When the /color page has no ID in the query params, it tries to redirect to /colors. But when arriving there from the redirect, the page fails. If you then just go directly to /colors, it will work. A link like this should successfully redirect to here. Page is empty, and under gatsby develop I have stack frames (none of which refer to any of my code, unfortunately). System:\nOS: Linux 3.13 Ubuntu 14.04.6 LTS, Trusty Tahr\nCPU: (12) x64 Intel(R) Core(TM) i7-5820K CPU @ 3.30GHz\nShell: 4.3.11 - /bin/bash\nBinaries:\nNode: 12.6.0 - /home/linuxbrew/.linuxbrew/bin/node\nnpm: 6.9.0 - /home/linuxbrew/.linuxbrew/bin/npm\nLanguages:\nPython: 2.7.6 - /usr/bin/python\nBrowsers:\nChrome: 76.0.3809.100\nFirefox: 66.0.3\nnpmPackages:\ngatsby: ^2.13.42 => 2.13.42\ngatsby-cli: ^2.7.21 => 2.7.21\ngatsby-image: ^2.2.7 => 2.2.7\ngatsby-plugin-manifest: ^2.2.4 => 2.2.4\ngatsby-plugin-mdx: ^1.0.18 => 1.0.18\ngatsby-plugin-offline: ^2.2.4 => 2.2.4\ngatsby-plugin-optimize-svgs: ^1.0.3 => 1.0.3\ngatsby-plugin-react-helmet: ^3.1.2 => 3.1.2\ngatsby-plugin-sharp: ^2.2.9 => 2.2.9\ngatsby-plugin-styled-components: ^3.1.2 => 3.1.2\ngatsby-plugin-typography: ^2.3.2 => 2.3.2\ngatsby-remark-images: ^3.1.10 => 3.1.10\ngatsby-source-filesystem: ^2.1.6 => 2.1.6\ngatsby-transformer-sharp: ^2.2.5 => 2.2.5 ", "code": [], "labels": ["stale?"]}
{"project": "spring-projects_spring-boot", "title": "Devtools: Enable automatic logins at dev time", "description": "Per brainstorming with @rwinch: I just went through the process of enabling remember-me authentication, essentially so I don't have to log into my application every time I re-start gradle bootRun. It would be nice if Boot's devtools solved this by introducing a DeveloperLoginFilter or some such that would set the security context automatically with a fake user (or a username of my choosing, configured in application.yml). This approach would be like in kind to the recent additions to Spring Security Test, e.g. @WithMockUser, only happening at development runtime, not just test-time. ", "code": [], "labels": ["type: enhancement"]}
{"project": "jekyll_jekyll", "title": "Rubocop 0.43.0 failing our fmt test-suite", "description": "Hi,\nLooks like the latest release of Rubocop (0.43.0) has some changes that are causing our test-suite:fmt to throw new offenses and fail. /cc @jekyll/ecosystem ", "code": [], "labels": ["frozen-due-to-age"]}
{"project": "hexojs_hexo", "title": "\u8fd9\u79cd\u62a5\u9519\u7684\u539f\u56e0\u662f\u4ec0\u4e48\uff0c\u8be5\u600e\u4e48\u89e3\u51b3\uff1f", "description": "[root@iZr567sp4k4sjxZ ~]# npm install -g hexo-cli\nnpm http GET <URL>\nnpm http GET <URL>\nnpm http GET <URL>\nnpm ERR! Error: CERT_UNTRUSTED\nnpm ERR!     at SecurePair. (tls.js:1370:32)\nnpm ERR!     at SecurePair.EventEmitter.emit (events.js:92:17)\nnpm ERR!     at SecurePair.maybeInitFinished (tls.js:982:10)\nnpm ERR!     at CleartextStream.read [as _read] (tls.js:469:13)\nnpm ERR!     at CleartextStream.Readable.read (_stream_readable.js:320:10)\nnpm ERR!     at EncryptedStream.write [as _write] (tls.js:366:25)\nnpm ERR!     at doWrite (_stream_writable.js:221:10)\nnpm ERR!     at writeOrBuffer (_stream_writable.js:211:5)\nnpm ERR!     at EncryptedStream.Writable.write (_stream_writable.js:180:11)\nnpm ERR!     at write (_stream_readable.js:583:24)\nnpm ERR! If you need help, you may report this entire log,\nnpm ERR! including the npm and node versions, at:\nnpm ERR!     <URL> npm ERR! System Linux 3.10.0-514.26.2.el7.x86_64\nnpm ERR! command \"/usr/local/node/0.10.24/bin/node\" \"/usr/local/node/0.10.24/bin/npm\" \"install\" \"-g\" \"hexo-cli\"\nnpm ERR! cwd /root\nnpm ERR! node -v v0.10.24\nnpm ERR! npm -v 1.3.21\nnpm ERR!\nnpm ERR! Additional logging details can be found in:\nnpm ERR!     /root/npm-debug.log\nnpm ERR! not ok code 0\n[root@iZr567sp4k4sjxZ ~]# node -v\nv0.10.24\n[root@iZr567sp4k4sjxZ ~]# npm -v\n1.3.21\n[root@iZr567sp4k4sjxZ ~]# ", "code": [], "labels": ["stale"]}
{"project": "dotnet_aspnetcore", "title": "Dotnet publish is not working with -c Release AspNetCore 3.0 Preview 6", "description": "Can't execute dotnet publish Project.csproj -c Release without exceptions on Web App.\n###Output <CODE> To successful publish. Include the output of dotnet --info\n.NET Core SDK (reflecting any global.json):\nVersion:   3.0.100-preview6-012264\nCommit:    be3f0c1a03 Runtime Environment:\nOS Name:     Windows\nOS Version:  10.0.18362\nOS Platform: Windows\nRID:         win10-x64\nBase Path:   C:\\Program Files\\dotnet\\sdk\\3.0.100-preview6-012264\\ Host (useful for support):\nVersion: 3.0.0-preview6-27804-01\nCommit:  fdf81c6faf .NET Core SDKs installed:\n2.1.202 [C:\\Program Files\\dotnet\\sdk]\n2.1.700 [C:\\Program Files\\dotnet\\sdk]\n2.2.300 [C:\\Program Files\\dotnet\\sdk]\n3.0.100-preview6-012264 [C:\\Program Files\\dotnet\\sdk] .NET Core runtimes installed:\nMicrosoft.AspNetCore.All 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\nMicrosoft.AspNetCore.All 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\nMicrosoft.AspNetCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\nMicrosoft.AspNetCore.App 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\nMicrosoft.AspNetCore.App 3.0.0-preview6.19307.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\nMicrosoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\nMicrosoft.NETCore.App 2.1.11 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\nMicrosoft.NETCore.App 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\nMicrosoft.NETCore.App 3.0.0-preview6-27804-01 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\nMicrosoft.WindowsDesktop.App 3.0.0-preview6-27804-01 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App] ", "code": ["3.0.100-preview6-012264/Sdks/Microsoft.NET.Sdk.Razor/build/netstandard2.0/Microsoft.NET.Sdk.Razor.MvcApplicationPartsDiscovery.targets(53,5): error MSB4018: The \"FindAssembliesWithReferencesTo\" task failed unexpectedly.\n"], "labels": ["External", "bug", "area-mvc"]}
{"project": "c3js_c3", "title": "is it possible to customer c3.js to meet my new type of chart requirements?", "description": "I have a requirement of the new graphs Zoomable Sunburst With Updating Data (<URL>, Heat Map (<URL>, Zoomable Circle Packing chart (<URL>, Co-occurrence Matrix  (<URL>  Is there is any possibility for me to customize c3.js to yield these charts? ", "code": [], "labels": ["wontfix", "C-feature-request"]}
{"project": "chrippa_livestreamer", "title": "HLS m3u8 Stream", "description": "Hi, i'm using a paid server to watch my favorite channels so i extracted some iptv url to watch them them in my linux based set top box (enigma2), and to get working HLS stream as 4097 service i'm using your nice plugin and its working good (quality, speed etc .. ) but just for some minutes with error and i should restart program or change channel to get back stream\nlink : <URL> i added it in channel list like this :\n#SERVICE 4097:0:0:0:0:0:0:0:0:0:http%3a//127.0.01%3a88/hlsvariant%3a//176.52.176.101/1737/playlist.m3u8?xxxxxx&password=yyyyyy here is log from Telnet: Welcome to openATV for maram9\nopenatv 4.0 maram9 maram9 login: root\nLast login: Thu Jun 26 21:36:39 +0200 2014 on /dev/pts/0.\nroot@maram9:~# /etc/init.d/livestreamersrv manualstart\nThu Jun 26 21:48:33 2014 Server Starts - :88\nlocalhost.localdomain - - [26/Jun/2014 21:48:38] \"GET /hlsvariant://176.52.176.1\n01/1737/playlist.m3u8?email=xxxxxx&password=yyyyy HTTP/1.1\" 200 -\nlocalhost.localdomain - - [26/Jun/2014 21:48:38] URL: hlsvariant://176.52.176.10\n1/1737/playlist.m3u8?email=xxxxxx&password=yyyyyy Quality: best\nStreams: ['1128k', 'worst', 'best']\n<HLSStream('<URL>')\nGot Exception:  Read timeout Sorry, i replaced my username with xxxxxx and my password with yyyyyy.\nany Help is welcome, thanks in advance.\nsorry for my bad english.\nBest Regards. ", "code": [], "labels": ["bug"]}
{"project": "endless-sky_endless-sky", "title": "bug with AI::FindTarget (AI does not target disabled ships properly)", "description": "@Elyssaen noted on Discord, that the AI did not attack some disabled ships even if the supposed attacker has personality heroic vindictive.\nI created a testfile to reproduce it, using a slightly different setup than @Elyssaen.\nTesting Tester.txt I could trace the problem down to <CODE> Disabling that if() condition by adding  && 1 == 2 helped in the testcase but obviously is not a general solution. <CODE> situation here. My guess is that the last part regarding the nemesis personality is \"wrong\". ", "code": ["// Pick a new target for the given ship.\nshared_ptr<Ship> AI::FindTarget(const Ship &ship) const\n{\n\t[...]\n\t\t\t// If your personality it to disable ships rather than destroy them,\n\t\t\t// never target disabled ships.\n\t\t\tif(it->IsDisabled() && !person.Plunders()\n\t\t\t\t\t&& (person.Disables() || (!person.IsNemesis() && it != oldTarget)))\n\t\t\t\tcontinue;\n", "if (true && true && (false || (true && true))\n\tcontinue;\n"], "labels": ["wontfix"]}
{"project": "eclipse_che", "title": "Dashboard tear down server attributes after change port or protocol on the server page", "description": "<CODE> TO: <CODE> <CODE> OS and version:\nminikube version: v0.30.0 ", "code": [" \"codeserver\": {\n              \"port\": \"9876\",\n              \"protocol\": \"http\"\n            },\n", " \"codeserver\": {\n              \"attributes\": {\n                \"key\": \"value\"\n              },\n              \"port\": \"9876\",\n              \"protocol\": \"http\"\n            },\n", " \"codeserver\": {\n              \"attributes\": {\n                     \"key\": \"value\"\n             },\n              \"port\": \"9877\",\n              \"protocol\": \"http\"\n            }\n"], "labels": ["kind/bug", "team/editors"]}
{"project": "jupyterlab_jupyterlab", "title": "Cell Metadata Editor buttons are missing", "description": "The save and revert buttons are no longer showing.  Seen in 0.18 and in master. ", "code": [], "labels": ["pkg:notebook", "status:resolved-locked", "type:Bug"]}
{"project": "golang_go", "title": "compile fails on Android", "description": "1.4.3 Android (linux/armv7-a) tried to compile go1.4.3 on android 4.2.2\nWith gcc 4.9 provided by cctools. I have also add some directory on Android to look like regular linux and used root user in  jackpal terminal. Compile successfully <CODE> ", "code": ["[/usr/local/go/src]# bash all.bash         \n# Building C bootstrap tool.\ncmd/dist\n\n# Building compilers and Go bootstrap tool for host, linux/arm.\nlib9\n/usr/local/go/src/lib9/dirfwstat.c: In function 'dirfwstat':\n/usr/local/go/src/lib9/dirfwstat.c:79:3: warning: implicit declaration of function 'futimes' [-Wimplicit-function-declaration]\n   if(futimes(fd, tv) < 0)\n   ^\nlibbio\nliblink\ncmd/cc\ncmd/gc\ncmd/5l\ncmd/5a\ncmd/5c\ncmd/5g\nruntime\nBseek: libbio compiled with 4-byte offset\n/usr/local/go/src/runtime/zversion.go:7: internal compiler error: fault\ngo tool dist: FAILED: /usr/local/go/pkg/tool/linux_arm/5g -pack -o $WORK/_go_.a -p main -+ /usr/local/go/src/runtime/alg.go /usr/local/go/src/runtime/arch_arm.go /usr/local/go/src/runtime/atomic_arm.go /usr/local/go/src/runtime/cgocall.go /usr/local/go/src/runtime/cgocallback.go /usr/local/go/src/runtime/chan.go /usr/local/go/src/runtime/compiler.go /usr/local/go/src/runtime/complex.go /usr/local/go/src/runtime/cpuprof.go /usr/local/go/src/runtime/debug.go /usr/local/go/src/runtime/env_posix.go /usr/local/go/src/runtime/error.go /usr/local/go/src/runtime/extern.go /usr/local/go/src/runtime/hashmap.go /usr/local/go/src/runtime/hashmap_fast.go /usr/local/go/src/runtime/iface.go /usr/local/go/src/runtime/lock_futex.go /usr/local/go/src/runtime/malloc.go /usr/local/go/src/runtime/mem.go /usr/local/go/src/runtime/mgc0.go /usr/local/go/src/runtime/mprof.go /usr/local/go/src/runtime/netpoll.go /usr/local/go/src/runtime/netpoll_epoll.go /usr/local/go/src/runtime/noasm_arm.go /usr/local/go/src/runtime/os_linux.go /usr/local/go/src/runtime/panic.go /usr/local/go/src/runtime/print1.go /usr/local/go/src/runtime/proc.go /usr/local/go/src/runtime/race0.go /usr/local/go/src/runtime/rdebug.go /usr/local/go/src/runtime/rune.go /usr/local/go/src/runtime/runtime.go /usr/local/go/src/runtime/select.go /usr/local/go/src/runtime/sema.go /usr/local/go/src/runtime/signal_unix.go /usr/local/go/src/runtime/sigpanic_unix.go /usr/local/go/src/runtime/sigqueue.go /usr/local/go/src/runtime/slice.go /usr/local/go/src/runtime/softfloat64.go /usr/local/go/src/runtime/sqrt.go /usr/local/go/src/runtime/stack.go /usr/local/go/src/runtime/string.go /usr/local/go/src/runtime/stubs.go /usr/local/go/src/runtime/symtab.go /usr/local/go/src/runtime/time.go /usr/local/go/src/runtime/traceback.go /usr/local/go/src/runtime/typekind.go /usr/local/go/src/runtime/vlrt.go /usr/local/go/src/runtime/zgoarch_arm.go /usr/local/go/src/runtime/zgoos_linux.go /usr/local/go/src/runtime/zruntime_defs_linux_arm.go /usr/local/go/src/runtime/zversion.go\n[/usr/local/go/src]#\n"], "labels": ["FrozenDueToAge"]}
{"project": "lettuce-io_lettuce-core", "title": "Upgrade to Reactor Core 3.2.8.RELEASE", "description": "\nNo description provided.\n ", "code": [], "labels": ["type: dependency-upgrade"]}
{"project": "ShareX_ShareX", "title": "%t and %pn in sub folder pattern for screenshot folder not working", "description": "ShareX 9.2.1\nWindows 8.1 64bit The placeholder %t (Title of active windows) and %pn (Process name of active window) don't appear to be working for me. Maybe I'm using it wrong. When I use the following pattern %y-%mo%t\\ I get folder structure that looks like this ..\\2014-08%t\\filename.ext The placeholder is not being replaced by the actual value. ", "code": [], "labels": ["Invalid"]}
{"project": "artf_grapesjs", "title": "[Suggestion] Insert a image inside link", "description": "Hi Art! A feature that is really needed is about insert a link into a image or have a link can place a image inside a link. Today it cannot possible to do that using drag and drop feature. We have to edit the html code e insert it by hands. Thanks. ", "code": [], "labels": ["outdated"]}
{"project": "flutter_flutter", "title": "\"ENGINE LAYER TREE INCONSISTENT\" spamming web engine tests", "description": "When running web engine tests, I see a few of these printed out in the terminal. ", "code": [], "labels": ["a: tests", "\u2638 platform-web"]}
{"project": "uglide_RedisDesktopManager", "title": "How to set up the UI theme?", "description": "My source code compiled successfully opened the app into this way, may I ask where I need to configure to change this theme? The font color is white and the button is on the top  ", "code": [], "labels": ["bug"]}
{"project": "SickChill_SickChill", "title": "[APP SUBMITTED]: SEARCHQUEUE-DAILY-SEARCH :: [1ed3156] DelugeD: Unable to set the pause for Torrent", "description": "Python Version: 2.7.14 (default, May 28 2018, 14:47:18) [GCC 4.7.3 20130102 (prerelease)]\nOperating System: Linux-3.10.105-x86_64-with-glibc2.2.5\nLocale: None\nBranch: master\nCommit: 1ed3156\nNo Log available with ERRORS: <CODE> STAFF NOTIFIED: @SickChill/owners @SickChill/moderators ", "code": ["SEARCHQUEUE-DAILY-SEARCH :: [1ed3156] DelugeD: Unable to set the pause for Torrent\n"], "labels": ["Stale"]}
{"project": "aws-amplify_amplify-cli", "title": "How do I debug the project in Visual Studio Code?", "description": "I'd like to be able to contribute to the project. In order to do that efficiently, I'd like to run the Amplify CLI in Visual Studio Code and debug the code by setting breakpoints. How does one do that? At first, I just forked/cloned to build the project and do a basic run of the project from source. I tried to start with the suggested steps to build the project from the Contributing  section of the README. However, these steps fail (see attached errors): <CODE> Amplify CLI npm run setup-dev errors.txt I noticed that there is this note in the GraphQL transformer docs: \"there are some debug configurations defined in .vscode/launch.json you can use Visual Studio code to add debug breakpoints to debug the code.\" However, there is no launch.json file as noted. At a bare minimum, it would be good to be able to build and run the project from source. And ideally, if there were a launch.json file to run in Visual Studio Code, that would be even better. How does the Amplify team debug the project? (It would be tough to imagine one could not debug the code and set breakpoints.) ", "code": ["$ npm run setup-dev\nyarn config set workspaces-experimental true\n"], "labels": ["pending-close-response-required"]}
{"project": "owncloud_core", "title": "Cleanup toplevel shares (cyclic shares)", "description": "See: #23153 Apparently it was possible somehow to share your root directory at some point. We should on upgrade check for such shares and remove them. Note that (at least on 9.0) I verified that it is no longer possible to create root shares. ", "code": [], "labels": ["technical debt", "feature:sharing"]}
{"project": "golang_go", "title": "cmd/cgo: permits reference to non-existent struct", "description": "This code compiles and runs: <CODE> It prints {}.  That makes no sense.  There is no type X here.  It should give an error somewhere. ", "code": ["package main\n\nimport \"C\"\n\nimport \"fmt\"\n\nvar V C.struct_X\n\nfunc main() {\n        fmt.Println(V)\n}\n"], "labels": ["NeedsFix"]}
{"project": "open-mmlab_mmdetection", "title": "IF i want to train on VOC and what should i do", "description": "I have made the data dir like the install.md suggested.\nWhere should i change the default train_dataset to voc ", "code": [], "labels": ["duplicate"]}
{"project": "pypa_pipenv", "title": "pipenv does not install gitlint", "description": "gitlint is not installed when using --dev --deploy flags. Here's my Pipfile: <CODE> Here's the command I am using: pipenv install --dev --deploy. The same happens with just --dev. It was working some versions ago. I expect every dependency from Pipfile to be installed. Here's my pip freeze: <CODE> ", "code": ["[[source]]\n\nurl = \"https://pypi.python.org/simple\"\nverify_ssl = true\n\n\n[requires]\n\npython_version = '3.6'\n\n\n[dev-packages]\n\ndjango-debug-toolbar = \"*\"\n\"pep8-naming\" = \"*\"\n\"flake8-builtins\" = \"*\"\n\"flake8-commas\" = \"*\"\n\"flake8-quotes\" = \"*\"\n\"flake8-blind-except\" = \"*\"\n\"flake8-bugbear\" = \"*\"\n\"flake8-comprehensions\" = \"*\"\n\"flake8-pep3101\" = \"*\"\npytest = \"*\"\n\"pytest-flake8\" = \"*\"\npytest-isort = \"*\"\npytest-django = \"*\"\npytest-cov = \"*\"\ngitlint = \"*\"\npre-commit = \"*\"\nxenon = \"*\"\nradon = \"*\"\npylint = \"*\"\npytest-xdist = \"*\"\n\n\n[packages]\n\ndjango = \"<1.12\"\ndjango-split-settings = \"*\"\ndjango-axes = \"*\"\n\"psycopg2\" = \"*\"\ngunicorn = \"*\"\nunipath = \"*\"\npython-decouple = \"*\"\ndjangorestframework = \"*\"\ndjangorestframework-jwt = \"*\"\n", "\u00bb pip freeze\napipkg==1.4\naspy.yaml==1.0.0\nastroid==1.5.3\nattrs==17.2.0\ncached-property==1.3.1\ncertifi==2017.7.27.1\nchardet==3.0.4\ncolorama==0.3.9\ncoverage==4.4.1\nDjango==1.11.7\ndjango-axes==2.3.3\ndjango-debug-toolbar==1.8\ndjango-split-settings==0.2.5\ndjangorestframework==3.7.1\ndjangorestframework-jwt==1.11.0\nexecnet==1.5.0\nflake8==3.5.0\nflake8-blind-except==0.1.1\nflake8-bugbear==17.4.0\nflake8-builtins==1.0\nflake8-commas==0.4.3\nflake8-comprehensions==1.4.1\nflake8-pep3101==1.1\nflake8-polyfill==1.0.1\nflake8-quotes==0.12.0\ngunicorn==19.7.1\nidentify==1.0.6\nidna==2.6\nisort==4.2.15\nlazy-object-proxy==1.3.1\nmando==0.6.4\nmccabe==0.6.1\nnodeenv==1.2.0\npep8-naming==0.4.1\npre-commit==1.3.0\npsycopg2==2.7.3.2\npy==1.4.34\npycodestyle==2.3.1\npyflakes==1.6.0\nPyJWT==1.5.3\npylint==1.7.4\npytest==3.2.3\npytest-cache==1.0\npytest-cov==2.5.1\npytest-django==3.1.2\npytest-flake8==0.9.1\npytest-forked==0.2\npytest-isort==0.1.0\npytest-xdist==1.20.1\npython-decouple==3.1\npytz==2017.3\nPyYAML==3.12\nradon==2.1.1\nrequests==2.18.4\nsix==1.11.0\nsqlparse==0.2.4\nUnipath==1.1\nurllib3==1.22\nvirtualenv==15.1.0\nwrapt==1.10.11\nxenon==0.5.4\n"], "labels": ["Type: Bug "]}
{"project": "woocommerce_woocommerce", "title": "My Account page form correction", "description": "Describe the bug\non the my account page for a non logged in user, if \"generate a username from the customers email address\" is selected, it correctly only shows email address and password to register. However, on the login side, it shows \"username or email address\". it should only show \"Email address\". If \"generate a username from the customers email address\" was NOT enabled, then it should show \"username or email address\". Screenshots\nIf applicable, add screenshots to help explain your problem. Expected behavior\nIF \"generate a username from the customers email address\" SELECTED show \"Email address\" for login.\nIF \"generate a username from the customers email address\" NOT SELECTED show \"Username or email address\" for login. Isolating the problem (mark completed items with an [x]): WordPress Environment\n5.1\n <CODE> ` Home URL: <URL>\nSite URL: <URL>\nWC Version: 3.5.6\nLog Directory Writable: \u2714\nWP Version: 5.1\nWP Multisite: \u2013\nWP Memory Limit: 256 MB\nWP Debug Mode: \u2013\nWP Cron: \u2714\nLanguage: en_US\nExternal object cache: \u2013 Server Info: Apache\nPHP Version: 7.2.15\nPHP Post Max Size: 33 MB\nPHP Time Limit: 30\nPHP Max Input Vars: 1000\ncURL Version: 7.45.0\nOpenSSL/1.0.1e SUHOSIN Installed: \u2013\nMySQL Version: 5.6.32-78.0-log\nMax Upload Size: 33 MB\nDefault Timezone is UTC: \u2714\nfsockopen/cURL: \u2714\nSoapClient: \u2714\nDOMDocument: \u2714\nGZip: \u2714\nMultibyte String: \u2714\nRemote Post: \u2714\nRemote Get: \u2714 WC Database Version: 3.5.6\nWC Database Prefix: wp_akqzmhydy9_\nMaxMind GeoIP Database: \u2714\nTotal Database Size: 7.74MB\nDatabase Data Size: 6.99MB\nDatabase Index Size: 0.75MB\nwp_akqzmhydy9_woocommerce_sessions: Data: 0.01MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_api_keys: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_attribute_taxonomies: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_downloadable_product_permissions: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_order_items: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_order_itemmeta: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_tax_rates: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_tax_rate_locations: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_shipping_zones: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_shipping_zone_locations: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_shipping_zone_methods: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_payment_tokens: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_payment_tokenmeta: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_woocommerce_log: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_commentmeta: Data: 0.00MB + Index: 0.01MB\nwp_akqzmhydy9_comments: Data: 0.01MB + Index: 0.01MB\nwp_akqzmhydy9_et_divi_ab_testing_stats: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_failed_jobs: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_draft_submissions: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_entry: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_entry_meta: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_entry_notes: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_form: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_form_meta: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_form_revisions: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_gf_form_view: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_links: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_mailchimp_carts: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_options: Data: 2.47MB + Index: 0.05MB\nwp_akqzmhydy9_postmeta: Data: 0.26MB + Index: 0.12MB\nwp_akqzmhydy9_posts: Data: 0.90MB + Index: 0.05MB\nwp_akqzmhydy9_queue: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_sm_sessions: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_ta_link_clicks: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_ta_link_clicks_meta: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_termmeta: Data: 0.00MB + Index: 0.01MB\nwp_akqzmhydy9_terms: Data: 0.00MB + Index: 0.01MB\nwp_akqzmhydy9_term_relationships: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_term_taxonomy: Data: 0.00MB + Index: 0.01MB\nwp_akqzmhydy9_usermeta: Data: 0.02MB + Index: 0.02MB\nwp_akqzmhydy9_users: Data: 0.00MB + Index: 0.01MB\nwp_akqzmhydy9_wc_download_log: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wc_webhooks: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfblockediplog: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfblocks7: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfconfig: Data: 1.18MB + Index: 0.01MB\nwp_akqzmhydy9_wfcrawlers: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wffilechanges: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wffilemods: Data: 1.31MB + Index: 0.28MB\nwp_akqzmhydy9_wfhits: Data: 0.03MB + Index: 0.01MB\nwp_akqzmhydy9_wfhoover: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfissues: Data: 0.01MB + Index: 0.01MB\nwp_akqzmhydy9_wfknownfilelist: Data: 0.66MB + Index: 0.09MB\nwp_akqzmhydy9_wflivetraffichuman: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wflocs: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wflogins: Data: 0.01MB + Index: 0.00MB\nwp_akqzmhydy9_wfnotifications: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfpendingissues: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfreversecache: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfsnipcache: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_wfstatus: Data: 0.12MB + Index: 0.05MB\nwp_akqzmhydy9_wftrafficrates: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_yoast_seo_links: Data: 0.00MB + Index: 0.00MB\nwp_akqzmhydy9_yoast_seo_meta: Data: 0.00MB + Index: 0.00MB attachment: 62\ncustom_css: 1\ncustom-css-js: 1\ncustomize_changeset: 30\net_pb_layout_stashed: 8\njetpack_migration: 2\njp_img_sitemap: 1\njp_sitemap: 1\njp_sitemap_master: 1\nlayout: 2\nnav_menu_item: 12\npage: 20\npost: 3\nproduct: 10\nproduct_variation: 32\nrevision: 78\nscheduled-action: 12\nshop_coupon: 1\nshop_order: 5\nshop_subscription: 1\nthirstylink: 1\nticket: 1\nticket_history: 2 Secure connection (HTTPS): \u2714\nHide errors from visitors: \u2714 ManageWP - Worker: by GoDaddy \u2013 4.7.5\nAkismet Anti-Spam: by Automattic \u2013 4.1.1\nAwesome Support: by Awesome Support Team \u2013 5.8.0\nWPBakery Page Builder: by Michael M - WPBakery.com \u2013 5.7\nMailchimp for WooCommerce: by Mailchimp \u2013 2.1.14 \u2013 Not tested with the active version of WooCommerce\nMy Custom Functions: by Space X-Chimp \u2013 4.35\nmyStickymenu: by m.r.d.a \u2013 2.0.6\nRegenerate Thumbnails: by Alex Mills (Viper007Bond) \u2013 3.1.0\nSearch Engine Visibility: by GoDaddy \u2013 0.5\nSimple Custom CSS: by John Regan\nDanny Van Kooten \u2013 4.0.1 Tawk.to Live Chat: by Tawkto \u2013 0.3.6\nUnder Construction: by WebFactory Ltd \u2013 3.31\nWC Password Strength Settings: by Daniel Santoro \u2013 2.0.2 \u2013 Not tested with the active version of WooCommerce\nWooCommerce Stripe Gateway: by WooCommerce \u2013 4.1.14\nWooCommerce Subscriptions: by Prospress Inc. \u2013 2.5.2\nWooCommerce: by Automattic \u2013 3.5.6\nWordfence Security: by Wordfence \u2013 7.2.3\nYoast SEO: by Team Yoast \u2013 9.7\nWP File Manager: by mndpsingh287 \u2013 4.4 API Enabled: \u2013\nForce SSL: \u2013\nCurrency: USD ($)\nCurrency Position: left\nThousand Separator: ,\nDecimal Separator: .\nNumber of Decimals: 2\nTaxonomies: Product Types: external (external)\ngrouped (grouped)\nsimple (simple)\nsubscription (subscription)\nvariable (variable)\nvariable subscription (variable-subscription) Taxonomies: Product Visibility: exclude-from-catalog (exclude-from-catalog)\nexclude-from-search (exclude-from-search)\nfeatured (featured)\noutofstock (outofstock)\nrated-1 (rated-1)\nrated-2 (rated-2)\nrated-3 (rated-3)\nrated-4 (rated-4)\nrated-5 (rated-5) Shop base: #166 - /shop\nCart: #167 - /cart\nCheckout: #168 - /checkout\nMy account: #169 - /my-account\nTerms and conditions: #297 - /terms Name: Divi\nVersion: 3.19.18\nAuthor URL: <URL>\nChild Theme: \u274c \u2013 If you are modifying WooCommerce on a parent theme that you did not build personally we recommend using a child theme. See: How to create a child theme\nWooCommerce Support: \u2714 Overrides: \u2013 WCS_DEBUG: \u2714 No\nSubscriptions Mode: \u2714 Live\nSubscriptions Live URL: <URL>\nSubscription Statuses: wc-active: 1\nWooCommerce Account Connected: \u2714 Yes\nActive Product Key: \u2714 Yes\nReport Cache Enabled: \u2714 Yes\nCache Update Failures: \u2714 0 failure Country / State: United States (US) \u2014 Nevada Stripe: wc-active: 1 Stripe: products\nrefunds\ntokenization\nadd_payment_method\nsubscriptions\nsubscription_cancellation\nsubscription_suspension\nsubscription_reactivation\nsubscription_amount_changes\nsubscription_date_changes\nsubscription_payment_method_change\nsubscription_payment_method_change_customer\nsubscription_payment_method_change_admin\nmultiple_subscriptions\npre-orders ` ", "code": ["Copy and paste the system status report from **WooCommerce > System Status** in WordPress admin.\n"], "labels": ["can't reproduce", "question"]}
{"project": "apache_skywalking", "title": "How can I configure ACK in zookeeper-cluster", "description": "Please answer these questions before submitting your issue. In my Env, ZK was set ACL, if I don't configure it, I can get this error\uff1a \"KeeperErrorcode=NoAuth for /skywalking\" when starting skywalking. I checked document, but I can't find corresponding entry in: zookeeper:\nnameSpace: ${SW_NAMESPACE:\"\"}\nhostPort: ${SW_CLUSTER_ZK_HOST_PORT:localhost:2181}\n#Retry Policy\nbaseSleepTimeMs: ${SW_CLUSTER_ZK_SLEEP_TIME:1000} # initial amount of time to wait between retries\nmaxRetries: ${SW_CLUSTER_ZK_MAX_RETRIES:3} # max number of times to retry\ninternalComHost: 172.10.4.10\ninternalComPort: 11800 ", "code": [], "labels": ["question"]}
{"project": "GoogleChrome_lighthouse", "title": "DevTools Error: PROTOCOL_TIMEOUT", "description": "Initial URL: <URL>\nChrome Version: 74.0.3729.6\nError Message: PROTOCOL_TIMEOUT\nStack Trace: <CODE> ", "code": ["LHError: PROTOCOL_TIMEOUT\n    at eval (chrome-devtools://devtools/remote/serve_file/@255758eccf3d244491b8a1317aa76e1ce10d57e9/audits2_worker/audits2_worker_module.js:1170:210)\n"], "labels": ["duplicate"]}
{"project": "WP-API_WP-API", "title": "Include Single Post pagination _links", "description": "Add \"previous\" and \"next\" _link objects for single pagination. ", "code": [], "labels": ["Enhancement"]}
{"project": "OnsenUI_OnsenUI", "title": "Error when using ons.createAlertDialog", "description": "Environment  <CODE> Encountered problem\nI just updated from Onsen 2.5.2 to 2.6.1 and now I get this error when using ons.createAlertDialog: <CODE> How to reproduce ", "code": ["[Core]\n    onsenui 2.6.1\n\n[Framework]\n    none\n\n[Framework binding]\n    none\n\n[Additional libraries]\n    Leaflet 1.2.0\n\n[Platform]\n    Desktop - Linux\n\n[Browser]\n    Desktop - Firefox 52.4.0\n", "14:27:56,982 TypeError: internal.doc.getElementById(...) is null 1 onsenui.js:31946:26\n\tinternal.getTemplateHTMLAsync/</</xhr.onload http://localhost/openvegemap/bower_components/onsenui/js/onsenui.js:31946:26\n"], "labels": ["outdated"]}
{"project": "redisson_redisson", "title": "Storing Redisson Live Object in RSetCache", "description": "Hi, Is it possible to store Redisson Live Object in RSetCache such that when the live object expires, it is evicted from RSetCache as well?\nAlso can we access the Live Objects from RSetCache?  While iterating over the live objects in RSetCache, I tried to assign the object to an instance of Live Object Class but I got an error stating that I cannot typecast object of type RedissonReference to object of type Class X. ", "code": [], "labels": ["bug"]}
{"project": "android-async-http_android-async-http", "title": "upload more file fail", "description": "my code : in server i can't get files ,i can only get one ,but i can't get 4 ", "code": [], "labels": ["wontfix", "question"]}
{"project": "katzer_cordova-plugin-local-notifications", "title": "Schedule notification as hidden on Android", "description": "To schedule a notification when the app is active (to do some housekeeping) I used to set text, title and sound to an empty string to create a 'invisible/silent' notification. On iOS the notification behaves as expected, doesn't show up in the notification center and triggers the trigger-event when the app is active/open. On Android however, the notification appears on the notification center. Is there a way to make the notification 'invisible/silent' on Android as well? ", "code": [], "labels": ["enhancement", "android"]}
{"project": "googleapis_google-cloud-python", "title": "Pubsub: How to flush unsent messages on program exit?", "description": "I have set caching configuration which may cache some messages and messages are not sent to pubsub yet. Is there a flush method when I want to exit the program. ", "code": [], "labels": ["type: question", "api: pubsub"]}
{"project": "alibaba_weex", "title": "scroller\u4e2donclick\u4e8b\u4ef6\u548conloading\u4e0d\u517c\u5bb9", "description": "\u91cd\u73b0\u6b65\u9aa4\uff1a\u5728\u5b98\u65b9\u63d0\u4f9b\u7684demo\uff1ascroller-demo.we\u4e2d\u52a0\u5165\u5982\u4e0b\u56fe\u4e2d\u7ea2\u8272\u6846\u4e2d\u7684\u6d4b\u8bd5\u4ee3\u7801\uff08\u5373\u6dfb\u52a0\u4e86onclick\u4e8b\u4ef6\uff09\n\u7ed3\u679c\uff1aonloading\u4e8b\u4ef6\u4e0d\u89e6\u53d1\n\u6d4b\u8bd5\u7cfb\u7edf\uff1aandriod\u548cios\u7684playground\u4e2d\u90fd\u662f\u540c\u6837\u7684\u95ee\u9898\n ", "code": [], "labels": ["android"]}
{"project": "mgechev_angular-seed", "title": "Gulp 4.0 - Upgrade Investigation / Deprecation Warnings", "description": "I'm submitting a ...  (check one with \"x\") <CODE> Current behavior\nAngular Seed uses Gulp 3.x.x. Expected behavior\nAngular Seed uses Gulp 4.0.x. Minimal reproduction of the problem with instructions\nN/A. Gulp 3.x.x lacks the gulp.symlink feature. What is the motivation / use case for changing the behavior?\nFor importing local modules, gulp.symlink is a highly desired feature instead of using gulp.dest. There's lots of infrastructure in angular-seed and angular-seed-advanced that depends on Gulp 3.x.x currently. Ideally, it would be useful to investigate the process of upgrading to Gulp 4.0.x to identify things in the build system that should be highlighted and identified as deprecated in the seed. Please tell us about your environment:\nN/A ", "code": ["[ ] bug report => search github for a similar issue or PR before submitting\n[x] feature request\n[ ] support request\n"], "labels": ["enhancement", "discuss"]}
{"project": "fish-shell_fish-shell", "title": "Error in command_not_found", "description": "I'm using OpenSUSE 12.2 with fish. It has /usr/bin/command-not-found for searching commands that not found on this system. However, when I use fish 2.1.0, as I type a command that doesn't exists in my system, an error occurs as follows. I've searched Google and stackoverflow, I cannot find the reason. ~> whois\n--: searching ...Cannot not open database file '/usr/share/scout/bin-whois.db'\n--: command not found ", "code": [], "labels": ["duplicate"]}
{"project": "desktop_desktop", "title": "make the version text under About selectable", "description": "To save accidentally mis-typing the version number, the text in the About GitHub Desktop should be selectable so you can copy and paste it elsewhere. GitHub Desktop version: 0.5.9 OS version: macOS (also relevant to Windows)  Expected behaviour: can highlight text Actual behaviour: nothing Reproduces how often: 100% ", "code": [], "labels": ["help wanted", "enhancement"]}
{"project": "ElemeFE_element", "title": "\u5f53\u83dc\u5355\u4e3a\u5782\u76f4\u663e\u793a\u65f6\uff0c\u70b9\u51fb\u5176\u5b83\u533a\u57df\u4f1a\u628a\u5df2\u7ecf\u5c55\u5f00\u7684\u5b50\u83dc\u5355\u5173\u95ed\uff0c\u8fd9\u4e2a\u95ee\u9898\u5f88\u4e25\u91cd\uff01", "description": "\nNo description provided.\n ", "code": [], "labels": ["invalid"]}
{"project": "ionic-team_ionic", "title": "[4.0.0-beta.11]ion-select not work", "description": "Ionic Info\nRun ionic info from a terminal/cmd prompt and paste the output below. <CODE> Describe the Bug\nion-select not work, show this error: <CODE> Steps to Reproduce\nSteps to reproduce the behavior: <CODE> Additional Context\nDoes ion-option not export? ", "code": ["   ionic (Ionic CLI)          : 4.1.2 (/Users/woodstream/.nvm/versions/node/v9.5.0/lib/node_modules/ionic)\n   Ionic Framework            : @ionic/angular 4.0.0-beta.11\n   @angular-devkit/core       : 0.7.5\n   @angular-devkit/schematics : 0.7.5\n   @angular/cli               : 6.2.2\n   @ionic/ng-toolkit          : 1.0.8\n   @ionic/schematics-angular  : 1.0.6\n", "ERROR Error: Uncaught (in promise): Error: Template parse errors:\n'ion-option' is not a known element:\n", "<ion-item>\n  <ion-label>Gender</ion-label>\n  <ion-select [(ngModel)]=\"gender\">\n    <ion-option value=\"f\">Female</ion-option>\n    <ion-option value=\"m\">Male</ion-option>\n  </ion-select>\n</ion-item>\n"], "labels": ["triage"]}
{"project": "go-gitea_gitea", "title": "Integrate Let's Encrypt with Gitea", "description": "It would be useful and encourage more people to use SSL if there is built in support for let's Encrypt. ", "code": [], "labels": ["kind/enhancement"]}
{"project": "facebook_react-native", "title": "0.48.4 init project does not work", "description": "I have a project with react-native 0.48.4 and it stopped work yesterday. I even try to create react-native project with init command (version 0.48.4) did not work. I got this error\n Environment:\nOS: macOS High Sierra 10.13.4\nNode: 8.11.1\nYarn: 1.3.2\nnpm: 5.6.0\nWatchman: 4.9.0\nXcode: Xcode 9.3.1 Build version 9E501\nAndroid Studio: 2.3 AI-162.3934792 Packages: (wanted => installed)\nreact: 16.0.0-alpha.12 => 16.0.0-alpha.12\nreact-native: 0.48.4 => 0.48.4 react-native init testapp --version=0.48.4 App works. App don't works.\n ", "code": [], "labels": ["Resolution: Locked", "Resolution: Old Version"]}
{"project": "OptimalBits_bull", "title": "Passing returnValues between repeatable jobs", "description": "Hello, I'm glad to see that finally we have repeatable jobs available. The code has changed a lot compared to my previous implementation. I've spent some time figuring out what would be the best way, but I am unsure: how could I pass the returnValue (or any kind of field set on the job inside the .process handler), so I could access it from the newly created/repeated job? My use case is very simple: I want to compare the results between two repetitions of the job. Thanks! ", "code": [], "labels": ["enhancement"]}
{"project": "fastlane_fastlane", "title": "Can't find variable: captureLocalizedScreenshot", "description": "I know this isn't an issue of Snapshot, but someone else may, like me, try to find help here. I was getting this error when running Snapshot: <CODE> This was my snapshot.js file: <CODE> The problem was the single quote on the import statement. For anyone like me, addicted to code stylers, make sure it doesn't change this first line. It should be: <CODE> ", "code": ["UIAutomation Error: Script threw an uncaught JavaScript error: Can't find variable: captureLocalizedScreenshot on line 8 of snapshot.js\n", "#import 'SnapshotHelper.js'\n\nvar target = UIATarget.localTarget();\nvar app = target.frontMostApp();\nvar window = app.mainWindow();\n\ntarget.delay(3);\ncaptureLocalizedScreenshot('0-LandingScreen');\n", "#import \"SnapshotHelper\"\n"], "labels": ["tool: snapshot"]}
{"project": "angular_angular", "title": "Dynamically FormControl not binding", "description": "My code is following . in dynamic Form Builder Component is following.\n<button (click)=\"addItem()\">Add <CODE> } addItem = () => {\nlet fieldsCtrls = {};\nfor (let f of this.fields) {\nfieldsCtrls[f.name] = new FormControl(f.value || '')\n}\nthis.items = this.form.get('items') as FormArray;\nthis.items.push(new FormGroup(fieldsCtrls));\nconsole.log(this.items);\n} onSubmit = (data) => {\nconsole.log(\"===vlaue\", data);\n}\n} TextBox component is following code .\n@component({\nselector: 'textbox',\ntemplate: <div [formGroup]=\"form\" > <input [attr.type]=\"field.type\" class=\"form-control\" id=\"{{field.name}}\" name=\"{{field.name}}\" formControlName=\"{{field.name}}\"> </div> \n})\nexport class TextBoxComponent {\n@input() field;\n@input() form:FormGroup;\nngOnInit() {\nconsole.log(this.field);\n}\nget isValid() { return this.form.controls[this.field.name].valid; }\nget isDirty() { return this.form.controls[this.field.name].dirty; } <CODE> } In appComponent.html Now error is coming that Cannot find control with name: 'firstName' after adding more fields  also it is showing the same error. So please tell me what is the issue with dynamic form control. \ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1\ud83d\uded1 ", "code": ["this.form = new FormGroup({\n  \"items\": new FormArray([new FormGroup(this.fieldsCtrls)])\n});\nconsole.log('fieldsCtrls', this.form)\n// this.form = new FormGroup(fieldsCtrls);\n", "constructor() {\n\n}\n"], "labels": ["comp: forms"]}
{"project": "socketio_socket.io-client-swift", "title": "How to force stop to reconnect loop?", "description": "Hello. Thank you for library. I socket created with .Reconnects(true) is it possible to stop reconnection when it is required? attempt 1: It crashed sometimes, in reason for Sometimes it not crashed, but reconnection loop not stops too. attempt 2: Set socket to nil and recreate it with same settings. Also fails, in reason of old client continue reconnection attempts. In logs i have two countdowns: <CODE> I can suppose i use it wrong way in reason of luck theoretical knowledge about sockets. But this lib has api which do not work as expected from it's naming. Questions:\n\u2013 What i am doing wrong?\n\u2013\u00a0Is there are way to have automatic reconnection but cancel it in any time?\n\u2013 According to line 202 SocketIO/SocketIOClient.swift \u2013 why is that? Why you can not just ignore disconnect request if socket was not connected? Strictly speaking task already done \u2013 no connection. or i miss something? ", "code": ["SocketConnector.swift:133: reconnectAttempt: [4] \nSocketConnector.swift:133: reconnectAttempt: [3]\nSocketConnector.swift:133: reconnectAttempt: [4]  \nSocketConnector.swift:133: reconnectAttempt: [2]\nSocketConnector.swift:133: reconnectAttempt: [3] \nSocketConnector.swift:133: reconnectAttempt: [1]\nSocketConnector.swift:133; reconnectAttempt: [2]\nSocketConnector.swift:133: reconnectAttempt: [1]    \n"], "labels": ["question"]}
{"project": "elastic_elasticsearch", "title": "Get missing aggregation to work for nested documents", "description": "Currently the missing aggreation doesn't work for nested documents (v1.4.2). It would be nice to have a simple way to count all the top level documents that do not have any nested documents within a specific key. For example (in a school setting) to find all pupils with no detentions. Where detentions is a key of student (if it exists at all), containing a 0-n length array of nested documents describing the date, duration and reason for each detention. ", "code": [], "labels": [":Analytics/Aggregations", ">enhancement"]}
{"project": "ansible_ansible", "title": "ansible_play_host vars don't always match play", "description": "When mid-play dynamic inventory actions (eg add_host, meta: refresh_inventory that causes hosts to appear/disappear) affect the host list for the currently-running play, ansible_play_hosts and ansible_play_hosts_all don't always reflect the current reality. By design, the in-flight play will not start running tasks on newly-added hosts, but it will stop running tasks on hosts that have disappeared. Newly-created hosts from an inventory refresh are immediately visible in ansible_play_hosts, even though they're not executing. Hosts added by an add_host do not appear in ansible_play_hosts. The behavior should probably be consistent, and favor reflecting what the current play is actually doing (ie the inventory refresh behavior seems incorrect). StrategyBase 2.8 NA NA Add a host mid-play via meta: refresh_inventory, dump ansible_play_hosts, note that the new host appears in the list. Add another host via add_host in the same play, dump ansible_play_hosts, note that the newest host does not appear. Consistent behavior between dynamically-added hosts- preferably that ansible_play_hosts always shows the actual list of hosts executing for the current play at the current time. Newly-added dynamic inventory-sourced hosts show up in ansible_play_hosts. ", "code": [], "labels": ["support:core", "bug", "affects_2.8"]}
{"project": "nylas_nylas-mail", "title": "Mail rules should ignore trash folder (or at least have the option to\u2026)", "description": "I can\u2019t delete (trash) anything that\u2019s been moved to a folder according to a matching rule since it just fetches it from the trash and puts it straight back into the folder again. ", "code": [], "labels": ["bug"]}
{"project": "spyder-ide_spyder", "title": "Automatic error report", "description": "changin 'scheme' (idle to zenburn or vice-versa) in 'syntax coloring' ", "code": [], "labels": ["resolution:Duplicate"]}
{"project": "matomo-org_matomo", "title": "Use crowd of all piwik users to enhance bot list, device list etc.", "description": "Giving normal, non developer piwik users the easy to use possibility to enhance bot list, device list, etc. (e.g. with the method described in #9182)\nthese data should not only be usable local in the piwik installation of the user who enhanced the list, but should be synced back to piwik and from there to other users.\n** With this one can make the power of the crowd accessible to make piwik better and better. ** ", "code": [], "labels": ["wontfix"]}
{"project": "elastic_elasticsearch", "title": "Fail `span_multi` queries that don't use `top_terms_*` rewriting", "description": "The span multi term query limits the number of expanded terms to search only if the inner multi term query uses top_terms_N rewrite. Otherwise it extracts all terms that match the inner multi term query and use them to build a giant span_or query without any limit.\nWe should force the inner multi term query to use a top_terms_N rewrite in order to limit the memory. Currently a prefix query like a* would extract all term that starts with a since the default rewrite of the prefix query is constant_score. This mode is optimized for prefix query and should never be used on a span_multi which needs to access all positions for the extracted terms. ", "code": [], "labels": [":Search/Search", ">bug"]}
{"project": "Carthage_Carthage", "title": "Carthage-managed submodules", "description": "Since Carthage has to create bare clones Git repositories of all your dependencies anyways, it could also git submodule add each repository into your local project folder\u2014but use a local clone path instead of a remote URL. This would allow you to use Carthage as usual, but still have versioned submodules (if you're into it). We could even make this clever and write the remote URL into .gitmodules, but use the local URL for cloning and updating the submodule in the particular user's working directory. This would allow you to set up a project with Carthage, but consume it with plain Git machinery. ", "code": [], "labels": ["enhancement"]}
{"project": "blynkkk_blynk-server", "title": "Investigate NPE for token manager", "description": "\nNo description provided.\n ", "code": [], "labels": ["bug"]}
{"project": "NixOS_nixpkgs", "title": "Python: bytecode in /bin", "description": "I just noticed that a __pycache__ symlink had made it into my /run/current-system/sw/bin directory. It points to /nix/store/$HASH-python3-3.6.2-env/bin/__pycache__. Here's a listing of the contents: <URL> I think this is a new issue. Python 3.6.2 was released on 2017-07-17, so I'm gussing it has to do with that. These files are not directly executable, so it should probably be filtered out of bin Is the right way to fix this just to remove the directory in postInstall? Like so: <CODE> Happy to open PR if that's correct. Pinging some of the package maintainers:\n@chaoflow @domenkozar System information: <CODE> ", "code": ["rm -r $out/bin/__pycache__\n", "NixOS version: 18.03.git.a75265924f (Impala)\nnix-env version: nix-env (Nix) 1.11.15\nnixpkgs version: 18.03.git.a75265924f\nbuild-use-sandbox: true\n"], "labels": ["6.topic: python", "0.kind: enhancement"]}
{"project": "ansible_ansible-modules-core", "title": "supervisorctl should support restarting service only if config changed", "description": "supervisorctl <CODE> supervisorctl module has no way to conditionally restart a service only if the config changed. This is currently possible with supervisor--call supervisor reread and if supervisor reports the config file changed, then we should call supervisor restart, otherwise do nothing. I suggest a new state value, although I'm not sure what to call it... restart_when_config_changed seems overly verbose. ", "code": ["2.2\n"], "labels": ["affects_2.2", "waiting_on_maintainer", "feature_idea"]}
{"project": "cockroachdb_cockroach", "title": "teamcity: failed test: TestImportCSVStmt", "description": "The following tests appear to have failed on master (testrace): TestImportCSVStmt/schema-in-query-transform-only, TestImportCSVStmt/empty-file, TestImportCSVStmt, TestImportCSVStmt/schema-in-query-opts, TestImportCSVStmt/empty-with-files, TestImportCSVStmt/schema-in-file-implicit-gzip, TestImportCSVStmt/schema-in-file-auto-gzip, TestImportCSVStmt/schema-in-file-no-decompress, TestImportCSVStmt/schema-in-file-auto-decompress, TestImportCSVStmt/schema-in-file-sstsize, TestImportCSVStmt/schema-in-file-explicit-gzip You may want to check for open issues. #1125897: <CODE> Please assign, take a look and update the issue accordingly. ", "code": ["TestImportCSVStmt/empty-file\n--- FAIL: testrace/TestImportCSVStmt: TestImportCSVStmt/empty-file (3.910s)\n\n------- Stdout: -------\nI190205 17:01:37.523685 10466 sql/event_log.go:135  [n1,client=127.0.0.1:35488,user=root] Event: \"create_database\", target: 63, info: {DatabaseName:csv6 Statement:CREATE DATABASE csv6 User:root}\nI190205 17:01:38.510520 26604 sql/event_log.go:135  [n1] Event: \"create_statistics\", target: 57, info: {StatisticName:__auto__ Statement:CREATE STATISTICS __auto__ FROM [57] AS OF SYSTEM TIME '-30s'}\nI190205 17:01:39.006451 27334 ccl/importccl/read_import_proc.go:75  [n2] could not fetch file size; falling back to per-file progress: <nil>\nI190205 17:01:39.767399 27361 ccl/importccl/read_import_proc.go:75  [n2] could not fetch file size; falling back to per-file progress: <nil>\n        import_stmt_test.go:1180: job 6 did not match:\n            Description: \"IMPORT TABLE csv6.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///empty.csv')\" != \"IMPORT TABLE csv4.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0', 'nodelocal:///csv/data-1', 'nodelocal:///csv/data-2', 'nodelocal:///csv/data-3', 'nodelocal:///csv/data-4') WITH sstsize = '10K'\"\n\n\n\nTestImportCSVStmt/empty-with-files\n...ica r140/1\nI190205 17:02:11.480262 23390 storage/queue.go:912  [n3,merge] purgatory is now empty\nI190205 17:02:11.521195 9608 storage/store.go:2669  [n2,s2,r173/2:/Table/59{-/1/2293}] removing replica r140/2\nI190205 17:02:12.390714 31243 storage/replica_command.go:244  [n3,s3,r243/3:/{Table/66/3/3\u2026-Max}] initiating a split of this range at key /Table/66/3/4386/\"S\"/PrefixEnd [r245] (manual)\nI190205 17:02:12.449743 31246 storage/replica_command.go:244  [n3,s3,r244/3:/Table/66/2/\"{I\"/1855-O\"/2849}] initiating a split of this range at key /Table/66/2/\"L\"/427 [r246] (manual)\nI190205 17:02:13.269133 9106 server/status/runtime.go:464  [n1] runtime stats: 1.2 GiB RSS, 678 goroutines, 65 MiB/42 MiB/138 MiB GO alloc/idle/total, 195 MiB/237 MiB CGO alloc/total, 2937.0 CGO/sec, 127.4/12.5 %(u/s)time, 1.7 %gc (9x), 3.8 MiB/3.8 MiB (r/w)net\nI190205 17:02:13.730235 31413 storage/replica_command.go:244  [n3,s3,r245/3:/{Table/66/3/4\u2026-Max}] initiating a split of this range at key /Table/67 [r247] (manual)\nI190205 17:02:13.972668 9638 storage/store.go:2669  [n2,s2,r76/2:/Table/61{-/2/\"O\"/4\u2026}] removing replica r199/2\nI190205 17:02:13.982182 9893 storage/store.go:2669  [n3,s3,r76/3:/Table/61{-/2/\"O\"/4\u2026}] removing replica r199/3\nI190205 17:02:13.995868 9314 storage/store.go:2669  [n1,s1,r76/1:/Table/61{-/2/\"O\"/4\u2026}] removing replica r199/1\nI190205 17:02:14.340019 31337 storage/replica_command.go:383  [n2,merge,s2,r76/2:/Table/61{-/3/3647/\u2026}] initiating a merge of r207:/Table/6{1/3/3647/\"H\"-4} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=2] into this range (lhs+rhs has (size=367 KiB+37 KiB qps=10.88+2.42 --> 13.30qps) below threshold (size=404 KiB, qps=13.30))\nI190205 17:02:15.108320 31517 storage/replica_command.go:244  [n3,s3,r238/3:/Table/66/3/{858/\"A\"-3719/\"\u2026}] initiating a split of this range at key /Table/66/3/1524/\"Q\"/PrefixEnd [r248] (manual)\nI190205 17:02:15.120373 9194 storage/store.go:2669  [n1,s1,r76/1:/Table/61{-/3/3647/\u2026}] removing replica r207/1\nI190205 17:02:15.135510 9864 storage/store.go:2669  [n3,s3,r76/3:/Table/61{-/3/3647/\u2026}] removing replica r207/3\nI190205 17:02:15.144323 9631 storage/store.go:2669  [n2,s2,r76/2:/Table/61{-/3/3647/\u2026}] removing replica r207/2\nI190205 17:02:15.342298 9663 server/status/runtime.go:464  [n2] runtime stats: 1.2 GiB RSS, 672 goroutines, 58 MiB/51 MiB/138 MiB GO alloc/idle/total, 195 MiB/237 MiB CGO alloc/total, 3280.9 CGO/sec, 127.5/13.6 %(u/s)time, 1.5 %gc (8x), 3.8 MiB/3.8 MiB (r/w)net\nI190205 17:02:15.688010 31549 storage/replica_command.go:244  [n3,s3,r248/3:/Table/66/3/{1524/\"\u2026-3719/\"\u2026}] initiating a split of this range at key /Table/66/3/2191/\"H\"/PrefixEnd [r249] (manual)\nI190205 17:02:15.986154 9890 server/status/runtime.go:464  [n3] runtime stats: 1.2 GiB RSS, 662 goroutines, 61 MiB/48 MiB/138 MiB GO alloc/idle/total, 186 MiB/228 MiB CGO alloc/total, 3369.6 CGO/sec, 127.7/14.0 %(u/s)time, 1.6 %gc (9x), 3.9 MiB/3.9 MiB (r/w)net\nI190205 17:02:16.237913 31591 storage/replica_command.go:244  [n3,s3,r249/3:/Table/66/3/{2191/\"\u2026-3719/\"\u2026}] initiating a split of this range at key /Table/66/3/2858/\"Y\"/PrefixEnd [r250] (manual)\nI190205 17:02:17.353424 31587 storage/replica_command.go:244  [n3,s3,r250/3:/Table/66/3/{2858/\"\u2026-3719/\"\u2026}] initiating a split of this range at key /Table/66/3/3053/\"L\" [r251] (manual)\n        import_stmt_test.go:1180: job 7 did not match:\n            Description: \"IMPORT TABLE csv7.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///empty.csv', 'nodelocal:///csv/data-0', 'nodelocal:///csv/data-1', 'nodelocal:///csv/data-2', 'nodelocal:///csv/data-3', 'nodelocal:///csv/data-4')\" != \"IMPORT TABLE \\\"\\\".\\\"\\\".t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0-opts', 'nodelocal:///csv/data-1-opts', 'nodelocal:///csv/data-2-opts', 'nodelocal:///csv/data-3-opts', 'nodelocal:///csv/data-4-opts') WITH comment = '#', delimiter = '|', \\\"nullif\\\" = '', skip = '2', transform = 'nodelocal:///5'\"\n\n\n\nTestImportCSVStmt/schema-in-query-transform-only\n--- FAIL: testrace/TestImportCSVStmt: TestImportCSVStmt/schema-in-query-transform-only (10.560s)\n\n------- Stdout: -------\nI190205 17:01:26.640192 25729 storage/replica_command.go:244  [n2,split,s2,r140/2:/Table/{59/1/2293-61/1/741}] initiating a split of this range at key /Table/61 [r76] (zone config)\nI190205 17:01:26.668177 10466 sql/event_log.go:135  [n1,client=127.0.0.1:35488,user=root] Event: \"create_database\", target: 62, info: {DatabaseName:csv5 Statement:CREATE DATABASE csv5 User:root}\nI190205 17:01:32.551750 9657 storage/compactor/compactor.go:329  [n2,s2,compactor] purging suggested compaction for range /Table/59/2/\"O\"/2926 - /Table/59/2/\"T\"/1424 that contains live data\nI190205 17:01:32.552120 9657 storage/compactor/compactor.go:329  [n2,s2,compactor] purging suggested compaction for range /Table/59/2/\"T\"/1424 - /Table/61/1/741 that contains live data\nI190205 17:01:32.556241 9348 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /Table/59/2/\"O\"/2926 - /Table/59/2/\"T\"/1424 that contains live data\nI190205 17:01:32.556650 9348 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /Table/59/2/\"T\"/1424 - /Table/61/1/741 that contains live data\nI190205 17:01:32.567219 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/59/2/\"O\"/2926 - /Table/59/2/\"T\"/1424 that contains live data\nI190205 17:01:32.567662 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/59/2/\"T\"/1424 - /Table/61/1/741 that contains live data\nI190205 17:01:33.159161 9106 server/status/runtime.go:464  [n1] runtime stats: 1.1 GiB RSS, 704 goroutines, 72 MiB/37 MiB/137 MiB GO alloc/idle/total, 204 MiB/243 MiB CGO alloc/total, 2833.3 CGO/sec, 140.1/14.2 %(u/s)time, 1.1 %gc (11x), 3.7 MiB/3.7 MiB (r/w)net\nI190205 17:01:35.284581 9663 server/status/runtime.go:464  [n2] runtime stats: 1.1 GiB RSS, 681 goroutines, 54 MiB/53 MiB/137 MiB GO alloc/idle/total, 195 MiB/235 MiB CGO alloc/total, 4821.5 CGO/sec, 136.6/13.3 %(u/s)time, 1.1 %gc (10x), 4.0 MiB/4.0 MiB (r/w)net\nI190205 17:01:35.891913 9890 server/status/runtime.go:464  [n3] runtime stats: 1.1 GiB RSS, 664 goroutines, 57 MiB/51 MiB/137 MiB GO alloc/idle/total, 186 MiB/226 MiB CGO alloc/total, 5175.5 CGO/sec, 138.2/12.1 %(u/s)time, 1.1 %gc (11x), 4.1 MiB/4.1 MiB (r/w)net\n        import_stmt_test.go:1180: job 5 did not match:\n            Description: \"IMPORT TABLE \\\"\\\".\\\"\\\".t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0-opts', 'nodelocal:///csv/data-1-opts', 'nodelocal:///csv/data-2-opts', 'nodelocal:///csv/data-3-opts', 'nodelocal:///csv/data-4-opts') WITH comment = '#', delimiter = '|', \\\"nullif\\\" = '', skip = '2', transform = 'nodelocal:///5'\" != \"IMPORT TABLE csv3.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0-opts', 'nodelocal:///csv/data-1-opts', 'nodelocal:///csv/data-2-opts', 'nodelocal:///csv/data-3-opts', 'nodelocal:///csv/data-4-opts') WITH comment = '#', delimiter = '|', \\\"nullif\\\" = '', skip = '2'\"\n\n\n\nTestImportCSVStmt/schema-in-file-auto-gzip\n...e, 0.9 %gc (10x), 4.0 MiB/4.0 MiB (r/w)net\nI190205 17:04:06.909910 44118 storage/replica_command.go:383  [n2,merge,s2,r296/2:/Table/72/2/\"{H\"/502-K\"/2923}] initiating a merge of r297:/Table/72/2/\"{K\"/2923-L\"/973} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=18 KiB+3.2 KiB qps=2.92+0.00 --> 2.92qps) below threshold (size=21 KiB, qps=2.92))\nI190205 17:04:07.036263 9302 storage/store.go:2669  [n1,s1,r293/1:/Table/72/{1/4316-2/\"H\"/5\u2026}] removing replica r296/1\nI190205 17:04:07.045185 9618 storage/store.go:2669  [n2,s2,r293/2:/Table/72/{1/4316-2/\"H\"/5\u2026}] removing replica r296/2\nI190205 17:04:07.085090 9875 storage/store.go:2669  [n3,s3,r293/3:/Table/72/{1/4316-2/\"H\"/5\u2026}] removing replica r296/3\nI190205 17:04:07.307294 44181 storage/replica_command.go:383  [n1,merge,s1,r293/1:/Table/72/{1/4316-2/\"K\"/2\u2026}] initiating a merge of r297:/Table/72/2/\"{K\"/2923-L\"/973} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=74 KiB+3.2 KiB qps=3.60+0.00 --> 3.60qps) below threshold (size=77 KiB, qps=3.60))\nI190205 17:04:07.595879 44178 storage/replica_command.go:244  [n3,s3,r381/3:/{Table/74/3/4\u2026-Max}] initiating a split of this range at key /Table/75 [r382] (manual)\nI190205 17:04:07.894242 44247 storage/replica_command.go:383  [n2,merge,s2,r297/2:/Table/72/2/\"{K\"/2923-L\"/973}] initiating a merge of r298:/Table/72/{2/\"L\"/973-3/1384/\"G\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=6] into this range (lhs+rhs has (size=3.2 KiB+115 KiB qps=0.00+0.00 --> 0.00qps) below threshold (size=118 KiB, qps=0.00))\nI190205 17:04:07.909553 9290 storage/store.go:2669  [n1,s1,r293/1:/Table/72/{1/4316-2/\"K\"/2\u2026}] removing replica r297/1\nI190205 17:04:07.927701 9693 storage/store.go:2669  [n3,s3,r293/3:/Table/72/{1/4316-2/\"K\"/2\u2026}] removing replica r297/3\nI190205 17:04:07.911213 9591 storage/store.go:2669  [n2,s2,r293/2:/Table/72/{1/4316-2/\"K\"/2\u2026}] removing replica r297/2\nI190205 17:04:08.159674 44309 storage/replica_command.go:383  [n1,merge,s1,r293/1:/Table/72/{1/4316-2/\"L\"/9\u2026}] initiating a merge of r298:/Table/72/{2/\"L\"/973-3/1384/\"G\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=6] into this range (lhs+rhs has (size=77 KiB+115 KiB qps=9.58+0.00 --> 9.58qps) below threshold (size=192 KiB, qps=9.58))\nI190205 17:04:08.717048 9299 storage/store.go:2669  [n1,s1,r293/1:/Table/72/{1/4316-2/\"L\"/9\u2026}] removing replica r298/1\nI190205 17:04:08.720016 9905 storage/store.go:2669  [n3,s3,r293/3:/Table/72/{1/4316-2/\"L\"/9\u2026}] removing replica r298/3\nI190205 17:04:08.723759 9602 storage/store.go:2669  [n2,s2,r293/2:/Table/72/{1/4316-2/\"L\"/9\u2026}] removing replica r298/2\nI190205 17:04:09.155128 44422 storage/replica_command.go:383  [n1,merge,s1,r293/1:/Table/72/{1/4316-3/1384/\u2026}] initiating a merge of r220:/Table/72/3/{1384/\"G\"/PrefixEnd-2051/\"X\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=192 KiB+18 KiB qps=9.63+0.00 --> 9.63qps) below threshold (size=210 KiB, qps=9.63))\nI190205 17:04:09.347026 44458 storage/replica_command.go:383  [n2,merge,s2,r220/2:/Table/72/3/{1384/\"\u2026-2051/\"\u2026}] initiating a merge of r271:/Table/72/3/2{051/\"X\"/PrefixEnd-718/\"O\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=18 KiB+18 KiB qps=0.00+0.00 --> 0.00qps) below threshold (size=36 KiB, qps=0.00))\n        import_stmt_test.go:1180: job 11 did not match:\n            Description: \"IMPORT TABLE csv11.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:////csv/data-0.gz', 'nodelocal:////csv/data-1.gz', 'nodelocal:////csv/data-2.gz', 'nodelocal:////csv/data-3.gz', 'nodelocal:////csv/data-4.gz') WITH decompress = 'auto'\" != \"IMPORT TABLE csv7.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///empty.csv', 'nodelocal:///csv/data-0', 'nodelocal:///csv/data-1', 'nodelocal:///csv/data-2', 'nodelocal:///csv/data-3', 'nodelocal:///csv/data-4')\"\n\n\n\nTestImportCSVStmt/empty-file\n--- FAIL: test/TestImportCSVStmt: TestImportCSVStmt/empty-file (4.090s)\n\n------- Stdout: -------\nI190205 16:56:38.588159 9114 sql/event_log.go:135  [n1,client=127.0.0.1:56600,user=root] Event: \"create_database\", target: 64, info: {DatabaseName:csv6 Statement:CREATE DATABASE csv6 User:root}\nI190205 16:56:38.634235 16476 ccl/importccl/read_import_proc.go:75  [n3] could not fetch file size; falling back to per-file progress: <nil>\nI190205 16:56:38.670653 16709 ccl/importccl/read_import_proc.go:75  [n3] could not fetch file size; falling back to per-file progress: <nil>\n------- Stdout: -------\nI190205 17:01:37.523685 10466 sql/event_log.go:135  [n1,client=127.0.0.1:35488,user=root] Event: \"create_database\", target: 63, info: {DatabaseName:csv6 Statement:CREATE DATABASE csv6 User:root}\nI190205 17:01:38.510520 26604 sql/event_log.go:135  [n1] Event: \"create_statistics\", target: 57, info: {StatisticName:__auto__ Statement:CREATE STATISTICS __auto__ FROM [57] AS OF SYSTEM TIME '-30s'}\nI190205 17:01:39.006451 27334 ccl/importccl/read_import_proc.go:75  [n2] could not fetch file size; falling back to per-file progress: <nil>\nI190205 17:01:39.767399 27361 ccl/importccl/read_import_proc.go:75  [n2] could not fetch file size; falling back to per-file progress: <nil>\n        import_stmt_test.go:1180: job 6 did not match:\n            Description: \"IMPORT TABLE csv6.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///empty.csv')\" != \"IMPORT TABLE csv4.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0', 'nodelocal:///csv/data-1', 'nodelocal:///csv/data-2', 'nodelocal:///csv/data-3', 'nodelocal:///csv/data-4') WITH sstsize = '10K'\"\n\n\n\nTestImportCSVStmt/schema-in-file-auto-decompress\n...g replica r231/1\nI190205 17:02:35.537024 9600 storage/store.go:2669  [n2,s2,r227/2:/Table/66/1/1{456-718}] removing replica r231/2\nI190205 17:02:35.643449 33416 storage/replica_command.go:383  [n3,merge,s3,r227/3:/Table/66/1/{1456-2433}] initiating a merge of r225:/Table/66/1/{2433-3148} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=26 KiB+19 KiB qps=0.00+0.00 --> 0.00qps) below threshold (size=45 KiB, qps=0.00))\nI190205 17:02:35.823850 32868 storage/replica_command.go:244  [n1,s1,r148/1:/{Table/68/3/4\u2026-Max}] initiating a split of this range at key /Table/69 [r149] (manual)\nI190205 17:02:36.007295 9890 server/status/runtime.go:464  [n3] runtime stats: 1.2 GiB RSS, 663 goroutines, 83 MiB/27 MiB/138 MiB GO alloc/idle/total, 188 MiB/228 MiB CGO alloc/total, 5879.6 CGO/sec, 134.8/10.4 %(u/s)time, 1.9 %gc (9x), 3.9 MiB/3.9 MiB (r/w)net\nI190205 17:02:36.337475 9877 storage/store.go:2669  [n3,s3,r227/3:/Table/66/1/{1456-2433}] removing replica r225/3\nI190205 17:02:36.360632 9305 storage/store.go:2669  [n1,s1,r227/1:/Table/66/1/{1456-2433}] removing replica r225/1\nI190205 17:02:36.382106 9630 storage/store.go:2669  [n2,s2,r227/2:/Table/66/1/{1456-2433}] removing replica r225/2\nI190205 17:02:36.526677 33512 storage/replica_command.go:383  [n3,merge,s3,r227/3:/Table/66/1/{1456-3148}] initiating a merge of r228:/Table/66/1/3{148-863} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=2] into this range (lhs+rhs has (size=45 KiB+19 KiB qps=8.90+0.00 --> 8.90qps) below threshold (size=64 KiB, qps=8.90))\nI190205 17:02:37.027656 9636 storage/store.go:2669  [n2,s2,r227/2:/Table/66/1/{1456-3148}] removing replica r228/2\nI190205 17:02:37.030620 9872 storage/store.go:2669  [n3,s3,r227/3:/Table/66/1/{1456-3148}] removing replica r228/3\nI190205 17:02:37.051433 9312 storage/store.go:2669  [n1,s1,r227/1:/Table/66/1/{1456-3148}] removing replica r228/1\nI190205 17:02:37.074744 33558 storage/replica_command.go:383  [n3,merge,s3,r227/3:/Table/66/1/{1456-3863}] initiating a merge of r233:/Table/66/1/{3863-4578} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=64 KiB+19 KiB qps=8.90+0.00 --> 8.90qps) below threshold (size=82 KiB, qps=8.90))\nI190205 17:02:37.588202 9884 storage/store.go:2669  [n3,s3,r227/3:/Table/66/1/{1456-3863}] removing replica r233/3\nI190205 17:02:37.592910 9321 storage/store.go:2669  [n1,s1,r227/1:/Table/66/1/{1456-3863}] removing replica r233/1\nI190205 17:02:37.595160 9632 storage/store.go:2669  [n2,s2,r227/2:/Table/66/1/{1456-3863}] removing replica r233/2\nI190205 17:02:37.666265 33632 storage/replica_command.go:383  [n3,merge,s3,r227/3:/Table/66/1/{1456-4578}] initiating a merge of r236:/Table/66/{1/4578-2/\"B\"/2108} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=82 KiB+19 KiB qps=8.99+0.00 --> 8.99qps) below threshold (size=101 KiB, qps=8.99))\nI190205 17:02:38.236396 9638 storage/store.go:2669  [n2,s2,r227/2:/Table/66/1/{1456-4578}] removing replica r236/2\nI190205 17:02:38.243092 9905 storage/store.go:2669  [n3,s3,r227/3:/Table/66/1/{1456-4578}] removing replica r236/3\nI190205 17:02:38.259911 9331 storage/store.go:2669  [n1,s1,r227/1:/Table/66/1/{1456-4578}] removing replica r236/1\nI190205 17:02:38.303735 33719 storage/replica_command.go:383  [n3,merge,s3,r227/3:/Table/66/{1/1456-2/\"B\"/2\u2026}] initiating a merge of r240:/Table/66/2/\"{B\"/2108-E\"/4477} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=101 KiB+18 KiB qps=8.99+0.00 --> 8.99qps) below threshold (size=119 KiB, qps=8.99))\n        import_stmt_test.go:1180: job 8 did not match:\n            Description: \"IMPORT TABLE csv8.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0', 'nodelocal:///csv/data-1', 'nodelocal:///csv/data-2', 'nodelocal:///csv/data-3', 'nodelocal:///csv/data-4') WITH decompress = 'auto'\" != \"CREATE STATISTICS __auto__ FROM [57] AS OF SYSTEM TIME '-30s'\"\n\n\n\nTestImportCSVStmt\n...scriptor r9:/Table/1{3-4} [(n1,s1):1, (n3,s3):2, next=3, gen=0]\nI190205 16:59:11.245961 9111 storage/replica_raft.go:372  [n1,s1,r9/1:/Table/1{3-4}] proposing ADD_REPLICA((n2,s2):3): updated=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4\nI190205 16:59:11.269390 9111 storage/store_snapshot.go:762  [n1,replicate,s1,r7/1:/Table/1{1-2}] sending preemptive snapshot f8c2d603 at applied index 20\nI190205 16:59:11.270239 9111 storage/store_snapshot.go:805  [n1,replicate,s1,r7/1:/Table/1{1-2}] streamed snapshot to (n2,s2):?: kv pairs: 9, log entries: 10, rate-limit: 8.0 MiB/sec, 0.01s\nI190205 16:59:11.272243 10485 storage/replica_raftstorage.go:805  [n2,s2,r7/?:{-}] applying preemptive snapshot at index 20 (id=f8c2d603, encoded size=1939, 1 rocksdb batches, 10 log entries)\nI190205 16:59:11.341847 10485 storage/replica_raftstorage.go:811  [n2,s2,r7/?:/Table/1{1-2}] applied preemptive snapshot in 69ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI190205 16:59:11.345650 9111 storage/replica_command.go:798  [n1,replicate,s1,r7/1:/Table/1{1-2}] change replicas (ADD_REPLICA (n2,s2):3): read existing descriptor r7:/Table/1{1-2} [(n1,s1):1, (n3,s3):2, next=3, gen=0]\nI190205 16:59:11.401863 9111 storage/replica_raft.go:372  [n1,s1,r7/1:/Table/1{1-2}] proposing ADD_REPLICA((n2,s2):3): updated=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4\nI190205 16:59:11.426362 9111 storage/store_snapshot.go:762  [n1,replicate,s1,r19/1:/Table/2{3-4}] sending preemptive snapshot f4d898b2 at applied index 17\nI190205 16:59:11.427213 9111 storage/store_snapshot.go:805  [n1,replicate,s1,r19/1:/Table/2{3-4}] streamed snapshot to (n3,s3):?: kv pairs: 11, log entries: 7, rate-limit: 8.0 MiB/sec, 0.02s\nI190205 16:59:11.430029 10462 storage/replica_raftstorage.go:805  [n3,s3,r19/?:{-}] applying preemptive snapshot at index 17 (id=f4d898b2, encoded size=1642, 1 rocksdb batches, 7 log entries)\nI190205 16:59:11.432351 10462 storage/replica_raftstorage.go:811  [n3,s3,r19/?:/Table/2{3-4}] applied preemptive snapshot in 2ms [clear=0ms batch=0ms entries=1ms commit=0ms]\nI190205 16:59:11.438373 9111 storage/replica_command.go:798  [n1,replicate,s1,r19/1:/Table/2{3-4}] change replicas (ADD_REPLICA (n3,s3):3): read existing descriptor r19:/Table/2{3-4} [(n1,s1):1, (n2,s2):2, next=3, gen=0]\nI190205 16:59:11.485656 9111 storage/replica_raft.go:372  [n1,s1,r19/1:/Table/2{3-4}] proposing ADD_REPLICA((n3,s3):3): updated=[(n1,s1):1 (n2,s2):2 (n3,s3):3] next=4\nI190205 16:59:11.539023 9111 storage/store_snapshot.go:762  [n1,replicate,s1,r15/1:/Table/{19-20}] sending preemptive snapshot 0d9ecedc at applied index 19\nI190205 16:59:11.539833 9111 storage/store_snapshot.go:805  [n1,replicate,s1,r15/1:/Table/{19-20}] streamed snapshot to (n2,s2):?: kv pairs: 8, log entries: 9, rate-limit: 8.0 MiB/sec, 0.01s\nI190205 16:59:11.552953 10502 storage/replica_raftstorage.go:805  [n2,s2,r15/?:{-}] applying preemptive snapshot at index 19 (id=0d9ecedc, encoded size=1687, 1 rocksdb batches, 9 log entries)\nI190205 16:59:11.562799 10502 storage/replica_raftstorage.go:811  [n2,s2,r15/?:/Table/{19-20}] applied preemptive snapshot in 3ms [clear=0ms batch=0ms entries=1ms commit=1ms]\nI190205 16:59:11.567651 9111 storage/replica_command.go:798  [n1,replicate,s1,r15/1:/Table/{19-20}] change replicas (ADD_REPLICA (n2,s2):3): read existing descriptor r15:/Table/{19-20} [(n1,s1):1, (n3,s3):2, next=3, gen=0]\nI190205 16:59:11.656183 9111 storage/replica_raft.go:372  [n1,s1,r15/1:/Table/{19-20}] proposing ADD_REPLICA((n2,s2):3): updated=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4\nI190205 16:59:12.086376 10466 sql/event_log.go:135  [n1,client=127.0.0.1:35488,user=root] Event: \"set_cluster_setting\", target: 0, info: {SettingName:kv.import.batch_size Value:10KB User:root}\nI190205 16:59:13.012229 9106 server/status/runtime.go:464  [n1] runtime stats: 743 MiB RSS, 627 goroutines, 28 MiB/84 MiB/137 MiB GO alloc/idle/total, 80 MiB/115 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (84x), 4.5 MiB/4.5 MiB (r/w)net\n\n\n\nTestImportCSVStmt/schema-in-file-no-decompress\n....go:329  [n1,s1,compactor] purging suggested compaction for range /Table/68/2/\"Y\"/2495 - /Table/68/3/403/\"N\"/PrefixEnd that contains live data\nI190205 17:03:04.099951 9348 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /Table/68/3/403/\"N\"/PrefixEnd - /Table/68/3/981/\"T\" that contains live data\nI190205 17:03:04.100292 9348 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /Table/68/3/981/\"T\" - /Table/68/3/1647/\"J\"/PrefixEnd that contains live data\nI190205 17:03:04.135575 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/66/2/\"I\"/1855 - /Table/68 that contains live data\nI190205 17:03:04.136135 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/66/2/\"O\"/2849 - /Table/66/3/205/\"X\"/PrefixEnd that contains live data\nI190205 17:03:04.136561 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/66/3/205/\"X\"/PrefixEnd - /Table/68 that contains live data\nI190205 17:03:04.136981 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/1/1456 - /Table/68/1/2171 that contains live data\nI190205 17:03:04.137376 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"E\"/707 - /Table/68/2/\"F\"/265 that contains live data\nI190205 17:03:04.137670 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"F\"/265 - /Table/68/2/\"I\"/2609 that contains live data\nI190205 17:03:04.140443 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"I\"/2609 - /Table/68/2/\"M\"/65 that contains live data\nI190205 17:03:04.140869 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"M\"/65 - /Table/68/2/\"O\"/170 that contains live data\nI190205 17:03:04.141367 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"O\"/170 - /Table/68/2/\"R\"/2592 that contains live data\nI190205 17:03:04.142351 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"R\"/2592 - /Table/68/2/\"V\"/48 that contains live data\nI190205 17:03:04.142763 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"V\"/48 - /Table/68/2/\"Y\"/2495 that contains live data\nI190205 17:03:04.149737 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/2/\"Y\"/2495 - /Table/68/3/403/\"N\"/PrefixEnd that contains live data\nI190205 17:03:04.150287 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/3/403/\"N\"/PrefixEnd - /Table/68/3/981/\"T\" that contains live data\nI190205 17:03:04.150617 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/68/3/981/\"T\" - /Table/68/3/1647/\"J\"/PrefixEnd that contains live data\nI190205 17:03:04.178378 36691 storage/replica_command.go:383  [n2,merge,s2,r79/2:/Table/68/1/{741-2171}] initiating a merge of r213:/Table/68/1/2{171-886} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=38 KiB+19 KiB qps=6.45+0.00 --> 6.45qps) below threshold (size=57 KiB, qps=6.45))\n        import_stmt_test.go:1180: job 9 did not match:\n            Description: \"IMPORT TABLE csv9.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0', 'nodelocal:///csv/data-1', 'nodelocal:///csv/data-2', 'nodelocal:///csv/data-3', 'nodelocal:///csv/data-4') WITH decompress = 'none'\" != \"IMPORT TABLE csv6.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///empty.csv')\"\n\n\n\nTestImportCSVStmt/schema-in-query-opts\n...is range at key /Table/59/3/4326/\"K\"/PrefixEnd [r171] (manual)\nI190205 17:00:46.772674 9297 storage/store.go:2669  [n1,s1,r115/1:/Table/57/{2/\"U\"/4\u2026-3/1798/\u2026}] removing replica r121/1\nI190205 17:00:47.019855 20624 storage/replica_command.go:383  [n2,merge,s2,r115/2:/Table/57/{2/\"U\"/4\u2026-3/2465/\u2026}] initiating a merge of r122:/Table/57/3/{2465/\"V\"/PrefixEnd-3132/\"M\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=2] into this range (lhs+rhs has (size=94 KiB+18 KiB qps=12.73+0.00 --> 12.73qps) below threshold (size=112 KiB, qps=12.73))\nI190205 17:00:47.331505 9316 storage/store.go:2669  [n1,s1,r110/1:/Table/57/2/\"{C\"/2915-G\"/293}] removing replica r112/1\nI190205 17:00:47.361861 9869 storage/store.go:2669  [n3,s3,r110/3:/Table/57/2/\"{C\"/2915-G\"/293}] removing replica r112/3\nI190205 17:00:47.375230 9627 storage/store.go:2669  [n2,s2,r110/2:/Table/57/2/\"{C\"/2915-G\"/293}] removing replica r112/2\nI190205 17:00:47.623997 20853 storage/replica_command.go:383  [n1,merge,s1,r110/1:/Table/57/2/\"{C\"/2915-J\"/2688}] initiating a merge of r70:/Table/57/2/\"{J\"/2688-N\"/170} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=37 KiB+18 KiB qps=4.88+0.00 --> 4.88qps) below threshold (size=55 KiB, qps=4.88))\nI190205 17:00:47.862012 9593 storage/store.go:2669  [n2,s2,r115/2:/Table/57/{2/\"U\"/4\u2026-3/2465/\u2026}] removing replica r122/2\nI190205 17:00:47.914227 9698 storage/store.go:2669  [n3,s3,r115/3:/Table/57/{2/\"U\"/4\u2026-3/2465/\u2026}] removing replica r122/3\nI190205 17:00:47.914329 9198 storage/store.go:2669  [n1,s1,r115/1:/Table/57/{2/\"U\"/4\u2026-3/2465/\u2026}] removing replica r122/1\nI190205 17:00:48.100643 20786 storage/replica_command.go:383  [n2,merge,s2,r115/2:/Table/57/{2/\"U\"/4\u2026-3/3132/\u2026}] initiating a merge of r127:/Table/57/3/3{132/\"M\"/PrefixEnd-799/\"D\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=112 KiB+18 KiB qps=5.60+0.00 --> 5.60qps) below threshold (size=131 KiB, qps=5.60))\nI190205 17:00:48.783909 20301 storage/replica_command.go:244  [n3,s3,r171/3:/{Table/59/3/4\u2026-Max}] initiating a split of this range at key /Table/60 [r172] (manual)\nI190205 17:00:48.896065 9306 storage/store.go:2669  [n1,s1,r115/1:/Table/57/{2/\"U\"/4\u2026-3/3132/\u2026}] removing replica r127/1\nI190205 17:00:48.900358 9625 storage/store.go:2669  [n2,s2,r115/2:/Table/57/{2/\"U\"/4\u2026-3/3132/\u2026}] removing replica r127/2\nI190205 17:00:48.903897 9903 storage/store.go:2669  [n3,s3,r115/3:/Table/57/{2/\"U\"/4\u2026-3/3132/\u2026}] removing replica r127/3\nI190205 17:00:48.985173 20911 storage/replica_command.go:383  [n2,merge,s2,r70/2:/Table/57/2/\"{J\"/2688-N\"/170}] initiating a merge of r71:/Table/57/2/\"{N\"/170-Q\"/2617} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=18 KiB+18 KiB qps=2.29+0.00 --> 2.29qps) below threshold (size=37 KiB, qps=2.29))\nI190205 17:00:49.013063 9604 storage/store.go:2669  [n2,s2,r110/2:/Table/57/2/\"{C\"/2915-J\"/2688}] removing replica r70/2\nI190205 17:00:49.020194 9280 storage/store.go:2669  [n1,s1,r110/1:/Table/57/2/\"{C\"/2915-J\"/2688}] removing replica r70/1\nI190205 17:00:49.027436 9690 storage/store.go:2669  [n3,s3,r110/3:/Table/57/2/\"{C\"/2915-J\"/2688}] removing replica r70/3\nI190205 17:00:50.018595 20986 storage/replica_command.go:383  [n2,merge,s2,r30/2:/Table/57/1/2{171-886}] initiating a merge of r31:/Table/57/1/{2886-3601} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=19 KiB+19 KiB qps=1.32+0.00 --> 1.32qps) below threshold (size=38 KiB, qps=1.32))\n        import_stmt_test.go:1180: job 3 did not match:\n            Description: \"IMPORT TABLE csv3.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0-opts', 'nodelocal:///csv/data-1-opts', 'nodelocal:///csv/data-2-opts', 'nodelocal:///csv/data-3-opts', 'nodelocal:///csv/data-4-opts') WITH comment = '#', delimiter = '|', \\\"nullif\\\" = '', skip = '2'\" != \"CREATE STATISTICS __auto__ FROM [55] AS OF SYSTEM TIME '-30s'\"\n\n\n\nTestImportCSVStmt/schema-in-file-sstsize\n...\nI190205 17:01:18.769888 24710 storage/replica_command.go:244  [n3,s3,r195/3:/{Table/61/3/1\u2026-Max}] initiating a split of this range at key /Table/61/3/2777/\"V\" [r197] (manual)\nI190205 17:01:18.920994 24607 storage/replica_command.go:244  [n3,s3,r196/3:/Table/61/2/\"{S\"/1631-V\"/1893}] initiating a split of this range at key /Table/61/2/\"S\"/4386 [r198] (manual)\nI190205 17:01:19.772860 24826 storage/replica_command.go:244  [n3,s3,r185/3:/Table/61/2/\"{M\"/4380-S\"/1631}] initiating a split of this range at key /Table/61/2/\"O\"/4174 [r199] (manual)\nI190205 17:01:19.915899 24858 storage/replica_command.go:244  [n3,s3,r197/3:/{Table/61/3/2\u2026-Max}] initiating a split of this range at key /Table/61/3/4236/\"Y\" [r200] (manual)\nI190205 17:01:20.578078 24969 storage/replica_command.go:244  [n2,s2,r190/2:/Table/61/{2/\"V\"/1\u2026-3/571/\"\u2026}] initiating a split of this range at key /Table/61/2/\"Z\"/1897 [r74] (manual)\nI190205 17:01:21.210366 25040 storage/replica_command.go:244  [n2,s2,r190/2:/Table/61/2/\"{V\"/1893-Z\"/1897}] initiating a split of this range at key /Table/61/2/\"Y\"/2624 [r75] (manual)\nI190205 17:01:21.842710 25099 storage/replica_command.go:244  [n3,s3,r195/3:/Table/61/3/{1017/\"\u2026-2777/\"\u2026}] initiating a split of this range at key /Table/61/3/2072/\"S\"/PrefixEnd [r201] (manual)\nI190205 17:01:22.152355 25166 storage/replica_command.go:244  [n3,s3,r195/3:/Table/61/3/{1017/\"\u2026-2072/\"\u2026}] initiating a split of this range at key /Table/61/3/1406/\"C\" [r203] (manual)\nI190205 17:01:22.342227 25099 storage/replica_command.go:244  [n3,s3,r201/3:/Table/61/3/2{072/\"S\u2026-777/\"V\"}] initiating a split of this range at key /Table/61/3/2504/\"I\" [r202] (manual); delayed split for 0.2s to avoid Raft snapshot\nI190205 17:01:23.053152 25266 storage/replica_command.go:244  [n3,s3,r197/3:/Table/61/3/{2777/\"\u2026-4236/\"\u2026}] initiating a split of this range at key /Table/61/3/3443/\"L\"/PrefixEnd [r204] (manual)\nI190205 17:01:23.154570 9106 server/status/runtime.go:464  [n1] runtime stats: 1.0 GiB RSS, 674 goroutines, 71 MiB/37 MiB/137 MiB GO alloc/idle/total, 194 MiB/232 MiB CGO alloc/total, 4614.4 CGO/sec, 142.0/14.0 %(u/s)time, 1.1 %gc (11x), 4.9 MiB/4.9 MiB (r/w)net\nI190205 17:01:23.458572 25296 storage/replica_command.go:244  [n3,s3,r204/3:/Table/61/3/{3443/\"\u2026-4236/\"\u2026}] initiating a split of this range at key /Table/61/3/3495/\"L\" [r205] (manual)\nI190205 17:01:23.574924 25363 storage/replica_command.go:244  [n3,s3,r204/3:/Table/61/3/{3443/\"\u2026-4236/\"\u2026}] initiating a split of this range at key /Table/61/3/3647/\"H\" [r206] (manual)\nI190205 17:01:23.920851 25363 storage/replica_command.go:244  [n3,s3,r205/3:/Table/61/3/{3495/\"\u2026-4236/\"\u2026}] initiating a split of this range at key /Table/61/3/3647/\"H\" [r207] (manual)\nI190205 17:01:24.325757 25422 storage/replica_command.go:244  [n3,s3,r200/3:/{Table/61/3/4\u2026-Max}] initiating a split of this range at key /Table/61/3/4902/\"O\"/PrefixEnd [r208] (manual)\nI190205 17:01:24.929581 25519 storage/replica_command.go:244  [n3,s3,r208/3:/{Table/61/3/4\u2026-Max}] initiating a split of this range at key /Table/62 [r209] (manual)\nI190205 17:01:25.279921 9663 server/status/runtime.go:464  [n2] runtime stats: 1.1 GiB RSS, 670 goroutines, 48 MiB/60 MiB/137 MiB GO alloc/idle/total, 185 MiB/224 MiB CGO alloc/total, 4301.9 CGO/sec, 142.7/14.2 %(u/s)time, 1.4 %gc (11x), 4.3 MiB/4.3 MiB (r/w)net\nI190205 17:01:25.882625 9890 server/status/runtime.go:464  [n3] runtime stats: 1.1 GiB RSS, 666 goroutines, 69 MiB/41 MiB/137 MiB GO alloc/idle/total, 185 MiB/224 MiB CGO alloc/total, 4247.8 CGO/sec, 141.6/14.8 %(u/s)time, 1.4 %gc (11x), 3.6 MiB/3.6 MiB (r/w)net\n        import_stmt_test.go:1180: job 4 did not match:\n            Description: \"IMPORT TABLE csv4.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0', 'nodelocal:///csv/data-1', 'nodelocal:///csv/data-2', 'nodelocal:///csv/data-3', 'nodelocal:///csv/data-4') WITH sstsize = '10K'\" != \"CREATE STATISTICS __auto__ FROM [53] AS OF SYSTEM TIME '-30s'\"\n\n\n\nTestImportCSVStmt/schema-in-file-explicit-gzip\n...ixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=18 KiB+18 KiB qps=0.00+0.00 --> 0.00qps) below threshold (size=36 KiB, qps=0.00))\nI190205 17:03:42.474702 9696 storage/store.go:2669  [n3,s3,r288/3:/Table/70/{2/\"Q\"/2\u2026-3/2079/\u2026}] removing replica r309/3\nI190205 17:03:42.485040 9600 storage/store.go:2669  [n2,s2,r288/2:/Table/70/{2/\"Q\"/2\u2026-3/2079/\u2026}] removing replica r309/2\nI190205 17:03:42.486567 9316 storage/store.go:2669  [n1,s1,r288/1:/Table/70/{2/\"Q\"/2\u2026-3/2079/\u2026}] removing replica r309/1\nI190205 17:03:42.712857 41223 storage/replica_command.go:383  [n2,merge,s2,r288/2:/Table/70/{2/\"Q\"/2\u2026-3/2745/\u2026}] initiating a merge of r270:/Table/70/3/{2745/\"P\"/PrefixEnd-3412/\"G\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=124 KiB+18 KiB qps=9.25+0.00 --> 9.25qps) below threshold (size=142 KiB, qps=9.25))\nI190205 17:03:43.118336 9608 storage/store.go:2669  [n2,s2,r288/2:/Table/70/{2/\"Q\"/2\u2026-3/2745/\u2026}] removing replica r270/2\nI190205 17:03:43.142516 9309 storage/store.go:2669  [n1,s1,r288/1:/Table/70/{2/\"Q\"/2\u2026-3/2745/\u2026}] removing replica r270/1\nI190205 17:03:43.151213 9907 storage/store.go:2669  [n3,s3,r288/3:/Table/70/{2/\"Q\"/2\u2026-3/2745/\u2026}] removing replica r270/3\nI190205 17:03:43.377117 41275 storage/replica_command.go:383  [n3,merge,s3,r314/3:/Table/70{-/1/741}] initiating a merge of r257:/Table/70/1/{741-1456} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=19 KiB+19 KiB qps=1.39+0.00 --> 1.39qps) below threshold (size=38 KiB, qps=1.39))\nI190205 17:03:43.387932 9106 server/status/runtime.go:464  [n1] runtime stats: 1.4 GiB RSS, 667 goroutines, 55 MiB/50 MiB/138 MiB GO alloc/idle/total, 266 MiB/304 MiB CGO alloc/total, 7642.1 CGO/sec, 138.4/10.8 %(u/s)time, 1.5 %gc (8x), 3.5 MiB/3.5 MiB (r/w)net\nI190205 17:03:43.422341 41210 storage/replica_command.go:383  [n2,merge,s2,r288/2:/Table/70/{2/\"Q\"/2\u2026-3/3412/\u2026}] initiating a merge of r303:/Table/70/3/{3412/\"G\"/PrefixEnd-4079/\"X\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=142 KiB+18 KiB qps=9.25+0.00 --> 9.25qps) below threshold (size=161 KiB, qps=9.25))\nI190205 17:03:43.990142 9881 storage/store.go:2669  [n3,s3,r314/3:/Table/70{-/1/741}] removing replica r257/3\nI190205 17:03:44.011569 9615 storage/store.go:2669  [n2,s2,r288/2:/Table/70/{2/\"Q\"/2\u2026-3/3412/\u2026}] removing replica r303/2\nI190205 17:03:44.014157 9315 storage/store.go:2669  [n1,s1,r314/1:/Table/70{-/1/741}] removing replica r257/1\nI190205 17:03:44.018869 9861 storage/store.go:2669  [n3,s3,r288/3:/Table/70/{2/\"Q\"/2\u2026-3/3412/\u2026}] removing replica r303/3\nI190205 17:03:44.027402 9314 storage/store.go:2669  [n1,s1,r288/1:/Table/70/{2/\"Q\"/2\u2026-3/3412/\u2026}] removing replica r303/1\nI190205 17:03:44.049534 9598 storage/store.go:2669  [n2,s2,r314/2:/Table/70{-/1/741}] removing replica r257/2\nI190205 17:03:44.298210 41360 storage/replica_command.go:383  [n2,merge,s2,r288/2:/Table/70/{2/\"Q\"/2\u2026-3/4079/\u2026}] initiating a merge of r307:/Table/7{0/3/4079/\"X\"/PrefixEnd-1} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=2] into this range (lhs+rhs has (size=161 KiB+25 KiB qps=11.25+0.00 --> 11.25qps) below threshold (size=186 KiB, qps=11.25))\nI190205 17:03:44.536060 41344 storage/replica_command.go:383  [n3,merge,s3,r307/3:/Table/7{0/3/4079\u2026-1}] initiating a merge of r312:/Table/7{1-2/1/741} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=25 KiB+19 KiB qps=0.00+2.95 --> 2.95qps) below threshold (size=44 KiB, qps=2.95))\n        import_stmt_test.go:1180: job 10 did not match:\n            Description: \"IMPORT TABLE csv10.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:////csv/data-0.gz', 'nodelocal:////csv/data-1.gz', 'nodelocal:////csv/data-2.gz', 'nodelocal:////csv/data-3.gz', 'nodelocal:////csv/data-4.gz') WITH decompress = 'gzip'\" != \"CREATE STATISTICS __auto__ FROM [59] AS OF SYSTEM TIME '-30s'\"\n\n\n\nTestImportCSVStmt/schema-in-file-implicit-gzip\n...d.go:244  [n3,s3,r398/3:/{Table/76/3/2\u2026-Max}] initiating a split of this range at key /Table/76/3/3640/\"A\"/PrefixEnd [r399] (manual)\nI190205 17:04:32.744830 9195 storage/store.go:2669  [n1,s1,r371/1:/Table/74/3/2{671/\"T\u2026-953/\"P\"}] removing replica r374/1\nI190205 17:04:32.783469 47164 storage/replica_command.go:383  [n3,merge,s3,r371/3:/Table/74/3/{2671/\"\u2026-3619/\"\u2026}] initiating a merge of r378:/Table/74/3/{3619/\"F\"/PrefixEnd-4286/\"W\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=26 KiB+18 KiB qps=4.79+0.00 --> 4.79qps) below threshold (size=44 KiB, qps=4.79))\nI190205 17:04:33.417365 9603 storage/store.go:2669  [n2,s2,r371/2:/Table/74/3/{2671/\"\u2026-3619/\"\u2026}] removing replica r378/2\nI190205 17:04:33.421176 9685 storage/store.go:2669  [n3,s3,r371/3:/Table/74/3/{2671/\"\u2026-3619/\"\u2026}] removing replica r378/3\nI190205 17:04:33.452997 9316 storage/store.go:2669  [n1,s1,r371/1:/Table/74/3/{2671/\"\u2026-3619/\"\u2026}] removing replica r378/1\nI190205 17:04:33.470483 9106 server/status/runtime.go:464  [n1] runtime stats: 1.5 GiB RSS, 674 goroutines, 79 MiB/28 MiB/138 MiB GO alloc/idle/total, 294 MiB/338 MiB CGO alloc/total, 6394.7 CGO/sec, 150.4/12.3 %(u/s)time, 1.3 %gc (9x), 3.5 MiB/3.5 MiB (r/w)net\nI190205 17:04:33.472594 46459 storage/replica_command.go:244  [n3,s3,r399/3:/{Table/76/3/3\u2026-Max}] initiating a split of this range at key /Table/76/3/4307/\"R\"/PrefixEnd [r400] (manual)\nI190205 17:04:33.873510 47382 storage/replica_command.go:383  [n3,merge,s3,r371/3:/Table/74/3/{2671/\"\u2026-4286/\"\u2026}] initiating a merge of r380:/Table/74/3/4{286/\"W\"/PrefixEnd-953/\"N\"/PrefixEnd} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=44 KiB+18 KiB qps=8.89+0.00 --> 8.89qps) below threshold (size=62 KiB, qps=8.89))\nI190205 17:04:34.023547 46459 storage/replica_command.go:244  [n3,s3,r400/3:/{Table/76/3/4\u2026-Max}] initiating a split of this range at key /Table/76/3/4974/\"I\"/PrefixEnd [r401] (manual); delayed split for 0.2s to avoid Raft snapshot\nI190205 17:04:34.094032 47406 storage/replica_command.go:383  [n2,merge,s2,r380/2:/Table/74/3/4{286/\"W\u2026-953/\"N\u2026}] initiating a merge of r381:/Table/7{4/3/4953/\"N\"/PrefixEnd-5} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=18 KiB+1.3 KiB qps=0.00+0.00 --> 0.00qps) below threshold (size=20 KiB, qps=0.00))\nI190205 17:04:34.110289 9898 storage/store.go:2669  [n3,s3,r371/3:/Table/74/3/{2671/\"\u2026-4286/\"\u2026}] removing replica r380/3\nI190205 17:04:34.117161 9274 storage/store.go:2669  [n1,s1,r371/1:/Table/74/3/{2671/\"\u2026-4286/\"\u2026}] removing replica r380/1\nI190205 17:04:34.123252 9464 storage/store.go:2669  [n2,s2,r371/2:/Table/74/3/{2671/\"\u2026-4286/\"\u2026}] removing replica r380/2\nI190205 17:04:34.428611 46459 storage/replica_command.go:244  [n3,s3,r401/3:/{Table/76/3/4\u2026-Max}] initiating a split of this range at key /Table/77 [r402] (manual)\nI190205 17:04:34.799078 47480 storage/replica_command.go:383  [n3,merge,s3,r365/3:/Table/74/2/\"{C\"/2083-O\"/586}] initiating a merge of r362:/Table/74/2/\"{O\"/586-R\"/3008} [(n1,s1):1, (n2,s2):2, (n3,s3):3, next=4, gen=1] into this range (lhs+rhs has (size=61 KiB+18 KiB qps=0.00+0.00 --> 0.00qps) below threshold (size=80 KiB, qps=0.00))\nI190205 17:04:34.999701 9332 storage/store.go:2669  [n1,s1,r365/1:/Table/74/2/\"{C\"/2083-O\"/586}] removing replica r362/1\nI190205 17:04:35.002212 9693 storage/store.go:2669  [n3,s3,r365/3:/Table/74/2/\"{C\"/2083-O\"/586}] removing replica r362/3\nI190205 17:04:35.007248 9635 storage/store.go:2669  [n2,s2,r365/2:/Table/74/2/\"{C\"/2083-O\"/586}] removing replica r362/2\n        import_stmt_test.go:1180: job 12 did not match:\n            Description: \"IMPORT TABLE csv12.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:////csv/data-0.gz', 'nodelocal:////csv/data-1.gz', 'nodelocal:////csv/data-2.gz', 'nodelocal:////csv/data-3.gz', 'nodelocal:////csv/data-4.gz')\" != \"CREATE STATISTICS __auto__ FROM [61] AS OF SYSTEM TIME '-30s'\"\n\n\n\nTestImportCSVStmt/schema-in-query-transform-only\n..., 660 goroutines, 41 MiB/58 MiB/137 MiB GO alloc/idle/total, 59 MiB/81 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (75x), 60 MiB/60 MiB (r/w)net\nW190205 16:56:36.557631 8073 server/node.go:869  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:queue.replicate.process.failure Value:21 XXX_NoUnkeyedLiteral:{} XXX_sizecache:0}] XXX_NoUnkeyedLiteral:{} XXX_sizecache:0}\nI190205 16:56:36.677400 8336 server/status/runtime.go:464  [n2] runtime stats: 216 MiB RSS, 660 goroutines, 48 MiB/51 MiB/137 MiB GO alloc/idle/total, 59 MiB/81 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (75x), 62 MiB/62 MiB (r/w)net\nI190205 16:56:36.733578 8603 server/status/runtime.go:464  [n3] runtime stats: 216 MiB RSS, 660 goroutines, 0 B/0 B/0 B GO alloc/idle/total, 59 MiB/81 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (75x), 63 MiB/63 MiB (r/w)net\n------- Stdout: -------\nI190205 17:01:26.640192 25729 storage/replica_command.go:244  [n2,split,s2,r140/2:/Table/{59/1/2293-61/1/741}] initiating a split of this range at key /Table/61 [r76] (zone config)\nI190205 17:01:26.668177 10466 sql/event_log.go:135  [n1,client=127.0.0.1:35488,user=root] Event: \"create_database\", target: 62, info: {DatabaseName:csv5 Statement:CREATE DATABASE csv5 User:root}\nI190205 17:01:32.551750 9657 storage/compactor/compactor.go:329  [n2,s2,compactor] purging suggested compaction for range /Table/59/2/\"O\"/2926 - /Table/59/2/\"T\"/1424 that contains live data\nI190205 17:01:32.552120 9657 storage/compactor/compactor.go:329  [n2,s2,compactor] purging suggested compaction for range /Table/59/2/\"T\"/1424 - /Table/61/1/741 that contains live data\nI190205 17:01:32.556241 9348 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /Table/59/2/\"O\"/2926 - /Table/59/2/\"T\"/1424 that contains live data\nI190205 17:01:32.556650 9348 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /Table/59/2/\"T\"/1424 - /Table/61/1/741 that contains live data\nI190205 17:01:32.567219 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/59/2/\"O\"/2926 - /Table/59/2/\"T\"/1424 that contains live data\nI190205 17:01:32.567662 9922 storage/compactor/compactor.go:329  [n3,s3,compactor] purging suggested compaction for range /Table/59/2/\"T\"/1424 - /Table/61/1/741 that contains live data\nI190205 17:01:33.159161 9106 server/status/runtime.go:464  [n1] runtime stats: 1.1 GiB RSS, 704 goroutines, 72 MiB/37 MiB/137 MiB GO alloc/idle/total, 204 MiB/243 MiB CGO alloc/total, 2833.3 CGO/sec, 140.1/14.2 %(u/s)time, 1.1 %gc (11x), 3.7 MiB/3.7 MiB (r/w)net\nI190205 17:01:35.284581 9663 server/status/runtime.go:464  [n2] runtime stats: 1.1 GiB RSS, 681 goroutines, 54 MiB/53 MiB/137 MiB GO alloc/idle/total, 195 MiB/235 MiB CGO alloc/total, 4821.5 CGO/sec, 136.6/13.3 %(u/s)time, 1.1 %gc (10x), 4.0 MiB/4.0 MiB (r/w)net\nI190205 17:01:35.891913 9890 server/status/runtime.go:464  [n3] runtime stats: 1.1 GiB RSS, 664 goroutines, 57 MiB/51 MiB/137 MiB GO alloc/idle/total, 186 MiB/226 MiB CGO alloc/total, 5175.5 CGO/sec, 138.2/12.1 %(u/s)time, 1.1 %gc (11x), 4.1 MiB/4.1 MiB (r/w)net\n        import_stmt_test.go:1180: job 5 did not match:\n            Description: \"IMPORT TABLE \\\"\\\".\\\"\\\".t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0-opts', 'nodelocal:///csv/data-1-opts', 'nodelocal:///csv/data-2-opts', 'nodelocal:///csv/data-3-opts', 'nodelocal:///csv/data-4-opts') WITH comment = '#', delimiter = '|', \\\"nullif\\\" = '', skip = '2', transform = 'nodelocal:///5'\" != \"IMPORT TABLE csv3.public.t (a INT8 PRIMARY KEY, b STRING, INDEX (b), INDEX (a, b)) CSV DATA ('nodelocal:///csv/data-0-opts', 'nodelocal:///csv/data-1-opts', 'nodelocal:///csv/data-2-opts', 'nodelocal:///csv/data-3-opts', 'nodelocal:///csv/data-4-opts') WITH comment = '#', delimiter = '|', \\\"nullif\\\" = '', skip = '2'\"\n\n\n\n\n"], "labels": ["O-robot", "C-test-failure"]}
{"project": "matomo-org_matomo", "title": "Breadcrump bar looks a lot like a text input", "description": "Especially when there's just one level, as shown in the screenshot. I'd suggest trying to remove the gray outline. ", "code": [], "labels": ["R: worksforme", "T: Bug"]}
{"project": "dotnet_coreclr", "title": "Azure Sphere Support", "description": "Understanding Azure Sphere has not even been released yet, I was wondering if .NET Core will be supported? ", "code": [], "labels": ["area-Meta", "question"]}
{"project": "pmmp_PocketMine-MP", "title": "Detected spam", "description": "SO reduced this issue because it is spam and Fe2+ oxidized this issue to base64 because it is a 24-hour no-life disrespectful watcher of issues.\nOriginal content: <CODE> ", "code": ["VGl0bGU6IERldGVjdGVkIHNwYW0KQm9keTogWzE5OjQ3OjMyXSBbU2VydmVyIHRocmVhZC9JTkZP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\nZSBhbHJlYWR5IHJlcG9ydGVkLCBidXQgaWYgdGhleSB3ZXJlIHNvcnJ5Lg==\n\n"], "labels": ["Resolution: Invalid"]}
{"project": "apache_incubator-echarts", "title": "bug(candlestick): data not render after NaN", "description": "4.2.1 <URL>,js,output Use the candlestick of offical example\n\u4f7f\u7528\u4e86\u5b98\u65b9\u7684\u80a1\u7968\u793a\u4f8b\u56fe\nSet the number from 800th to 820th to be NaN\n\u7b2c800\u5230820\u4e2a\u6570\u636e\u7684\u6570\u503c\u8bbe\u7f6e\u4e3aNaN\nThen the previous 800 numbers can be rendered, while the data after 820th cannot be rendered, but the tooltip is available.\n\u6b64\u65f6\u53ea\u663e\u793a\u524d800\u4e2a\u6570\u636e\u53ef\u4ee5\u7ed8\u5236\u56fe\u5f62\uff0c820\u4e2a\u6570\u636e\u4e4b\u540e\u7684\u56fe\u5f62\u6ca1\u6709\u7ed8\u5236\uff0c\u4f46tooltip\u53ef\u89c1\u3002 Data is visible.\nk\u7ebf\u56fe\u5e94\u8be5\u8981\u53ef\u89c1 The later half part of the data is not visible.\n\u540e\u534a\u622ak\u7ebf\u56fe\u4e0d\u53ef\u89c1 ", "code": [], "labels": ["bug"]}
{"project": "facebook_jest", "title": "Bring back typeahead as a watch-mode plugin", "description": "I tried to reinstall jest many times, tried to run it in no-cache mode. I'm running jest:\njest --watch ./assets --notify Config: <CODE> <CODE> And no any results are displayed, unlike it was using version 20. But if I push enter the pattern will be applied and files will be found successfully. ", "code": ["  \"jest\": {\n    \"setupTestFrameworkScriptFile\": \"<rootDir>/assets/tests/setup.js\",\n    \"moduleNameMapper\": {\n      \"\\\\.(css|less|scss)$\": \"<rootDir>/assets/mocks/styleMock.js\",\n      \"^((?:libs|stores|components|tests).*)$\": \"<rootDir>/assets/$1\",\n      \"^react-pdf/build/entry.webpack$\": \"<rootDir>/node_modules/react-pdf\"\n    }\n  },\n", "Active Filters: filename /./assets/\n\nPattern Mode Usage\n \u203a Press Esc to exit pattern mode.\n \u203a Press Enter to filter by a filenames regex pattern.\n\n pattern \u203a *test.jsx\n"], "labels": ["Help Wanted"]}
{"project": "python_mypy", "title": "Python version-conditional import inside function does not respect test", "description": "This is OK at the top level: This causes the error as noted in the comment: ", "code": [], "labels": ["bug"]}
{"project": "PapirusDevelopmentTeam_papirus-icon-theme", "title": "\u0421\u0442\u0438\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0430\u043f\u043e\u043a.", "description": "\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e \u0442\u0435\u043c\u0443 \u0438\u043a\u043e\u043d\u043e\u043a ePapirus, \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f, (\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u043b \u0441 PPA \u0438 \u0447\u0435\u0440\u0435\u0437 wget), \u0438\u043a\u043e\u043d\u043a\u0438 \u043f\u0430\u043f\u043e\u043a \u0441\u0442\u0430\u043b\u0438 \u0432\u043e\u0442 \u0442\u0430\u043a\u0438\u043c\u0438:\n \u041f\u0440\u043e\u0431\u043e\u0432\u0430\u043b \u043c\u0435\u043d\u044f\u0442\u044c \u0442\u0435\u043c\u044b \u0438\u043a\u043e\u043d\u043e\u043a \u043d\u0430 \u0434\u0440\u0443\u0433\u0438\u0435, \u043d\u043e \u043f\u0430\u043f\u043a\u0438 \u043f\u043e\u0447\u0435\u043c\u0443-\u0442\u043e \u043d\u0435 \u043c\u0435\u043d\u044f\u044e\u0442\u0441\u044f. \u0422\u0430\u043a \u0438 \u0434\u043e\u043b\u0436\u043d\u043e \u0431\u044b\u0442\u044c \u043f\u043e\u0441\u043b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f? \u041c\u043e\u0436\u043d\u043e \u0438\u0445 \u043a\u0430\u043a-\u0442\u043e \u0432\u0435\u0440\u043d\u0443\u0442\u044c \u043d\u0430 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0435, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0431\u044b\u043b\u0438 \u0432 ePapirus? ", "code": [], "labels": ["question"]}
{"project": "EFForg_https-everywhere", "title": "[Request] New Ruleset: CommunityCrimeMap.com", "description": "Type: new ruleset Domain: communitycrimemap.com HTTPS is available but not enforced / redirected. ", "code": [], "labels": ["new-ruleset", "good first issue"]}
{"project": "laurent22_joplin", "title": "Cannot Type Chinese characters directly within App", "description": "Cannot type Chinese characters directly within the app on iOS but I can copy from somewhere else. ", "code": [], "labels": ["bug"]}
{"project": "grpc_grpc", "title": "RuntimeError for `_reconnect_test` Python unit test with Bazel", "description": "gRPC version: 1.15.0.dev0 (Built from source)\nLanguage: Python Operating System: Ubuntu\nVersion: 16.04 Xenial\nKernel: Kernel: x86_64 Linux 4.13.0-1013-gcp Python version: 2.7.12\nBazel version: 0.15.0 #16335 introduces Bazel targets for grpcio Python unit tests. One of the tests is //src/python/grpcio_tests/tests/unit:_reconnect_test. For the test to pass, since it passes in the current build setup. Ran into an error: RuntimeError: maximum recursion depth exceeded while calling a Python object. ", "code": [], "labels": ["lang/Python", "infra/BUILDPONY", "kind/enhancement", "priority/P2"]}
{"project": "Tribler_tribler", "title": "Error in API tests", "description": "<CODE> Reference: <URL>*view*/ ", "code": ["Testing whether the API returns a formatted 500 error if ValueError is raised ... Unhandled Error\nTraceback (most recent call last):\n  File \"C:\\Python27\\lib\\threading.py\", line 763, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"C:\\workspace\\jenkins\\workspace\\GH_Tribler_PR_tests_win64\\tribler\\Tribler\\Core\\Utilities\\twisted_thread.py\", line 55, in _reactor_runner\n    reactor.run(installSignalHandlers=False)\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\base.py\", line 1194, in run\n    self.mainLoop()\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\base.py\", line 1203, in mainLoop\n    self.runUntilCurrent()\n--- <exception caught here> ---\n  File \"C:\\Python27\\lib\\site-packages\\twisted\\internet\\base.py\", line 825, in runUntilCurrent\n    call.func(*call.args, **call.kw)\n  File \"C:\\workspace\\jenkins\\workspace\\GH_Tribler_PR_tests_win64\\tribler\\Tribler\\Core\\APIImplementation\\threadpoolmanager.py\", line 50, in caller\n    fun(*args, **kwargs)\n  File \"C:\\workspace\\jenkins\\workspace\\GH_Tribler_PR_tests_win64\\tribler\\Tribler\\Core\\Libtorrent\\LibtorrentMgr.py\", line 482, in do_dht_check\n    lt_session = self.get_session()\n  File \"C:\\workspace\\jenkins\\workspace\\GH_Tribler_PR_tests_win64\\tribler\\Tribler\\Core\\Libtorrent\\LibtorrentMgr.py\", line 186, in get_session\n    if hops not in self.ltsessions:\nexceptions.TypeError: argument of type 'NoneType' is not iterable\n"], "labels": ["bug"]}
{"project": "askmike_gekko", "title": "error in IRC plugin", "description": "I'm getting the following error when trying to enable the IRC plugin (node v7.5.0, npm 4.1.2, Linux x86_64) <CODE> ", "code": ["TypeError: The super constructor to \"inherits\" must not be null or undefined\n   at Object.exports.inherits (util.js:962:11)\n   at Object. (/user/gitrepos/gekko/node_modules/irc/lib/irc.js:545:17)\n   at Module._compile (module.js:571:32)\n   at Object.Module._extensions..js (module.js:580:10)\n   at Module.load (module.js:488:32)\n   at tryModuleLoad (module.js:447:12)\n   at Function.Module._load (module.js:439:3)\n   at Module.require (module.js:498:17)\n   at require (internal/module.js:20:19)\n   at /user/gitrepos/gekko/core/pluginUtil.js:28:19 '\\n\\n'\n"], "labels": ["bug"]}
{"project": "golang_go", "title": "x/tools/cmd/gopls: fails on filepaths with spaces", "description": "golang.org/x/tools/gopls v0.1.5\ngolang.org/x/tools/gopls@v0.1.5 h1:bfyquCQT+XBur/qfeq64IXf1fv54Kh4y6/tDWA31M3g=\ngolang.org/x/sync@v0.0.0-20190423024810-112230192c58 h1:8gQV6CLnAEikrhgkHFbMAEhagSSnXWGV915qUMm9mrU=\ngolang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2 h1:4m1a+ssoIi4N/776T3Dc79eRjDc5sEhMQXFAKoO3TM8=\ngolang.org/x/xerrors@v0.0.0-20190717185122-a985d3407aa7 h1:9zdDQZ7Thm29KFXgAX/+yaf3eVbP7djjWp/dXAppNCc= go version go1.13 darwin/amd64 GO111MODULE=\"\"\nGOARCH=\"amd64\"\nGOBIN=\"\"\nGOCACHE=\"/Users/fabrizio/Library/Caches/go-build\"\nGOENV=\"/Users/fabrizio/Library/Application Support/go/env\"\nGOEXE=\"\"\nGOFLAGS=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"darwin\"\nGONOPROXY=\"\"\nGONOSUMDB=\"\"\nGOOS=\"darwin\"\nGOPATH=\"/Users/fabrizio/go\"\nGOPRIVATE=\"\"\nGOPROXY=\"<URL>,direct\"\nGOROOT=\"/usr/local/go\"\nGOSUMDB=\"sum.golang.org\"\nGOTMPDIR=\"\"\nGOTOOLDIR=\"/usr/local/go/pkg/tool/darwin_amd64\"\nGCCGO=\"gccgo\"\nAR=\"ar\"\nCC=\"clang\"\nCXX=\"clang++\"\nCGO_ENABLED=\"1\"\nGOMOD=\"/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/go.mod\"\nCGO_CFLAGS=\"-g -O2\"\nCGO_CPPFLAGS=\"\"\nCGO_CXXFLAGS=\"-g -O2\"\nCGO_FFLAGS=\"-g -O2\"\nCGO_LDFLAGS=\"-g -O2\"\nPKG_CONFIG=\"pkg-config\"\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/t3/bmtk93rn4_d9t8ybmnrb5qwm0000gq/T/go-build515512987=/tmp/go-build -gno-record-gcc-switches -fno-common\" [Info  - 1:16:04 PM] 2019/09/12 13:16:04 24.638118ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"env\" \"GOMOD\", stderr: <<>> [Info  - 1:16:04 PM] 2019/09/12 13:16:04 60.026984ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"list\" \"-e\" \"-json\" \"-compiled=true\" \"-test=true\" \"-export=false\" \"-deps=true\" \"-find=false\" \"--\" \"builtin\", stderr: <<>> [Info  - 1:16:04 PM] 2019/09/12 13:16:04 85.624693ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"list\" \"-m\" \"-json\" \"all\", stderr: <<>> [Info  - 1:16:04 PM] 2019/09/12 13:16:04 27.643196ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"env\" \"GOMOD\", stderr: <<>> [Info  - 1:16:04 PM] 2019/09/12 13:16:04 102.18129ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"list\" \"-m\" \"-json\" \"all\", stderr: <<>> [Info  - 1:16:04 PM] 2019/09/12 13:16:04 343.526148ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"list\" \"-e\" \"-json\" \"-compiled=true\" \"-test=true\" \"-export=false\" \"-deps=true\" \"-find=false\" \"--\" \"/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3\", stderr: <<>> [Info  - 1:16:04 PM] 2019/09/12 13:16:04 go/packages.Load\npackages = 1\n[Info  - 1:16:04 PM] 2019/09/12 13:16:04 go/packages.Load\npackage = github.com/fblanco/gcs_to_gbq_V3\nfiles = [/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/pull.go /Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/receiver_queue.go /Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/scheduler.go /Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/schema.go]\n[Info  - 1:16:04 PM] 2019/09/12 13:16:04 22.558159ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"env\" \"GOMOD\", stderr: <<>> [Info  - 1:16:04 PM] 2019/09/12 13:16:04 60.059133ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"list\" \"-m\" \"-json\" \"all\", stderr: <<>> [Info  - 1:16:05 PM] 2019/09/12 13:16:05 372.406579ms for GOROOT=/usr/local/go GOPATH=/Users/fabrizio/go GO111MODULE= PWD=/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3 go \"list\" \"-e\" \"-json\" \"-compiled=true\" \"-test=true\" \"-export=false\" \"-deps=true\" \"-find=false\" \"--\" \"/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3\", stderr: <<>> [Info  - 1:16:05 PM] 2019/09/12 13:16:05 go/packages.Load\npackages = 1\n[Info  - 1:16:05 PM] 2019/09/12 13:16:05 go/packages.Load\npackage = github.com/fblanco/gcs_to_gbq_V3\nfiles = [/Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/pull.go /Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/receiver_queue.go /Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/scheduler.go /Users/fabrizio/Library/Mobile Documents/comappleCloudDocs/Code/fblanco/gcs_to_gbq_V3/schema.go]\n[Error - 1:16:05 PM] Request textDocument/documentSymbol failed.\nMessage: method \"textDocument/documentSymbol\" did not reply\nCode: -32603\npanic: runtime error: invalid memory address or nil pointer dereference\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x13b34f6] goroutine 7 [running]:\ngolang.org/x/tools/internal/lsp/source.pkgToMapper(0x18112c0, 0xc000298000, 0x181c260, 0xc0002d0000, 0x181c1c0, 0xc0001892c0, 0xc009204380, 0x68, 0x0, 0xc000418077, ...)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/source/util.go:126 +0x116\ngolang.org/x/tools/internal/lsp/source.cachedFileToMapper(0x18112c0, 0xc000298000, 0x181c260, 0xc0002d0000, 0xc009204380, 0x68, 0x19, 0x1, 0x1, 0x203002)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/source/util.go:112 +0x19e\ngolang.org/x/tools/internal/lsp/source.posToRange(0x18112c0, 0xc000298000, 0x181c260, 0xc0002d0000, 0x6bc9, 0x6bec, 0x0, 0x0, 0x0, 0x0, ...)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/source/util.go:226 +0x1a6\ngolang.org/x/tools/internal/lsp/source.nodeToMappedRange(0x18112c0, 0xc000298000, 0x181c260, 0xc0002d0000, 0x1807180, 0xc000a100c0, 0x0, 0x0, 0x0, 0x0, ...)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/source/util.go:215 +0xd8\ngolang.org/x/tools/internal/lsp/source.nodeToProtocolRange(0x18112c0, 0xc000298000, 0x181c260, 0xc0002d0000, 0x1807180, 0xc000a100c0, 0xc0002532c0, 0x100f9d6, 0x10138b2, 0xc0002532c0, ...)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/source/util.go:184 +0x81\ngolang.org/x/tools/internal/lsp/source.varSymbol(0x18112c0, 0xc000298000, 0x181c260, 0xc0002d0000, 0x1807180, 0xc000a100c0, 0xc0009c6380, 0x181cda0, 0xc009360780, 0xc00843db00, ...)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/source/symbols.go:278 +0x133\ngolang.org/x/tools/internal/lsp/source.DocumentSymbols(0x18112c0, 0xc000298000, 0x181c260, 0xc0002d0000, 0x181ac20, 0xc0004102d0, 0x0, 0x0, 0x0, 0x0, ...)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/source/symbols.go:66 +0x53d\ngolang.org/x/tools/internal/lsp.(*Server).documentSymbol(0xc000220600, 0x18112c0, 0xc0003c5710, 0xc00040d2c0, 0x0, 0x0, 0x0, 0x0, 0x0)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/symbols.go:26 +0x21a\ngolang.org/x/tools/internal/lsp.(*Server).DocumentSymbol(0xc000220600, 0x1811200, 0xc000031d80, 0xc00040d2c0, 0xc00040d2c0, 0x0, 0x0, 0x510dc00, 0x100)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/server.go:196 +0x4d\ngolang.org/x/tools/internal/lsp/protocol.serverHandler.Deliver(0x1822ec0, 0xc000220600, 0x1811200, 0xc000031d80, 0xc000031dc0, 0x0, 0xc0000b0001)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/lsp/protocol/tsserver.go:389 +0x3c4d\ngolang.org/x/tools/internal/jsonrpc2.(*Conn).Run.func1(0xc0000a44e0, 0xc000031dc0, 0xc000220660, 0x1811200, 0xc000031d80, 0x0, 0x0, 0xc000069d50)\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/jsonrpc2/jsonrpc2.go:370 +0x170\ncreated by golang.org/x/tools/internal/jsonrpc2.(*Conn).Run\n/Users/fabrizio/go/pkg/mod/golang.org/x/tools@v0.0.0-20190911225940-c7d52e45e2f2/internal/jsonrpc2/jsonrpc2.go:354 +0x86a\n[Error - 1:16:05 PM] Connection to server got closed. Server will not be restarted.\n[Error - 1:16:05 PM] Request textDocument/codeAction failed.\nError: Connection got disposed.\nat Object.dispose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/main.js:876:25)\nat Object.dispose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:57:35)\nat LanguageClient.handleConnectionClosed (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:2036:42)\nat LanguageClient.handleConnectionClosed (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/main.js:127:15)\nat closeHandler (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:2023:18)\nat CallbackList.invoke (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:62:39)\nat Emitter.fire (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:120:36)\nat closeHandler (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/main.js:226:26)\nat CallbackList.invoke (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:62:39)\nat Emitter.fire (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:120:36)\nat StreamMessageReader.fireClose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/messageReader.js:111:27)\nat Socket.listen.readable.on (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/messageReader.js:151:46)\nat Socket.emit (events.js:187:15)\nat Pipe.Socket._destroy._handle.close (net.js:606:12)\n[Error - 1:16:05 PM] Request textDocument/documentLink failed.\nError: Connection got disposed.\nat Object.dispose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/main.js:876:25)\nat Object.dispose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:57:35)\nat LanguageClient.handleConnectionClosed (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:2036:42)\nat LanguageClient.handleConnectionClosed (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/main.js:127:15)\nat closeHandler (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:2023:18)\nat CallbackList.invoke (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:62:39)\nat Emitter.fire (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:120:36)\nat closeHandler (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/main.js:226:26)\nat CallbackList.invoke (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:62:39)\nat Emitter.fire (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:120:36)\nat StreamMessageReader.fireClose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/messageReader.js:111:27)\nat Socket.listen.readable.on (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/messageReader.js:151:46)\nat Socket.emit (events.js:187:15)\nat Pipe.Socket._destroy._handle.close (net.js:606:12)\n[Error - 1:16:05 PM] Request textDocument/foldingRange failed.\nError: Connection got disposed.\nat Object.dispose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/main.js:876:25)\nat Object.dispose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:57:35)\nat LanguageClient.handleConnectionClosed (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:2036:42)\nat LanguageClient.handleConnectionClosed (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/main.js:127:15)\nat closeHandler (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-languageclient/lib/client.js:2023:18)\nat CallbackList.invoke (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:62:39)\nat Emitter.fire (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:120:36)\nat closeHandler (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/main.js:226:26)\nat CallbackList.invoke (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:62:39)\nat Emitter.fire (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/events.js:120:36)\nat StreamMessageReader.fireClose (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/messageReader.js:111:27)\nat Socket.listen.readable.on (/Users/fabrizio/.vscode/extensions/ms-vscode.go-0.11.4/node_modules/vscode-jsonrpc/lib/messageReader.js:151:46)\nat Socket.emit (events.js:187:15)\nat Pipe.Socket._destroy._handle.close (net.js:606:12) ", "code": [], "labels": ["Tools", "gopls"]}
{"project": "sourcegraph_sourcegraph", "title": "\"No results\" appears at the bottom of every search on sourcegraph.com", "description": " ", "code": [], "labels": ["search", "bug", "web"]}
{"project": "eslint_eslint", "title": "Proposal: Simplified configuration", "description": "Problem: We're getting more complaints about the severity code (0, 1, 2) in configuration files. While I personally don't see this as a big problem, and people do seem to get used to it, it's still confusing to new users. Proposal: We augment configuration with some additional options. In addition to rules, we introduce warnings and errors, so you can place a rule directly into the group you want it in. Usage would entail: What it would look like: We would also then have to introduce some new inline comments, like: Implementation: In order to keep things simple, we could just augment configurations as they come, pulling out errors and warnings, converting their options to an array and prepending the correct severity code. Basically, preprocess new-style configs into old-style configs and then let the old-style configs flow through the rest of ESLint. Points to investigate: Want to back this issue? Post a bounty on it! We accept bounties via Bountysource.\n ", "code": [], "labels": ["archived due to age", "accepted", "core", "enhancement"]}
{"project": "lovell_sharp", "title": "calling overlayWith on a jpeg with an svg segfaulting (docker alpine image)", "description": "I'm having issues with a particular operation in my operation pipeline, namely overlayWith. My sequence of operations looks something like this: On my computer it all works (Mac OS X). My issue is using one of the many variations of the sharp alpine distro (I'm following this one). As I need to do a bit more, I've copied and modified the entries in the Dockerfile to suit my needs, and the end result looks like this: <CODE> After the lengthy process of building the image and running my program, it segfaults. I've isolated it to the overlayWith call (if I comment it, it works). I'm aware that this might be an issue with libvips / alpine / smth else, so I'd appreciate at the very least some help in redirecting me to the proper person who can help me (maybe those maintainers are also maintaining sharp?). ", "code": ["FROM node:8.2-alpine\n...\nENV VIPS_VERSION 8.5.7\nENV SHARP_VERSION 0.18.2\nENV GYP_VERSION 3.6.2\n\n# Compile Vips and Sharp\nRUN\tapk --no-cache add libpng librsvg libgsf libjpeg-turbo musl \\\n\t\t&& apk --no-cache add --virtual .build-dependencies \\\n\t\t\t g++ libc-dev make python curl tar gtk-doc glib-dev \\\n\t\t\t libpng-dev libjpeg-turbo-dev librsvg-dev \\\n\t\t\t gobject-introspection expat-dev giflib-dev \\\n  \t&& mkdir -p /usr/src \\\n  \t&& curl -o vips.tar.gz -SL https://github.com/jcupitt/libvips/releases/download/v${VIPS_VERSION}/vips-${VIPS_VERSION}.tar.gz \\\n\t\t&& tar -xzf vips.tar.gz -C /usr/src/ \\\n\t\t&& rm vips.tar.gz \\\n\t\t&& chown -R nobody.nobody /usr/src/vips-${VIPS_VERSION} \\\n\t\t&& cd /usr/src/vips-${VIPS_VERSION} \\\n\t\t&& ./configure \\\n\t\t&& make \\\n\t\t&& make install \\\n\t\t&& cd / \\\n\t\t&& rm -r /usr/src/vips-${VIPS_VERSION} \\\n\t\t&& yarn add global node-gyp@${GYP_VERSION} sharp@${SHARP_VERSION} \\\n\t\t&& apk del .build-dependencies \n...\n"], "labels": ["question"]}
{"project": "frappe_erpnext", "title": "Integration Service menu does multiple buttons", "description": "Selecting and switching to available integrations such as PayPal, Dropbox, LDAP renders/accumulates multiple buttons regardless of what is actually selected.\n Installed Apps\nERPNext: v7.1.25\nFrappe Framework: v7.1.25 ", "code": [], "labels": ["ux", "bug"]}
{"project": "stackblitz_core", "title": "Install packages that are hosted on github", "description": "I want to use the nightly build of @angular/flex-layout. Normally I can do one of these: None of these seem to work in the StackBlizt IDE.  ", "code": [], "labels": ["enhancement"]}
{"project": "wenzhixin_bootstrap-table", "title": "updateCell\u4f1a\u5bfc\u81f4\u6574\u4e2a\u5217\u8868\u6570\u636e\u4ece\u65b0\u52a0\u8f7d\uff0c\u90a3\u5176\u4ed6\u884c\u7684formatter\u4e5f\u90fd\u6267\u884c\u4e00\u904d\uff0c\u5408\u7406\u5417", "description": "updateCell updateRow \u4e0d\u80fd\u53ea\u5237\u65b0\u5f53\u524did\u6216\u8005\u5f53\u524d\u884c\u7801\uff0c\u9700\u8981\u6574\u4e2a\u5217\u8868\u6570\u636e\u90fd\u91cd\u65b0init\uff1f ", "code": [], "labels": ["duplicate"]}
{"project": "red_red", "title": "Console crash if break is evaluated on foreach-face loop", "description": "Describe the bug\nThe Red console crashes if BREAK is evaluated inside a FOREACH-FACE loop To reproduce\nSteps to reproduce the behavior: Copy this code on console: <CODE> Expected behavior\nThe loop ends and return to the console prompt. Platform version (please complete the following information)\nTested on W10 Red 0.6.4 for Windows built 15-Aug-2019/19:02:53+02:00 commit #b255dee ", "code": ["l: layout [a: area 100x100 red b: box 100x100 green c: field 100x100 blue]\nforeach-face l [if face/size/x = 100 [break]]\n"], "labels": ["status.tested", "status.built", "type.bug"]}
{"project": "joomla_joomla-cms", "title": "Captcha - reCaptcha - Friendly Error Message & Retaining Form Field Values on Contact Form after unsuccessful reCAPTCHA V2 submission", "description": "When using a contact form and reCAPTCHA utilizing Joomla's native Contact component and Captcha - ReCaptcha plugin (set to version 2.0) When the user fails to check the \"I'm not a robot\" checkbox, two undesirable things happen from a 'user experience' point-of-view. Ideally, the Joomla site should provide a friendly descriptive error message, such as \"reCAPTHA submission failed\"  and retain the entered form field data. Unfriendly, non-descript error message \"Error: Empty solution not allowed.\" Information in contact form fields cleared. LAMP on HostGator running PHP7 Joomla 3.8.1 ", "code": [], "labels": ["No Code Attached Yet"]}
{"project": "dotnet_coreclr", "title": "Test failure: JIT.HardwareIntrinsics.X86.ScalarTernOpBinResTest__MultiplyNoFlagsUInt32.RunBasicScenario_UnsafeRead", "description": "<CODE> ", "code": ["System.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\n   at JIT.HardwareIntrinsics.X86.ScalarTernOpBinResTest__MultiplyNoFlagsUInt32.RunBasicScenario_UnsafeRead()\n   at JIT.HardwareIntrinsics.X86.Program.MultiplyNoFlagsUInt32BinRes()\n   at JIT.HardwareIntrinsics.X86.Program.Main(System.String[])\n\n\nReturn code:      1\nRaw output file:      C:\\\\dotnetbuild\\\\work\\\\9c2346ee-a8c9-488f-bc5f-9cf2ab13fd35\\\\Work\\\\4cd95052-0f4e-4bba-837b-b9aa42b944e9\\\\Exec\\\\Reports\\\\JIT.HardwareIntrinsics\\\\X86\\\\Bmi2\\\\Bmi2_r\\\\Bmi2_r.output.txt\nRaw output:\nBEGIN EXECUTION\n \\\"C:\\\\dotnetbuild\\\\work\\\\9c2346ee-a8c9-488f-bc5f-9cf2ab13fd35\\\\Payload\\\\corerun.exe\\\" Bmi2_r.exe \nSupported ISAs:\n  AES:       True\n  AVX:       True\n  AVX2:      True\n  BMI1:      True\n  BMI2:      True\n  FMA:       True\n  LZCNT:     True\n  PCLMULQDQ: True\n  POPCNT:    True\n  SSE:       True\n  SSE2:      True\n  SSE3:      True\n  SSE4.1:    True\n  SSE4.2:    True\n  SSSE3:     True\n\nBeginning test case ParallelBitDeposit.UInt32 at 3/28/2019 10:56:01 PM\nRandom seed: 20010415; set environment variable CORECLR_SEED to this value to repro\n\nBeginning scenario: RunBasicScenario_UnsafeRead\nBeginning scenario: RunReflectionScenario_UnsafeRead\nBeginning scenario: RunClsVarScenario\nBeginning scenario: RunLclVarScenario_UnsafeRead\nBeginning scenario: RunClassLclFldScenario\nBeginning scenario: RunClassFldScenario\nBeginning scenario: RunStructLclFldScenario\nBeginning scenario: RunStructFldScenario\n\nEnding test case at 3/28/2019 10:56:01 PM\nBeginning test case ParallelBitExtract.UInt32 at 3/28/2019 10:56:01 PM\nRandom seed: 20010415; set environment variable CORECLR_SEED to this value to repro\n\nBeginning scenario: RunBasicScenario_UnsafeRead\nBeginning scenario: RunReflectionScenario_UnsafeRead\nBeginning scenario: RunClsVarScenario\nBeginning scenario: RunLclVarScenario_UnsafeRead\nBeginning scenario: RunClassLclFldScenario\nBeginning scenario: RunClassFldScenario\nBeginning scenario: RunStructLclFldScenario\nBeginning scenario: RunStructFldScenario\n\nEnding test case at 3/28/2019 10:56:01 PM\nBeginning test case ZeroHighBits.UInt32 at 3/28/2019 10:56:01 PM\nRandom seed: 20010415; set environment variable CORECLR_SEED to this value to repro\n\nBeginning scenario: RunBasicScenario_UnsafeRead\nBeginning scenario: RunReflectionScenario_UnsafeRead\nBeginning scenario: RunClsVarScenario\nBeginning scenario: RunLclVarScenario_UnsafeRead\nBeginning scenario: RunClassLclFldScenario\nBeginning scenario: RunClassFldScenario\nBeginning scenario: RunStructLclFldScenario\nBeginning scenario: RunStructFldScenario\n\nEnding test case at 3/28/2019 10:56:01 PM\nBeginning test case MultiplyNoFlags.UInt32 at 3/28/2019 10:56:01 PM\nRandom seed: 20010415; set environment variable CORECLR_SEED to this value to repro\n\nBeginning scenario: RunBasicScenario_UnsafeRead\nBeginning scenario: RunReflectionScenario_UnsafeRead\nBeginning scenario: RunClsVarScenario\nBeginning scenario: RunLclVarScenario_UnsafeRead\nBeginning scenario: RunClassLclFldScenario\nBeginning scenario: RunClassFldScenario\nBeginning scenario: RunStructLclFldScenario\nBeginning scenario: RunStructFldScenario\n\nEnding test case at 3/28/2019 10:56:01 PM\nBeginning test case MultiplyNoFlags.UInt32.BinRes at 3/28/2019 10:56:01 PM\nRandom seed: 20010415; set environment variable CORECLR_SEED to this value to repro\n\nExpected: 100\nActual: -1073741819\nEND EXECUTION - FAILED\nFAILED\nTest Harness Exitcode is : 1\n"], "labels": ["area-CodeGen"]}
{"project": "eclipse_che", "title": "Add ability to try a command", "description": "According to the specification #2681 , we need to let the user being able to test a command.  In the command editor's toolbar, we will add a small \"run\" button, which allow to execute the command. ", "code": [], "labels": ["kind/enhancement"]}
{"project": "dart-lang_sdk", "title": "Delete item in Files view shouldn't have a checkbox", "description": "With the addition of the \"Remove from Editor\" item, the Delete item now has a single purpose. While there should be a confirmation dialog, the user should not be required to also check a check box in order to delete the file. ", "code": [], "labels": ["closed-obsolete", "Priority-Medium"]}
{"project": "phan_phan", "title": "Add option to automatically narrow/set return type if none is provided?", "description": "#1163 (comment) Examples: This could be done in the parse phase, on only the files being analyzed. Non-quick mode does something similar, these may interfere. If any return types can't be inferred, don't modify the inferred return type. (E.g. @return $closure() ", "code": [], "labels": ["enhancement"]}
{"project": "timgrossmann_InstaPy", "title": "AttributeError: 'NoneType' object has no attribute 'lower', and dont_skip_business_categories", "description": "Able to follow, interact with users. Should use dont_skip_business_categories properly like it was doing in previous versions. Session ends, and I get an AttributeError. Also doesn't seem to be properly filtering/allowing certain business categories. This was workign on previous versions. I was only able to get this far after using this fix: #4908 Logs: <CODE> Script: <CODE> v.0.6.1 ", "code": ["Workspace in use: \"/Users/shoma/InstaPy\"\n\nOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO\nINFO [2019-08-20 10:20:06] [USERNAME]  Session started!\noooooooooooooooooooooooooooooooooooooooooooooooooooooo\nINFO [2019-08-20 10:20:06] [USERNAME]  -- Connection Checklist [1/3] (Internet Connection Status)\nINFO [2019-08-20 10:20:06] [USERNAME]  - Internet Connection Status: ok\nINFO [2019-08-20 10:20:06] [USERNAME]  - Current IP is \"38.142.253.74\" and it's from \"United States/US\"\nINFO [2019-08-20 10:20:06] [USERNAME]  -- Connection Checklist [2/3] (Instagram Server Status)\nINFO [2019-08-20 10:20:10] [USERNAME]  - Instagram WebSite Status: Currently Up\nINFO [2019-08-20 10:20:10] [USERNAME]  - Instagram Response Time: 37.585 ms\nINFO [2019-08-20 10:20:10] [USERNAME]  - Instagram Reponse Code: 200\nINFO [2019-08-20 10:20:10] [USERNAME]  - Instagram Server Status: ok\nINFO [2019-08-20 10:20:10] [USERNAME]  -- Connection Checklist [3/3] (Hide Selenium Extension)\nINFO [2019-08-20 10:20:10] [USERNAME]  - window.navigator.webdriver response: False\nINFO [2019-08-20 10:20:10] [USERNAME]  - Hide Selenium Extension: ok\n\n................................................................\nINFO [2019-08-20 10:20:20] [USERNAME]  Logged in successfully!\n''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\nINFO [2019-08-20 10:20:20] [USERNAME]  Saving account progress...\n\n______________________________________________________________________________\nINFO [2019-08-20 10:20:24] [USERNAME]  Starting to follow user `Followers`..\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nINFO [2019-08-20 10:20:24] [USERNAME]  User 'uniquelyetsy' [1/6]\n['the_modern_crafter', 'angieandauggie', 'kerajinan_tangan01', 'jfancicrafts', 'orangedotsbyselin', 'carolinefilou', 'trender.master', 'lucywortonillustration', 'southernbellajewelry', 'yog_artica', 'begi\nnnig_mohomshop', 'karivintageornaments', 'strandkleden', 'forager__thelabel', 'mehrdad.s5211', 'lunarchest', 'handmadebyheidijade', 'alycollabs', 'oiledstone', 'markscreative_room', 'moonstone_creative_de\nsigns', 'popup_soap', 'ganeshcraftsstore', 'gemstones_valley', 'poshkrystalstore', 'bowsitos.ve', 'farmveucrafts', 'hitomi.embroidery', 'kristensensmith', 'istanbulturkeyjewellery', 'agatestoneworkshop',\n'veritycarder', 'jbeachnau1', 'sensualingerie.ua', 'jeff_and_stephs', '204events', 'littlebigcookies', 'customdesignportofolio', 'sublimation6', 'goodna_accessoires', 'indonesian_stone_craftsmen', '_kits$\nhycoolstuff', 'gumbosgrotto', 'mundopaula_ccp', 'tasneem.342', 'foreverandadaydream_', 'willowlakevintage', 'labascashop', 'lazzoperu', 'dj_gavs', 'soulfoljewelry', 'fairygardenglow', 'heritageonly', 'the\nwritesidestudio', 'fabcraft.india', '6546mostafa', 'luxuryblingboutique', 'inspiredjewls', 'rooberryoxford', 'soapandparty', 'theballerinaboutique', 'usalasmanos', 'buffalowraps', 'sanistonlietuva', 'ther\nahallfarmandphoto', 'gandg_creations', 'royalminky', 'twynklaccessories', 'sweetstreetdeals', 'oh.so.pawsh.jewlz.and.gemz', 'roseandivycandles', 'allthelittlefinds_shop', 'meyaamber', 'myyellowhat', 'wood\nworking__.squadron', 'alexamelidesign']\n\nINFO [2019-08-20 10:20:43] [USERNAME]  Grabbed 76 usernames from 'uniquelyetsy's `Followers` to do following\n\nINFO [2019-08-20 10:20:55] [USERNAME]  Ongoing Follow [4/76]: now following 'jfancicrafts'...\nINFO [2019-08-20 10:20:57] [USERNAME]  User: 'jfancicrafts'  |> followers: 98  |> following: 434  |> relationship ratio: 4.42\nINFO [2019-08-20 10:20:57] [USERNAME]  'jfancicrafts' has a business account\n\nINFO [2019-08-20 10:20:57] [USERNAME]  Ongoing Follow [5/76]: now following 'orangedotsbyselin'...\nINFO [2019-08-20 10:21:02] [USERNAME]  User: 'orangedotsbyselin'  |> followers: 95  |> following: 128  |> relationship ratio: 1.34\nINFO [2019-08-20 10:21:02] [USERNAME]  'orangedotsbyselin' has a business account\n\nINFO [2019-08-20 10:21:02] [USERNAME]  Ongoing Follow [6/76]: now following 'carolinefilou'...\nINFO [2019-08-20 10:21:04] [USERNAME]  User: 'carolinefilou'  |> followers: 177  |> following: 1403  |> relationship ratio: 7.92\n\nINFO [2019-08-20 10:21:05] [USERNAME]  Sessional Live Report:\n        |> No any statistics to show\n\nOn session start was FOLLOWING 2228 users & had 1582 FOLLOWERS\n[Session lasted 1.09 minutes]\n\nOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO\nINFO [2019-08-20 10:21:05] [USERNAME]  Session ended!\nooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n\n\n\nTraceback (most recent call last):\n  File \"autoRunner.py\", line 166, in <module>\n    interact=True)\n  File \"/Users/shoma/code/ig-bot/.venv/lib/python3.7/site-packages/instapy/instapy.py\", line 3477, in follow_user_followers\n    validation, details = self.validate_user_call(person)\n  File \"/Users/shoma/code/ig-bot/.venv/lib/python3.7/site-packages/instapy/instapy.py\", line 1313, in validate_user_call\n    self.logfolder,\n  File \"/Users/shoma/code/ig-bot/.venv/lib/python3.7/site-packages/instapy/util.py\", line 417, in validate_username\n    if bio_keyword.lower() in profile_bio.lower():\nAttributeError: 'NoneType' object has no attribute 'lower'\npipenv run python autoRunner.py  25.83s user 8.01s system 49% cpu 1:08.76 total\n", "\"\"\"\nThis template is written by @Nuzzo235\n\nWhat does this quickstart script aim to do?\n- This script is targeting followers of similar accounts and influencers.\n- This is my starting point for a conservative approach: Interact with the\naudience of influencers in your niche with the help of 'Target-Lists' and\n'randomization'.\n\nNOTES:\n- For the ease of use most of the relevant data is retrieved in the upper part.\n\"\"\"\n\nimport random\nfrom instapy import InstaPy\nfrom instapy import smart_run\n\n# login credentials\ninsta_username = 'USERNAME'\ninsta_password = 'PASSWORD'\n\n# restriction data\ndont_likes = ['sad', 'rain', 'depression']\nignore_users = []\n\n\"\"\" Prevent commenting on and unfollowing your good friends (the images will\nstill be liked)...\n\"\"\"\nfriends = []\n\n\"\"\" Prevent posts that contain...\n\"\"\"\nignore_list = []\n\n# TARGET data\n\"\"\" Set similar accounts and influencers from your niche to target...\n\"\"\"\ntargets = [\n   TARGETS HERE\n]\n\n\"\"\" Skip all business accounts, except from list given...\n\"\"\"\ntarget_business_categories = [\n    'Personal Goods & General Merchandise Stores',\n    'Home Services',\n    'Home Goods Stores',\n    'General Interest',\n    'Food & Personal Goods',\n    'Business & Utility Services',\n    'Creators & Celebrities',\n    None,\n]\n\n# COMMENT data\ncomments = [\n    u'What an amazing shot! :heart_eyes: What do '\n    u'you think of my recent shot?',\n    u'What an amazing shot! :heart_eyes: I think '\n    u'you might also like mine. :wink:',\n    u'Wonderful!! :heart_eyes: Would be awesome if '\n    u'you would checkout my photos as well!',\n    u'Wonderful!! :heart_eyes: I would be honored '\n    u'if you would checkout my images and tell me '\n    u'what you think. :wink:',\n    u'This is awesome!! :heart_eyes: Any feedback '\n    u'for my photos? :wink:',\n    u'This is awesome!! :heart_eyes:  maybe you '\n    u'like my photos, too? :wink:',\n    u'I really like the way you captured this. I '\n    u'bet you like my photos, too :wink:',\n    u'I really like the way you captured this. If '\n    u'you have time, check out my photos, too. I '\n    u'bet you will like them. :wink:',\n    u'Great capture!! :smiley: Any feedback for my '\n    u'recent shot? :wink:',\n    u'Great capture!! :smiley: :thumbsup: What do '\n    u'you think of my recent photo?'\n]\n\n# get a session!\nsession = InstaPy(username=insta_username,\n                  password=insta_password,\n                  headless_browser=False,\n                  multi_logs=False)\n\n# let's go! :>\nwith smart_run(session):\n    # HEY HO LETS GO\n    # general settings\n    session.set_dont_include(friends)\n    session.set_dont_like(dont_likes)\n    session.set_ignore_if_contains(ignore_list)\n    session.set_ignore_users(ignore_users)\n    session.set_simulation(enabled=True)\n    session.set_relationship_bounds(enabled=True,\n                                    potency_ratio=-1.0,\n                                    delimit_by_numbers=True,\n                                    max_followers=100000,\n                                    max_following=100000,\n                                    min_followers=50,\n                                    min_following=50,\n                                    min_posts=10)\n\n    session.set_skip_users(skip_private=True,\n                           skip_no_profile_pic=True,\n                           skip_business=True,\n                           dont_skip_business_categories=target_business_categories)\n\n    session.set_user_interact(amount=3, randomize=True, percentage=60,\n                              media='Photo')\n    session.set_do_like(enabled=True, percentage=60)\n    session.set_do_comment(enabled=True, percentage=33)\n    session.set_comments(comments, media='Photo')\n    session.set_do_follow(enabled=True, percentage=75, times=2)\n    session.set_delimit_liking(enabled=True, max_likes=80, min_likes=0)\n    session.set_delimit_commenting(enabled=True, max_comments=20, min_comments=0)\n    session.set_quota_supervisor(enabled=True,\n                                 sleep_after=[\"likes\", \"comments\", \"follows\", \"unfollows\", \"server_calls\"],\n                                 sleepyhead=True, stochastic_flow=True,\n                                 notify_me=True,\n                                 peak_likes_hourly=50,\n                                 peak_likes_daily=300,\n                                 peak_unfollows_hourly=35,\n                                 peak_unfollows_daily=402,\n                                 peak_comments_hourly=10,\n                                 peak_comments_daily=100,\n                                 peak_follows_hourly=20,\n                                 peak_follows_daily=150)\n\n    # activities\n\n    # FOLLOW+INTERACTION on TARGETED accounts\n    \"\"\" Select users form a list of a predefined targets...\n    \"\"\"\n    number = random.randint(5, 7)\n    random_targets = targets\n\n    if len(targets) <= number:\n        random_targets = targets\n\n    else:\n        random_targets = random.sample(targets, number)\n\n    \"\"\" Interact with the chosen targets...\n    \"\"\"\n    session.follow_user_followers(random_targets,\n                                  amount=random.randint(60, 90),\n                                  randomize=True, sleep_delay=300,\n                                  interact=True)\n\n    # UNFOLLOW activity\n    \"\"\" Unfollow nonfollowers after one day...\n    \"\"\"\n    session.unfollow_users(amount=random.randint(75, 100),\n                           InstapyFollowed=(True, \"nonfollowers\"),\n                           style=\"FIFO\",\n                           unfollow_after=24 * 60 * 60, sleep_delay=600)\n\n    \"\"\" Unfollow all users followed by InstaPy after one week to keep the\n    following-level clean...\n    \"\"\"\n    session.unfollow_users(amount=random.randint(75, 100),\n                           InstapyFollowed=(True, \"all\"), style=\"FIFO\",\n                           unfollow_after=168 * 60 * 60, sleep_delay=600)\n\n    \"\"\" Joining Engagement Pods...\n    \"\"\"\n    session.join_pods()\n"], "labels": ["wontfix"]}
{"project": "endless-sky_endless-sky", "title": "Translations", "description": "It would be interesting to have different languages, maybe for players that don't speak English.\nI would be glad to translate the missions and dialogues, but I don't know the game engine code enough to support language selection or translating text replacements (like ) ", "code": [], "labels": ["enhancement"]}